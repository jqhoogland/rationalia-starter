---
tags: ['LessWrong', 'Portal', 'Concept']
src: https://www.lesswrong.com/tag/priors
---

In the context of [Bayes's Theorem](https://wiki.lesswrong.com/wiki/Bayes's_Theorem), priors refer generically to the beliefs an agent holds regarding a fact, hypothesis or consequence, before being presented with evidence. Upon being presented with new evidence, the agent can multiply their prior with a [likelihood distribution](https://wiki.lesswrong.com/wiki/likelihood_distribution) to calculate a new (posterior) probability for their belief.

## Examples
Suppose you had a barrel containing some number of red and white balls. You start with the belief that each ball was independently assigned red color (vs. white color) at some fixed probability. Furthermore, you start out ignorant of this fixed probability (the parameter could be anywhere between 0 and 1). Each red ball you see then makes it *more* likely that the next ball will be red, following a [Laplacian Rule of Succession](http://en.wikipedia.org/wiki/Rule_of_succession). For example, seeing 6 red balls out of 10 suggests that the initial probability used for assigning the balls a red color was .6, and that there's also a probability of .6 for the next ball being red.

On the other hand, if you start out with the prior belief that the barrel contains exactly 10 red balls and 10 white balls, then each red ball you see makes it *less* likely that the next ball will be red (because there are fewer red balls remaining)....[(Read More)]()



---

