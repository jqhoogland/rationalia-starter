---
tags: ['LessWrong', 'Portal', 'Concept']
src: https://www.lesswrong.com/tag/preference
---

Preference is usually conceptualized as a set of attitudes or evaluations made by an agent towards a specific object, and it has been proposed that AI has a robust set of methods to deal with them. These can be divided in several steps:

This sequential chain of thought can be particularly useful when dealing with [[Coherent Extrapolated Volition]], as a way of systematically exploring agentâ€™s goals and motivations.

## Further Reading & References
- [Would Your Real Preferences Please Stand Up?](http://lesswrong.com/lw/15c/would_your_real_preferences_please_stand_up)
-  by 
- [Yvain](https://wiki.lesswrong.com/wiki/Yvain)
- [Notion of Preference in Ambient Control](http://lesswrong.com/lw/2tq/notion_of_preference_in_ambient_control/)
-  by 
- [Vladimir Nesov](https://wiki.lesswrong.com/wiki/Vladimir_Nesov)
- [To What Degree Do We Have Goals?](http://lesswrong.com/lw/6oo/to_what_degree_do_we_have_goals/)
-  by Yvain
- [A brief tutorial on preferences in AI](http://lesswrong.com/lw/a73/a_brief_tutorial_on_preferences_in_ai/)
-  by 
- Luke Muehlhauser

## See also
- [Complexity of Value|Complexity of value](https://www.lesswrong.com/tag/complexity-of-value)
- [Utility Functions|Utility function](https://www.lesswrong.com/tag/utility-functions)
- [Decision Theory|Decision theory](https://www.lesswrong.com/tag/decision-theory)
- [Optimization|Optimization process](https://www.lesswrong.com/tag/optimization)
- [[Akrasia]]
- [Corrupted Hardware|Corrupted hardware](https://www.lesswrong.com/tag/corrupted-hardware)



---

