---
tags: ['LessWrong', 'Portal', 'Concept']
src: https://www.lesswrong.com/tag/functional-decision-theory
---

Functional Decision Theory is a [decision theory](https://www.lesswrong.com/tag/decision-theory) described by Eliezer Yudkowsky and Nate Soares which says that agents should treat one’s decision as the output of a ﬁxed mathematical function that answers the question, “Which output of this very function would yield the best outcome?”. It is a replacement of [Timeless Decision Theory](https://www.lesswrong.com/tag/timeless-decision-theory), and it outperforms other decision theories such as [Causal Decision Theory](https://www.lesswrong.com/tag/causal-decision-theory) (CDT) and [Evidential Decision Theory](https://www.lesswrong.com/tag/evidential-decision-theory) (EDT). For example, it does better than CDT on [Newcomb's Problem](https://www.lesswrong.com/tag/newcomb-s-problem), better than EDT on the [smoking lesion problem](https://www.lesswrong.com/tag/smoking-lesion), and better than both in [Parﬁt’s hitchhiker problem](https://www.lesswrong.com/tag/parfits-hitchhiker).

In Newcomb's Problem, an FDT agent reasons that Omega must have used some kind of model of her decision procedure in order to make an accurate prediction of her behavior. Omega's model and the agent are therefore both calculating the same function (the agent's decision procedure): they are *subjunctively dependent *on that function. Given perfect prediction by Omega, there are therefore only two outcomes in Newcomb's Problem: either the agent one-boxes and Omega predicted it (because its model also one-boxed), or the agent two-boxes and Omega predicted *that*. Because one-boxing then results in a million and two-boxing only in a thousand dollars, the FDT agent one-boxes.

External links:...[(Read More)]()



---

