---
tags: ['LessWrong', 'Concept']
src: https://www.lesswrong.com/tag/treacherous-turn
---

# Treacherous Turn
A Treacherous Turn is a hypothetical event where an advanced [AI](ai) system which has been pretending to be aligned due to its relative weakness turns on humanity once it achieves sufficient power that it can pursue its true objective without risk.

*See also:*

