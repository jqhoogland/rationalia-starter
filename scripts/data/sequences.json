[
  {
    "_id": "9ctJpFJvf8h5ivT6Q",
    "title": "Bah-Humbug Sequence",
    "curatedOrder": null,
    "contents": {
      "markdown": "A.k.a. \"Everything I Don't Like Is A Defect/Defect Equilibrium\". Epistemic status: strong opinion weakly held, somewhat exaggerated for dramatic effect; I'm posting this here so that the ensuing discussion might help me clarify my position. Anyway, the time has now come for me to explain my overbearing attitude of cynicism towards all aspects of life. Why now, of all times? I hope to make that clear by the end."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Adversarial epistemology",
            "tags": [
              {
                "name": "Trust"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Epistemic Hygiene"
              },
              {
                "name": "Rationality"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "4WiyAJ2Y7Fuyz8RtM",
    "title": "Thoughts in Philosophy of Science of AI alignment",
    "curatedOrder": null,
    "contents": {
      "markdown": "In this series of posts, I introduce ideas in the “*philosophy of science of AI alignment*\". \n\nPhilosophy of science is concerned with the epistemic foundations, methods, and implications of science in general or the science of a specific domain. Accordingly, leading questions of this series include: what is the epistemic nature of the alignment problem? What epistemic strategies appear promising, and conditional a on which epistemic assumptions? Other posts aim to introduce or clarify language for talking more clearly about the problem, about the existing research landscape, or about what progress might look like. Some posts more specifically explore and develop epistemic assumptions underlying the research direction pursued by [PIBBSS](https://www.pibbss.ai/). \n\nThis sequence is a collection of related ideas rather than a series of posts with a signle red thread/coherent arch; it is a \"living\" project in that I expect to be adding new posts over an undefined amount of time."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Epistemic Artefacts of (conceptual) AI alignment research",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "Distillation & Pedagogy"
              },
              {
                "name": "Intellectual Progress (Society-Level)"
              }
            ]
          },
          {
            "title": "AI alignment as “navigating the space of intelligent behaviour”",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "PIBBSS"
              },
              {
                "name": "AI Alignment Fieldbuilding"
              },
              {
                "name": "Distillation & Pedagogy"
              },
              {
                "name": "Practice & Philosophy of Science"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "BvbzaXhDasgRYqPdp",
    "title": "Goal-directedness via explanations",
    "curatedOrder": null,
    "contents": {
      "markdown": "This sequence records an ongoing attempt to formalize the concept of \"goal-directedness\", as an eventual foundation for analysing philosophical arguments for the risks from AI which are based on this concept.\n\n*Above, a selection of images generated on craiyon.com in response to the prompts \"AI Goal-directed\" and \"Goal-directed AI\". It was mildly interesting to observe that the former produced images with darker, blue-green backgrounds, while the latter produced white backgrounds.*"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Goal-directedness: my baseline beliefs",
            "tags": [
              {
                "name": "Goal-Directedness"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Goal-directedness: exploring explanations",
            "tags": [
              {
                "name": "Goal-Directedness"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Goal-directedness: imperfect reasoning, limited knowledge and inaccurate beliefs",
            "tags": [
              {
                "name": "Goal-Directedness"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Goal-directedness: tackling complexity",
            "tags": [
              {
                "name": "Goal-Directedness"
              },
              {
                "name": "AI"
              },
              {
                "name": "Kolmogorov Complexity"
              }
            ]
          },
          {
            "title": "Goal-directedness: relativising complexity",
            "tags": [
              {
                "name": "Goal-Directedness"
              },
              {
                "name": "Kolmogorov Complexity"
              },
              {
                "name": "World Modeling"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "TLSzP4xP42PPBctgw",
    "title": "\"Why Not Just...\"",
    "curatedOrder": null,
    "contents": {
      "markdown": "A compendium of rants about alignment proposals, of varying charitability."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Deep Learning Systems Are Not Less Interpretable Than Logic/Probability/Etc",
            "tags": [
              {
                "name": "Transparency / Interpretability (ML & AI)"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Godzilla Strategies",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Using AI to solve Alignment"
              }
            ]
          },
          {
            "title": "Rant on Problem Factorization for Alignment",
            "tags": [
              {
                "name": "Factored Cognition"
              },
              {
                "name": "AI"
              },
              {
                "name": "Humans Consulting HCH"
              },
              {
                "name": "Debate (AI safety technique)"
              },
              {
                "name": "Ought"
              }
            ]
          },
          {
            "title": "Interpretability/Tool-ness/Alignment/Corrigibility are not Composable",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Transparency / Interpretability (ML & AI)"
              },
              {
                "name": "Corrigibility"
              },
              {
                "name": "Tool AI"
              }
            ]
          },
          {
            "title": "How To Go From Interpretability To Alignment: Just Retarget The Search",
            "tags": [
              {
                "name": "Transparency / Interpretability (ML & AI)"
              },
              {
                "name": "Inner Alignment"
              },
              {
                "name": "AI"
              },
              {
                "name": "AI Risk"
              }
            ]
          },
          {
            "title": "Oversight Misses 100% of Thoughts The AI Does Not Think",
            "tags": [
              {
                "name": "AI Risk"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Human Mimicry Mainly Works When We’re Already Close",
            "tags": [
              {
                "name": "Whole Brain Emulation"
              },
              {
                "name": "Outer Alignment"
              },
              {
                "name": "AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "eqtiQjbk83JHyttrr",
    "title": "Meetup in a box",
    "curatedOrder": null,
    "contents": {
      "markdown": "The in-person community runs on meetups. The people who run meetups – often called organizers – often run on more Hero Power than I would prefer. The Meetup-In-A-Box sequence is intended to provide meetup activities that do not require creativity on the scale of inventing your own holiday or designing your own rationality training programs from scratch, yet give you and your group something to do in addition to general socialization. A Meetup-In-A-Box is intended to be a bit like a board game: Open the box, follow the instructions, and have a good time. You still need to gather enough people and find a place for it, but those are problems common to almost any sort of group activity. \n\nThis sequence owes a lot to Maia's [Meetup Cookbook](https://tigrennatenn.neocities.org/meetup_cookbook.html), and is being written here because I can't edit the cookbook. I'd love to add meetups other people come up with as well as my own!\n\nMeetups contained in this sequence are categorized with the following tags: \n\n*   **Small:** Small meetups work for groups from 1-4 people.\n*   **Medium:** Medium meetups work for groups from 5-15.\n*   **Large:** Large meetups work for groups from 15 and up.\n*   **Experiment:** Experimental meetups are meetups we don't have much feedback on yet. If you run one, we would especially love to hear how it went!\n*   **Repeatable:** Repeatable meetups can be run again and again for the same group. Many of them are designed specifically to be run every meeting!\n*   **One-off:** One-off meetups will generally only work as intended once in a while. Once you've run a once-off meetup, we recommend putting it back on the shelf and running other things.\n*   **Investment:** Investment meetups generally require high buy-in or unusual amounts of trust or commitment. They can be a good pick for an established group of regulars, but we recommend against using them when you have lots of newcomers.\n\n**A note on size**: Small, Medium, and Large are about the size of the group. It's sometimes possible to adjust how you run a meetup to make it work with more or fewer participants. Split a group of fifteen into three groups of five and have each group run their own version of a Small meetup.\n\nFinally, if you want to run a meetup and can't decide or don't know what you should run, we hereby declare you should run Calibration Trivia. It's fun, easy to explain, works for any size gathering, and can be done with no materials other than the device you're reading this on and some writing materials."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Running a Basic Meetup",
            "tags": [
              {
                "name": "Community"
              },
              {
                "name": "Meetups & Local Communities (topic)"
              }
            ]
          },
          {
            "title": "Calibration Trivia",
            "tags": [
              {
                "name": "Calibration"
              },
              {
                "name": "Exercises / Problem-Sets"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Meetups (specific examples)"
              }
            ]
          },
          {
            "title": "Cambist Booking",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Meetups (specific examples)"
              }
            ]
          },
          {
            "title": "The Falling Drill",
            "tags": [
              {
                "name": "Exercises / Problem-Sets"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Meetups (specific examples)"
              }
            ]
          },
          {
            "title": "Dissent Collusion",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Meetups (specific examples)"
              },
              {
                "name": "Games (posts describing)"
              }
            ]
          },
          {
            "title": "Troll Timers",
            "tags": [
              {
                "name": "Meetups (specific examples)"
              }
            ]
          },
          {
            "title": "Oops It's Time To Overthrow the Organizer Day!",
            "tags": [
              {
                "name": "Meetups (specific examples)"
              },
              {
                "name": "Community"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "ZytYxd523oTnBNnRT",
    "title": "Law-Following AI",
    "curatedOrder": null,
    "contents": {
      "markdown": "This Sequence of posts will argue that working to ensure that AI systems follow laws is a worthwhile way to improve the long-term future of AI. Additional relevant posts are also linked at the end of the Sequence.\n\nThe posts in this Sequence are by me in my personal capacity, and are not representative of OpenAI or any other organization.\n\nCover art by OpenAI's DALL•E."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Law-Following AI 1: Sequence Introduction and Structure",
            "tags": [
              {
                "name": "Law and Legal systems"
              },
              {
                "name": "AI Governance"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Law-Following AI 2: Intent Alignment + Superintelligence → Lawless AI (By Default)",
            "tags": [
              {
                "name": "AI Governance"
              },
              {
                "name": "Law and Legal systems"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Law-Following AI 3: Lawless AI Agents Undermine Stabilizing Agreements",
            "tags": [
              {
                "name": "AI Governance"
              },
              {
                "name": "Law and Legal systems"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Law-Following AI 4: Don't Rely on Vicarious Liability",
            "tags": [
              {
                "name": "Law and Legal systems"
              },
              {
                "name": "AI Governance"
              },
              {
                "name": "AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "hCt6GL4SXX6ezkcJn",
    "title": "Unifying Bargaining",
    "curatedOrder": null,
    "contents": {
      "markdown": "A small sequence introducing the CoCo values, Shapley values, and Nash bargaining solution, proving that they're all equivalent, and looking for possible improvements."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Unifying Bargaining Notions (1/2)",
            "tags": [
              {
                "name": "Game Theory"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Fairness"
              }
            ]
          },
          {
            "title": "Unifying Bargaining Notions (2/2)",
            "tags": [
              {
                "name": "Game Theory"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Decision Theory"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "pJHp3uBgM2EFCoYn3",
    "title": "My AI Risk Model",
    "curatedOrder": null,
    "contents": {
      "markdown": "This sequence is an attempt to think concretely about where the danger from misaligned AI comes from. Why might AI systems develop objectives? Why might these objectives not be compatible with our human values? When does this misalignment seem particularly dangerous?\n\nThis work was done as part of the first iteration of the SERI MATS program."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Why I'm Worried About AI",
            "tags": [
              {
                "name": "AI Risk"
              },
              {
                "name": "AI"
              },
              {
                "name": "Inner Alignment"
              },
              {
                "name": "Deception"
              },
              {
                "name": "Threat Models"
              }
            ]
          },
          {
            "title": "A Story of AI Risk: InstructGPT-N",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Mesa-Optimization"
              },
              {
                "name": "Inner Alignment"
              },
              {
                "name": "Threat Models"
              },
              {
                "name": "AI Risk"
              }
            ]
          },
          {
            "title": "Confusions in My Model of AI Risk",
            "tags": [
              {
                "name": "AI Risk"
              },
              {
                "name": "AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "wdcJiw2bSqtFqvK6n",
    "title": " Become A TypeTwo Civilisation",
    "curatedOrder": null,
    "contents": {
      "markdown": "Type II on the [The Kardashev Scale](https://en.wikipedia.org/wiki/Kardashev_scale), a civilization advanced enough to harness the energy of its star - The Sun. This is just a beginning- Interplanetary civilization, Dyson Spheres & Asteroid mining."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": []
      }
    ]
  },
  {
    "_id": "kjcioCkqSSS4LiMAe",
    "title": "Inconsistent Values and Extrapolation ",
    "curatedOrder": null,
    "contents": {
      "markdown": "We might care about making inconsistent preferences and values consistent. What exactly would that mean? How can me model inconsistent values?\n\nPossibly has implications for value learning and ontological shifts."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Formalizing Value Extrapolation",
            "tags": []
          },
          {
            "title": "Value extrapolation, concept extrapolation, model splintering",
            "tags": [
              {
                "name": "Value Learning"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Model splintering: moving from one imperfect model to another",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Machine Learning  (ML)"
              },
              {
                "name": "Iterated Amplification "
              }
            ]
          },
          {
            "title": "Ontological Crises in Artificial Agents' Value Systems by Peter de Blanc",
            "tags": [
              {
                "name": "Ontological Crisis"
              }
            ]
          },
          {
            "title": "Ontological Crisis in Humans",
            "tags": [
              {
                "name": "Motivations"
              },
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "Moral Uncertainty"
              },
              {
                "name": "Ontological Crisis"
              }
            ]
          },
          {
            "title": "Two More Decision Theory Problems for Humans",
            "tags": [
              {
                "name": "Decision Theory"
              }
            ]
          },
          {
            "title": "Using vector fields to visualise preferences and make them consistent",
            "tags": [
              {
                "name": "Value Learning"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Turning Some Inconsistent Preferences into Consistent Ones",
            "tags": [
              {
                "name": "Rationality"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "YiA2ukmfsLFzWTiiK",
    "title": "Random Attempts at Apllied Rationality",
    "curatedOrder": null,
    "contents": {
      "markdown": ""
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Definition Practice: Applied Rationality",
            "tags": [
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "What are the simplest questions in applied rationality where you don't know the answer to? ",
            "tags": [
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Are there practical exercises for developing the Scout mindset?",
            "tags": [
              {
                "name": "Exercises / Problem-Sets"
              },
              {
                "name": "Rationality"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "nyEFg3AuJpdAozmoX",
    "title": "The Shard Theory of Human Values",
    "curatedOrder": null,
    "contents": {
      "markdown": "*Written by Quintin Pope, Alex Turner, Charles Foster, and Logan Smith. Card image generated by DALL-E 2:*\n\n![](https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/a6a9e89a88f93ea26fc1150c0634979f913c5528c1d78d06.png)"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Humans provide an untapped wealth of evidence about alignment",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Human Values"
              },
              {
                "name": "Ontology"
              },
              {
                "name": "Shard Theory of Human Values"
              }
            ]
          },
          {
            "title": "Human values & biases are inaccessible to the genome",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Human Values"
              },
              {
                "name": "Evolution"
              }
            ]
          },
          {
            "title": "Against Relying on Evolution to Forecast AI Outcomes (Part 1)",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Shard Theory of Human Values"
              }
            ]
          },
          {
            "title": "Reward is not the optimization target",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Reinforcement Learning"
              },
              {
                "name": "Reward Functions"
              },
              {
                "name": "Wireheading"
              },
              {
                "name": "Inner Alignment"
              },
              {
                "name": "Outer Alignment"
              },
              {
                "name": "Shard Theory of Human Values"
              }
            ]
          },
          {
            "title": "General alignment properties",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Embedded Agency"
              },
              {
                "name": "Ontology"
              },
              {
                "name": "Complexity of Value"
              },
              {
                "name": "General Alignment Properties"
              },
              {
                "name": "Shard Theory of Human Values"
              }
            ]
          },
          {
            "title": "Shard Theory: An Overview",
            "tags": [
              {
                "name": "Psychology"
              },
              {
                "name": "AI"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Human Values"
              },
              {
                "name": "Utility Functions"
              },
              {
                "name": "Complexity of Value"
              },
              {
                "name": "Reinforcement Learning"
              },
              {
                "name": "Subagents"
              },
              {
                "name": "Outer Alignment"
              },
              {
                "name": "SERI MATS"
              },
              {
                "name": "Shard Theory of Human Values"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "jiqxd9ZmSSocs5Qcz",
    "title": "AGI-assisted Alignment",
    "curatedOrder": null,
    "contents": {
      "markdown": "Can we start out with an unaligned superintelligent AGI, and end up with an aligned AGI-system? I argue *maybe*, and discuss principles, techniques and strategies that may enable us to do so.  \n  \nOne reason for exploring such strategies is contingency planning (what if we haven’t solved alignment by the time the first superintelligent AGI arrives?). Another reason is that additional layers of security could be beneficial (even if we *think* we have solved alignment, are there ways to relatively quickly add additional layers of alignment-assurance?).\n\nThis is an ongoing series."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Getting from an unaligned AGI to an aligned AGI? ",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Outer Alignment"
              },
              {
                "name": "AI Boxing (Containment)"
              },
              {
                "name": "AI Success Models"
              }
            ]
          },
          {
            "title": "Making it harder for an AGI to \"trick\" us, with STVs",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Outer Alignment"
              },
              {
                "name": "Verification"
              },
              {
                "name": "AI Success Models"
              },
              {
                "name": "AI Boxing (Containment)"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "ix7grGajtrJJYXsY3",
    "title": "Bonus: Best Essays of LessWrong",
    "curatedOrder": null,
    "contents": {
      "markdown": "If you've enjoyed the [Sequence Highlights](https://www.lesswrong.com/highlights), you might also like these posts. They're all-time favorites from the LessWrong archives."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "Babble",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Poetry"
              },
              {
                "name": "Babble and Prune"
              }
            ]
          },
          {
            "title": "Being the (Pareto) Best in the World",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Efficient Market Hypothesis"
              },
              {
                "name": "Careers"
              }
            ]
          },
          {
            "title": "\"Other people are wrong\" vs \"I am right\"",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Updated Beliefs (examples of)"
              },
              {
                "name": "Chesterton's Fence"
              },
              {
                "name": "Distinctions"
              }
            ]
          },
          {
            "title": "Yes Requires the Possibility of No\n",
            "tags": [
              {
                "name": "Conservation of Expected Evidence"
              },
              {
                "name": "Filtered Evidence"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Internal Double Crux"
              },
              {
                "name": "Principles"
              }
            ]
          },
          {
            "title": "Schelling fences on slippery slopes",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Game Theory"
              },
              {
                "name": "Value Drift"
              }
            ]
          },
          {
            "title": "The Best Textbooks on Every Subject",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Scholarship & Learning"
              },
              {
                "name": "Practical"
              },
              {
                "name": "List of Links"
              },
              {
                "name": "Book Reviews"
              },
              {
                "name": "Whole Brain Emulation"
              },
              {
                "name": "Comfort Zone Expansion (CoZE)"
              }
            ]
          },
          {
            "title": "The Costly Coordination Mechanism of Common Knowledge",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Common Knowledge"
              },
              {
                "name": "Game Theory"
              },
              {
                "name": "Mechanism Design"
              },
              {
                "name": "Coordination / Cooperation"
              }
            ]
          },
          {
            "title": "Slack",
            "tags": [
              {
                "name": "Slack"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Lies, Damn Lies, and Fabricated Options",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Heuristics & Biases"
              }
            ]
          },
          {
            "title": "When Money Is Abundant, Knowledge Is The Real Wealth",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Expertise (topic)"
              },
              {
                "name": "Economics"
              }
            ]
          },
          {
            "title": "What Money Cannot Buy",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Expertise (topic)"
              }
            ]
          },
          {
            "title": "Bets, Bonds, and Kindergarteners",
            "tags": [
              {
                "name": "Parenting"
              },
              {
                "name": "Betting"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "How to Ignore Your Emotions (while also thinking you're awesome at emotions)",
            "tags": [
              {
                "name": "Emotions"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Growth Stories"
              }
            ]
          },
          {
            "title": "Pain is not the unit of Effort",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Well-being"
              },
              {
                "name": "Happiness"
              },
              {
                "name": "Heroic Responsibility"
              },
              {
                "name": "Fallacies"
              },
              {
                "name": "Suffering"
              },
              {
                "name": "Willpower"
              }
            ]
          },
          {
            "title": "Fact Posts: How and Why",
            "tags": [
              {
                "name": "Fact posts"
              },
              {
                "name": "Practical"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Scholarship & Learning"
              }
            ]
          },
          {
            "title": "The correct response to uncertainty is *not* half-speed",
            "tags": [
              {
                "name": "Planning & Decision-Making"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Goal Factoring"
              }
            ]
          },
          {
            "title": "On learning difficult things",
            "tags": [
              {
                "name": "Scholarship & Learning"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Diseased thinking: dissolving questions about disease",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Health / Medicine / Disease"
              },
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Carving / Clustering Reality"
              },
              {
                "name": "Reversal Test"
              },
              {
                "name": "Motivational Intro Posts"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "aaTrp2g86Qo3hinXQ",
    "title": "Why We Fight",
    "curatedOrder": null,
    "contents": {
      "markdown": "*Part 6 of 6 from the* [*Sequence Highlights*](https://www.lesswrong.com/highlights)*.*\n\nThe pursuit of rationality and that of doing better on purpose, can in fact be rather *hard.* You have to get the motivation for that from somewhere."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "Something to Protect",
            "tags": [
              {
                "name": "World Optimization"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Motivations"
              },
              {
                "name": "Heroic Responsibility"
              },
              {
                "name": "Something To Protect"
              }
            ]
          },
          {
            "title": "The Gift We Give To Tomorrow",
            "tags": [
              {
                "name": "Evolutionary Psychology"
              },
              {
                "name": "Complexity of Value"
              },
              {
                "name": "Human Values"
              }
            ]
          },
          {
            "title": "On Caring",
            "tags": [
              {
                "name": "Motivations"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Motivational Intro Posts"
              }
            ]
          },
          {
            "title": "Tsuyoku Naritai! (I Want To Become Stronger)",
            "tags": [
              {
                "name": "Ambition"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Something To Protect"
              },
              {
                "name": "Tsuyoku Naritai"
              },
              {
                "name": "Motivational Intro Posts"
              }
            ]
          },
          {
            "title": "A Sense That More Is Possible",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Rationality Verification"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "paoDwasxFpSpzwA2f",
    "title": "Connecting Words to Reality",
    "curatedOrder": null,
    "contents": {
      "markdown": "*Part 5 of 6 from the* [*Sequence Highlights*](https://www.lesswrong.com/highlights)*.*\n\nTo understand reality, especially on confusing topics, it's important to understand the mental processes involved in forming concepts and using words to speak about them."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "Taboo Your Words",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Disagreement"
              },
              {
                "name": "Conversation (topic)"
              },
              {
                "name": "Techniques"
              },
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Rationalist Taboo"
              }
            ]
          },
          {
            "title": "Dissolving the Question",
            "tags": [
              {
                "name": "Introspection"
              },
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Philosophy"
              },
              {
                "name": "Dissolving the Question"
              }
            ]
          },
          {
            "title": "Diseased thinking: dissolving questions about disease",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Health / Medicine / Disease"
              },
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Carving / Clustering Reality"
              },
              {
                "name": "Reversal Test"
              },
              {
                "name": "Motivational Intro Posts"
              }
            ]
          },
          {
            "title": "Hug the Query",
            "tags": [
              {
                "name": "Anticipated Experiences"
              }
            ]
          },
          {
            "title": "Say Not \"Complexity\"",
            "tags": [
              {
                "name": "Anticipated Experiences"
              }
            ]
          },
          {
            "title": "Mind Projection Fallacy",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Fallacies"
              },
              {
                "name": "Mind Projection Fallacy"
              },
              {
                "name": "Map and Territory"
              }
            ]
          },
          {
            "title": "How An Algorithm Feels From Inside",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Cognitive Reduction"
              }
            ]
          },
          {
            "title": "Expecting Short Inferential Distances",
            "tags": [
              {
                "name": "Inferential Distance"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Evolutionary Psychology"
              },
              {
                "name": "Conversation (topic)"
              },
              {
                "name": "Public Discourse"
              },
              {
                "name": "Illusion of Transparency"
              }
            ]
          },
          {
            "title": "Illusion of Transparency:  Why No One Understands You",
            "tags": [
              {
                "name": "Conversation (topic)"
              },
              {
                "name": "Inferential Distance"
              },
              {
                "name": "Calibration"
              },
              {
                "name": "Illusion of Transparency"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "pwK9RsvCdpPgKmrf6",
    "title": "Science Isn't Enough",
    "curatedOrder": null,
    "contents": {
      "markdown": "*Part 4 of 6 from the* [*Sequence Highlights*](https://www.lesswrong.com/highlights)*.*  \n  \nWhile far better than what came before, \"science\" and the \"scientific method\" are still crude, inefficient, and inadequate to prevent you from wasting years of effort on doomed research directions."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "When Science Can't Help",
            "tags": [
              {
                "name": "Practice & Philosophy of Science"
              }
            ]
          },
          {
            "title": "Faster Than Science",
            "tags": [
              {
                "name": "Practice & Philosophy of Science"
              }
            ]
          },
          {
            "title": "Science Doesn't Trust Your Rationality",
            "tags": [
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "No Safe Defense, Not Even Science",
            "tags": [
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Courage"
              },
              {
                "name": "Trust"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "NBDFAKt3GbFwnwzQF",
    "title": "Thinking Better on Purpose",
    "curatedOrder": 502,
    "contents": {
      "markdown": "*Part 1 of 6 from the* [*Sequence Highlights*](https://www.lesswrong.com/highlights)*. *\n\nHumans can not only think, but think about our own thinking. This makes it possible for us to recognize the shortcomings of our default reasoning and work to improve it – the project of human rationality."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "The Lens That Sees Its Flaws",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Gears-Level"
              },
              {
                "name": "Epistemology"
              },
              {
                "name": "Map and Territory"
              }
            ]
          },
          {
            "title": "What Do We Mean By \"Rationality\"?",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Definitions"
              },
              {
                "name": "Distinctions"
              },
              {
                "name": "Motivational Intro Posts"
              }
            ]
          },
          {
            "title": "Humans are not automatically strategic",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Goodhart's Law"
              },
              {
                "name": "Introspection"
              },
              {
                "name": "General Intelligence"
              },
              {
                "name": "Motivational Intro Posts"
              }
            ]
          },
          {
            "title": "Use the Try Harder, Luke",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "More Dakka"
              },
              {
                "name": "Five minute timers"
              }
            ]
          },
          {
            "title": "Your Strength as a Rationalist",
            "tags": [
              {
                "name": "Rationalization"
              },
              {
                "name": "Noticing"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "The Meditation on Curiosity",
            "tags": [
              {
                "name": "Curiosity"
              },
              {
                "name": "Litany of Tarski"
              }
            ]
          },
          {
            "title": "The Importance of Saying \"Oops\"",
            "tags": [
              {
                "name": "Honesty"
              },
              {
                "name": "Self-Deception"
              },
              {
                "name": "Epistemology"
              },
              {
                "name": "Changing Your Mind"
              }
            ]
          },
          {
            "title": "The Martial Art of Rationality",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Cultural knowledge"
              },
              {
                "name": "Habits"
              },
              {
                "name": "Rationality Verification"
              },
              {
                "name": "Motivational Intro Posts"
              }
            ]
          },
          {
            "title": "Twelve Virtues of Rationality",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Rationality"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "gFvira6tHpLXnqCLH",
    "title": "Pitfalls of Human Cognition",
    "curatedOrder": null,
    "contents": {
      "markdown": "*Part 2 of 6 from the* [*Sequence Highlights*](https://www.lesswrong.com/highlights)*.*  \n  \nA major theme of the Sequences is the ways in which human reasoning goes astray. This sample of essays describes a number of failure modes and invokes us to do better."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "The Bottom Line",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Rationalization"
              },
              {
                "name": "Filtered Evidence"
              },
              {
                "name": "Litany of Tarski"
              }
            ]
          },
          {
            "title": "Rationalization",
            "tags": [
              {
                "name": "Rationalization"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "You Can Face Reality",
            "tags": [
              {
                "name": "Poetry"
              },
              {
                "name": "Litanies & Mantras"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Courage"
              }
            ]
          },
          {
            "title": "Is That Your True Rejection?",
            "tags": [
              {
                "name": "Rationalization"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Motivated Reasoning"
              },
              {
                "name": "Motivations"
              },
              {
                "name": "Conversation (topic)"
              }
            ]
          },
          {
            "title": "Avoiding Your Belief's Real Weak Points",
            "tags": [
              {
                "name": "Religion"
              },
              {
                "name": "Motivated Reasoning"
              },
              {
                "name": "Noticing"
              }
            ]
          },
          {
            "title": "Belief as Attire",
            "tags": [
              {
                "name": "Social Reality"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Motivations"
              },
              {
                "name": "Motivated Reasoning"
              },
              {
                "name": "Tribalism"
              }
            ]
          },
          {
            "title": "Cached Thoughts",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Cached Thoughts"
              }
            ]
          },
          {
            "title": "The Fallacy of Gray",
            "tags": [
              {
                "name": "Fallacies"
              },
              {
                "name": "Fallacy of Gray"
              }
            ]
          },
          {
            "title": "Lonely Dissent",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Social Reality"
              },
              {
                "name": "Groupthink"
              },
              {
                "name": "Social & Cultural Dynamics"
              },
              {
                "name": "Courage"
              },
              {
                "name": "Conformity Bias"
              }
            ]
          },
          {
            "title": "Positive Bias: Look Into the Dark",
            "tags": [
              {
                "name": "Confirmation Bias"
              }
            ]
          },
          {
            "title": "Knowing About Biases Can Hurt People",
            "tags": [
              {
                "name": "Rationalization"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Information Hazards"
              },
              {
                "name": "Pitfalls of Rationality"
              },
              {
                "name": "Fallacies"
              },
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Valley of Bad Rationality"
              },
              {
                "name": "Motivational Intro Posts"
              }
            ]
          },
          {
            "title": "Politics is the Mind-Killer",
            "tags": [
              {
                "name": "Politics"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Tribalism"
              },
              {
                "name": "Social & Cultural Dynamics"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "6xgy8XYEisLk3tCjH",
    "title": "The Laws Governing Belief",
    "curatedOrder": null,
    "contents": {
      "markdown": "*Part 3 of 6 from the* [*Sequence Highlights*](https://www.lesswrong.com/highlights)*.*  \n  \nWhile beliefs are subjective, that doesn't mean that one gets to choose their beliefs willy-nilly. There are laws that theoretically determine the correct belief given the evidence, and it's towards such beliefs that we should aspire."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "Making Beliefs Pay Rent (in Anticipated Experiences)",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Anticipated Experiences"
              },
              {
                "name": "Epistemology"
              },
              {
                "name": "Empiricism"
              },
              {
                "name": "Principles"
              }
            ]
          },
          {
            "title": "What is Evidence?",
            "tags": [
              {
                "name": "Epistemology"
              },
              {
                "name": "Causality"
              },
              {
                "name": "Anticipated Experiences"
              }
            ]
          },
          {
            "title": "Scientific Evidence, Legal Evidence, Rational Evidence",
            "tags": [
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Empiricism"
              },
              {
                "name": "Law and Legal systems"
              },
              {
                "name": "Distinctions"
              }
            ]
          },
          {
            "title": "How Much Evidence Does It Take?",
            "tags": [
              {
                "name": "Bayes' Theorem"
              },
              {
                "name": "Epistemology"
              }
            ]
          },
          {
            "title": "Absence of Evidence Is Evidence of Absence",
            "tags": [
              {
                "name": "Conservation of Expected Evidence"
              }
            ]
          },
          {
            "title": "Conservation of Expected Evidence",
            "tags": [
              {
                "name": "Conservation of Expected Evidence"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Bayes' Theorem"
              }
            ]
          },
          {
            "title": "Argument Screens Off Authority",
            "tags": [
              {
                "name": "Epistemology"
              },
              {
                "name": "Social Status"
              }
            ]
          },
          {
            "title": "An Intuitive Explanation of Bayes's Theorem",
            "tags": [
              {
                "name": "Bayes' Theorem"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Needs Fixup"
              },
              {
                "name": "Probability & Statistics"
              }
            ]
          },
          {
            "title": "The Second Law of Thermodynamics, and Engines of Cognition",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Law-Thinking"
              },
              {
                "name": "Physics"
              },
              {
                "name": "Probability & Statistics"
              },
              {
                "name": "Information Theory"
              },
              {
                "name": "Bayesianism"
              }
            ]
          },
          {
            "title": "Toolbox-thinking and Law-thinking",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Law-Thinking"
              },
              {
                "name": "Distinctions"
              }
            ]
          },
          {
            "title": "Local Validity as a Key to Sanity and Civilization",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Common Knowledge"
              },
              {
                "name": "Public Discourse"
              },
              {
                "name": "Epistemology"
              },
              {
                "name": "Gears-Level"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "KAv8z6oJCTxjR8vdR",
    "title": "CFAR Handbook",
    "curatedOrder": null,
    "contents": {
      "markdown": "The Center for Applied Rationality set out to develop simple, concrete concepts and techniques that could be straightforwardly applied to anyone's problems and goals, (hopefully) resulting in clearer thinking, better decision-making, and better follow-through.  \n\nThis is the result of the first five years or so of that research and development."
    },
    "chapters": [
      {
        "title": "Getting Started",
        "subtitle": null,
        "number": 0,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "CFAR Handbook: Introduction",
            "tags": [
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Opening Session Tips & Advice",
            "tags": [
              {
                "name": "Center for Applied Rationality (CFAR)"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Building a Bugs List prompts",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Center for Applied Rationality (CFAR)"
              }
            ]
          }
        ]
      },
      {
        "title": "Classes",
        "subtitle": null,
        "number": 1,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "Seeking PCK (Pedagogical Content Knowledge)",
            "tags": [
              {
                "name": "Distillation & Pedagogy"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Units of Exchange",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Economics"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Murphyjitsu: an Inner Simulator algorithm",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Inner Simulator / Suprise-o-meter"
              }
            ]
          },
          {
            "title": "Trigger-Action Planning",
            "tags": [
              {
                "name": "Center for Applied Rationality (CFAR)"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Trigger-Action Planning"
              }
            ]
          },
          {
            "title": "Goal Factoring",
            "tags": [
              {
                "name": "Goal Factoring"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Aversion Factoring",
            "tags": [
              {
                "name": "Aversion"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Turbocharging",
            "tags": [
              {
                "name": "Skill Building"
              },
              {
                "name": "Techniques"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Taste & Shaping",
            "tags": [
              {
                "name": "Techniques"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Goodhart's Imperius",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Systemization",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Againstness",
            "tags": [
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Comfort Zone Exploration",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Resolve Cycles",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Five minute timers"
              }
            ]
          },
          {
            "title": "Focusing",
            "tags": [
              {
                "name": "Focusing"
              },
              {
                "name": "Techniques"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Internal Double Crux",
            "tags": [
              {
                "name": "Techniques"
              },
              {
                "name": "Internal Double Crux"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Double Crux",
            "tags": [
              {
                "name": "Double-Crux"
              },
              {
                "name": "Techniques"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Bucket Errors",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Pitfalls of Rationality"
              },
              {
                "name": "Bucket Errors"
              }
            ]
          }
        ]
      },
      {
        "title": "Flash Classes",
        "subtitle": null,
        "number": 1,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "Polaris, Five-Second Versions, and Thought Lengths",
            "tags": [
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Socratic Ducking, OODA Loops, Frame-by-Frame Debugging",
            "tags": [
              {
                "name": "Techniques"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Gears-Level Understanding, Deliberate Performance, The Strategic Level",
            "tags": [
              {
                "name": "Techniques"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Area under the curve, Eat Dirt, Broccoli Errors, Copernicus & Chaos",
            "tags": [
              {
                "name": "Techniques"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Pendulums, Policy-Level Decisionmaking, Saving State",
            "tags": [
              {
                "name": "Center for Applied Rationality (CFAR)"
              },
              {
                "name": "Rationality"
              }
            ]
          }
        ]
      },
      {
        "title": "Appendices",
        "subtitle": null,
        "number": 1,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "Appendix: Hamming Questions",
            "tags": [
              {
                "name": "Hamming Questions"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Appendix: Jargon Dictionary",
            "tags": [
              {
                "name": "Terminology / Jargon (meta)"
              },
              {
                "name": "Rationality"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "AthjSa2Sm8jGWCbP5",
    "title": "Alignment For Foxes",
    "curatedOrder": null,
    "contents": {
      "markdown": "A series of posts on AI Alignment. Intended as an alternative approach to the subject for those allergic to grand narratives."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Reflections on My Own Missing Mood",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "AI Risk"
              },
              {
                "name": "Community"
              },
              {
                "name": "Missing Moods"
              }
            ]
          },
          {
            "title": "Parable: The Bomb that doesn't Explode",
            "tags": [
              {
                "name": "AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "ApA5XmewGQ8wSrv5C",
    "title": "Selection Theorems: Modularity",
    "curatedOrder": null,
    "contents": {
      "markdown": "This is a sequence of posts describing our team's research into modularity: how to measure it, and which factors select for it in a variety of learned systems. The project began as part of the AI Safety Camp 2022 under the mentorship of John Wentworth, and has continued outside of this, with funding from CEA."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Theories of Modularity in the Biological Literature",
            "tags": [
              {
                "name": "AI Safety Camp"
              },
              {
                "name": "Modularity"
              },
              {
                "name": "Biology"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Project Intro: Selection Theorems for Modularity",
            "tags": [
              {
                "name": "AI Safety Camp"
              },
              {
                "name": "Modularity"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Inner Alignment"
              },
              {
                "name": "Outer Alignment"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Ten experiments in modularity, which we'd like you to run!",
            "tags": [
              {
                "name": "Modularity"
              },
              {
                "name": "Request Post"
              },
              {
                "name": "Experiments"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "What Is The True Name of Modularity?",
            "tags": [
              {
                "name": "Modularity"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Information Theory"
              },
              {
                "name": "Causality"
              },
              {
                "name": "AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "v55BhXbpJuaExkpcD",
    "title": "2022 MIRI Alignment Discussion",
    "curatedOrder": 494,
    "contents": {
      "markdown": "A collection of MIRI write-ups and conversations about alignment released in 2022, following the [Late 2021 MIRI Conversations](https://www.lesswrong.com/s/n945eovrA3oDueqtq)."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "Six Dimensions of Operational Adequacy in AGI Projects",
            "tags": [
              {
                "name": "Security Mindset"
              },
              {
                "name": "Organizational Culture & Design"
              },
              {
                "name": "AI Governance"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "AGI Ruin: A List of Lethalities",
            "tags": [
              {
                "name": "AI Risk"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "A central AI alignment problem: capabilities generalization, and the sharp left turn",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Threat Models"
              }
            ]
          },
          {
            "title": "On how various plans miss the hard bits of the alignment challenge",
            "tags": [
              {
                "name": "AI Risk"
              },
              {
                "name": "AI"
              },
              {
                "name": "Research Agendas"
              }
            ]
          },
          {
            "title": "The inordinately slow spread of good AGI conversations in ML",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Machine Learning  (ML)"
              },
              {
                "name": "AI Alignment Fieldbuilding"
              }
            ]
          },
          {
            "title": "A note about differential technological development",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Brainstorm of things that could force an AI team to burn their lead",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "AGI ruin scenarios are likely (and disjunctive)",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "AI Risk"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "pfowch7ryfxniAhyb",
    "title": "Breaking Down Goal-Directed Behaviour",
    "curatedOrder": null,
    "contents": {
      "markdown": "When we speak about entities 'wanting' things, or having 'goal-directed behaviour', what do we mean?\n\nHere I aim to take steps to break down 'goal-directed behaviour' into a conceptual framework of computational abstractions for which I offer tentative terminology, and which helps me to better understand and describe analogies and disanalogies between various goal-directed systems. The overarching motivation is to better understand goal-directed behaviour, in the sense of being able to better predict its (especially counterfactual and off-distribution) implications, its arisal, and other properties. Hopefully it is clear why I consider this worthwhile."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Breaking Down Goal-Directed Behaviour",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Abstraction"
              },
              {
                "name": "Optimization"
              },
              {
                "name": "Goal-Directedness"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "You Only Get One Shot: an Intuition Pump for Embedded Agency",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Embedded Agency"
              }
            ]
          },
          {
            "title": "Deliberation, Reactions, and Control: Tentative Definitions and a Restatement of Instrumental Convergence",
            "tags": [
              {
                "name": "Goal-Directedness"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Abstraction"
              },
              {
                "name": "Embedded Agency"
              },
              {
                "name": "AI"
              },
              {
                "name": "Instrumental Convergence"
              }
            ]
          },
          {
            "title": "Deliberation Everywhere: Simple Examples",
            "tags": [
              {
                "name": "Goal-Directedness"
              },
              {
                "name": "Evolution"
              },
              {
                "name": "Adaptation Executors"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "B9Qc8ifidAtDpsuu8",
    "title": "A Tour of AI Timelines",
    "curatedOrder": null,
    "contents": {
      "markdown": "This is an overview of the [AI Timelines](https://www.alignmentforum.org/tag/ai-timelines) landscape that aims to make previous timelines research more accessible, and to also introduce new ideas/framings.\n\nSome questions that we'll be diving into include:\n\n*   What's the difference between capabilities-based and impact-based forecasts?\n*   How do the [bioanchors](https://www.alignmentforum.org/posts/KrJfoZzpSDpnrv9va/draft-report-on-ai-timelines), [semi-informative priors](https://www.openphilanthropy.org/semi-informative-priors), and [insights-based AI timelines](http://mediangroup.org/insights) models actually work?\n*   What might the future of forecasting AI Timelines look like? What kind of work is most urgently needed?\n\nMy current plan is to put out the rest of the sequence slowly, probably between September and December 2022."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Grokking “Forecasting TAI with biological anchors”",
            "tags": [
              {
                "name": "AI Timelines"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Grokking “Semi-informative priors over AI timelines”",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "AI Timelines"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "Nsms3ub442NYvw9cb",
    "title": "Networking: The Abridged Game Manual",
    "curatedOrder": null,
    "contents": {
      "markdown": "Networking is a skill useful for pretty much all human endeavors. In this sequence, I collect brief summaries of some things I've found to work well in different domains of the game."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Guidelines for cold messaging people",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "Relationships (Interpersonal)"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "ogntdnjG6Y9tbLsNS",
    "title": "Basic Foundations for Agent Models",
    "curatedOrder": null,
    "contents": {
      "markdown": ""
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Utility Maximization = Description Length Minimization",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Information Theory"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Utility Functions"
              },
              {
                "name": "Optimization"
              }
            ]
          },
          {
            "title": "Against Time in Agent Models",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Optimization at a Distance",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Bits of Optimization Can Only Be Lost Over A Distance",
            "tags": [
              {
                "name": "Optimization"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "The \"Measuring Stick of Utility\" Problem",
            "tags": [
              {
                "name": "Coherence Arguments"
              },
              {
                "name": "Utility Functions"
              }
            ]
          },
          {
            "title": "Distributed Decisions",
            "tags": [
              {
                "name": "Optimization"
              },
              {
                "name": "AI"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Abstraction"
              },
              {
                "name": "World Modeling"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "FaEBwhhe3otzYKGQt",
    "title": "Pragmatic AI Safety",
    "curatedOrder": null,
    "contents": {
      "markdown": "Linked to at [pragmaticaisafety.com](http://pragmaticaisafety.com/).\n\nGiven that ML is progressing quickly, that pre-paradigmatic research is not highly scalable to many researchers, and that safety research that advances capabilities is not safely scalable to a broader research community, we suggest an approach that some of us have been developing in academia over the past several years. We propose a simple, underrated, and complementary research paradigm, which we call Pragmatic AI Safety (PAIS). By complementary, we mean that we intend for it to stand alongside current approaches, rather than replace them.\n\n![](https://lh4.googleusercontent.com/X1qXj8heKwZj3XOUyINRXJeBulQmpxGVo1VXr45IwXWqGvdrSoKEckwZG4_05aKHRRu1g3Trw4H0QYJE2kTra6uUGROVXS3BsPmjB3pi-1CB28817HKdCy7C1xumDvUlwwWpeziqaGD6hWXInQ)\n\nPragmatic AI Safety rests on three essential pillars:\n\n*   *ML research precedents*. Safety involves technical AI problems, and the ML community’s precedents enable it to be unusually effective at solving technical AI problems.\n*   *Minimal capabilities externalities. Safety research at scale needs to be precautious and avoid advancing capabilities in the name of safety.*\n*   *Sociotechnical systems view. Preventing catastrophes requires more than technical work, such as improving incentives, safety culture, protocols, and so on.*"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Introduction to Pragmatic AI Safety [Pragmatic AI Safety #1]",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "A Bird's Eye View of the ML Field [Pragmatic AI Safety #2]",
            "tags": [
              {
                "name": "Machine Learning  (ML)"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Complex Systems for AI Safety [Pragmatic AI Safety #3]",
            "tags": [
              {
                "name": "AI Risk"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Perform Tractable Research While Avoiding Capabilities Externalities [Pragmatic AI Safety #4]",
            "tags": [
              {
                "name": "AI Risk"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Open Problems in AI X-Risk [PAIS #5]",
            "tags": [
              {
                "name": "AI Risk"
              },
              {
                "name": "Open Problems"
              },
              {
                "name": "AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "opnkEkLCej3mPHwHx",
    "title": "Insights from Dath Ilan",
    "curatedOrder": null,
    "contents": {
      "markdown": "Insights into the Way of rationality, written up as I read through [*planecrash.*](https://www.glowfic.com/posts/4582) If you're not going to read the story but would still like to get all the kernels of rationality insight buried within, this is for you!\n\nPosts are a mix of lower-effort merely-passing-on-key-excerpts and somewhat higher-effort analyses. I'll be sure to at *least* copy/paste/link everything I judge to be an important rationality insight [in](https://www.lesswrong.com/posts/KGLJeeF6psTzHiuiR/david-udell-s-shortform?commentId=vEvd2fEquHvHXcrTq) [a](https://www.lesswrong.com/posts/KGLJeeF6psTzHiuiR/david-udell-s-shortform?commentId=vRsgTkoBRuja7KHd7) [shortform](https://www.lesswrong.com/posts/KGLJeeF6psTzHiuiR/david-udell-s-shortform?commentId=F85JqSSk7YLgCYQED) [post,](https://www.lesswrong.com/posts/KGLJeeF6psTzHiuiR/david-udell-s-shortform?commentId=odjLNu4evD4RLpKPq) [and](https://www.lesswrong.com/posts/KGLJeeF6psTzHiuiR/david-udell-s-shortform?commentId=zD7Pn7dKgevSGvCzi) [then](https://www.lesswrong.com/posts/KGLJeeF6psTzHiuiR/david-udell-s-shortform?commentId=vs8jWm2wQ7pjfBBHn) [link](https://www.lesswrong.com/posts/KGLJeeF6psTzHiuiR/david-udell-s-shortform?commentId=nWgM7ZoS8TrCzA3Kv) [each](https://www.lesswrong.com/posts/KGLJeeF6psTzHiuiR/david-udell-s-shortform?commentId=Lxw3jXieavAmADrGm) [shortform](https://www.lesswrong.com/posts/KGLJeeF6psTzHiuiR/david-udell-s-shortform?commentId=WqhR5zkxLxCdu5nut) here.\n\n(Spoilers are flagged at the beginning of each post, but are *not hidden* within those posts! The relevant *planecrash* Book -- 'Glowfic Post' --  is also flagged before each post.)"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Dath Ilan vs. Sid Meier's Alpha Centauri: Pareto Improvements",
            "tags": [
              {
                "name": "Fiction (Topic)"
              },
              {
                "name": "dath ilan"
              },
              {
                "name": "Coordination / Cooperation"
              }
            ]
          },
          {
            "title": "Your Utility Function is Your Utility Function",
            "tags": [
              {
                "name": "dath ilan"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Altruism"
              }
            ]
          },
          {
            "title": "Dath Ilani Rule of Law",
            "tags": [
              {
                "name": "dath ilan"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Pre-Commitment"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "The \"Adults in the Room\"",
            "tags": [
              {
                "name": "Emotions"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "dath ilan"
              }
            ]
          },
          {
            "title": "Infernal Corrigibility, Fiendishly Difficult",
            "tags": [
              {
                "name": "dath ilan"
              },
              {
                "name": "Corrigibility"
              }
            ]
          },
          {
            "title": "The STEM Attractor",
            "tags": [
              {
                "name": "dath ilan"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "How to Visualize Bayesianism",
            "tags": [
              {
                "name": "Bayes' Theorem"
              },
              {
                "name": "dath ilan"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Abadarian Trades",
            "tags": [
              {
                "name": "dath ilan"
              },
              {
                "name": "Pre-Commitment"
              },
              {
                "name": "Coordination / Cooperation"
              },
              {
                "name": "Rationality"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "eAuK3qJd678LFdGyz",
    "title": "An Inside View of AI Alignment",
    "curatedOrder": null,
    "contents": {
      "markdown": "This is Ansh Radhakrishnan's current (as of mid 2022) inside view of the AI Alignment field. See the introduction for more."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "An Inside View of AI Alignment",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "RLHF",
            "tags": [
              {
                "name": "Reinforcement Learning"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "The Bio Anchors Forecast",
            "tags": [
              {
                "name": "AI Timelines"
              },
              {
                "name": "AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "DpZy5s9g2TAKEJwst",
    "title": "AI Races and Macrostrategy",
    "curatedOrder": null,
    "contents": {
      "markdown": "Thinking about the scaling of large language models, especially the consequences of coding AI on the economy."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Ethan Caballero on Private Scaling Progress",
            "tags": [
              {
                "name": "Scaling Laws"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "A concrete bet offer to those with short AI timelines",
            "tags": [
              {
                "name": "Betting"
              },
              {
                "name": "AI"
              },
              {
                "name": "AI Timelines"
              }
            ]
          },
          {
            "title": "Why Copilot Accelerates Timelines",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "AI Timelines"
              },
              {
                "name": "AI Takeoff"
              },
              {
                "name": "Recursive Self-Improvement"
              },
              {
                "name": "Language Models"
              },
              {
                "name": "Superintelligence"
              }
            ]
          },
          {
            "title": "The Codex Skeptic FAQ",
            "tags": [
              {
                "name": "Software Tools"
              },
              {
                "name": "Practical"
              },
              {
                "name": "AI"
              },
              {
                "name": "Language Models"
              }
            ]
          },
          {
            "title": "Phil Trammell on Economic Growth Under Transformative AI",
            "tags": [
              {
                "name": "Economics"
              },
              {
                "name": "World Modeling"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "GyvZkBRf8m6NAccgw",
    "title": "Treacherous Turn",
    "curatedOrder": null,
    "contents": {
      "markdown": "Nick Bostrom came up with the idea of a [treacherous turn](https://www.lesswrong.com/posts/B39GNTsN3HocW8KFo/superintelligence-11-the-treacherous-turn) for smart AIs.\n\n> while weak, an AI behaves cooperatively. When the AI is strong enough to be unstoppable it pursues its own values.\n\nBen Goertzel criticised this thesis, [pointing out](https://jetpress.org/v26.1/goertzel.pdf) that:\n\n> for a resource-constrained system, learning to actually possess human values is going to be much easier than learning to fake them. This is related to the everyday observation that maintaining a web of lies rapidly gets very complicated.\n\nThis argument has been formalised into the [sordid stumble](https://poseidon01.ssrn.com/delivery.php?ID=478069124110088028103018016004012092030042006012089031090113089070105030104016095087043038022017031001018003099009013078002070110010017028007092090099081125122099100010008001004000106096123020075089074092074001004092092026065123067092086116116000002081&EXT=pdf):\n\n> An AI that lacks human desirable values will behave in a way that reveals its human-undesirable values to humans before it gains the capability to deceive humans into believing that it has human-desirable values."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "An Increasingly Manipulative Newsfeed",
            "tags": [
              {
                "name": "Deception"
              },
              {
                "name": "Outer Alignment"
              },
              {
                "name": "AI Risk"
              }
            ]
          },
          {
            "title": "A Gym Gridworld Environment for the  Treacherous Turn",
            "tags": [
              {
                "name": "AI Risk"
              },
              {
                "name": "Corrigibility"
              },
              {
                "name": "Programming"
              },
              {
                "name": "Instrumental Convergence"
              },
              {
                "name": "Treacherous Turn"
              }
            ]
          },
          {
            "title": "A toy model of the treacherous turn",
            "tags": [
              {
                "name": "AI Risk"
              },
              {
                "name": "Treacherous Turn"
              }
            ]
          },
          {
            "title": "Superintelligence 11: The treacherous turn",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Reading Group"
              },
              {
                "name": "Deception"
              },
              {
                "name": "Treacherous Turn"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "aB9DPaYnktuufLy47",
    "title": "The Inside View (Podcast)",
    "curatedOrder": null,
    "contents": {
      "markdown": "Quotes, diagrams and transcripts for my podcast \"The Inside View\" available at theinsideview.ai"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Connor Leahy on Dying with Dignity, EleutherAI and Conjecture",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Conjecture (org)"
              }
            ]
          },
          {
            "title": "Raphaël Millière on Generalization and Scaling Maximalism",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Blake Richards on Why he is Skeptical of Existential Risk from AI",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Ethan Caballero on Private Scaling Progress",
            "tags": [
              {
                "name": "Scaling Laws"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Phil Trammell on Economic Growth Under Transformative AI",
            "tags": [
              {
                "name": "Economics"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Evan Hubinger on Homogeneity in Takeoff Speeds, Learned Optimization and Interpretability",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Myopia"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "rmZt45HAxFFgJ8vEH",
    "title": "Winding My Way Through Alignment",
    "curatedOrder": null,
    "contents": {
      "markdown": "A sequence of my alignment distillations, written up as I work my way through understanding AI alignment theory.\n\nMy rough guiding research algorithm is to focus in on the biggest hazard in my current model of alignment, try to understand and explain that hazard and the proposed solutions to it, and then recurse."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "HCH and Adversarial Questions",
            "tags": [
              {
                "name": "Iterated Amplification "
              },
              {
                "name": "Humans Consulting HCH"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Agency and Coherence",
            "tags": [
              {
                "name": "Agency"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Deceptive Agents are a Good Way to Do Things",
            "tags": [
              {
                "name": "Inner Alignment"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "But What's Your *New Alignment Insight,* out of a Future-Textbook Paragraph?",
            "tags": [
              {
                "name": "Inside/Outside View"
              },
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Gato as the Dawn of Early AGI",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "AI Timelines"
              }
            ]
          },
          {
            "title": "Intelligence in Commitment Races",
            "tags": [
              {
                "name": "Pre-Commitment"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "How Deadly Will Roughly-Human-Level AGI Be?",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Threat Models"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "jef8ntrWuJ7SvZjCM",
    "title": "Interpretability Research for the Most Important Century",
    "curatedOrder": null,
    "contents": {
      "markdown": "This series of posts attempts to answer the following question from Holden Karnofsky’s [Important, actionable research questions for the most important century](https://forum.effectivealtruism.org/posts/zGiD94SHwQ9MwPyfW/important-actionable-research-questions-for-the-most) (from which the name of this sequence is inspired as well):\n\n> *“What relatively well-scoped research activities are particularly likely to be useful for longtermism-oriented AI alignment?”*.\n\nAs one answer to Holden's question, I explore the argument that interpretability research is one of these high-leverage activities in the AI alignment research space.\n\n*Featured image was created by DALL·E*"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Introduction to the sequence: Interpretability Research for the Most Important Century",
            "tags": [
              {
                "name": "AI Success Models"
              },
              {
                "name": "AI"
              },
              {
                "name": "Transparency / Interpretability (ML & AI)"
              }
            ]
          },
          {
            "title": "Interpretability’s Alignment-Solving Potential: Analysis of 7 Scenarios",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Transparency / Interpretability (ML & AI)"
              },
              {
                "name": "AI Success Models"
              },
              {
                "name": "Myopia"
              },
              {
                "name": "Debate (AI safety technique)"
              },
              {
                "name": "Market making (AI safety technique) "
              },
              {
                "name": "Iterated Amplification "
              },
              {
                "name": "AI Risk"
              },
              {
                "name": "Inner Alignment"
              },
              {
                "name": "Outer Alignment"
              },
              {
                "name": "Eliciting Latent Knowledge (ELK)"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "cmdSDLFTbmiKnuugW",
    "title": "Test sequence (ignore)",
    "curatedOrder": null,
    "contents": {
      "markdown": "Just a test sequence so I can understand this feature and its limitations. I have a series of posts I'm trying to decide between posting as individual posts or as a sequence."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": []
      }
    ]
  },
  {
    "_id": "2TBwjAn2TPyJMDEui",
    "title": "Neural Networks, More than you wanted to Show",
    "curatedOrder": null,
    "contents": {
      "markdown": "A sequence where I explore and visualize various neural networks.\n\nWith thanks to [https://huggingface.co/spaces/multimodalart/latentdiffusion](https://huggingface.co/spaces/multimodalart/latentdiffusion) for the text to images AI used to create the banner art."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Exploring toy neural nets under node removal. Section 1.",
            "tags": [
              {
                "name": "Machine Learning  (ML)"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Visualizing Neural networks, how to blame the bias",
            "tags": [
              {
                "name": "Transparency / Interpretability (ML & AI)"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Train first VS prune first in neural networks.",
            "tags": [
              {
                "name": "Machine Learning  (ML)"
              },
              {
                "name": "AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "u9uawicHx7Ng7vwxA",
    "title": "Concept Extrapolation",
    "curatedOrder": null,
    "contents": {
      "markdown": "This sequence collects the key posts on concept extrapolation. They are not necessarily to be read in this order; different people will find different posts useful.\n\nConcept extrapolation is the skill of taking a concept, a feature, or a goal that is defined in a narrow training situation... and extrapolating it safely to a more general situation. This more general situation might be very extreme, and the original concept might not make much sense (eg defining \"human beings\" in terms of quantum fields).\n\nNevertheless, since training data is always insufficient, key concepts must be extrapolated. And doing so successfully is a skill that humans have to a certain degree, and that an aligned AI would need to possess to a higher extent."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Concept extrapolation: key posts",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Coherent Extrapolated Volition"
              }
            ]
          },
          {
            "title": "Different perspectives on concept extrapolation",
            "tags": [
              {
                "name": "Value Learning"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Model splintering: moving from one imperfect model to another",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Machine Learning  (ML)"
              },
              {
                "name": "Iterated Amplification "
              }
            ]
          },
          {
            "title": "General alignment plus human values, or alignment via human values?",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Value extrapolation, concept extrapolation, model splintering",
            "tags": [
              {
                "name": "Value Learning"
              },
              {
                "name": "AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "PKKsrXtuptWzaKCjr",
    "title": "Alignment & Agency",
    "curatedOrder": null,
    "contents": {
      "markdown": ""
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "An Orthodox Case Against Utility Functions",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "AI"
              },
              {
                "name": "Utility Functions"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Indexical Information"
              }
            ]
          },
          {
            "title": "The Pointers Problem: Human Values Are A Function Of Humans' Latent Variables",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "AI"
              },
              {
                "name": "Value Learning"
              },
              {
                "name": "The Pointers Problem"
              }
            ]
          },
          {
            "title": "Alignment By Default",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Abstraction"
              }
            ]
          },
          {
            "title": "An overview of 11 proposals for building safe advanced AI",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Iterated Amplification "
              },
              {
                "name": "Debate (AI safety technique)"
              },
              {
                "name": "Inner Alignment"
              },
              {
                "name": "Outer Alignment"
              },
              {
                "name": "Myopia"
              },
              {
                "name": "AI Risk"
              },
              {
                "name": "AI Success Models"
              },
              {
                "name": "Research Agendas"
              }
            ]
          },
          {
            "title": "The ground of optimization",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "General Intelligence"
              },
              {
                "name": "Optimization"
              },
              {
                "name": "Selection vs Control"
              }
            ]
          },
          {
            "title": "Search versus design",
            "tags": [
              {
                "name": "Optimization"
              },
              {
                "name": "Machine Learning  (ML)"
              },
              {
                "name": "AI"
              },
              {
                "name": "Transparency / Interpretability (ML & AI)"
              },
              {
                "name": "Distinctions"
              }
            ]
          },
          {
            "title": "Inner Alignment: Explain like I'm 12 Edition",
            "tags": [
              {
                "name": "Inner Alignment"
              },
              {
                "name": "AI"
              },
              {
                "name": "Mesa-Optimization"
              }
            ]
          },
          {
            "title": "Inaccessible information",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "AGI safety from first principles: Introduction",
            "tags": [
              {
                "name": "AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "EyNdA5jh7qoCmBdyJ",
    "title": "test",
    "curatedOrder": null,
    "contents": {
      "markdown": "test"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": []
      }
    ]
  },
  {
    "_id": "pfxyqvAZ4o4bguAJk",
    "title": "Calculus in Game and Decision Theory",
    "curatedOrder": null,
    "contents": {
      "markdown": "This sequence explores some concepts in the fields of Game Theory and Decision Theory from the perspective of calculus. The first post is a math-heavy explanation of derivatives, and the second and third post apply knowledge of the first to problems like the Prisoner's dilemma and Newcomb's problem."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "A Very Mathematical Explanation of Derivatives",
            "tags": [
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "The Calculus of Nash Equilibria",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Prisoner's Dilemma"
              }
            ]
          },
          {
            "title": "The Calculus of Newcomb's Problem",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Newcomb's Problem"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "KgrG4cQdLtL9DvNr2",
    "title": "Alignment Stream of Thought",
    "curatedOrder": null,
    "contents": {
      "markdown": "This sequence contains posts that are lower effort than my usual posts, where instead of thinking things all the way through before posting something polished about them, I instead post things that are rough and in-progress as I think about them. I'm trying this because I noticed that I had lots of interesting thoughts that I didn't want to share due to not having totally figured it out yet, and that the process of writing things and posting them often helps me make progress. \n\nAnything in this sequence is at even greater risk than usual of being obsoleted or unendorsed later down the road. It will also be more difficult to follow than usual, because I'm not putting as much effort as usual into explaining background.\n\nI am hoping to eventually do a distillation of the important insights of this sequence into more legible post(s) once I'm less confused."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "[ASoT] Observations about ELK",
            "tags": [
              {
                "name": "Eliciting Latent Knowledge (ELK)"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[ASoT] Some ways ELK could still be solvable in practice",
            "tags": [
              {
                "name": "Eliciting Latent Knowledge (ELK)"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[ASoT] Searching for consequentialist structure",
            "tags": [
              {
                "name": "Consequentialism"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[ASoT] Some thoughts about deceptive mesaoptimization",
            "tags": [
              {
                "name": "Mesa-Optimization"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[ASoT] Some thoughts about LM monologue limitations and ELK",
            "tags": [
              {
                "name": "Language Models"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[ASoT] Some thoughts about imperfect world modeling",
            "tags": [
              {
                "name": "Mesa-Optimization"
              },
              {
                "name": "Outer Alignment"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[ASoT] Consequentialist models as a superset of mesaoptimizers",
            "tags": [
              {
                "name": "Mesa-Optimization"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Humans Reflecting on HRH",
            "tags": [
              {
                "name": "AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "jstoEiuKxHPfASRJK",
    "title": "Civilization & Cooperation",
    "curatedOrder": null,
    "contents": {
      "markdown": "What does it mean to exist in a society?  What does it mean to be more or less civilized?  Why do people do it, and why do they (sometimes) stop?"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Civilization as Self-Restraint",
            "tags": [
              {
                "name": "World Optimization"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "yjcCtcifEnW76YAHk",
    "title": "CERI SRF '22",
    "curatedOrder": null,
    "contents": {
      "markdown": "*click* [*here*](https://forum.effectivealtruism.org/s/c42cHpNCLPN8cLtje) *to view the complete sequence on the EA Forum*\n\nThe Cambridge Existential Risks Initiative (CERI, pronounced /ˈkɛri/) Summer Research Fellowship (SRF) '22 is a ten-week programme for students and junior researchers who want to work on mitigating existential risks. Fellows will experience an all-expenses-paid summer in Cambridge, receive a generous stipend, gain support from our network of researchers, policymakers and grantmakers, and develop skills for an impactful career."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": []
      }
    ]
  },
  {
    "_id": "pFatcKW3JJhTSxqAF",
    "title": "Replacing Guilt",
    "curatedOrder": 50,
    "contents": {
      "markdown": "> My goal is to help people remove guilt-based motivation entirely, and replace it with intrinsic motivation. I'm aiming to both reduce the frequency of Netflix binges *and* reduce the bad feelings that follow. I'm aiming to help people feel like they're still worthwhile human beings if they stop working before they literally drop.\n\nA sequence about replacing guilt with other feelings and finding better ways to self-motivate, so that you can build a better future without falling apart in the process.\n\n> When all is said and done, Nature will not judge us by our actions; we will be measured only by what *actually happens.* Our goal, in the end, is to ensure that the timeless history of our universe is one that is filled with whatever it is we're fighting for. For me, at least, this is the underlying driver that takes the place of guilt: Once we have learned our lessons from the past, there is no reason to wrack ourselves with guilt. All we need to do, in any given moment, is look upon the actions available to us, consider, and take whichever one seems most likely to lead to a future full of light.\n\nOriginally posted on [Minding Our Way](https://mindingourway.com/guilt/). There's also an [official audio version](https://pod.link/1498321446)."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": []
      },
      {
        "title": "Preliminaries",
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "Half-assing it with everything you've got",
            "tags": []
          },
          {
            "title": "Failing with abandon",
            "tags": []
          }
        ]
      },
      {
        "title": "Fighting for something",
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "Replacing guilt",
            "tags": []
          },
          {
            "title": "The Stamp Collector",
            "tags": [
              {
                "name": "Wireheading"
              },
              {
                "name": "AI"
              },
              {
                "name": "Altruism"
              }
            ]
          },
          {
            "title": "You're allowed to fight for something",
            "tags": []
          },
          {
            "title": "Caring about something larger than yourself",
            "tags": []
          },
          {
            "title": "You don't get to know what you're fighting for",
            "tags": []
          }
        ]
      },
      {
        "title": "Drop your obligations",
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "\"Should\" considered harmful",
            "tags": []
          },
          {
            "title": "Not because you \"should\"",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Your \"shoulds\" are not a duty",
            "tags": []
          }
        ]
      },
      {
        "title": "Half monkey, half god",
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "Working yourself ragged is not a virtue",
            "tags": [
              {
                "name": "Well-being"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Rest in motion",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Shifting guilt",
            "tags": [
              {
                "name": "World Optimization"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Don't steer with guilt",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Update from the suckerpunch",
            "tags": [
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Be a new homunculus",
            "tags": [
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Not yet gods",
            "tags": [
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Where coulds go",
            "tags": [
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Self compassion",
            "tags": [
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "There are no \"bad people\"",
            "tags": [
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Residing in the mortal realm",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "World Optimization"
              }
            ]
          }
        ]
      },
      {
        "title": "The dark world",
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "Being unable to despair",
            "tags": [
              {
                "name": "World Optimization"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "See the dark world",
            "tags": [
              {
                "name": "World Optimization"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Choose without suffering",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Detach the grim-o-meter",
            "tags": [
              {
                "name": "World Optimization"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Simply locate yourself",
            "tags": [
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Have no excuses",
            "tags": [
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Come to your terms",
            "tags": [
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Transmute guilt into resolve",
            "tags": [
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "The best you can",
            "tags": [
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Dark, not colorless",
            "tags": [
              {
                "name": "World Optimization"
              }
            ]
          }
        ]
      },
      {
        "title": "Fire within",
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "Stop trying to try and try",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "There is no try",
            "tags": [
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Obvious advice",
            "tags": [
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "The art of response",
            "tags": []
          },
          {
            "title": "Confidence all the way up",
            "tags": [
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Desperation",
            "tags": [
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Recklessness",
            "tags": [
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Defiance",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "How we will be measured",
            "tags": [
              {
                "name": "World Optimization"
              }
            ]
          }
        ]
      },
      {
        "title": "Related",
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "On Caring",
            "tags": [
              {
                "name": "Motivations"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Motivational Intro Posts"
              }
            ]
          },
          {
            "title": "The Value of a Life",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Moving towards the goal",
            "tags": [
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Self-signaling the ability to do what you want",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Productivity through self-loyalty",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Conclusion of the Replacing Guilt series",
            "tags": [
              {
                "name": "World Optimization"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "hFom77cBBnnbNLzzm",
    "title": "Reality & Reason",
    "curatedOrder": null,
    "contents": {
      "markdown": ""
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "What Money Cannot Buy",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Expertise (topic)"
              }
            ]
          },
          {
            "title": "To listen well, get curious",
            "tags": [
              {
                "name": "Communication Cultures"
              },
              {
                "name": "Practical"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Conversation (topic)"
              },
              {
                "name": "Curiosity"
              }
            ]
          },
          {
            "title": "The Felt Sense: What, Why and How",
            "tags": [
              {
                "name": "Focusing"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Introspection"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "The Solomonoff Prior is Malign",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Solomonoff Induction"
              },
              {
                "name": "Priors"
              },
              {
                "name": "Inner Alignment"
              },
              {
                "name": "Distillation & Pedagogy"
              }
            ]
          },
          {
            "title": "The Treacherous Path to Rationality",
            "tags": [
              {
                "name": "Pitfalls of Rationality"
              },
              {
                "name": "Group Rationality"
              },
              {
                "name": "Epistemology"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Community"
              },
              {
                "name": "Explicit Reasoning"
              }
            ]
          },
          {
            "title": "The Pointers Problem: Human Values Are A Function Of Humans' Latent Variables",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "AI"
              },
              {
                "name": "Value Learning"
              },
              {
                "name": "The Pointers Problem"
              }
            ]
          },
          {
            "title": "A non-mystical explanation of \"no-self\" (three characteristics series)",
            "tags": [
              {
                "name": "Meditation"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Subagents"
              },
              {
                "name": "Identity"
              },
              {
                "name": "Personal Identity"
              },
              {
                "name": "Buddhism"
              }
            ]
          },
          {
            "title": "Anti-Aging: State of the Art ",
            "tags": [
              {
                "name": "World Optimization"
              },
              {
                "name": "Aging"
              },
              {
                "name": "Life Extension"
              }
            ]
          },
          {
            "title": "Search versus design",
            "tags": [
              {
                "name": "Optimization"
              },
              {
                "name": "Machine Learning  (ML)"
              },
              {
                "name": "AI"
              },
              {
                "name": "Transparency / Interpretability (ML & AI)"
              },
              {
                "name": "Distinctions"
              }
            ]
          },
          {
            "title": "Reality-Revealing and Reality-Masking Puzzles",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Memetic Immune System"
              },
              {
                "name": "Pitfalls of Rationality"
              }
            ]
          },
          {
            "title": "When Money Is Abundant, Knowledge Is The Real Wealth",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Expertise (topic)"
              },
              {
                "name": "Economics"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "cv2aZaRR22MPC5QwE",
    "title": "Coordination & Constraint",
    "curatedOrder": null,
    "contents": {
      "markdown": ""
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "Coordination as a Scarce Resource",
            "tags": [
              {
                "name": "Economics"
              },
              {
                "name": "Coordination / Cooperation"
              }
            ]
          },
          {
            "title": "Transportation as a Constraint",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "History"
              },
              {
                "name": "Progress Studies"
              },
              {
                "name": "Economics"
              }
            ]
          },
          {
            "title": "Interfaces as a Scarce Resource",
            "tags": [
              {
                "name": "UI Design"
              },
              {
                "name": "Mechanism Design"
              }
            ]
          },
          {
            "title": "Simulacra Levels and their Interactions",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Covid-19"
              },
              {
                "name": "Simulacrum Levels"
              }
            ]
          },
          {
            "title": "microCOVID.org: A tool to estimate COVID risk from common activities",
            "tags": [
              {
                "name": "Covid-19"
              },
              {
                "name": "Software Tools"
              }
            ]
          },
          {
            "title": "Most Prisoner's Dilemmas are Stag Hunts; Most Stag Hunts are Schelling Problems",
            "tags": [
              {
                "name": "Game Theory"
              },
              {
                "name": "Coordination / Cooperation"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Prisoner's Dilemma"
              },
              {
                "name": "Stag Hunt"
              }
            ]
          },
          {
            "title": "Swiss Political System: More than You ever Wanted to Know (I.)",
            "tags": [
              {
                "name": "World Optimization"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Mechanism Design"
              },
              {
                "name": "Politics"
              },
              {
                "name": "Fact posts"
              }
            ]
          },
          {
            "title": "\"Can you keep this confidential? How do you know?\"",
            "tags": [
              {
                "name": "Robust Agents"
              },
              {
                "name": "Communication Cultures"
              },
              {
                "name": "Community"
              },
              {
                "name": "Privacy"
              }
            ]
          },
          {
            "title": "Motive Ambiguity",
            "tags": [
              {
                "name": "Signaling"
              },
              {
                "name": "Moral Mazes"
              },
              {
                "name": "Tradeoffs"
              }
            ]
          },
          {
            "title": "Studies On Slack",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Evolution"
              },
              {
                "name": "Slack"
              },
              {
                "name": "Moloch"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Can crimes be discussed literally?",
            "tags": [
              {
                "name": "Deception"
              },
              {
                "name": "Conflict vs Mistake"
              },
              {
                "name": "Simulacrum Levels"
              },
              {
                "name": "The Signaling Trilemma"
              }
            ]
          },
          {
            "title": "Why haven't we celebrated any major achievements lately?",
            "tags": [
              {
                "name": "Progress Studies"
              },
              {
                "name": "History"
              },
              {
                "name": "Social Status"
              },
              {
                "name": "Stagnation"
              },
              {
                "name": "Ritual"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "EcKbpm4f7fBwhxRZs",
    "title": "Takeoff & Takeover",
    "curatedOrder": null,
    "contents": {
      "markdown": "> Imagine an advanced society, with complex structures more intricate and intelligent than anything that exists today – a society which nevertheless lacks any being that is conscious, or whose welfare has moral significance. In a sense, this would be an uninhabited society. It would be a society of economic miracles and technological awesomeness, with nobody there to benefit. A Disneyland with no children.\n> \n> – Nick Bostrom"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "Draft report on AI timelines",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "AI Timelines"
              }
            ]
          },
          {
            "title": "An overview of 11 proposals for building safe advanced AI",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Iterated Amplification "
              },
              {
                "name": "Debate (AI safety technique)"
              },
              {
                "name": "Inner Alignment"
              },
              {
                "name": "Outer Alignment"
              },
              {
                "name": "Myopia"
              },
              {
                "name": "AI Risk"
              },
              {
                "name": "AI Success Models"
              },
              {
                "name": "Research Agendas"
              }
            ]
          },
          {
            "title": "Cortés, Pizarro, and Afonso as Precedents for Takeover",
            "tags": [
              {
                "name": "History"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Nuclear war is unlikely to cause human extinction",
            "tags": [
              {
                "name": "Existential Risk"
              },
              {
                "name": "War"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Nuclear War"
              }
            ]
          },
          {
            "title": "Reply to Eliezer on Biological Anchors",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Biology-Inspired AGI Timelines: The Trick That Never Works",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "AI Timelines"
              },
              {
                "name": "Dialogue (format)"
              },
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "Technological Forecasting"
              },
              {
                "name": "History"
              }
            ]
          },
          {
            "title": "Against GDP as a metric for timelines and takeoff speeds",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "AI Timelines"
              },
              {
                "name": "AI Takeoff"
              },
              {
                "name": "Center on Long-Term Risk (CLR)"
              }
            ]
          },
          {
            "title": "The date of AI Takeover is not the day the AI takes over",
            "tags": [
              {
                "name": "AI Timelines"
              },
              {
                "name": "AI"
              },
              {
                "name": "AI Takeoff"
              }
            ]
          },
          {
            "title": "Some AI research areas and their relevance to existential safety",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Existential Risk"
              },
              {
                "name": "Academic Papers"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Agent Foundations"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "4aARF2ZoBpFZAhbbe",
    "title": "More Is Different for AI",
    "curatedOrder": null,
    "contents": {
      "markdown": "Machine learning is touching increasingly many aspects of our society, and its effect will only continue to grow. Given this, I and many others care about risks from future ML systems and how to mitigate them.\n\nI've distilled my thoughts into a series of blog posts, where I'll argue that:\n\n1.  [*Future ML Systems Will be Qualitatively Different*](https://www.lesswrong.com/posts/pZaPhGg2hmmPwByHc/future-ml-systems-will-be-qualitatively-different) from those we see today. Indeed, ML systems have historically exhibited qualitative changes as a result of increasing their scale. This is an instance of \"More Is Different\", which is commonplace in other fields such as physics, biology, and economics (see *Appendix: More Is Different in Other Domains*). Consequently, we should expect ML to exhibit more qualitative changes as it scales up in the future.\n2.  Most discussions of ML failures are anchored either on existing systems or on humans. [*Thought Experiments Provide a Third Anchor*](https://www.lesswrong.com/posts/tcyvthAkAtQ72P7Qd/thought-experiments-provide-a-third-anchor), and having three anchors is much better than having two, but each has its own weaknesses.\n3.  If we take thought experiments seriously, we end up predicting that [*ML Systems Will Have Weird Failure Modes*](https://www.lesswrong.com/posts/ncQoyxtqmBPLftwYR/ml-systems-will-have-weird-failure-modes). Some important failure modes of ML systems will not be present in any existing systems, and might manifest quickly enough that we can't safely wait for them to occur before addressing them.\n4.  My biggest disagreement with the Philosophy view is that I think [*Empirical Findings Generalize Surprisingly Far*](https://www.lesswrong.com/posts/ekFMGpsfhfWQzMW2h/empirical-findings-generalize-surprisingly-far), meaning that well-chosen experiments on current systems can tell us a lot about future systems."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "More Is Different for AI",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "AI Risk"
              }
            ]
          },
          {
            "title": "Future ML Systems Will Be Qualitatively Different",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Machine Learning  (ML)"
              }
            ]
          },
          {
            "title": "Thought Experiments Provide a Third Anchor",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "ML Systems Will Have Weird Failure Modes",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Machine Learning  (ML)"
              }
            ]
          },
          {
            "title": "Empirical Findings Generalize Surprisingly Far",
            "tags": [
              {
                "name": "AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "T9pBzinPXYB3mxSGi",
    "title": "Trends in Machine Learning",
    "curatedOrder": null,
    "contents": {
      "markdown": "In the last few decades the field of Machine Learning has seen rapid advances. More is to come in the next few decades. Understanding better what has happened and might happen will lead us to better AI governance and prioritization of AI risk.\n\nThis sequence is a compilation of publication from **Epoch**. We are researching trends in the inputs and performance of Machine Learning systems.\n\nOur core research program centers around trends in *parameters*, *compute* and *data*. This is motivated from [previous work on ML scaling](https://arxiv.org/abs/2001.08361), showing regular improvements in capabilities associated with these three factors.  \n\nWe are mantaining a [public dataset](https://ml-progress.com/data) of parameters, compute and data of milestone ML models. An [interactive visualization](https://ml-progress.com/visualization) is also available. We encourage other researchers to build on top of our work."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Compute Trends Across Three eras of Machine Learning",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Machine Learning  (ML)"
              },
              {
                "name": "Scaling Laws"
              },
              {
                "name": "Moore's Law"
              },
              {
                "name": "Technological Forecasting"
              }
            ]
          },
          {
            "title": "Parameter counts in Machine Learning",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Machine Learning  (ML)"
              },
              {
                "name": "Scaling Laws"
              }
            ]
          },
          {
            "title": "Estimating training compute of Deep Learning models",
            "tags": [
              {
                "name": "AI Capabilities"
              },
              {
                "name": "Scaling Laws"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "What’s the backward-forward FLOP ratio for Neural Networks?",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "AI Timelines"
              },
              {
                "name": "AI Capabilities"
              }
            ]
          },
          {
            "title": "How to measure FLOP/s for Neural Networks empirically?",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "AI Risk"
              },
              {
                "name": "AI Capabilities"
              },
              {
                "name": "Scaling Laws"
              }
            ]
          },
          {
            "title": "Projecting compute trends in Machine Learning",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "AI Timelines"
              },
              {
                "name": "Moore's Law"
              }
            ]
          },
          {
            "title": "Compute Trends — Comparison to OpenAI’s AI and Compute",
            "tags": [
              {
                "name": "Moore's Law"
              },
              {
                "name": "Scaling Laws"
              },
              {
                "name": "Machine Learning  (ML)"
              },
              {
                "name": "AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "KA9nQEGG6T5knX3Lq",
    "title": "Becoming Stronger as Epistemologist",
    "curatedOrder": null,
    "contents": {
      "markdown": "My two-month training to learn and build better epistemic tool for alignment research."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Becoming Stronger as Epistemologist: Introduction",
            "tags": [
              {
                "name": "Epistemology"
              },
              {
                "name": "AI"
              },
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "Intellectual Progress (Society-Level)"
              }
            ]
          },
          {
            "title": "An analogy as the midwife of thermodynamics",
            "tags": [
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "Intellectual Progress (Society-Level)"
              },
              {
                "name": "Physics"
              },
              {
                "name": "Epistemology"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "What The Foucault",
            "tags": [
              {
                "name": "Intellectual Progress (Society-Level)"
              },
              {
                "name": "Social & Cultural Dynamics"
              },
              {
                "name": "Epistemology"
              },
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "The Art and Science of Intuition Pumping",
            "tags": [
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "Intellectual Progress (Society-Level)"
              },
              {
                "name": "Intuition"
              },
              {
                "name": "Epistemology"
              }
            ]
          },
          {
            "title": "Scientific Wrestling: Beyond Passive Hypothesis-Testing",
            "tags": [
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "Chemistry"
              },
              {
                "name": "Biology"
              },
              {
                "name": "Experiments"
              }
            ]
          },
          {
            "title": "Shotgun Book Reviews: Against Method, The Knowledge Machine and Understanding Nature",
            "tags": [
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "Physics"
              },
              {
                "name": "Epistemology"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Replacing Natural Interpretations",
            "tags": [
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "Physics"
              },
              {
                "name": "Evolution"
              },
              {
                "name": "Quantum Mechanics"
              },
              {
                "name": "Epistemology"
              },
              {
                "name": "Intellectual Progress (Society-Level)"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "evLkoqsbi79AnM5sz",
    "title": "Intro to Naturalism",
    "curatedOrder": null,
    "contents": {
      "markdown": "Here is what will happen in this sequence: I will pick out the concepts that seem central to my understanding of naturalism; I will name them with words; and I will do my best to tell you what I mean by those words. My only goal in this sequence is to communicate what I mean by the sentence, “Knowing the territory takes patient and direct observation.”"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Intro to Naturalism: Orientation",
            "tags": [
              {
                "name": "Naturalism"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Cognitive Reduction"
              }
            ]
          },
          {
            "title": "Knowing",
            "tags": [
              {
                "name": "Naturalism"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "The Territory",
            "tags": [
              {
                "name": "Naturalism"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Map and Territory"
              }
            ]
          },
          {
            "title": "Interlude: On Realness",
            "tags": [
              {
                "name": "Naturalism"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Observation",
            "tags": [
              {
                "name": "Naturalism"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Direct Observation",
            "tags": [
              {
                "name": "Naturalism"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Patient Observation",
            "tags": [
              {
                "name": "Naturalism"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Naturalism",
            "tags": [
              {
                "name": "Naturalism"
              },
              {
                "name": "World Modeling"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "HMs2yT9D6LjYR5jQT",
    "title": "Fundamental Uncertainty: A Book",
    "curatedOrder": null,
    "contents": {
      "markdown": "I'm writing a book about fundamental uncertainty, aka the problem of the criterion. Here's where I'm sticking the chapters as I work on them as posts in public."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Fundamental Uncertainty: Prelude",
            "tags": [
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Fundamental Uncertainty: Chapter 2 - Why do words have meaning?",
            "tags": [
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Rationality"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "q2WQMoQSexx7xqqZR",
    "title": "Intuitive Introduction to Functional Decision Theory",
    "curatedOrder": null,
    "contents": {
      "markdown": "This sequence aims to explain Functional Decision Theory (FDT) in an intuitive way, with as little math as possible. The posts in this sequence heavily draw upon [Eliezer Yudkowsky](https://www.lesswrong.com/users/eliezer_yudkowsky) and [Nate Soares](https://www.lesswrong.com/users/so8res)' article [Functional Decision Theory: A New Theory of Instrumental Rationality](https://arxiv.org/abs/1710.05060). Although this article provides an excellent introduction to FDT, this sequence offers a more informal introduction, starting out with introducing Causal and Evidential Decision Theory and their shortcomings in order to show the strength of FDT."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Basic Concepts in Decision Theory",
            "tags": [
              {
                "name": "Decision Theory"
              }
            ]
          },
          {
            "title": "An Intuitive Introduction to Causal Decision Theory",
            "tags": [
              {
                "name": "Decision Theory"
              }
            ]
          },
          {
            "title": "An Intuitive Introduction to Evidential Decision Theory",
            "tags": [
              {
                "name": "Decision Theory"
              }
            ]
          },
          {
            "title": "An Intuitive Introduction to Functional Decision Theory",
            "tags": [
              {
                "name": "Decision Theory"
              },
              {
                "name": "Functional Decision Theory"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "Yt3Js2mjkxbZuHw5h",
    "title": "Making A Logical Language",
    "curatedOrder": null,
    "contents": {
      "markdown": "Documentation on my work-in-progress logical language, Sekko, and my reflections on the process of making it."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Why I want to make a logical language",
            "tags": [
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Phonology | Sekko",
            "tags": [
              {
                "name": "World Modeling"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "iWnHtRB5ucqPjjDmv",
    "title": "Paradigm-Building for AGI Safety Research",
    "curatedOrder": null,
    "contents": {
      "markdown": "This sequence introduces and defends an end-to-end theoretical framework for AGI safety research. Beginning with foundational principles in effective altruism, the framework moves hierarchically: it starts by formalizing the problem that AGI safety research intends to solve and proceeds to specify the progression of field-level questions that seem like they must be answered to solve the problem. This sequence is intended for new and seasoned researchers alike—my hope is that this report will help organize and streamline the individual efforts of safety researchers *and* facilitate crisper field-level communication, collaboration, and debate."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Paradigm-building: Introduction",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Community"
              },
              {
                "name": "Research Agendas"
              },
              {
                "name": "AI Risk"
              }
            ]
          },
          {
            "title": "Paradigm-building from first principles: Effective altruism, AGI, and alignment",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Community"
              },
              {
                "name": "Effective Altruism"
              },
              {
                "name": "Philosophy"
              },
              {
                "name": "AI Risk"
              },
              {
                "name": "Risks of Astronomical Suffering (S-risks)"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Paradigm-building: The hierarchical question framework",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Research Agendas"
              },
              {
                "name": "Community"
              }
            ]
          },
          {
            "title": "Question 1: Predicted architecture of AGI learning algorithm(s)",
            "tags": [
              {
                "name": "Reinforcement Learning"
              },
              {
                "name": "Machine Learning  (ML)"
              },
              {
                "name": "AI"
              },
              {
                "name": "Research Agendas"
              },
              {
                "name": "Superintelligence"
              }
            ]
          },
          {
            "title": "Question 2: Predicted bad outcomes of AGI learning architecture",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Research Agendas"
              },
              {
                "name": "Inner Alignment"
              },
              {
                "name": "Outer Alignment"
              },
              {
                "name": "Human Values"
              }
            ]
          },
          {
            "title": "Question 3: Control proposals for minimizing bad outcomes",
            "tags": [
              {
                "name": "Transparency / Interpretability (ML & AI)"
              },
              {
                "name": "Corrigibility"
              },
              {
                "name": "AI"
              },
              {
                "name": "Research Agendas"
              }
            ]
          },
          {
            "title": "Question 4: Implementing the control proposals",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Community Outreach"
              },
              {
                "name": "Incentives"
              },
              {
                "name": "Human Values"
              },
              {
                "name": "AI Governance"
              }
            ]
          },
          {
            "title": "Question 5: The timeline hyperparameter",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "AI Timelines"
              },
              {
                "name": "AI Takeoff"
              },
              {
                "name": "Satisficer"
              },
              {
                "name": "Research Agendas"
              }
            ]
          },
          {
            "title": "Paradigm-building: Conclusion and practical takeaways",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Research Agendas"
              },
              {
                "name": "Community"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "HzcM2dkCq7fwXBej8",
    "title": "Intro to Brain-Like-AGI Safety",
    "curatedOrder": null,
    "contents": {
      "markdown": "Suppose we someday build an Artificial General Intelligence algorithm using similar principles of learning and cognition as the human brain. How would we use such an algorithm safely?\n\nI will argue that this is an open technical problem, and my goal in this post series is to bring readers with no prior knowledge all the way up to the front-line of unsolved problems as I see them.\n\nIf this whole thing seems weird or stupid, you should start right in on [Post #1](https://www.alignmentforum.org/posts/4basF9w9jaPZpoC8R/intro-to-brain-like-agi-safety-1-what-s-the-problem-and-why), which contains definitions, background, and motivation. Then Posts [#2](https://www.alignmentforum.org/posts/wBHSYwqssBGCnwvHg/intro-to-brain-like-agi-safety-2-learning-from-scratch-in)–[#7](https://www.alignmentforum.org/posts/zXibERtEWpKuG5XAC/intro-to-brain-like-agi-safety-7-from-hardcoded-drives-to) are mainly neuroscience, and Posts [#8](https://www.alignmentforum.org/posts/fDPsYdDtkzhBp9A8D/intro-to-brain-like-agi-safety-8-takeaways-from-neuro-1-2-on)–[#15](https://www.alignmentforum.org/posts/tj8AC3vhTnBywdZoA/intro-to-brain-like-agi-safety-15-conclusion-open-problems-1) are more directly about AGI safety, ending with a list of open questions and advice for getting involved in the field.\n\n*(Thanks to Beth Barnes & the* [*EA Funds Donor Lottery program*](https://funds.effectivealtruism.org/donor-lottery) *for financial support. Thanks to the following people for critical comments on drafts: Adam Marblestone, Linda Linsefors, Justis Mills, Charlie Steiner, Maksym Taran, Adam Scholl, Aysja Johnson, Adam Shimi, Cameron Berg, Jacob Cannell, Oliver Daniels-Koch.)*"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "[Intro to brain-like-AGI safety] 1. What's the problem & Why work on it now?",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Neuromorphic AI"
              }
            ]
          },
          {
            "title": "[Intro to brain-like-AGI safety] 2. “Learning from scratch” in the brain",
            "tags": [
              {
                "name": "Neuroscience"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[Intro to brain-like-AGI safety] 3. Two subsystems: Learning & Steering",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Neuroscience"
              },
              {
                "name": "AI Timelines"
              }
            ]
          },
          {
            "title": "\n[Intro to brain-like-AGI safety] 4. The “short-term predictor”",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Neuromorphic AI"
              }
            ]
          },
          {
            "title": "[Intro to brain-like-AGI safety] 5. The “long-term predictor”, and TD learning",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Neuromorphic AI"
              },
              {
                "name": "Reinforcement Learning"
              }
            ]
          },
          {
            "title": "[Intro to brain-like-AGI safety] 6. Big picture of motivation, decision-making, and RL",
            "tags": [
              {
                "name": "Reinforcement Learning"
              },
              {
                "name": "AI"
              },
              {
                "name": "Neuromorphic AI"
              }
            ]
          },
          {
            "title": "[Intro to brain-like-AGI safety] 7. From hardcoded drives to foresighted plans: A worked example",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Neuromorphic AI"
              }
            ]
          },
          {
            "title": "[Intro to brain-like-AGI safety] 8. Takeaways from neuro 1/2: On AGI development",
            "tags": [
              {
                "name": "Neuromorphic AI"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[Intro to brain-like-AGI safety] 9. Takeaways from neuro 2/2: On AGI motivation",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "The Pointers Problem"
              },
              {
                "name": "Wireheading"
              },
              {
                "name": "Transparency / Interpretability (ML & AI)"
              }
            ]
          },
          {
            "title": "[Intro to brain-like-AGI safety] 10. The alignment problem",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Inner Alignment"
              },
              {
                "name": "Outer Alignment"
              },
              {
                "name": "Instrumental Convergence"
              },
              {
                "name": "Goodhart's Law"
              },
              {
                "name": "Wireheading"
              }
            ]
          },
          {
            "title": "[Intro to brain-like-AGI safety] 11. Safety ≠ alignment (but they’re close!)",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "AI Boxing (Containment)"
              },
              {
                "name": "Tool AI"
              }
            ]
          },
          {
            "title": "[Intro to brain-like-AGI safety] 12. Two paths forward: “Controlled AGI” and “Social-instinct AGI”",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[Intro to brain-like-AGI safety] 13. Symbol grounding & human social instincts",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Neuroscience"
              },
              {
                "name": "Symbol Grounding"
              }
            ]
          },
          {
            "title": " [Intro to brain-like-AGI safety] 14. Controlled AGI",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Conservatism (AI)"
              },
              {
                "name": "Corrigibility"
              }
            ]
          },
          {
            "title": "[Intro to brain-like-AGI safety] 15. Conclusion: Open problems, how to help, AMA",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Open Problems"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "nDjTh6xRPL23YSH6k",
    "title": "Mechanics of Tradecraft",
    "curatedOrder": null,
    "contents": {
      "markdown": "What kinds of organized criminal and paramilitary organizations exist? What are their capabilities? How do they form? How do they survive the pressure of law enforcement and militaries? What causes them to wither and die?"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "A non-magical explanation of Jeffrey Epstein",
            "tags": [
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Addendum: A non-magical explanation of Jeffrey Epstein",
            "tags": [
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Don't take the organizational chart literally",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "World Modeling"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "zYAL4KwSF2ZyoP4sK",
    "title": "True Stories",
    "curatedOrder": null,
    "contents": null,
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "[Book Review] \"Sorceror's Apprentice\" by Tahir Shah",
            "tags": [
              {
                "name": "Book Reviews"
              },
              {
                "name": "Practical"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Narratives (stories)"
              }
            ]
          },
          {
            "title": "Accelerated [Honors] Calculus",
            "tags": [
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Ten Minutes with Sam Altman",
            "tags": [
              {
                "name": "Narratives (stories)"
              },
              {
                "name": "Startups"
              }
            ]
          },
          {
            "title": "Where's my magic sword?",
            "tags": [
              {
                "name": "China"
              },
              {
                "name": "Narratives (stories)"
              },
              {
                "name": "Altruism"
              }
            ]
          },
          {
            "title": "The Machine that Broke My Heart",
            "tags": [
              {
                "name": "Narratives (stories)"
              },
              {
                "name": "Health / Medicine / Disease"
              },
              {
                "name": "Heroic Responsibility"
              }
            ]
          },
          {
            "title": "Training My Friend to Cook",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "Nutrition"
              },
              {
                "name": "Cooking"
              },
              {
                "name": "Habits"
              },
              {
                "name": "Reinforcement Learning"
              },
              {
                "name": "Well-being"
              },
              {
                "name": "Narratives (stories)"
              }
            ]
          },
          {
            "title": "All I Know is that I Know Nothing",
            "tags": [
              {
                "name": "Parables & Fables"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "April was weird",
            "tags": [
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "[Book Review] \"Heart of Darkness\" by Joseph Conrad",
            "tags": [
              {
                "name": "Book Reviews"
              },
              {
                "name": "World Modeling"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "o3XiwpF2YqnvFbQbK",
    "title": "Adversarial Strategy",
    "curatedOrder": null,
    "contents": null,
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Help your rivals when they are numerous",
            "tags": [
              {
                "name": "World Optimization"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Coordinating the Unequal Treaties",
            "tags": [
              {
                "name": "Coordination / Cooperation"
              },
              {
                "name": "Prisoner's Dilemma"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "First Strike and Second Strike",
            "tags": [
              {
                "name": "Coordination / Cooperation"
              },
              {
                "name": "War"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "[Prediction] What war between the USA and China would look like in 2050",
            "tags": [
              {
                "name": "War"
              },
              {
                "name": "China"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "The Future of Biological Warfare",
            "tags": [
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Postmodern Warfare",
            "tags": [
              {
                "name": "War"
              },
              {
                "name": "AI"
              },
              {
                "name": "Coordination / Cooperation"
              },
              {
                "name": "China"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Prediction Markets are for Outcomes Beyond Our Control",
            "tags": [
              {
                "name": "Prediction Markets"
              },
              {
                "name": "Betting"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Bet on Rare Undesirable Outcomes when Seeding a Prediction Market",
            "tags": [
              {
                "name": "Prediction Markets"
              },
              {
                "name": "Betting"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Your Enemies Can Use Your Prediction Markets Against You",
            "tags": [
              {
                "name": "Prediction Markets"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Using Prediction Markets to Guide Government Policy",
            "tags": [
              {
                "name": "Politics"
              },
              {
                "name": "Prediction Markets"
              },
              {
                "name": "World Optimization"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "ESrcNgmFkYCaAHMLv",
    "title": "Rationality",
    "curatedOrder": null,
    "contents": {
      "markdown": ""
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": []
      }
    ]
  },
  {
    "_id": "CDF4uBtZnef6TMpQ6",
    "title": "Independent AI Research ",
    "curatedOrder": null,
    "contents": {
      "markdown": "I'm trying my hand at independent AI research. Here are my collected posts about it.\n\n*(Banner image source:* [*https://www.flickr.com/photos/fdecomite/3237967443/*](https://www.flickr.com/photos/fdecomite/3237967443/) *licensed under creative commons)*"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Modelling and Understanding SGD",
            "tags": [
              {
                "name": "Machine Learning  (ML)"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "SGD Understood through Probability Current",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Hypotheses about Finding Knowledge and One-Shot Causal Entanglements",
            "tags": [
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Knowledge Localization: Tentatively Positive Results on OCR",
            "tags": [
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Defining Optimization in a Deeper Way Part 1",
            "tags": [
              {
                "name": "Optimization"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Defining Optimization in a Deeper Way Part 2",
            "tags": [
              {
                "name": "Optimization"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Defining Optimization in a Deeper Way Part 3",
            "tags": [
              {
                "name": "Optimization"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Defining Optimization in a Deeper Way Part 4",
            "tags": [
              {
                "name": "Optimization"
              },
              {
                "name": "AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "FN5Gj4JM6Xr7F4vts",
    "title": "My Overview of the AI Alignment Landscape",
    "curatedOrder": null,
    "contents": null,
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "My Overview of the AI Alignment Landscape: A Bird's Eye View",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Inner Alignment"
              },
              {
                "name": "Outer Alignment"
              },
              {
                "name": "Transparency / Interpretability (ML & AI)"
              },
              {
                "name": "AI Risk"
              },
              {
                "name": "Existential Risk"
              },
              {
                "name": "Threat Models"
              },
              {
                "name": "AI Timelines"
              },
              {
                "name": "AI Takeoff"
              },
              {
                "name": "Coordination / Cooperation"
              },
              {
                "name": "Iterated Amplification "
              },
              {
                "name": "Debate (AI safety technique)"
              }
            ]
          },
          {
            "title": "My Overview of the AI Alignment Landscape: Threat Models",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Inner Alignment"
              },
              {
                "name": "Outer Alignment"
              },
              {
                "name": "Coordination / Cooperation"
              },
              {
                "name": "Goodhart's Law"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "AI Risk"
              },
              {
                "name": "Existential Risk"
              },
              {
                "name": "Threat Models"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "tDBYJd4p6EorGLEFA",
    "title": "ML Alignment Theory Scholars Program Winter 2021",
    "curatedOrder": null,
    "contents": null,
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": "In the past six weeks, the Stanford Existential Risks Initiative (SERI) has been running a work trial for the “ML Alignment Theory Scholars” (MATS) program. Our goal is to increase the number of people working on alignment theory, and to do this, we’re running a scholars program that provides mentorship, funding, and community to promising new alignment theorists. This program is run in partnership with Evan Hubinger, who has been providing all of the mentorship to each of the scholars for their work trial.\n\nAs the final phase of the work trial, each participant has taken a previous research artifact (usually an Alignment Forum post) and written a distillation and expansion of that post. The posts were picked by Evan and each participant signed up for one they were interested in. **Within the next two weeks (12/7 - 12/17), we’ll be posting all of these posts to lesswrong and the alignment forum as part of a sequence, with a couple of posts going up each day.** (There will be around 10-15 posts total.)"
        },
        "posts": [
          {
            "title": "ML Alignment Theory Program under Evan Hubinger",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Project Announcement"
              }
            ]
          },
          {
            "title": "Theoretical Neuroscience For Alignment Theory",
            "tags": [
              {
                "name": "Neuroscience"
              },
              {
                "name": "Inner Alignment"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Introduction to inaccessible information",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Transparency / Interpretability (ML & AI)"
              }
            ]
          },
          {
            "title": "Understanding Gradient Hacking",
            "tags": [
              {
                "name": "Inner Alignment"
              },
              {
                "name": "Gradient Hacking"
              },
              {
                "name": "Optimization"
              },
              {
                "name": "AI"
              },
              {
                "name": "Mesa-Optimization"
              }
            ]
          },
          {
            "title": "Understanding and controlling auto-induced distributional shift",
            "tags": [
              {
                "name": "Machine Learning  (ML)"
              },
              {
                "name": "AI"
              },
              {
                "name": "Myopia"
              }
            ]
          },
          {
            "title": "The Natural Abstraction Hypothesis: Implications and Evidence",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Abstraction"
              },
              {
                "name": "Transparency / Interpretability (ML & AI)"
              }
            ]
          },
          {
            "title": "Should we rely on the speed prior for safety?",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Motivations, Natural Selection, and Curriculum Engineering",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Mesa-Optimization"
              },
              {
                "name": "Evolution"
              },
              {
                "name": "Adaptation Executors"
              },
              {
                "name": "General Intelligence"
              },
              {
                "name": "Corrigibility"
              }
            ]
          },
          {
            "title": "Universality and the “Filter”",
            "tags": [
              {
                "name": "AI Risk"
              },
              {
                "name": "AI"
              },
              {
                "name": "Humans Consulting HCH"
              }
            ]
          },
          {
            "title": "Evidence Sets: Towards Inductive-Biases based Analysis of Prosaic AGI",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Adversarial Examples"
              },
              {
                "name": "Machine Learning  (ML)"
              },
              {
                "name": "Inner Alignment"
              },
              {
                "name": "Language Models"
              }
            ]
          },
          {
            "title": "Disentangling Perspectives On Strategy-Stealing in AI Safety",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Existential Risk"
              }
            ]
          },
          {
            "title": "Don't Influence the Influencers!",
            "tags": [
              {
                "name": "AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "aek5ksSs2FHTeofsf",
    "title": "Agency: What it is and why it matters",
    "curatedOrder": null,
    "contents": {
      "markdown": "This sequence explains my take on agency. The first post is the intro + overview.\n\nETA: I'm deprioritizing completing this sequence because it seems that other people are writing good similar stuff. In particular, see e.g. [https://www.lesswrong.com/posts/kpPnReyBC54KESiSn/optimality-is-the-tiger-and-agents-are-its-teeth](https://www.lesswrong.com/posts/kpPnReyBC54KESiSn/optimality-is-the-tiger-and-agents-are-its-teeth) and [https://www.lesswrong.com/posts/pdJQYxCy29d7qYZxG/agency-and-coherence](https://www.lesswrong.com/posts/pdJQYxCy29d7qYZxG/agency-and-coherence)"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Agency: What it is and why it matters",
            "tags": [
              {
                "name": "Agency"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "P₂B: Plan to P₂B Better",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Goal-Directedness"
              },
              {
                "name": "Instrumental Convergence"
              },
              {
                "name": "Practical"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Agents as P₂B Chain Reactions",
            "tags": [
              {
                "name": "Agency"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Interlude: Agents as Automobiles",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Gradations of Agency",
            "tags": [
              {
                "name": "Agency"
              },
              {
                "name": "Robust Agents"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Why agents are powerful",
            "tags": [
              {
                "name": "Agency"
              },
              {
                "name": "AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "dxCZoP3TDaB8Acwjo",
    "title": "Failure",
    "curatedOrder": null,
    "contents": {
      "markdown": "The fourth book is about failure. It’s what happens when a system behaves differently from how we expected it to, with adverse consequences for those who were relying on the success of that system. Failure is often as much about misunderstanding how a system works, as it is about the lack of effort or plan to  \nbring the system into a successful configuration.\n\nAlmost nothing humans build ever works on the first try. Failure is part of almost any successful endeavor, whether it’s an engineer trying to build a successful rocket engine, a CEO trying to build a successful organization, or a scientist trying  \nto discover a new mathematical formalism that accurately describes some phenomena.\n\nThis book will cover three primary facets of failure: How to avoid it, how to recover from it, and how to learn from it. \n\nThe worst failures of all are the kind that you can neither recover nor learn from. The ones that put a permanent end to your attempts at solving the problem you are aiming to solve. This book puts a special emphasis on that kind of failure."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "The Parable of Predict-O-Matic",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Myopia"
              },
              {
                "name": "Oracle AI"
              },
              {
                "name": "Parables & Fables"
              },
              {
                "name": "Self Fulfilling/Refuting Prophecies"
              }
            ]
          },
          {
            "title": "Blackmail",
            "tags": [
              {
                "name": "Blackmail / Extortion"
              }
            ]
          },
          {
            "title": "Bioinfohazards",
            "tags": [
              {
                "name": "Biology"
              },
              {
                "name": "Information Hazards"
              },
              {
                "name": "Existential Risk"
              }
            ]
          },
          {
            "title": "What failure looks like",
            "tags": [
              {
                "name": "World Optimization"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "AI"
              },
              {
                "name": "AI Risk"
              },
              {
                "name": "Threat Models"
              },
              {
                "name": "AI Takeoff"
              }
            ]
          },
          {
            "title": "AI Safety \"Success Stories\"",
            "tags": [
              {
                "name": "AI Risk"
              },
              {
                "name": "AI Success Models"
              }
            ]
          },
          {
            "title": "Reframing Impact",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Impact Measures"
              },
              {
                "name": "Exercises / Problem-Sets"
              }
            ]
          },
          {
            "title": "The strategy-stealing assumption",
            "tags": [
              {
                "name": "AI Risk"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Is Rationalist Self-Improvement Real?",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Life Improvements"
              },
              {
                "name": "Value of Rationality"
              }
            ]
          },
          {
            "title": "The Curse Of The Counterfactual",
            "tags": [
              {
                "name": "Akrasia"
              },
              {
                "name": "Mind Projection Fallacy"
              },
              {
                "name": "Sunk-Cost Fallacy"
              },
              {
                "name": "Emotions"
              },
              {
                "name": "Map and Territory"
              },
              {
                "name": "Counterfactuals"
              },
              {
                "name": "Memory Reconsolidation"
              }
            ]
          },
          {
            "title": "human psycholinguists: a critical appraisal",
            "tags": [
              {
                "name": "AI Timelines"
              },
              {
                "name": "AI Takeoff"
              },
              {
                "name": "AI"
              },
              {
                "name": "GPT"
              }
            ]
          },
          {
            "title": "[Answer] Why wasn't science invented in China?",
            "tags": [
              {
                "name": "History"
              },
              {
                "name": "Progress Studies"
              },
              {
                "name": "Industrial Revolution"
              },
              {
                "name": "Intellectual Progress (Society-Level)"
              },
              {
                "name": "China"
              }
            ]
          },
          {
            "title": "Make more land",
            "tags": [
              {
                "name": "Physics"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Rest Days vs Recovery Days",
            "tags": [
              {
                "name": "Well-being"
              },
              {
                "name": "Sabbath"
              },
              {
                "name": "Slack"
              },
              {
                "name": "Distinctions"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "SgomvxZ3cJWy2SBCu",
    "title": "Modularity",
    "curatedOrder": null,
    "contents": {
      "markdown": "The second book is about modularity. Well designed or evolved structures are often not just made of parts, but made of parts with simple interfaces. These interfaces allow the parts to be reused in alternative contexts, and thus recombined in different ways.\n\nOne of the most important benefits is inspection and debugging. Modular systems are easier to understand, because their components are self-contained. However, this can also be a curse; when components have boundaries that are simple relative to their internals, they cannot share all of their information with the other components, which can lead to communication and coordination failures.\n\nThe essays in this collection have been split into four clusters, to make them easier to and and remember. This book contains essays related to modularity, both as a thing that we engineer, and as a thing that we discover in the world.\n\nThis book will explore modularized systems through topics such as biology, machine learning, companies, human emotion, and more."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Book Review: Design Principles of Biological Circuits",
            "tags": [
              {
                "name": "Biology"
              },
              {
                "name": "Book Reviews"
              },
              {
                "name": "Gears-Level"
              },
              {
                "name": "Updated Beliefs (examples of)"
              }
            ]
          },
          {
            "title": "Reframing Superintelligence: Comprehensive AI Services as General Intelligence",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "General Intelligence"
              },
              {
                "name": "AI Services (CAIS)"
              },
              {
                "name": "Narrow AI"
              }
            ]
          },
          {
            "title": "Building up to an Internal Family Systems model",
            "tags": [
              {
                "name": "Motivations"
              },
              {
                "name": "Subagents"
              },
              {
                "name": "Emotions"
              },
              {
                "name": "Therapy"
              },
              {
                "name": "Internal Family Systems"
              }
            ]
          },
          {
            "title": "Being the (Pareto) Best in the World",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Efficient Market Hypothesis"
              },
              {
                "name": "Careers"
              }
            ]
          },
          {
            "title": "The Schelling Choice is \"Rabbit\", not \"Stag\"",
            "tags": [
              {
                "name": "Game Theory"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Stag Hunt"
              }
            ]
          },
          {
            "title": "Literature Review: Distributed Teams",
            "tags": [
              {
                "name": "Productivity"
              },
              {
                "name": "Literature Reviews"
              }
            ]
          },
          {
            "title": "Gears-Level Models are Capital Investments",
            "tags": [
              {
                "name": "Gears-Level"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Evolution of Modularity",
            "tags": [
              {
                "name": "Evolution"
              },
              {
                "name": "Biology"
              },
              {
                "name": "Gears-Level"
              },
              {
                "name": "Modularity"
              }
            ]
          },
          {
            "title": "You Get About Five Words",
            "tags": [
              {
                "name": "Public Discourse"
              },
              {
                "name": "Common Knowledge"
              }
            ]
          },
          {
            "title": "Coherent decisions imply consistent utilities",
            "tags": [
              {
                "name": "Utility Functions"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Coherence Arguments"
              }
            ]
          },
          {
            "title": "Alignment Research Field Guide",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "Social & Cultural Dynamics"
              },
              {
                "name": "Community"
              },
              {
                "name": "Intellectual Progress (Individual-Level)"
              }
            ]
          },
          {
            "title": "Forum participation as a research strategy",
            "tags": [
              {
                "name": "Scholarship & Learning"
              },
              {
                "name": "Intellectual Progress via LessWrong"
              },
              {
                "name": "Intellectual Progress (Individual-Level)"
              }
            ]
          },
          {
            "title": "The Credit Assignment Problem",
            "tags": [
              {
                "name": "Myopia"
              },
              {
                "name": "Optimization"
              }
            ]
          },
          {
            "title": "Selection vs Control",
            "tags": [
              {
                "name": "Optimization"
              },
              {
                "name": "Adaptation Executors"
              },
              {
                "name": "Distinctions"
              },
              {
                "name": "Selection vs Control"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "FoaLfnrZGGGMdcAoF",
    "title": "Incentives",
    "curatedOrder": null,
    "contents": {
      "markdown": "The third book is about incentives, which are the patterns of what is rewarded and what is punished.\n\nThe dynamics of what is incentivized and disincentivized in a group is a primary force in determining how that group behaves. When those incentives are aligned with what the individuals actually want, the output can be far greater than the sum of the parts; when they are misaligned with what the individuals want, the results can be far worse than what any individual in the group would ever choose themselves. \n\nIt is also a perspective to help with understanding one’s own actions, why one is not acting in line with one’s reflected goals, and how to change the path of least resistance for yourself (or other agents).\n\nIf we can't see the effects of incentives, many parts of the world will confuse us. The essays in this book will apply this lens to a number of different parts of the world with the goal of better understanding them.\n\nThe authors of these essays all participated in a community that awards social status for writing and for insight, and their essays were then selected by a quadratic-voting procedure."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Asymmetric Justice",
            "tags": [
              {
                "name": "Heroic Responsibility"
              },
              {
                "name": "Incentives"
              },
              {
                "name": "Ethics & Morality"
              }
            ]
          },
          {
            "title": "Unconscious Economics",
            "tags": [
              {
                "name": "Economics"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Power Buys You Distance From The Crime",
            "tags": [
              {
                "name": "Moral Mazes"
              },
              {
                "name": "Incentives"
              }
            ]
          },
          {
            "title": "Seeking Power is Often Convergently Instrumental in MDPs",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Instrumental Convergence"
              },
              {
                "name": "Myopia"
              }
            ]
          },
          {
            "title": "Yes Requires the Possibility of No\n",
            "tags": [
              {
                "name": "Conservation of Expected Evidence"
              },
              {
                "name": "Filtered Evidence"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Internal Double Crux"
              },
              {
                "name": "Principles"
              }
            ]
          },
          {
            "title": "Mistakes with Conservation of Expected Evidence",
            "tags": [
              {
                "name": "Conservation of Expected Evidence"
              },
              {
                "name": "Hansonian Pre-Rationality"
              },
              {
                "name": "Pitfalls of Rationality"
              },
              {
                "name": "Rationalization"
              },
              {
                "name": "Inside/Outside View"
              },
              {
                "name": "Humility"
              },
              {
                "name": "Anthropics"
              }
            ]
          },
          {
            "title": "Heads I Win, Tails?—Never Heard of Her; Or, Selective Reporting and the Tragedy of the Green Rationalists",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Politics"
              },
              {
                "name": "Filtered Evidence"
              },
              {
                "name": "Blues & Greens (metaphor)"
              },
              {
                "name": "Group Rationality"
              },
              {
                "name": "Censorship"
              }
            ]
          },
          {
            "title": "Excerpts from a larger discussion about simulacra",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Simulacrum Levels"
              }
            ]
          },
          {
            "title": "Moloch Hasn’t Won",
            "tags": [
              {
                "name": "Game Theory"
              },
              {
                "name": "Mechanism Design"
              },
              {
                "name": "Moloch"
              },
              {
                "name": "Moral Mazes"
              }
            ]
          },
          {
            "title": "Integrity and accountability are core parts of rationality",
            "tags": [
              {
                "name": "Honesty"
              },
              {
                "name": "Motivated Reasoning"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "The Real Rules Have No Exceptions",
            "tags": [
              {
                "name": "Deontology"
              },
              {
                "name": "Planning & Decision-Making"
              },
              {
                "name": "Social Reality"
              }
            ]
          },
          {
            "title": "Simple Rules of Law",
            "tags": [
              {
                "name": "Politics"
              },
              {
                "name": "Government"
              },
              {
                "name": "Mechanism Design"
              }
            ]
          },
          {
            "title": "The Amish, and Strategic Norms around Technology",
            "tags": [
              {
                "name": "Book Reviews"
              }
            ]
          },
          {
            "title": "Risks from Learned Optimization: Introduction",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Mesa-Optimization"
              },
              {
                "name": "Optimization"
              },
              {
                "name": "Inner Alignment"
              },
              {
                "name": "Outer Alignment"
              },
              {
                "name": "AI Risk"
              }
            ]
          },
          {
            "title": "Gradient hacking",
            "tags": [
              {
                "name": "Mesa-Optimization"
              },
              {
                "name": "Inner Alignment"
              },
              {
                "name": "Transparency / Interpretability (ML & AI)"
              },
              {
                "name": "AI"
              },
              {
                "name": "Gradient Hacking"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "LqKeFpoxTpHiPdzXh",
    "title": "NFT as a Digital Art",
    "curatedOrder": null,
    "contents": {
      "markdown": "I recently learned about the NFT token and its use in art. I was so interested in this article that I decided to find out all about it. I advise everyone to read this article on [Bytechats](https://bytechats.info/blogs/nft-as-a-digital-art/)."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": []
      }
    ]
  },
  {
    "_id": "vLArRpNdkex68oem8",
    "title": "Thoughts on Corrigibility",
    "curatedOrder": null,
    "contents": {
      "markdown": "My writings on different kinds of corrigibility. These thoughts build on each other and form part of my alignment worldview, but they are not yet woven into a coherent narrative."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Non-Obstruction: A Simple Concept Motivating Corrigibility",
            "tags": [
              {
                "name": "Corrigibility"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Corrigibility as outside view",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Corrigibility"
              },
              {
                "name": "Inside/Outside View"
              }
            ]
          },
          {
            "title": "Corrigibility Can Be VNM-Incoherent",
            "tags": [
              {
                "name": "Corrigibility"
              },
              {
                "name": "Instrumental Convergence"
              },
              {
                "name": "AI"
              },
              {
                "name": "Open Problems"
              }
            ]
          },
          {
            "title": "Formalizing Policy-Modification Corrigibility",
            "tags": [
              {
                "name": "Corrigibility"
              },
              {
                "name": "AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "g72vrjJSJSZnqBrKx",
    "title": "Trust",
    "curatedOrder": null,
    "contents": {
      "markdown": "The first book is about trust, the belief in something in the absence of understanding.\n\nThe Royal Society was founded in 1660, with the motto Nullius in Verba, \"On No One's Word\". The promise of science was that it would be a method for discovering truth without needing to trust anyone: because experiments can and would be replicated, incorrect theories and incorrect information would be !ltered out. By exploring systems that could be understood in full, scientists eventually made breakthroughs in our understanding of every part of the natural world.\n\nYou might hope that this sort of understanding can be expanded further — that you could come to understand every part of the world, look inside to see how it works, and personally arrive at true beliefs about it. This hope would be wrong. To understand everything in the world would take an amount of time many orders of magnitude more than historical human lifespans.\n\nIn place of being able to understand any system, we have its lowly sibling, trust. Can I believe what this paper is telling me, when I don't have time to replicate its results or even read every page? Can I trust my emotions when I don’t know where they come from? Some code on StackExchange I haven’t read?\n\nA trained machine learning system off-distribution? These are questions where we can't feasibly get a repeatable, replicable setup. The essays in this book explore the judgments we make about how to decide which sources to trust, when building our models of the world and acting upon it."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Rule Thinkers In, Not Out",
            "tags": [
              {
                "name": "Epistemology"
              },
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "History"
              },
              {
                "name": "Affect Heuristic"
              },
              {
                "name": "Distinctions"
              }
            ]
          },
          {
            "title": "Gears vs Behavior",
            "tags": [
              {
                "name": "Gears-Level"
              },
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "Probability & Statistics"
              },
              {
                "name": "Distinctions"
              }
            ]
          },
          {
            "title": "Book Review: The Secret Of Our Success",
            "tags": [
              {
                "name": "Book Reviews"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Religion"
              },
              {
                "name": "Cultural knowledge"
              }
            ]
          },
          {
            "title": "Reason isn't magic",
            "tags": [
              {
                "name": "Cultural knowledge"
              }
            ]
          },
          {
            "title": "\"Other people are wrong\" vs \"I am right\"",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Updated Beliefs (examples of)"
              },
              {
                "name": "Chesterton's Fence"
              },
              {
                "name": "Distinctions"
              }
            ]
          },
          {
            "title": "In My Culture",
            "tags": [
              {
                "name": "Inferential Distance"
              },
              {
                "name": "Conversation (topic)"
              },
              {
                "name": "Social & Cultural Dynamics"
              }
            ]
          },
          {
            "title": "Chris Olah’s views on AGI safety",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Transparency / Interpretability (ML & AI)"
              },
              {
                "name": "OpenAI"
              }
            ]
          },
          {
            "title": "Understanding “Deep Double Descent”",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Machine Learning  (ML)"
              },
              {
                "name": "Lottery Ticket Hypothesis"
              }
            ]
          },
          {
            "title": "How to Ignore Your Emotions (while also thinking you're awesome at emotions)",
            "tags": [
              {
                "name": "Emotions"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Growth Stories"
              }
            ]
          },
          {
            "title": "Paper-Reading for Gears",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Scholarship & Learning"
              },
              {
                "name": "Gears-Level"
              },
              {
                "name": "Intellectual Progress (Individual-Level)"
              }
            ]
          },
          {
            "title": "Book summary: Unlocking the Emotional Brain",
            "tags": [
              {
                "name": "Book Reviews"
              },
              {
                "name": "Subagents"
              },
              {
                "name": "Emotions"
              },
              {
                "name": "Neuroscience"
              },
              {
                "name": "Internal Double Crux"
              },
              {
                "name": "Alief"
              },
              {
                "name": "Motivations"
              },
              {
                "name": "Summaries"
              },
              {
                "name": "Memory Reconsolidation"
              },
              {
                "name": "Cached Thoughts"
              },
              {
                "name": "Therapy"
              },
              {
                "name": "Internal Family Systems"
              }
            ]
          },
          {
            "title": "Noticing Frame Differences",
            "tags": [
              {
                "name": "Noticing"
              },
              {
                "name": "Conversation (topic)"
              },
              {
                "name": "Disagreement"
              },
              {
                "name": "Distinctions"
              },
              {
                "name": "Frames"
              }
            ]
          },
          {
            "title": "Propagating Facts into Aesthetics",
            "tags": [
              {
                "name": "Aesthetics"
              }
            ]
          },
          {
            "title": "Do you fear the rock or the hard place?",
            "tags": [
              {
                "name": "Tribalism"
              },
              {
                "name": "Disagreement"
              },
              {
                "name": "Conversation (topic)"
              }
            ]
          },
          {
            "title": "Mental Mountains",
            "tags": [
              {
                "name": "Subagents"
              },
              {
                "name": "Emotions"
              },
              {
                "name": "Book Reviews"
              },
              {
                "name": "Psychotropics"
              },
              {
                "name": "Therapy"
              },
              {
                "name": "Internal Family Systems"
              }
            ]
          },
          {
            "title": "Steelmanning Divination",
            "tags": [
              {
                "name": "Steelmanning"
              },
              {
                "name": "Cultural knowledge"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "BckmPkLNFsdpmhNgg",
    "title": "Choosing a crypto exchange",
    "curatedOrder": null,
    "contents": {
      "markdown": "I recently read on the Internet about this exchanger and decided to read a review of it on [Bytechats](https://bytechats.info/reviews/eclipcoin/). This is the highest quality review I’ve ever read on crypto. Anyone interested in cryptocurrencies and platforms for working with them, I recommend you visit this site!"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": []
      }
    ]
  },
  {
    "_id": "wEefod8jTLgJMm4yc",
    "title": "Ray's Rough Rationality Sequence",
    "curatedOrder": null,
    "contents": null,
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Double Crux — A Strategy for Mutual Understanding",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Anticipated Experiences"
              },
              {
                "name": "Techniques"
              },
              {
                "name": "Disagreement"
              },
              {
                "name": "Double-Crux"
              },
              {
                "name": "Falsifiability"
              }
            ]
          },
          {
            "title": "The Basic Double Crux pattern",
            "tags": [
              {
                "name": "Double-Crux"
              },
              {
                "name": "Disagreement"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Noticing Frame Differences",
            "tags": [
              {
                "name": "Noticing"
              },
              {
                "name": "Conversation (topic)"
              },
              {
                "name": "Disagreement"
              },
              {
                "name": "Distinctions"
              },
              {
                "name": "Frames"
              }
            ]
          },
          {
            "title": "Propagating Facts into Aesthetics",
            "tags": [
              {
                "name": "Aesthetics"
              }
            ]
          },
          {
            "title": "The Costly Coordination Mechanism of Common Knowledge",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Common Knowledge"
              },
              {
                "name": "Game Theory"
              },
              {
                "name": "Mechanism Design"
              },
              {
                "name": "Coordination / Cooperation"
              }
            ]
          },
          {
            "title": "Being a Robust Agent",
            "tags": [
              {
                "name": "Robust Agents"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Agency"
              }
            ]
          },
          {
            "title": "A Sketch of Good Communication",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Conversation (topic)"
              },
              {
                "name": "Anticipated Experiences"
              }
            ]
          },
          {
            "title": "Toolbox-thinking and Law-thinking",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Law-Thinking"
              },
              {
                "name": "Distinctions"
              }
            ]
          },
          {
            "title": "Babble",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Poetry"
              },
              {
                "name": "Babble and Prune"
              }
            ]
          },
          {
            "title": "More Babble",
            "tags": [
              {
                "name": "Babble and Prune"
              }
            ]
          },
          {
            "title": "Prune",
            "tags": [
              {
                "name": "Babble and Prune"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Subagents"
              }
            ]
          },
          {
            "title": "Heads I Win, Tails?—Never Heard of Her; Or, Selective Reporting and the Tragedy of the Green Rationalists",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Politics"
              },
              {
                "name": "Filtered Evidence"
              },
              {
                "name": "Blues & Greens (metaphor)"
              },
              {
                "name": "Group Rationality"
              },
              {
                "name": "Censorship"
              }
            ]
          },
          {
            "title": "The Schelling Choice is \"Rabbit\", not \"Stag\"",
            "tags": [
              {
                "name": "Game Theory"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Stag Hunt"
              }
            ]
          },
          {
            "title": "Being the (Pareto) Best in the World",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Efficient Market Hypothesis"
              },
              {
                "name": "Careers"
              }
            ]
          },
          {
            "title": "You Get About Five Words",
            "tags": [
              {
                "name": "Public Discourse"
              },
              {
                "name": "Common Knowledge"
              }
            ]
          },
          {
            "title": "Humans Who Are Not Concentrating Are Not General Intelligences",
            "tags": [
              {
                "name": "GPT"
              },
              {
                "name": "AI"
              },
              {
                "name": "General Intelligence"
              }
            ]
          },
          {
            "title": "Yes Requires the Possibility of No\n",
            "tags": [
              {
                "name": "Conservation of Expected Evidence"
              },
              {
                "name": "Filtered Evidence"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Internal Double Crux"
              },
              {
                "name": "Principles"
              }
            ]
          }
        ]
      },
      {
        "title": "Alignment (But Also Rationality)",
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Robustness to Scale",
            "tags": [
              {
                "name": "Robust Agents"
              },
              {
                "name": "AI"
              },
              {
                "name": "AI Robustness"
              }
            ]
          },
          {
            "title": "Embedded Agents",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Research Agendas"
              },
              {
                "name": "Embedded Agency"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "n945eovrA3oDueqtq",
    "title": "2021 MIRI Conversations",
    "curatedOrder": 400,
    "contents": {
      "markdown": "This sequence is a (chronological) series of chatroom conversation logs about artificial general intelligence. A large number of topics are covered, beginning with conversations related to alignment difficulty.\n\nShort summaries of each post, and links to audio versions, are available [here](https://intelligence.org/late-2021-miri-conversations/). There are also two related posts released shortly before this sequence:\n\n*   [Discussion with Eliezer Yudkowsky on AGI Interventions](https://www.lesswrong.com/posts/CpvyhFy9WvCNsifkY/discussion-with-eliezer-yudkowsky-on-agi-interventions)\n*   [Comments \\[by Nate Soares\\] on Joe Carlsmith's \"Is power-seeking AI an existential risk?\"](https://www.lesswrong.com/posts/cCMihiwtZx7kdcKgt/comments-on-carlsmith-s-is-power-seeking-ai-an-existential)\n\nRob Bensinger edited and posted this sequence, and Matthew Graves helped with much of the formatting.\n\n⠀"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": "Part One   (Primarily Richard Ngo and Eliezer Yudkowsky)"
        },
        "posts": [
          {
            "title": "Ngo and Yudkowsky on alignment difficulty",
            "tags": [
              {
                "name": "AI Risk"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Ngo and Yudkowsky on AI capability gains",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Recursive Self-Improvement"
              },
              {
                "name": "AI Takeoff"
              },
              {
                "name": "Utility Functions"
              },
              {
                "name": "Optimization"
              },
              {
                "name": "Effective Altruism"
              },
              {
                "name": "Modest Epistemology"
              },
              {
                "name": "AI Governance"
              }
            ]
          },
          {
            "title": "Yudkowsky and Christiano discuss \"Takeoff Speeds\"",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "AI Takeoff"
              },
              {
                "name": "AI Timelines"
              },
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "General Intelligence"
              },
              {
                "name": "Inside/Outside View"
              }
            ]
          },
          {
            "title": "Soares, Tallinn, and Yudkowsky discuss AGI cognition",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "General Intelligence"
              },
              {
                "name": "AI Takeoff"
              },
              {
                "name": "Treacherous Turn"
              }
            ]
          }
        ]
      },
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": "Part Two   (Primarily Paul Christiano and Eliezer Yudkowsky)"
        },
        "posts": [
          {
            "title": "Christiano, Cotra, and Yudkowsky on AI progress",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "Technological Forecasting"
              },
              {
                "name": "AI Takeoff"
              },
              {
                "name": "AI Timelines"
              },
              {
                "name": "Inside/Outside View"
              }
            ]
          },
          {
            "title": "Biology-Inspired AGI Timelines: The Trick That Never Works",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "AI Timelines"
              },
              {
                "name": "Dialogue (format)"
              },
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "Technological Forecasting"
              },
              {
                "name": "History"
              }
            ]
          },
          {
            "title": "Reply to Eliezer on Biological Anchors",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Shulman and Yudkowsky on AI progress",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "AI Timelines"
              },
              {
                "name": "AI Takeoff"
              }
            ]
          },
          {
            "title": "More Christiano, Cotra, and Yudkowsky on AI progress",
            "tags": [
              {
                "name": "AI Timelines"
              },
              {
                "name": "AI"
              },
              {
                "name": "AI Takeoff"
              },
              {
                "name": "Technological Forecasting"
              },
              {
                "name": "Double-Crux"
              }
            ]
          },
          {
            "title": "Conversation on technology forecasting and gradualism",
            "tags": [
              {
                "name": "Technological Forecasting"
              },
              {
                "name": "AI Timelines"
              },
              {
                "name": "AI Takeoff"
              },
              {
                "name": "Progress Studies"
              }
            ]
          }
        ]
      },
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": "Part Three  (Varied Participants)"
        },
        "posts": [
          {
            "title": "Ngo's view on alignment difficulty",
            "tags": [
              {
                "name": "AI Governance"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Ngo and Yudkowsky on scientific reasoning and pivotal acts",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "General Intelligence"
              }
            ]
          },
          {
            "title": "Christiano and Yudkowsky on AI predictions and human intelligence",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Shah and Yudkowsky on alignment failures",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Late 2021 MIRI Conversations: AMA / Discussion",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "AMA"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "gn7MJrCNeehzDW9LT",
    "title": "Choosing a cryptocurrency platform",
    "curatedOrder": null,
    "contents": {
      "markdown": "I recently read on the Internet about this exchanger and decided to read a review of it on [Bytechats](https://bytechats.info/reviews/eclipcoin/). This is the highest quality review I’ve ever read on crypto. Anyone interested in cryptocurrencies and platforms for working with them, I recommend you visit this site!"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": []
      }
    ]
  },
  {
    "_id": "skRvz2mmvhLwhHbaN",
    "title": "Curiosity",
    "curatedOrder": null,
    "contents": {
      "markdown": "*\"A burning itch to know is higher than a solemn vow to pursue truth.\"*\n\nThis fourth book is about curiosity, which is the desire to understand how some corner of the world works. \n\nCuriosity is diving into Wikipedia. It’s running a survey to get data from your friends. It’s dropping balls from different heights and measuring how long they take to fall. Empiricism, scholarship, googling, introspection, data-gathering, science: all these are examples of the curious impulse in action. Applying one’s thinking and reasoning and finding out how the damn thing works, for no other reason than that you want to know.\n\nThere are many motives that subvert the pursuit of truth, and there are many motives that will mostly seek truth but sometimes defend lies for some greater purpose. Curiosity does not have these flaws. This is why it is the first virtue of  \nrationality.\n\nThis is not a book of essays about curiosity, but rather a book of essays exemplifying it. The authors were curious about something, they set out to explore it, and they wrote down what they learned for the rest of us. Of all the essays in this  \nbook set, these are the most wide-ranging in nature."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Is Science Slowing Down?",
            "tags": [
              {
                "name": "Progress Studies"
              },
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "Intellectual Progress (Society-Level)"
              },
              {
                "name": "Stagnation"
              }
            ]
          },
          {
            "title": "Research: Rescuers during the Holocaust",
            "tags": [
              {
                "name": "History"
              },
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "Altruism"
              }
            ]
          },
          {
            "title": "An Untrollable Mathematician",
            "tags": []
          },
          {
            "title": "Why did everything take so long?",
            "tags": [
              {
                "name": "Progress Studies"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Intellectual Progress (Society-Level)"
              }
            ]
          },
          {
            "title": "Is Clickbait Destroying Our General Intelligence?",
            "tags": [
              {
                "name": "Goodhart's Law"
              },
              {
                "name": "Superstimuli"
              },
              {
                "name": "General Intelligence"
              },
              {
                "name": "Public Discourse"
              },
              {
                "name": "Memetics"
              }
            ]
          },
          {
            "title": "What makes people intellectually active?",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Scholarship & Learning"
              },
              {
                "name": "Intellectual Progress (Society-Level)"
              },
              {
                "name": "Progress Studies"
              },
              {
                "name": "Intellectual Progress (Individual-Level)"
              }
            ]
          },
          {
            "title": "Open question: are minimal circuits daemon-free?",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Inner Alignment"
              },
              {
                "name": "Mesa-Optimization"
              },
              {
                "name": "Open Problems"
              }
            ]
          },
          {
            "title": "Beyond Astronomical Waste",
            "tags": [
              {
                "name": "Simulation Hypothesis"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Astronomical Waste"
              }
            ]
          },
          {
            "title": "Historical mathematicians exhibit a birth order effect too",
            "tags": [
              {
                "name": "Biology"
              },
              {
                "name": "IQ and g-factor"
              },
              {
                "name": "Developmental Psychology"
              },
              {
                "name": "Human Genetics"
              }
            ]
          },
          {
            "title": "Birth order effect found in Nobel Laureates in Physics",
            "tags": [
              {
                "name": "Developmental Psychology"
              },
              {
                "name": "IQ and g-factor"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "JdAfXBx4gS3DjN5s6",
    "title": "Coordination",
    "curatedOrder": null,
    "contents": {
      "markdown": "*\"Indeed. Moving from bad equilibria to better equilibria is the whole point of having a civilization in the first place.\"*\n\nCoordination is the ability of multiple agents to work together.\n\nThis is the difficult question of how to work with other agents in the world, and how to have healthy reasoning and decision-making processes within a group.\n\nIf many agents in a group are working on different projects, how do we decide on resource allocation between those projects? If many agents in a group believe different theories about some subject like chemistry or machine learning, how do we use that information to inform our own beliefs about these topics? If many agents in a group want different things, how do we set collective priorities?\n\nThese are all deep questions that functional groups must answer, and this book will explore."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Anti-social Punishment",
            "tags": [
              {
                "name": "Game Theory"
              },
              {
                "name": "Mechanism Design"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Social & Cultural Dynamics"
              }
            ]
          },
          {
            "title": "The Costly Coordination Mechanism of Common Knowledge",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Common Knowledge"
              },
              {
                "name": "Game Theory"
              },
              {
                "name": "Mechanism Design"
              },
              {
                "name": "Coordination / Cooperation"
              }
            ]
          },
          {
            "title": "The Intelligent Social Web",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Social Reality"
              },
              {
                "name": "Relationships (Interpersonal)"
              },
              {
                "name": "Identity"
              },
              {
                "name": "Social & Cultural Dynamics"
              },
              {
                "name": "Social Status"
              },
              {
                "name": "Narratives (stories)"
              }
            ]
          },
          {
            "title": "Prediction Markets: When Do They Work?",
            "tags": [
              {
                "name": "Prediction Markets"
              }
            ]
          },
          {
            "title": "Spaghetti Towers",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Programming"
              },
              {
                "name": "Definitions"
              },
              {
                "name": "Coordination / Cooperation"
              }
            ]
          },
          {
            "title": "On the Loss and Preservation of Knowledge",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Progress Studies"
              },
              {
                "name": "Cultural knowledge"
              },
              {
                "name": "Intellectual Progress (Society-Level)"
              }
            ]
          },
          {
            "title": "A voting theory primer for rationalists",
            "tags": [
              {
                "name": "Voting Theory"
              },
              {
                "name": "Mechanism Design"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "The Pavlov Strategy",
            "tags": [
              {
                "name": "Game Theory"
              },
              {
                "name": "Prisoner's Dilemma"
              }
            ]
          },
          {
            "title": "Inadequate Equilibria vs. Governance of the Commons",
            "tags": [
              {
                "name": "Economics"
              },
              {
                "name": "Coordination / Cooperation"
              },
              {
                "name": "Mechanism Design"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "bjewXnagXTjeGPtHx",
    "title": "Agency",
    "curatedOrder": null,
    "contents": {
      "markdown": "*A mind must be created already in motion.*  \n*There is no argument so compelling*  \n*that it will give dynamics to a static thing.*  \n*There is no computer program so persuasive*  \n*that you can run it on a rock.*\n\nThis second book is about agency, the ability to take action in the world and control the future.\n\nThere’s something very strange about being human. We do not have a single simple goal, but rather a weird amalgam of desires and wants that evolution hacked together for some entirely unrelated purpose. We can introspect on our thoughts and feelings to an extent, but at some point our mind bottoms out in individual neurons firing or chemicals bonding or quarks moving.\n\nWe would like to live with fire in our hearts, and rise to the virtues of honesty, courage and integrity. But it is unclear how they can be grounded in the cold-seeming math of decision-making.\n\nThese are challenges we face as humans – beings with agency in the world. As we awaken more fully to our abilities and limitations, it is up to us to come to understand ourselves and reshape ourselves into the force in the world that we would, on reflection, like to be.\n\nThis book will explore some of these challenges."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Noticing the Taste of Lotus",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Noticing"
              },
              {
                "name": "Goodhart's Law"
              },
              {
                "name": "Motivations"
              }
            ]
          },
          {
            "title": "The Tails Coming Apart As Metaphor For Life",
            "tags": [
              {
                "name": "Probability & Statistics"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Meta-Honesty: Firming Up Honesty Around Its Edge-Cases",
            "tags": [
              {
                "name": "Meta-Honesty"
              },
              {
                "name": "Honesty"
              }
            ]
          },
          {
            "title": "My attempt to explain Looking, insight meditation, and enlightenment in non-mysterious terms",
            "tags": [
              {
                "name": "Meditation"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Alief"
              },
              {
                "name": "Introspection"
              },
              {
                "name": "Cognitive Fusion"
              }
            ]
          },
          {
            "title": "Being a Robust Agent",
            "tags": [
              {
                "name": "Robust Agents"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Agency"
              }
            ]
          },
          {
            "title": "Anti-social Punishment",
            "tags": [
              {
                "name": "Game Theory"
              },
              {
                "name": "Mechanism Design"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Social & Cultural Dynamics"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "Pavm47mqgjDAF7XYT",
    "title": "Epistemology",
    "curatedOrder": null,
    "contents": {
      "markdown": "This first book is about epistemology, the study of how we come to know the world.\n\nA healthy epistemology is not only about avoiding sins like self-deception and obfuscation. It is also about living out virtues like curiosity and empiricism, and taking active steps to dissolve confusion and see the world more clearly over time.\n\nWe do not understand how many parts of reality work. We also have many motives to not look directly at it or obscure it from others. Yet we humans are able to understand and fix a broken kitchen sink, build valuable products, and invent highly predictive theories of physics.\n\nFrom practical heuristics to idealized cognitive algorithms, this book is about these types of thinking. Thinking that helps us understand the world, and helps us build a map that reflects the territory."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "A Sketch of Good Communication",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Conversation (topic)"
              },
              {
                "name": "Anticipated Experiences"
              }
            ]
          },
          {
            "title": "Babble",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Poetry"
              },
              {
                "name": "Babble and Prune"
              }
            ]
          },
          {
            "title": "Local Validity as a Key to Sanity and Civilization",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Common Knowledge"
              },
              {
                "name": "Public Discourse"
              },
              {
                "name": "Epistemology"
              },
              {
                "name": "Gears-Level"
              }
            ]
          },
          {
            "title": "The Loudest Alarm Is Probably False",
            "tags": [
              {
                "name": "Self-Deception"
              },
              {
                "name": "Introspection"
              }
            ]
          },
          {
            "title": "Varieties Of Argumentative Experience",
            "tags": [
              {
                "name": "Disagreement"
              }
            ]
          },
          {
            "title": "More Babble",
            "tags": [
              {
                "name": "Babble and Prune"
              }
            ]
          },
          {
            "title": "Naming the Nameless",
            "tags": [
              {
                "name": "Aesthetics"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "The SF Bay Area"
              },
              {
                "name": "Social Status"
              },
              {
                "name": "UI Design"
              },
              {
                "name": "Politics"
              }
            ]
          },
          {
            "title": "Toolbox-thinking and Law-thinking",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Law-Thinking"
              },
              {
                "name": "Distinctions"
              }
            ]
          },
          {
            "title": "Prune",
            "tags": [
              {
                "name": "Babble and Prune"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Subagents"
              }
            ]
          },
          {
            "title": "Towards a New Impact Measure",
            "tags": [
              {
                "name": "Impact Measures"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "QyQcBpSur9SFyRuvB",
    "title": "Alignment",
    "curatedOrder": null,
    "contents": {
      "markdown": "This fifth book is about alignment, the problem of aligning the thoughts and goals of artificial intelligences with those of humans.\n\nThis relates to the art of human rationality in two ways.\n\nFirst, the laws of reasoning and decision-making apply similarly to all agents, whether they are human or artificial. Many of the deepest insights about rationality at LessWrong have come directly from users’ attempts to grapple with the problem of understanding and aligning artificial intelligences.\n\nSecond, the design of AI is a topic that a rational agent in the present day will have a natural interest in. This technology is of great leverage at this point in history – that is, the period in which we are actively developing it. In the words of I.J. Good “the first ultraintelligent machine is the last invention that man need ever make”.\n\nFor the reader who is not well-versed in the discussion around how to align powerful AI systems, treat the essays in this book as a collection of letters between scientists in a field you are not part of. While there will be terms that are not fully explained, authors will attempt to speak plainly, make honest efforts to convey the structure of their arguments, and to convey the most abstract and philosophical ideas, hand-drawn cartoons will be their mode of communication."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Arguments about fast takeoff",
            "tags": [
              {
                "name": "AI Takeoff"
              }
            ]
          },
          {
            "title": "Specification gaming examples in AI",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Goodhart's Law"
              },
              {
                "name": "AI Risk"
              }
            ]
          },
          {
            "title": "The Rocket Alignment Problem",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Fiction"
              },
              {
                "name": "Machine Intelligence Research Institute (MIRI)"
              },
              {
                "name": "Dialogue (format)"
              },
              {
                "name": "Agent Foundations"
              }
            ]
          },
          {
            "title": "Embedded Agents",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Research Agendas"
              },
              {
                "name": "Embedded Agency"
              }
            ]
          },
          {
            "title": "Paul's research agenda FAQ",
            "tags": [
              {
                "name": "Research Agendas"
              },
              {
                "name": "Iterated Amplification "
              },
              {
                "name": "Humans Consulting HCH"
              },
              {
                "name": "Q&A (format)"
              }
            ]
          },
          {
            "title": "Challenges to Christiano’s capability amplification proposal",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Iterated Amplification "
              }
            ]
          },
          {
            "title": "Robustness to Scale",
            "tags": [
              {
                "name": "Robust Agents"
              },
              {
                "name": "AI"
              },
              {
                "name": "AI Robustness"
              }
            ]
          },
          {
            "title": "Coherence arguments do not entail goal-directed behavior",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Utility Functions"
              },
              {
                "name": "Value Learning"
              },
              {
                "name": "Goal-Directedness"
              },
              {
                "name": "Coherence Arguments"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "geAekf56iuNqcafWZ",
    "title": "How to Write",
    "curatedOrder": null,
    "contents": null,
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Three Principles to Writing Original Nonfiction",
            "tags": [
              {
                "name": "Writing (communication method)"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Start with a Title",
            "tags": [
              {
                "name": "Writing (communication method)"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Death by a Single Cut",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Double-Crux"
              }
            ]
          },
          {
            "title": "Write Surprisingly About Reality",
            "tags": [
              {
                "name": "Writing (communication method)"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Tell the Truth",
            "tags": [
              {
                "name": "Writing (communication method)"
              }
            ]
          },
          {
            "title": "Contrarian Writing Advice",
            "tags": [
              {
                "name": "Writing (communication method)"
              }
            ]
          },
          {
            "title": "Blog Respectably",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "Writing (communication method)"
              }
            ]
          },
          {
            "title": "Business Writing Example #1",
            "tags": [
              {
                "name": "Writing (communication method)"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Marketing"
              }
            ]
          },
          {
            "title": "Business Writing Example #2",
            "tags": [
              {
                "name": "Writing (communication method)"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Creative nonfiction training exercises",
            "tags": [
              {
                "name": "Exercises / Problem-Sets"
              },
              {
                "name": "Rationality"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "Tp3ryR4AxY56ctGh2",
    "title": "Open Philanthropy 2021 AI Alignment RFP",
    "curatedOrder": null,
    "contents": {
      "markdown": "This is a sequence version of Open Philanthropy's [request for proposals for projects in AI alignment that work with deep learning systems.](https://www.openphilanthropy.org/focus/global-catastrophic-risks/potential-risks-advanced-artificial-intelligence/request-for-proposals-for-projects-in-ai-alignment-that-work-with-deep-learning-systems)"
    },
    "chapters": [
      {
        "title": "Request and application process",
        "subtitle": null,
        "number": 0,
        "contents": null,
        "posts": [
          {
            "title": "Request for proposals for projects in AI alignment that work with deep learning systems",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Grants & Fundraising Opportunities"
              }
            ]
          }
        ]
      },
      {
        "title": "Research directions",
        "subtitle": null,
        "number": 1,
        "contents": null,
        "posts": [
          {
            "title": "Measuring and forecasting risks",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Techniques for enhancing human feedback",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Interpretability",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Truthful and honest AI",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Language Models"
              },
              {
                "name": "AI Risk"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "LLEJJoaYpCoS5JYSY",
    "title": "Epistemic Cookbook for Alignment",
    "curatedOrder": null,
    "contents": {
      "markdown": "Sequence of post analyzing the [epistemic strategies](https://www.alignmentforum.org/posts/FQqcejhNWGG8vHDch/on-solving-problems-before-they-appear-the-weird) of specific alignment research results."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "On Solving Problems Before They Appear: The Weird Epistemologies of Alignment",
            "tags": [
              {
                "name": "AI Risk"
              },
              {
                "name": "Epistemology"
              },
              {
                "name": "Intellectual Progress (Society-Level)"
              },
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Epistemic Strategies of Selection Theorems",
            "tags": [
              {
                "name": "Epistemology"
              },
              {
                "name": "Epistemic Review"
              },
              {
                "name": "AI Risk"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Selection Effects"
              },
              {
                "name": "Intellectual Progress (Individual-Level)"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Epistemic Strategies of Safety-Capabilities Tradeoffs",
            "tags": [
              {
                "name": "Tradeoffs"
              },
              {
                "name": "AI Risk"
              },
              {
                "name": "AI Capabilities"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Interpreting Yudkowsky on Deep vs Shallow Knowledge",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "AI Capabilities"
              }
            ]
          },
          {
            "title": "Redwood's Technique-Focused Epistemic Strategy",
            "tags": [
              {
                "name": "Redwood Research"
              },
              {
                "name": "AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "uPjHAiXAKrMzvTFyt",
    "title": "Why Everyone (Else) Is a Hypocrite: Evolution and the Modular Mind",
    "curatedOrder": null,
    "contents": {
      "markdown": "An (unfinished) sequence presenting material from Robert Kurzban's book [*Why Everyone (Else) Is a Hypocrite: Evolution and the Modular Mind*](http://www.amazon.com/Why-Everyone-Else-Hypocrite-Evolution/dp/0691146748)*.*"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Consistently Inconsistent",
            "tags": [
              {
                "name": "Subagents"
              },
              {
                "name": "Compartmentalization"
              }
            ]
          },
          {
            "title": "Modularity and Buzzy",
            "tags": [
              {
                "name": "Evolution"
              },
              {
                "name": "Book Reviews"
              },
              {
                "name": "Modularity"
              }
            ]
          },
          {
            "title": "Strategic ignorance and plausible deniability",
            "tags": [
              {
                "name": "Game Theory"
              },
              {
                "name": "Self-Deception"
              },
              {
                "name": "Subagents"
              },
              {
                "name": "Motivations"
              },
              {
                "name": "Motivated Reasoning"
              }
            ]
          },
          {
            "title": "Modularity, signaling, and belief in belief",
            "tags": [
              {
                "name": "Modularity"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "bJi3hd8E8qjBeHz9Z",
    "title": "Transformative AI and Compute",
    "curatedOrder": null,
    "contents": {
      "markdown": "Modern progress in AI systems has been driven and enabled mainly by acquiring more computational resources. AI systems rely on computation-intensive training runs — they require massive amounts of *compute*.\n\nLearning about the compute requirements for training existing AI systems and their capabilities allows us to get a more nuanced understanding and take appropriate action within the technical and governance domain to enable a safe development of potential transformative AI systems.\n\nTo understand the role of compute, I decided to (a) do a literature review, (b) update existing work with new data, (c) investigate the role of compute for timelines, and lastly, (d) explore concepts to enhance our analysis and forecasting efforts.\n\nIn this sequence, I present a brief analysis of AI systems’ compute requirements and capabilities, explore compute’s role for transformative AI timelines, and lastly, discuss the compute governance domain."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Transformative AI and Compute [Summary]",
            "tags": [
              {
                "name": "Moore's Law"
              },
              {
                "name": "AI Timelines"
              },
              {
                "name": "Transformative AI"
              },
              {
                "name": "Scaling Laws"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "What is Compute? - Transformative AI and Compute [1/4]",
            "tags": [
              {
                "name": "Moore's Law"
              },
              {
                "name": "AI Timelines"
              },
              {
                "name": "Transformative AI"
              },
              {
                "name": "AI"
              },
              {
                "name": "Scaling Laws"
              }
            ]
          },
          {
            "title": "Forecasting Compute - Transformative AI and Compute [2/4]",
            "tags": [
              {
                "name": "AI Timelines"
              },
              {
                "name": "Moore's Law"
              },
              {
                "name": "Scaling Laws"
              },
              {
                "name": "Transformative AI"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Compute Governance and Conclusions - Transformative AI and Compute [3/4]",
            "tags": [
              {
                "name": "AI Timelines"
              },
              {
                "name": "Moore's Law"
              },
              {
                "name": "Scaling Laws"
              },
              {
                "name": "AI Governance"
              },
              {
                "name": "Transformative AI"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Compute Research Questions and Metrics - Transformative AI and Compute [4/4]",
            "tags": [
              {
                "name": "AI Timelines"
              },
              {
                "name": "Scaling Laws"
              },
              {
                "name": "Transformative AI"
              },
              {
                "name": "Moore's Law"
              },
              {
                "name": "Technological Forecasting"
              },
              {
                "name": "AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "xujLGRKFLKsPCTimd",
    "title": "AI Safety Subprojects",
    "curatedOrder": null,
    "contents": {
      "markdown": "There are the AI safety subprojects designed for elucidating \"model splintering\" and \"learning the preferences of irrational agents\"."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Immobile AI makes a move: anti-wireheading, ontology change, and model splintering",
            "tags": [
              {
                "name": "Research Agendas"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "AI, learn to be conservative, then learn to be less so: reducing side-effects, learning preserved features, and going beyond conservatism",
            "tags": [
              {
                "name": "Research Agendas"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "AI learns betrayal and how to avoid it",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Research Agendas"
              },
              {
                "name": "Treacherous Turn"
              }
            ]
          },
          {
            "title": "Force neural nets to use models, then detect these",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Preferences from (real and hypothetical) psychology papers",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Machine Learning  (ML)"
              }
            ]
          },
          {
            "title": "Finding the multiple ground truths of CoinRun and image classification",
            "tags": [
              {
                "name": "AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "3yFQvrNd6C2cY7tG4",
    "title": "Gravity Turn",
    "curatedOrder": null,
    "contents": {
      "markdown": "Reflections on graduate school in mathematics."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Gravity Turn",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Careers"
              },
              {
                "name": "Intellectual Progress (Society-Level)"
              },
              {
                "name": "Education"
              }
            ]
          },
          {
            "title": "Where do your eyes go?",
            "tags": [
              {
                "name": "Scholarship & Learning"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Gaming (videogames/tabletop)"
              },
              {
                "name": "Skill Building"
              },
              {
                "name": "Attention"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "MCYqCMTsDHbn3kcKg",
    "title": "The Coordination Frontier",
    "curatedOrder": null,
    "contents": null,
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "The Coordination Frontier: Sequence Intro",
            "tags": [
              {
                "name": "World Optimization"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Coordination / Cooperation"
              }
            ]
          },
          {
            "title": "Coordination Schemes Are Capital Investments",
            "tags": [
              {
                "name": "Coordination / Cooperation"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Norm Innovation and Theory of Mind",
            "tags": [
              {
                "name": "Coordination / Cooperation"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Coordination Motivation: The Pandemic",
            "tags": [
              {
                "name": "Coordination / Cooperation"
              }
            ]
          },
          {
            "title": "Coordination Skills I Wish I Had For the Pandemic",
            "tags": [
              {
                "name": "Coordination / Cooperation"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Practical"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "CXJTAqQXdEqWNkjqj",
    "title": "Meetup Advice",
    "curatedOrder": null,
    "contents": {
      "markdown": "Work in progress: A compendium of advice on running a rationality meetup."
    },
    "chapters": [
      {
        "title": "Meetup Advice Sequence",
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": "A writeup of advice given by hundreds of meetup organizers and attendees"
        },
        "posts": [
          {
            "title": "Meetup Advice #0: Sequence intro",
            "tags": [
              {
                "name": "Community"
              },
              {
                "name": "Meetups & Local Communities (topic)"
              }
            ]
          },
          {
            "title": "Meetup Advice #1: Choosing a venue",
            "tags": [
              {
                "name": "Meetups & Local Communities (topic)"
              },
              {
                "name": "Community"
              }
            ]
          }
        ]
      },
      {
        "title": "Other resources",
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": "A curated collection of others' advice on running meetups."
        },
        "posts": [
          {
            "title": "Meetup Cookbook",
            "tags": [
              {
                "name": "Meetups & Local Communities (topic)"
              }
            ]
          },
          {
            "title": "Building a Community Institution In Five Hours A Week",
            "tags": [
              {
                "name": "Meetups & Local Communities (topic)"
              }
            ]
          },
          {
            "title": "How to Run a Successful Less Wrong Meetup",
            "tags": [
              {
                "name": "Meetups & Local Communities (topic)"
              }
            ]
          },
          {
            "title": "Less Wrong NYC: Case Study of a Successful Rationalist Chapter",
            "tags": [
              {
                "name": "Community"
              },
              {
                "name": "Meetups & Local Communities (topic)"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Group Rationality"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "eF4JeviJaraMijtXb",
    "title": "Meetup Theorizing",
    "curatedOrder": null,
    "contents": {
      "markdown": "I've been involved in global meetup coordination in some capacity since 2017. I've surveyed and interviewed meetup organizers from all over the world, and over time have built up fairly broad theoretical knowledge of rationality meetups in general. This is a collection of writing I've done on the topic so far, hopefully soon to be followed by a more structured and intentional sequence on meetup organization."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "SlateStarCodex Meetups Everywhere: Analysis",
            "tags": [
              {
                "name": "Postmortems & Retrospectives"
              },
              {
                "name": "Meetups & Local Communities (topic)"
              }
            ]
          },
          {
            "title": "What Are Meetups Actually Trying to Accomplish?",
            "tags": [
              {
                "name": "Community"
              },
              {
                "name": "Meetups & Local Communities (topic)"
              }
            ]
          },
          {
            "title": "Meetups as Institutions for Intellectual Progress",
            "tags": [
              {
                "name": "Community"
              },
              {
                "name": "Meetups & Local Communities (topic)"
              },
              {
                "name": "Intellectual Progress (Society-Level)"
              },
              {
                "name": "Intellectual Progress (Individual-Level)"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "gDiScDuMrWNpzwNSJ",
    "title": "D&D.Sci",
    "curatedOrder": null,
    "contents": {
      "markdown": "A series of Data Science and Analysis challenges, presented as decision problems in a fantasy setting.\n\nNote: This sequence collects all D&D.Sci scenarios I made which both can and should be replayed. It *doesn't* include [Return of the Gray Swan](https://www.lesswrong.com/posts/ycG3mrtdqddCkK9et/d-and-d-sci-pathfinder-return-of-the-gray-swan) (because that was created by someone else), [Interdimensional Monster Carcass Auction](https://www.lesswrong.com/posts/kmZjtuo4Gzv5WhTTX/a-d-and-d-sci-may-2021-interdimensional-monster-carcass) (because that was a one-time event), or [Mancer Matchups](https://www.lesswrong.com/posts/pTB58QeNkDMKPjAiv/d-and-d-sci-iii-mancer-matchups) (because that wasn't up to my standards)."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "D&D.Sci",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Exercises / Problem-Sets"
              },
              {
                "name": "D&D.Sci"
              },
              {
                "name": "Games (posts describing)"
              }
            ]
          },
          {
            "title": "D&D.Sci Evaluation and Ruleset",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "D&D.Sci"
              }
            ]
          },
          {
            "title": "D&D.Sci II: The Sorceror's Personal Shopper",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Exercises / Problem-Sets"
              },
              {
                "name": "D&D.Sci"
              }
            ]
          },
          {
            "title": "D&D.Sci II Evaluation and Ruleset",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "D&D.Sci"
              }
            ]
          },
          {
            "title": "D&D.Sci April 2021: Voyages of the Gray Swan",
            "tags": [
              {
                "name": "Exercises / Problem-Sets"
              },
              {
                "name": "D&D.Sci"
              }
            ]
          },
          {
            "title": "D&D.Sci April 2021 Evaluation and Ruleset",
            "tags": [
              {
                "name": "Exercises / Problem-Sets"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "D&D.Sci"
              }
            ]
          },
          {
            "title": "D&D.Sci May 2021: Monster Carcass Auction",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Exercises / Problem-Sets"
              },
              {
                "name": "D&D.Sci"
              }
            ]
          },
          {
            "title": "D&D.Sci May 2021 Evaluation and Ruleset",
            "tags": [
              {
                "name": "D&D.Sci"
              }
            ]
          },
          {
            "title": "D&D.Sci(-Fi) June 2021: The Duel with Earwax",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Exercises / Problem-Sets"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "D&D.Sci"
              },
              {
                "name": "Games (posts describing)"
              }
            ]
          },
          {
            "title": "D&D.Sci(-Fi) June 2021 Evaluation and Ruleset",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "D&D.Sci"
              }
            ]
          },
          {
            "title": "D&D.Sci August 2021: The Oracle and the Monk",
            "tags": [
              {
                "name": "Exercises / Problem-Sets"
              },
              {
                "name": "Games (posts describing)"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "D&D.Sci"
              }
            ]
          },
          {
            "title": "D&D.Sci August 2021 Evaluation and Ruleset",
            "tags": [
              {
                "name": "D&D.Sci"
              },
              {
                "name": "Exercises / Problem-Sets"
              },
              {
                "name": "Rationality"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "yYxggfHYRrqnJXuRx",
    "title": "The Most Important Century",
    "curatedOrder": null,
    "contents": {
      "markdown": "I think we have good reason to believe that the **21st century could be the most important century ever for humanity.** I think the most likely way this would happen would be via the development of advanced AI systems that lead to explosive growth and scientific advancement, getting us more quickly than most people imagine to a deeply unfamiliar future.\n\nA bit more specifically,[**^1^**](https://www.lesswrong.com/posts/yHzDrTCum4rdNRDJJ/the-most-important-century-sequence-introduction?commentId=k7Fy2PF5z7kGxbxSP) I think there is a good chance that:\n\n1.  During the century we're in right now, we will develop technologies that cause us to transition to a state in which humans as we know them are no longer the main force in world events. This is our last chance to shape how that transition happens.\n2.  Whatever the main force in world events is (perhaps digital people, misaligned AI, or something else) will create highly stable civilizations that populate our entire galaxy for billions of years to come. The transition taking place this century could shape all of that.\n\nI think it's very unclear whether this would be a good or bad thing. What matters is that it could go a lot of different ways, and we have a chance to affect that.\n\nI believe the above possibility doesn't get enough attention, discussion, or investment, particularly from people whose goal is to make the world better. By writing about it, I'd like to either help change that, or gain more opportunities to get criticized and change my mind."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": " The Most Important Century: Sequence Introduction",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "All Possible Views About Humanity's Future Are Wild",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Space Exploration & Colonization"
              }
            ]
          },
          {
            "title": "The Duplicator: Instant Cloning Would Make the World Economy Explode",
            "tags": [
              {
                "name": "Economics"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Digital People Would Be An Even Bigger Deal",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Digital People FAQ",
            "tags": [
              {
                "name": "World Optimization"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "This Can't Go On",
            "tags": [
              {
                "name": "Economics"
              },
              {
                "name": "Existential Risk"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Forecasting Transformative AI, Part 1: What Kind of AI?",
            "tags": [
              {
                "name": "Transformative AI"
              },
              {
                "name": "Progress Studies"
              },
              {
                "name": "AI"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "World Optimization"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "ZnSMHcWjRx6yT4H92",
    "title": "LessWrong Political Prerequisites",
    "curatedOrder": 101,
    "contents": {
      "markdown": "Politics is a hard subject to discuss rationally. Correspondingly, LessWrong has a developed a unique set of norms and habits around discussions politics that still allow for dialog while hopefully avoiding many pitfalls. The exact norms are hard to summarize, but approximately they are:\n\n*   Read this sequence of posts before discussing politics on LessWrong.\n*   Generally, be extra careful and charitable when discussing politics.\n*   Recent news-driven\" posts (which includes much mainstream politics) will generally not be given much visibility. Moderators don't promote them to the Frontpage, so only longtime LessWrong readers are likely to see them when browsing the site.\n*   If you're a new user who came specifically to weigh in on some recent political discourse, I recommend instead focusing on other topics until you've gotten a better feel for LessWrong discussion culture."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Politics is the Mind-Killer",
            "tags": [
              {
                "name": "Politics"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Tribalism"
              },
              {
                "name": "Social & Cultural Dynamics"
              }
            ]
          },
          {
            "title": "Policy Debates Should Not Appear One-Sided",
            "tags": [
              {
                "name": "Politics"
              },
              {
                "name": "Libertarianism"
              },
              {
                "name": "Conflict vs Mistake"
              }
            ]
          },
          {
            "title": "The Scales of Justice, the Notebook of Rationality",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Affect Heuristic"
              }
            ]
          },
          {
            "title": "Correspondence Bias",
            "tags": [
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Motivations"
              },
              {
                "name": "Correspondence Bias"
              }
            ]
          },
          {
            "title": "Are Your Enemies Innately Evil?",
            "tags": [
              {
                "name": "Politics"
              },
              {
                "name": "Motivations"
              },
              {
                "name": "Social & Cultural Dynamics"
              },
              {
                "name": "Correspondence Bias"
              }
            ]
          },
          {
            "title": "Reversed Stupidity Is Not Intelligence",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Epistemology"
              },
              {
                "name": "Principles"
              },
              {
                "name": "Reversed Stupidity Is Not Intelligence"
              },
              {
                "name": "Distinctions"
              },
              {
                "name": "Steelmanning"
              }
            ]
          },
          {
            "title": "Argument Screens Off Authority",
            "tags": [
              {
                "name": "Epistemology"
              },
              {
                "name": "Social Status"
              }
            ]
          },
          {
            "title": "Hug the Query",
            "tags": [
              {
                "name": "Anticipated Experiences"
              }
            ]
          },
          {
            "title": "Rationality and the English Language",
            "tags": [
              {
                "name": "Writing (communication method)"
              },
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Human Evil and Muddled Thinking",
            "tags": [
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Politics is hard mode",
            "tags": [
              {
                "name": "Politics"
              },
              {
                "name": "Public Discourse"
              },
              {
                "name": "Tribalism"
              },
              {
                "name": "Community"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "aJvgWxkCBWpHpXti4",
    "title": "Reducing Goodhart",
    "curatedOrder": null,
    "contents": null,
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Introduction to Reducing Goodhart",
            "tags": [
              {
                "name": "Goodhart's Law"
              },
              {
                "name": "Value Learning"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Competent Preferences",
            "tags": [
              {
                "name": "Goodhart's Law"
              },
              {
                "name": "Modeling People"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Goodhart Ethology",
            "tags": [
              {
                "name": "Goodhart's Law"
              },
              {
                "name": "AI"
              },
              {
                "name": "Value Learning"
              }
            ]
          },
          {
            "title": "Models Modeling Models",
            "tags": [
              {
                "name": "Goodhart's Law"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Goodhart: Endgame",
            "tags": [
              {
                "name": "AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "Fu7Euu3F96rKhFRWH",
    "title": "Framing Practicum",
    "curatedOrder": null,
    "contents": {
      "markdown": "Much of the value I get from math is not from detailed calculations or elaborate models, but rather from *framing tools*: tools which suggest useful questions to ask, approximations to make, what to pay attention to and what to ignore.\n\nEach of these posts is meant to train/practice one mathematical framing tool.\n\nThe structure is like a [trigger-action pattern](https://www.lesswrong.com/tag/trigger-action-planning): the hard part is to notice a pattern, a place where a particular tool can apply (the “trigger”). Once we notice the pattern, it suggests certain questions or approximations (the “action”). Each of these posts contains a Challenge to ingrain the abstract trigger-pattern, and a Bonus Exercise to practice applying the actions.\n\nThe hope is that practicing these tools will help us notice useful frames for [problems we don’t understand](https://www.lesswrong.com/posts/CSZnj2YNMKGfsMbZA/specializing-in-problems-we-don-t-understand) \\- i.e. problems where we don't already know the best framing."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Framing Practicum: Stable Equilibrium",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Exercises / Problem-Sets"
              }
            ]
          },
          {
            "title": "Framing Practicum: Bistability",
            "tags": [
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Framing Practicum: Dynamic Equilibrium",
            "tags": [
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Framing Practicum: Timescale Separation",
            "tags": [
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Framing Practicum: Turnover Time",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Exercises / Problem-Sets"
              }
            ]
          },
          {
            "title": "Framing Practicum: Incentive",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Exercises / Problem-Sets"
              },
              {
                "name": "Incentives"
              }
            ]
          },
          {
            "title": "Framing Practicum: Selection Incentive",
            "tags": [
              {
                "name": "Exercises / Problem-Sets"
              },
              {
                "name": "Incentives"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Framing Practicum: Comparative Advantage",
            "tags": [
              {
                "name": "Economics"
              }
            ]
          },
          {
            "title": "Framing Practicum: Semistable Equilibrium",
            "tags": [
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Framing Practicum: General Factor",
            "tags": [
              {
                "name": "Frames"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Framing Practicum: Dynamic Programming",
            "tags": [
              {
                "name": "Programming"
              },
              {
                "name": "Rationality"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "zCksS4AXFnLBWweC6",
    "title": "Rationality in Research",
    "curatedOrder": null,
    "contents": {
      "markdown": "I'm working in (biological chemistry) research as of mid-2021. These are my thoughts and findings as to how applying rationality can make scientific research faster and higher-quality."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "The Reductionist Trap",
            "tags": [
              {
                "name": "Reductionism"
              },
              {
                "name": "Scholarship & Learning"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Fudging Work and Rationalization",
            "tags": [
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Generator Systems: Coincident Constraints",
            "tags": [
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Amyloid Plaques: Chemical Streetlight, Medical Goodhart",
            "tags": [
              {
                "name": "Health / Medicine / Disease"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Addendum to \"Amyloid Plaques: Medical Goodhart, Chemical Streetlight\"",
            "tags": [
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "Aging"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "A Taxonomy of Research",
            "tags": [
              {
                "name": "Intellectual Progress (Individual-Level)"
              },
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "How to Find a Problem",
            "tags": [
              {
                "name": "Intellectual Progress (Individual-Level)"
              },
              {
                "name": "Practical"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "A Confused Chemist's Review of AlphaFold 2",
            "tags": [
              {
                "name": "DeepMind"
              },
              {
                "name": "Biology"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "STQByy4J8NfLKkGQa",
    "title": "AI Defense in Depth: A Layman's Guide",
    "curatedOrder": null,
    "contents": {
      "markdown": "The global community of AI researchers is a life-critical system that was not designed as such, or indeed, at all. What does this entail for laypersons?"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "What is the problem?",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Existential Risk"
              }
            ]
          },
          {
            "title": "Could you have stopped Chernobyl?",
            "tags": [
              {
                "name": "AI Risk"
              },
              {
                "name": "Existential Risk"
              },
              {
                "name": "AI"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Expertise (topic)"
              }
            ]
          },
          {
            "title": "Pivot!",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Existential Risk"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "aERZoriyHfCqvWkzg",
    "title": "Modeling Transformative AI Risk (MTAIR)",
    "curatedOrder": null,
    "contents": {
      "markdown": "This is a sequence outlining work by the Modeling Transformative AI Risk (MTAIR) project. The project is an attempt to map out the relationships between key hypotheses and cruxes involved in debates about catastrophic risks from advanced AI. The project is also an attempt to convert our hypothesis / crux map into a software-based model that can incorporate probability estimates or other quantitative factors in ways that might be useful for exploration, planning, and/or decision support.\n\nThis series of posts presents a preliminary version of the model, along with a discussion of some of our plans going forward. The primary purpose of this sequence of posts is to inform the community about our progress, and hopefully contribute meaningfully to the ongoing discussion. \n\nA critical secondary goal is to get feedback from the community about this model as a form of expert engagement / elicitation. Although the project is still very much a work in progress, we believe that we are now at the stage where we can productively engage the community to solicit feedback, critiques, and suggestions, as well as contribute to the discourse. We also welcome ideas for further collaboration with other members of the community who are interested, or who are working on related projects."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Modelling Transformative AI Risks (MTAIR) Project: Introduction",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "World Modeling Techniques"
              },
              {
                "name": "Deconfusion"
              },
              {
                "name": "Distinctions"
              }
            ]
          },
          {
            "title": "Analogies and General Priors on Intelligence",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "AI"
              },
              {
                "name": "Evolution"
              },
              {
                "name": "AI Takeoff"
              }
            ]
          },
          {
            "title": "Paths To High-Level Machine Intelligence",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "AI Timelines"
              },
              {
                "name": "Whole Brain Emulation"
              }
            ]
          },
          {
            "title": "Takeoff Speeds and Discontinuities",
            "tags": [
              {
                "name": "AI Takeoff"
              },
              {
                "name": "AI"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Modeling Risks From Learned Optimization",
            "tags": [
              {
                "name": "Mesa-Optimization"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Modeling the impact of safety agendas",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Modeling Failure Modes of High-Level Machine Intelligence",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "AI Risk"
              },
              {
                "name": "Threat Models"
              }
            ]
          },
          {
            "title": "Elicitation for Modeling Transformative AI Risks",
            "tags": [
              {
                "name": "AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "HFyami76kSs4vEHqy",
    "title": "Practical Guide to Anthropics",
    "curatedOrder": null,
    "contents": {
      "markdown": "How to do anthropics simply and practically.\n\nIf there are no issues of exact copies, or advanced decision theory, and the questions you're asking aren't weird, then use SIA. And by \"use SIA\", I mean \"ignore the definition of SIA, and just do a conventional Bayesian update on your own existence\". Infinite universes won't be a problem (any more than they are with conventional probabilities). And this might not increase your expected population by much."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Anthropic decision theory for self-locating beliefs",
            "tags": [
              {
                "name": "Sleeping Beauty Paradox"
              },
              {
                "name": "Anthropics"
              }
            ]
          },
          {
            "title": "Anthropics: different probabilities, different questions",
            "tags": [
              {
                "name": "Anthropics"
              },
              {
                "name": "Sleeping Beauty Paradox"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "SIA is basically just Bayesian updating on existence",
            "tags": [
              {
                "name": "Sleeping Beauty Paradox"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Non-poisonous cake: anthropic updates are normal",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Anthropics in infinite universes",
            "tags": [
              {
                "name": "Anthropics"
              },
              {
                "name": "Infinity"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "The SIA population update can be surprisingly small",
            "tags": [
              {
                "name": "Anthropics"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Anthropics and Fermi: grabby, visible, zoo-keeping, and early aliens",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Anthropics"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Extraterrestrial Life"
              },
              {
                "name": "Grabby Aliens"
              }
            ]
          },
          {
            "title": "Practical anthropics summary",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Anthropics"
              },
              {
                "name": "Rationality"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "fSMbebQyR4wheRrvk",
    "title": "The Causes of Power-seeking and Instrumental Convergence",
    "curatedOrder": null,
    "contents": {
      "markdown": "Instrumental convergence posits that smart goal-directed agents will tend to take certain actions (eg gain resources, stay alive) in order to achieve their goals. These actions seem to involve taking power *from* humans. Human disempowerment seems like a key part of how AI might go very, very wrong. \n\nBut where does instrumental convergence come from? When does it occur, and how strongly? And what does the math look like?"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Seeking Power is Often Convergently Instrumental in MDPs",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Instrumental Convergence"
              },
              {
                "name": "Myopia"
              }
            ]
          },
          {
            "title": "Power as Easily Exploitable Opportunities",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Instrumental Convergence"
              },
              {
                "name": "LessWrong Event Transcripts"
              }
            ]
          },
          {
            "title": "The Catastrophic Convergence Conjecture",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Instrumental Convergence"
              },
              {
                "name": "Impact Measures"
              }
            ]
          },
          {
            "title": "Generalizing POWER to multi-agent games",
            "tags": [
              {
                "name": "Instrumental Convergence"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "MDP models are determined by the agent architecture and the environmental dynamics",
            "tags": [
              {
                "name": "Instrumental Convergence"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Environmental Structure Can Cause Instrumental Convergence",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "AI Risk"
              },
              {
                "name": "Instrumental Convergence"
              }
            ]
          },
          {
            "title": "A world in which the alignment problem seems lower-stakes",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Instrumental Convergence"
              }
            ]
          },
          {
            "title": "The More Power At Stake, The Stronger Instrumental Convergence Gets For Optimal Policies",
            "tags": [
              {
                "name": "Instrumental Convergence"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Seeking Power is Convergently Instrumental in a Broad Class of Environments",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Instrumental Convergence"
              }
            ]
          },
          {
            "title": "When Most VNM-Coherent Preference Orderings Have Convergent Instrumental Incentives",
            "tags": [
              {
                "name": "Instrumental Convergence"
              },
              {
                "name": "Coherence Arguments"
              },
              {
                "name": "AI"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Goal-Directedness"
              }
            ]
          },
          {
            "title": "Satisficers Tend To Seek Power: Instrumental Convergence Via Retargetability",
            "tags": [
              {
                "name": "Instrumental Convergence"
              },
              {
                "name": "AI"
              },
              {
                "name": "Satisficer"
              }
            ]
          },
          {
            "title": "Corrigibility Can Be VNM-Incoherent",
            "tags": [
              {
                "name": "Corrigibility"
              },
              {
                "name": "Instrumental Convergence"
              },
              {
                "name": "AI"
              },
              {
                "name": "Open Problems"
              }
            ]
          },
          {
            "title": "Instrumental Convergence For Realistic Agent Objectives",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Instrumental Convergence"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "jyqhEPACWZy8vYfGD",
    "title": "2021 Less Wrong Darwin Game",
    "curatedOrder": null,
    "contents": null,
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "The 2021 Less Wrong Darwin Game",
            "tags": [
              {
                "name": "Biology"
              },
              {
                "name": "Exercises / Problem-Sets"
              }
            ]
          },
          {
            "title": "2021 Darwin Game - Contestants",
            "tags": [
              {
                "name": "Exercises / Problem-Sets"
              },
              {
                "name": "Biology"
              }
            ]
          },
          {
            "title": "2021 Darwin Game - Tundra",
            "tags": [
              {
                "name": "Biology"
              },
              {
                "name": "Exercises / Problem-Sets"
              }
            ]
          },
          {
            "title": "2021 Darwin Game - Desert",
            "tags": [
              {
                "name": "Biology"
              },
              {
                "name": "Exercises / Problem-Sets"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "2021 Darwin Game - Ocean",
            "tags": [
              {
                "name": "Biology"
              },
              {
                "name": "Exercises / Problem-Sets"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "2021 Darwin Game - Benthic",
            "tags": [
              {
                "name": "Biology"
              },
              {
                "name": "Exercises / Problem-Sets"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "2021 Darwin Game - Human Garbage Dump",
            "tags": [
              {
                "name": "Biology"
              },
              {
                "name": "Exercises / Problem-Sets"
              }
            ]
          },
          {
            "title": "2021 Darwin Game - River",
            "tags": [
              {
                "name": "Biology"
              },
              {
                "name": "Exercises / Problem-Sets"
              }
            ]
          },
          {
            "title": "2021 Darwin Game - Everywhere Else",
            "tags": [
              {
                "name": "Biology"
              },
              {
                "name": "Exercises / Problem-Sets"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "ugBmtzucLhe8ApYfo",
    "title": "Beyond Questions & Answers",
    "curatedOrder": null,
    "contents": {
      "markdown": "A short set of posts that try to investigate problems and solutions that come when imagining intellectual delegation as a series of particular questions and answers. \n\nThe Discernment post is the main one. I came up with the other two when working on it."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Questions are tools to help answerers optimize utility",
            "tags": [
              {
                "name": "QURI"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Philosophy of Language"
              }
            ]
          },
          {
            "title": "Oracles, Informers, and Controllers",
            "tags": [
              {
                "name": "QURI"
              },
              {
                "name": "Oracle AI"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "The Practice & Virtue of Discernment",
            "tags": [
              {
                "name": "QURI"
              },
              {
                "name": "Virtues"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Planning & Decision-Making"
              },
              {
                "name": "General Semantics"
              },
              {
                "name": "Distinctions"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "kxs3eeEti9ouwWFzr",
    "title": "Finite Factored Sets",
    "curatedOrder": null,
    "contents": {
      "markdown": "This is an introduction to a new way of thinking about time, based on finite factored sets.\n\nA factored set is a set understood as a Cartesian product, in the same sense that a partition is a way to understand a set as a disjoint union.\n\nThis sequence begins by applying finite factored sets to *temporal inference*, showing some advantages of this framework over Judea Pearl's theory of causal inference. Finite factored sets have many potential applications outside of temporal inference, however, and future writing will explore embedded agency and other topics through the lens of finite factored sets.\n\nThe \"Details and Proofs\" section of this sequence is also [available](https://www.lesswrong.com/s/2A7rrZ4ySx6R8mfoT/p/MnWQ4o7Y4HryE5ffN) as an arXiv paper: \"[Temporal Inference with Finite Factored Sets](https://arxiv.org/abs/2109.11513).\"\n\n\\\\(\\ \\\\)\\\\( \\\\)"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": "Overview"
        },
        "posts": [
          {
            "title": "Finite Factored Sets",
            "tags": [
              {
                "name": "Causality"
              },
              {
                "name": "Abstraction"
              },
              {
                "name": "Finite Factored Sets"
              }
            ]
          }
        ]
      },
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": "Details and Proofs"
        },
        "posts": [
          {
            "title": "Finite Factored Sets: Introduction and Factorizations",
            "tags": [
              {
                "name": "Causality"
              },
              {
                "name": "Abstraction"
              },
              {
                "name": "Finite Factored Sets"
              }
            ]
          },
          {
            "title": "Finite Factored Sets: Orthogonality and Time",
            "tags": [
              {
                "name": "Finite Factored Sets"
              }
            ]
          },
          {
            "title": "Finite Factored Sets: Conditional Orthogonality",
            "tags": [
              {
                "name": "Finite Factored Sets"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "AI"
              },
              {
                "name": "Causality"
              },
              {
                "name": "Abstraction"
              }
            ]
          },
          {
            "title": "Finite Factored Sets: Polynomials and Probability",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Finite Factored Sets"
              }
            ]
          },
          {
            "title": "Finite Factored Sets: Inferring Time",
            "tags": [
              {
                "name": "Finite Factored Sets"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Finite Factored Sets: Applications",
            "tags": [
              {
                "name": "Finite Factored Sets"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "AI"
              }
            ]
          }
        ]
      },
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": "Applications and Discussion"
        },
        "posts": [
          {
            "title": "Saving Time",
            "tags": [
              {
                "name": "Causality"
              },
              {
                "name": "Abstraction"
              },
              {
                "name": "AI"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Agency"
              }
            ]
          },
          {
            "title": "AXRP Episode 9 - Finite Factored Sets with Scott Garrabrant",
            "tags": [
              {
                "name": "Interviews"
              },
              {
                "name": "AI"
              },
              {
                "name": "Embedded Agency"
              },
              {
                "name": "Causality"
              },
              {
                "name": "Abstraction"
              },
              {
                "name": "Audio"
              },
              {
                "name": "Finite Factored Sets"
              },
              {
                "name": "AXRP"
              }
            ]
          },
          {
            "title": "[AN #163]: Using finite factored sets for causal and temporal inference",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Finite Factored Sets"
              }
            ]
          },
          {
            "title": "Countably Factored Spaces",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Finite Factored Sets"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "H6kiZXJwYgxZubtmD",
    "title": "The accumulation of knowledge",
    "curatedOrder": null,
    "contents": {
      "markdown": "Suppose I show you a physically closed system and tell you that knowledge is accumulating within a certain physical region within the system. What does this mean, at the level of physics?"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Problems facing a correspondence theory of knowledge",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Truth, Semantics, & Meaning"
              }
            ]
          },
          {
            "title": "Knowledge is not just map/territory resemblance",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "AI"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Truth, Semantics, & Meaning"
              }
            ]
          },
          {
            "title": "Knowledge is not just mutual information",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "AI"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Truth, Semantics, & Meaning"
              }
            ]
          },
          {
            "title": "Knowledge is not just digital abstraction layers",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Truth, Semantics, & Meaning"
              }
            ]
          },
          {
            "title": "Knowledge is not just precipitation of action",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Truth, Semantics, & Meaning"
              }
            ]
          },
          {
            "title": "The accumulation of knowledge: literature review",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "AI"
              },
              {
                "name": "Truth, Semantics, & Meaning"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "z7wp9Bkqc9A9zK53M",
    "title": "Comprehensive Information Gatherings",
    "curatedOrder": null,
    "contents": {
      "markdown": "A write-up of my [Comprehensive Information Gatherings](https://www.lesswrong.com/posts/9LXxgXySTFsnookkw/exercises-in-comprehensive-information-gathering) on various topics useful for my research in AI Alignment"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "April 2021 Deep Dive: Transformers and GPT-3",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alex Turner's Research, Comprehensive Information Gathering",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Impact Measures"
              },
              {
                "name": "Instrumental Convergence"
              },
              {
                "name": "AI Risk"
              },
              {
                "name": "Deconfusion"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "57bsaXbJXbzKqNkrf",
    "title": "Intermittent Distllations",
    "curatedOrder": null,
    "contents": {
      "markdown": "An intermittent publication summarizing content relevant to AI safety. \n\n[Rohin Shah](https://rohinshah.com/faq-career-advice-for-ai-alignment-researchers/): \"if you’re going to bother reading an article carefully, you should probably summarize it.\""
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Intermittent Distillations #1",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Intermittent Distillations #2",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Intermittent Distillations #3",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Intermittent Distillations #4: Semiconductors, Economics, Intelligence, and Technological Progress.\n\n",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Automation"
              },
              {
                "name": "Superintelligence"
              },
              {
                "name": "Economic Consequences of AGI"
              },
              {
                "name": "Practice & Philosophy of Science"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "N4Conn9z4pgA2rznh",
    "title": "Litereature Summaries",
    "curatedOrder": null,
    "contents": {
      "markdown": "My posts on textbooks from [Miri's research guide](https://intelligence.org/research-guide/)."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Insights from Munkres' Topology",
            "tags": [
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "Book Reviews"
              },
              {
                "name": "Summaries"
              }
            ]
          },
          {
            "title": "Insights from Linear Algebra Done Right",
            "tags": [
              {
                "name": "Book Reviews"
              },
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "Summaries"
              }
            ]
          },
          {
            "title": "Understanding Machine Learning (I)",
            "tags": [
              {
                "name": "Machine Learning  (ML)"
              }
            ]
          },
          {
            "title": "Insights from \"All of Statistics\": Probability",
            "tags": [
              {
                "name": "Probability & Statistics"
              },
              {
                "name": "Summaries"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Insights from \"All of Statistics\": Statistical Inference",
            "tags": [
              {
                "name": "Summaries"
              },
              {
                "name": "Probability & Statistics"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Rationality"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "Ejxov75SxyPXsATRn",
    "title": "Using Credence Calibration for Everything",
    "curatedOrder": null,
    "contents": {
      "markdown": ""
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Prediction-based medicine (PBM)",
            "tags": [
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "Health / Medicine / Disease"
              }
            ]
          },
          {
            "title": "Preventing overcharging by prosecutors",
            "tags": [
              {
                "name": "Law and Legal systems"
              },
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Prediction-based-Medicine instead of E̵v̵i̵d̵e̵n̵c̵e̵ ̵b̵a̵s̵e̵d̵ ̵M̵e̵d̵i̵c̵i̵n̵e̵ Authority-based-Medicine",
            "tags": [
              {
                "name": "Health / Medicine / Disease"
              },
              {
                "name": "Expertise (topic)"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "World Optimization"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "kmryZRz5r9bjsug9e",
    "title": "Anthropic Decision Theory",
    "curatedOrder": null,
    "contents": {
      "markdown": "Collecting the posts on Anthropic Decision Theory in a single place; the paper can be found [here](https://arxiv.org/abs/1110.6437), while the explanatory video is [here](https://www.youtube.com/watch?v=aiGOGkBiWEo)."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Anthropic decision theory I: Sleeping beauty and selflessness",
            "tags": [
              {
                "name": "Anthropics"
              },
              {
                "name": "Sleeping Beauty Paradox"
              }
            ]
          },
          {
            "title": "Anthropic Decision Theory II: Self-Indication, Self-Sampling and decisions",
            "tags": [
              {
                "name": "Anthropics"
              }
            ]
          },
          {
            "title": "Anthropic Decision Theory III: Solving Selfless and Total Utilitarian Sleeping Beauty",
            "tags": [
              {
                "name": "Anthropics"
              },
              {
                "name": "Sleeping Beauty Paradox"
              }
            ]
          },
          {
            "title": "Anthropic Decision Theory IV: Solving Selfish and Average-Utilitarian Sleeping Beauty",
            "tags": [
              {
                "name": "Anthropics"
              },
              {
                "name": "Sleeping Beauty Paradox"
              }
            ]
          },
          {
            "title": "Anthropic Decision Theory V: Linking and ADT",
            "tags": [
              {
                "name": "Anthropics"
              }
            ]
          },
          {
            "title": "Anthropic Decision Theory VI: Applying ADT to common anthropic problems",
            "tags": [
              {
                "name": "Anthropics"
              }
            ]
          },
          {
            "title": "Anthropic Decision Theory V: Linking and ADT",
            "tags": [
              {
                "name": "Anthropics"
              }
            ]
          },
          {
            "title": "\"Solving\" selfishness for UDT",
            "tags": [
              {
                "name": "Anthropics"
              },
              {
                "name": "Paradoxes"
              },
              {
                "name": "Sleeping Beauty Paradox"
              },
              {
                "name": "Utility Functions"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "pvXAS868E2BZEc2Fu",
    "title": "Reviews for the Alignment Forum",
    "curatedOrder": null,
    "contents": {
      "markdown": "We (Adam Shimi, Joe Collman and Jérémy Perret) are reviewing posts in the Alignment Forum to get a better idea of what a peer-review for AI Alignment would look like."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Suggestions of posts on the AF to review",
            "tags": [
              {
                "name": "Intellectual Progress (Society-Level)"
              },
              {
                "name": "Intellectual Progress via LessWrong"
              },
              {
                "name": "AI Risk"
              },
              {
                "name": "AI"
              },
              {
                "name": "Community"
              }
            ]
          },
          {
            "title": "Review of \"Fun with +12 OOMs of Compute\"",
            "tags": [
              {
                "name": "Intellectual Progress (Society-Level)"
              },
              {
                "name": "Intellectual Progress via LessWrong"
              },
              {
                "name": "AI Timelines"
              },
              {
                "name": "AI Risk"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Review of \"Learning Normativity: A Research Agenda\"",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Intellectual Progress via LessWrong"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "xqgwpmwDYsn8osoje",
    "title": "Notes on Virtues",
    "curatedOrder": null,
    "contents": {
      "markdown": "Investigating a variety of human virtues, with the hope of learning how we might improve in their practice."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Notes on notes on virtues",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Recursive Self-Improvement"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Summaries"
              },
              {
                "name": "Skill Building"
              }
            ]
          },
          {
            "title": "Notes on Honesty",
            "tags": [
              {
                "name": "Honesty"
              },
              {
                "name": "Meta-Honesty"
              },
              {
                "name": "Deception"
              },
              {
                "name": "Virtues"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Truth, Semantics, & Meaning"
              }
            ]
          },
          {
            "title": "Notes on Courage",
            "tags": [
              {
                "name": "Courage"
              },
              {
                "name": "Virtues"
              }
            ]
          },
          {
            "title": "Notes on Self Control",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Akrasia"
              },
              {
                "name": "Willpower"
              }
            ]
          },
          {
            "title": "Notes on Respect-for-Others",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Conformity Bias"
              },
              {
                "name": "Altruism"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Notes on Piety",
            "tags": [
              {
                "name": "World Optimization"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Virtues"
              },
              {
                "name": "Religion"
              },
              {
                "name": "Ritual"
              }
            ]
          },
          {
            "title": "Notes on Loyalty",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Group Rationality"
              },
              {
                "name": "Tribalism"
              },
              {
                "name": "Blues & Greens (metaphor)"
              },
              {
                "name": "Signaling"
              },
              {
                "name": "Motivations"
              },
              {
                "name": "Coordination / Cooperation"
              }
            ]
          },
          {
            "title": "Notes on Compassion",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Altruism"
              },
              {
                "name": "Practical"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Suffering"
              }
            ]
          },
          {
            "title": "Notes on Wisdom",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Humility"
              },
              {
                "name": "Philosophy"
              },
              {
                "name": "Map and Territory"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Notes on Temperance",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Motivations"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Human Values"
              },
              {
                "name": "Self Improvement"
              }
            ]
          },
          {
            "title": "Notes on Fitness",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Exercise (Physical)"
              },
              {
                "name": "Well-being"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Life Extension"
              },
              {
                "name": "Human Bodies"
              }
            ]
          },
          {
            "title": "Notes on Sincerity and such",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Honesty"
              },
              {
                "name": "Communication Cultures"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Hypocrisy"
              },
              {
                "name": "Conversation (topic)"
              },
              {
                "name": "Truth, Semantics, & Meaning"
              },
              {
                "name": "Deception"
              },
              {
                "name": "Philosophy of Language"
              }
            ]
          },
          {
            "title": "Notes on Justice (as a virtue)",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Motivations"
              },
              {
                "name": "Fairness"
              },
              {
                "name": "Social Skills"
              },
              {
                "name": "Law and Legal systems"
              }
            ]
          },
          {
            "title": "Notes on Industriousness",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Ambition"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Productivity"
              },
              {
                "name": "Planning & Decision-Making"
              }
            ]
          },
          {
            "title": "Notes on Duty",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Motivations"
              },
              {
                "name": "Heroic Responsibility"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Notes on Social Responsibility",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Social & Cultural Dynamics"
              },
              {
                "name": "Politics"
              },
              {
                "name": "Coordination / Cooperation"
              },
              {
                "name": "Organizational Culture & Design"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Government"
              }
            ]
          },
          {
            "title": "Notes on Prudence",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Risk Management"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Notes on Know-how",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Skill Building"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Notes on Honor",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Scrupulosity"
              },
              {
                "name": "Motivations"
              }
            ]
          },
          {
            "title": "Notes on Moderation, Balance, & Harmony",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Skill Building"
              },
              {
                "name": "Skill / Expertise Assessment"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Complexity of Value"
              }
            ]
          },
          {
            "title": "Notes on Patience & Forbearance",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Stoicism / Letting Go / Making Peace"
              }
            ]
          },
          {
            "title": "Notes on Care",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Bystander Effect"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Motivations"
              }
            ]
          },
          {
            "title": "Notes on Attention",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Luminosity"
              },
              {
                "name": "Noticing"
              },
              {
                "name": "Empiricism"
              },
              {
                "name": "Meditation"
              },
              {
                "name": "Consciousness"
              },
              {
                "name": "Focusing"
              },
              {
                "name": "Attention"
              }
            ]
          },
          {
            "title": "Notes on Rationality",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Virtues"
              }
            ]
          },
          {
            "title": "Notes on Amiability",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Signaling"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Social Skills"
              },
              {
                "name": "Conversation (topic)"
              }
            ]
          },
          {
            "title": "Notes on Simplicity",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Virtues"
              },
              {
                "name": "Occam's Razor"
              },
              {
                "name": "Slack"
              },
              {
                "name": "Optimization"
              },
              {
                "name": "Prioritization"
              }
            ]
          },
          {
            "title": "Notes on Forgiveness",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Stoicism / Letting Go / Making Peace"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Memory Reconsolidation"
              },
              {
                "name": "Cached Thoughts"
              },
              {
                "name": "Law and Legal systems"
              }
            ]
          },
          {
            "title": "Notes on Integrity",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Compartmentalization"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Internal Double Crux"
              },
              {
                "name": "Internal Alignment (Human)"
              }
            ]
          },
          {
            "title": "Notes on Humility",
            "tags": [
              {
                "name": "Humility"
              },
              {
                "name": "Virtues"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Modest Epistemology"
              }
            ]
          },
          {
            "title": "Notes on Optimism, Hope, and Trust",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Hope"
              },
              {
                "name": "Trust"
              },
              {
                "name": "Depression"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Self Fulfilling/Refuting Prophecies"
              }
            ]
          },
          {
            "title": "Notes on Good Temper",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Stoicism / Letting Go / Making Peace"
              }
            ]
          },
          {
            "title": "Notes on Fairness",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "Game Theory"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Motivated Reasoning"
              },
              {
                "name": "Self-Deception"
              },
              {
                "name": "Hypocrisy"
              },
              {
                "name": "Motivations"
              },
              {
                "name": "Fairness"
              }
            ]
          },
          {
            "title": "Notes on Endurance",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Suffering"
              }
            ]
          },
          {
            "title": "Notes on Benevolence (being “less bad”)",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Motivations"
              },
              {
                "name": "Moral Uncertainty"
              }
            ]
          },
          {
            "title": "Notes on Ambition",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Ambition"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Motivations"
              }
            ]
          },
          {
            "title": "Notes on Perseverance",
            "tags": [
              {
                "name": "Virtues"
              }
            ]
          },
          {
            "title": "Notes on Kindness",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Altruism"
              },
              {
                "name": "Animal Welfare"
              }
            ]
          },
          {
            "title": "Notes on Empathy",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Modeling People"
              },
              {
                "name": "Mind Projection Fallacy"
              },
              {
                "name": "Typical Mind Fallacy"
              },
              {
                "name": "Emotions"
              },
              {
                "name": "Psychology"
              },
              {
                "name": "Social Skills"
              },
              {
                "name": "Relationships (Interpersonal)"
              },
              {
                "name": "Circling"
              },
              {
                "name": "Groupthink"
              }
            ]
          },
          {
            "title": "Notes on Frugality",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Time (value of)"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Financial Investing"
              },
              {
                "name": "Economics"
              },
              {
                "name": "Tradeoffs"
              }
            ]
          },
          {
            "title": "Notes on Dignity",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Social Status"
              },
              {
                "name": "Signaling"
              }
            ]
          },
          {
            "title": "Notes on Courtesy",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Social & Cultural Dynamics"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Coordination / Cooperation"
              }
            ]
          },
          {
            "title": "Notes on Chastity",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Sex & Gender"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Notes on Love",
            "tags": [
              {
                "name": "Love "
              },
              {
                "name": "Virtues"
              },
              {
                "name": "Altruism"
              },
              {
                "name": "Social Skills"
              },
              {
                "name": "Emotions"
              },
              {
                "name": "Relationships (Interpersonal)"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Notes on Judgment and Righteous Anger",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Social & Cultural Dynamics"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Human Values"
              }
            ]
          },
          {
            "title": "Notes on Gratitude",
            "tags": [
              {
                "name": "Gratitude"
              },
              {
                "name": "Virtues"
              },
              {
                "name": "Recursive Self-Improvement"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Notes on Shame",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Social Reality"
              },
              {
                "name": "Guilt & Shame"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Incentives"
              },
              {
                "name": "Pre-Commitment"
              },
              {
                "name": "Signaling"
              },
              {
                "name": "Scrupulosity"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "eC3gbMmpvt9LxeDap",
    "title": "Participating in a Covid-19 Vaccination Trial",
    "curatedOrder": null,
    "contents": {
      "markdown": "I participated in the PREVENT-19 study sponsored by Novavax to study their Coronavirus vaccine candidate."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Participating in a Covid-19 Vaccine Trial",
            "tags": [
              {
                "name": "Covid-19"
              },
              {
                "name": "Experiments"
              }
            ]
          },
          {
            "title": "Participating in a Covid-19 Vaccine Trial #2: We pretty much knew it would work the whole time",
            "tags": [
              {
                "name": "Covid-19"
              },
              {
                "name": "Government"
              }
            ]
          },
          {
            "title": "Participating in a Covid-19 Vaccine Trial #3: I Hope I feel Worse Tomorrow",
            "tags": [
              {
                "name": "Covid-19"
              },
              {
                "name": "Experiments"
              },
              {
                "name": "Bayes' Theorem"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "tYCu3WG89kAW8QmoM",
    "title": "Predictions & Self-awareness",
    "curatedOrder": null,
    "contents": {
      "markdown": "Some animals, if put in front of a mirror, will notice that there is some kind of moving animal-ish thing in front of them.  They are \"aware of themselves\", but they are not necessarily \"self-aware\" in the sense we normally use the term.  The animals that pass the [mirror test](https://en.wikipedia.org/wiki/Mirror_test) are the ones that realize the moving animal-ish thing is *them*.\n\nSuppose we create a powerful AI system that uses (un)supervised learning techniques to understand and make predictions about the world.  If the dataset the AI system is trained on includes data about itself, the AI system will be \"aware of itself\" in the sense of seeing an animal-ish thing in the mirror.  Is there a risk that it could graduate to \"self-awareness\" in the sense of realizing the thing in its training data is *it*?\n\nI contend this risk is low. When an animal passes the mirror test, it is noticing an isomorphism between its inborn sense of self (endowed by evolution for self-preservation) and the thing in the mirror. But if we don't endow our AI system with an inborn sense of self, there is no isomorphism to notice.\n\nThat doesn't mean purely predictive AI systems are completely safe.\n\n[Photo](https://www.flickr.com/photos/crsan/4804870020/in/photostream/): [Christian Holmér](http://www.christianholmer.com/)"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "The Dualist Predict-O-Matic ($100 prize)",
            "tags": [
              {
                "name": "Bounties (closed)"
              },
              {
                "name": "Myopia"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Self-Fulfilling Prophecies Aren't Always About Self-Awareness",
            "tags": [
              {
                "name": "Myopia"
              },
              {
                "name": "AI"
              },
              {
                "name": "Self Fulfilling/Refuting Prophecies"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "Gmc7vtnpyKZRHWdt5",
    "title": "Pointing at Normativity",
    "curatedOrder": null,
    "contents": null,
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Learning Normativity: A Research Agenda",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Normativity",
            "tags": [
              {
                "name": "Value Learning"
              },
              {
                "name": "Human Values"
              },
              {
                "name": "Moral Uncertainty"
              },
              {
                "name": "Meta-Philosophy"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "AI"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Recursive Quantilizers II",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Value Learning"
              },
              {
                "name": "Meta-Philosophy"
              }
            ]
          },
          {
            "title": "The Pointers Problem: Clarifications/Variations",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "The Pointers Problem"
              }
            ]
          },
          {
            "title": "Four Motivations for Learning Normativity",
            "tags": [
              {
                "name": "AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "3dCMdafmKmb6dRjMF",
    "title": "Counterfactual Planning",
    "curatedOrder": null,
    "contents": {
      "markdown": "Counterfactual planning is a design approach for creating a range of safety mechanisms that can be applied to AGI systems. \nThis sequence introduces the graphical notation used in counterfactual planning, and it defines several safety mechanisms."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Counterfactual Planning in AGI Systems",
            "tags": [
              {
                "name": "Counterfactuals"
              },
              {
                "name": "Corrigibility"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Embedded Agency"
              },
              {
                "name": "AI"
              },
              {
                "name": "Intelligence Explosion"
              }
            ]
          },
          {
            "title": "Graphical World Models, Counterfactuals, and Machine Learning Agents",
            "tags": [
              {
                "name": "Counterfactuals"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Myopia"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Creating AGI Safety Interlocks",
            "tags": [
              {
                "name": "Counterfactuals"
              },
              {
                "name": "Corrigibility"
              },
              {
                "name": "Intelligence Explosion"
              },
              {
                "name": "AI"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Disentangling Corrigibility: 2015-2021",
            "tags": [
              {
                "name": "Corrigibility"
              },
              {
                "name": "Wireheading"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Safely controlling the AGI agent reward function",
            "tags": [
              {
                "name": "Counterfactuals"
              },
              {
                "name": "Corrigibility"
              },
              {
                "name": "Wireheading"
              },
              {
                "name": "AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "k2fboiMkdfbCdgFzx",
    "title": "Wedding Ceremony",
    "curatedOrder": null,
    "contents": {
      "markdown": "Our wedding was intended to be a ceremony of commitment, to each other, and also to our values. We ([Ruben Bloom](https://www.lesswrong.com/users/ruby) and [Miranda Dixon-Luinenburg](https://www.lesswrong.com/users/swimmer963)) got married in the Lawrence Hall of Science planetarium in Berkeley on February 21st, 2015. Mostly because it took me six years to get the audio recording processed, I'm now, at last, posting on the occasion of our 6th anniversary the recordings and transcripts of our ceremony.\n\nOur friends gave speeches, each expressing a different facet of the values that we were committing to pursue together. They delivered their words against the backdrop of wonderous starscapes, and in between the prose, we played music that captured our love and ambitions.\n\nThe speeches stand as excellent essays in their own right, and although some of the authors/speakers have published them independently on their blogs, it seems worthwhile bringing all of them together in one place, especially together alongside the accompanying images and music. (Since it was in a dark planetarium, there is no video).\n\n* * *\n\n*Recording of the entire ceremony. Individual posts have the recordings for each speech alongside the transcript*\n\nThe ceremony had the following structure and was graciously officiated by [Logan Brienne Strohl](https://www.lesswrong.com/users/brienneyudkowsky):\n\n1.  **Values**\n    1.  [Darkness (Nate Soares)](https://www.lesswrong.com/posts/qFBf2aDT2oYNWKFaR/intro-darkness)\n    2.  [Hope & Triump:  How Far Humany Has Come (Tara Mac Aulay, written by Jess Whittlestone)](https://www.lesswrong.com/posts/xjzEbogdheFqhdszW/triumph-and-hope)\n    3.  [Light: The Grandest Vision for Humanity (Riva Melissa-Tez)](https://www.lesswrong.com/posts/rzruCSWMXja6x9BdN/the-grandest-vision-for-humanity-light)\n    4.  [Tsuyoku Naritai (Ruby)](https://www.lesswrong.com/s/k2fboiMkdfbCdgFzx/p/WrvQiTvvYeAxPLovW)\n2.  [**Community** (Oliver Habryka)](https://www.lesswrong.com/posts/Av3XA5AHJRsKzqrFZ/community)\n3.  [**Partnership** (Miranda)](https://www.lesswrong.com/posts/rDPgv9KTor6MgmBup/partnership)\n4.  **Declaration**\n    1.  [Feelings and Admiration](https://www.lesswrong.com/posts/LEiXp3SdM6rCJZCyP/feelings-of-admiration-ruby-less-than-greater-than-miranda)\n        1.  [Ruby towards Miranda](https://www.lesswrong.com/posts/LEiXp3SdM6rCJZCyP/feelings-of-admiration-ruby-less-than-greater-than-miranda)\n        2.  [Miranda towards Ruby](https://www.lesswrong.com/posts/LEiXp3SdM6rCJZCyP/feelings-of-admiration-ruby-less-than-greater-than-miranda)\n    2.  [Vows](https://www.lesswrong.com/posts/LWs6KSFBpmWo97fyb/vows-and-declaration)\n    3.  [Declaration, exchange of rings](https://www.lesswrong.com/posts/LWs6KSFBpmWo97fyb/vows-and-declaration)\n\nMiranda and I met via LessWrong (me finding her many excellent writings), so it feels quite fitting to celebrate one of our anniversaries here.\n\n*This Sunday, I have published the first two speeches. I will post the remaining ones daily until the Sequence is complete.*"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Intro to the Wedding Sequence",
            "tags": [
              {
                "name": "Community"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Ritual"
              },
              {
                "name": "Marriage"
              }
            ]
          },
          {
            "title": "[Ceremony Intro + ] Darkness",
            "tags": [
              {
                "name": "Community"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Existential Risk"
              },
              {
                "name": "Ritual"
              },
              {
                "name": "Marriage"
              },
              {
                "name": "Audio"
              }
            ]
          },
          {
            "title": "Triumph & Hope: How Far Humanity Has Come",
            "tags": [
              {
                "name": "Ritual"
              },
              {
                "name": "Relationships (Interpersonal)"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Community"
              },
              {
                "name": "Marriage"
              },
              {
                "name": "Audio"
              }
            ]
          },
          {
            "title": "The Grandest Vision for Humanity (Light)",
            "tags": [
              {
                "name": "Ritual"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Ambition"
              },
              {
                "name": "Marriage"
              },
              {
                "name": "Audio"
              }
            ]
          },
          {
            "title": "Tsuyoku Naritai",
            "tags": [
              {
                "name": "Community"
              },
              {
                "name": "Tsuyoku Naritai"
              },
              {
                "name": "Ritual"
              },
              {
                "name": "Marriage"
              },
              {
                "name": "Audio"
              }
            ]
          },
          {
            "title": "Community",
            "tags": [
              {
                "name": "Community"
              },
              {
                "name": "Ritual"
              },
              {
                "name": "Audio"
              },
              {
                "name": "Marriage"
              }
            ]
          },
          {
            "title": "Partnership",
            "tags": [
              {
                "name": "Ritual"
              },
              {
                "name": "Community"
              },
              {
                "name": "Coordination / Cooperation"
              },
              {
                "name": "Audio"
              },
              {
                "name": "Marriage"
              }
            ]
          },
          {
            "title": "Feelings of Admiration, Ruby <=> Miranda",
            "tags": [
              {
                "name": "Community"
              },
              {
                "name": "Audio"
              }
            ]
          },
          {
            "title": "Vows & Declaration",
            "tags": [
              {
                "name": "Community"
              },
              {
                "name": "Ritual"
              },
              {
                "name": "Audio"
              },
              {
                "name": "Marriage"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "8RpeegksiYavJrSA5",
    "title": "Non-Coercive Motivation",
    "curatedOrder": null,
    "contents": {
      "markdown": "How to motivate yourself in a consistent way without shame, guilt, or excessive willpower."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Why Productivity Systems Don't Stick",
            "tags": [
              {
                "name": "Productivity"
              },
              {
                "name": "Motivations"
              },
              {
                "name": "Subagents"
              },
              {
                "name": "Procrastination"
              },
              {
                "name": "Akrasia"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Would most people benefit from being less coercive to themselves?",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Productivity"
              },
              {
                "name": "Procrastination"
              }
            ]
          },
          {
            "title": "Non-Coercive Perfectionism",
            "tags": [
              {
                "name": "Internal Alignment (Human)"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Subagents"
              },
              {
                "name": "Guilt & Shame"
              },
              {
                "name": "Akrasia"
              },
              {
                "name": "Procrastination"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "qpvqinidbEE3i73Jd",
    "title": "AI Alignment Unwrapped",
    "curatedOrder": null,
    "contents": {
      "markdown": "Distillation posts about AI Alignment"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Universality Unwrapped",
            "tags": [
              {
                "name": "Humans Consulting HCH"
              },
              {
                "name": "AI"
              },
              {
                "name": "Deception"
              },
              {
                "name": "Distillation & Pedagogy"
              }
            ]
          },
          {
            "title": "Infra-Bayesianism Unwrapped",
            "tags": [
              {
                "name": "Logical Uncertainty"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Distillation & Pedagogy"
              },
              {
                "name": "AI"
              },
              {
                "name": "Infra-Bayesianism"
              }
            ]
          },
          {
            "title": "Epistemology of HCH",
            "tags": [
              {
                "name": "Humans Consulting HCH"
              },
              {
                "name": "AI"
              },
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "Epistemology"
              }
            ]
          },
          {
            "title": "Epistemological Framing for AI Alignment Research",
            "tags": [
              {
                "name": "Intellectual Progress (Society-Level)"
              },
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "AI Risk"
              },
              {
                "name": "Epistemology"
              },
              {
                "name": "AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "5Eg2urmQjA4ZNcezy",
    "title": "AI Timelines",
    "curatedOrder": null,
    "contents": {
      "markdown": "This sequence collects my AI timelines-related posts in order from most to least important. If you want to read them all, I'd recommend going in reverse order, since that was the order in which they were written. Originally I was going to tie it all together with a hub post that gives my overall thoughts, but then I changed my mind. Feel free to reach out to me if you want my overall thoughts."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Fun with +12 OOMs of Compute",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "AI Timelines"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Birds, Brains, Planes, and AI: Against Appeals to the Complexity/Mysteriousness/Efficiency of the Brain",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "AI Timelines"
              },
              {
                "name": "Technological Forecasting"
              },
              {
                "name": "History"
              },
              {
                "name": "Center on Long-Term Risk (CLR)"
              }
            ]
          },
          {
            "title": "Against GDP as a metric for timelines and takeoff speeds",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "AI Timelines"
              },
              {
                "name": "AI Takeoff"
              },
              {
                "name": "Center on Long-Term Risk (CLR)"
              }
            ]
          },
          {
            "title": "The date of AI Takeover is not the day the AI takes over",
            "tags": [
              {
                "name": "AI Timelines"
              },
              {
                "name": "AI"
              },
              {
                "name": "AI Takeoff"
              }
            ]
          },
          {
            "title": "What 2026 looks like",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "Forecasts (Specific Predictions)"
              },
              {
                "name": "AI Timelines"
              },
              {
                "name": "AI Takeoff"
              },
              {
                "name": "AI Persuasion"
              }
            ]
          },
          {
            "title": "How Roodman's GWP model translates to TAI timelines",
            "tags": [
              {
                "name": "AI Timelines"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "What will 2040 probably look like assuming no singularity?",
            "tags": [
              {
                "name": "Futurism"
              },
              {
                "name": "World Modeling"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "yiFxBWDXnLpbWGTkK",
    "title": "Ray's Coordination Sequence",
    "curatedOrder": null,
    "contents": {
      "markdown": "These are posts that feel important to me for coordinating in the real world. It includes some game theory posts by various authors, as well as some fuzzier posts about how to navigate disagreement."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Why Our Kind Can't Cooperate",
            "tags": [
              {
                "name": "Coordination / Cooperation"
              },
              {
                "name": "Social & Cultural Dynamics"
              },
              {
                "name": "Community"
              },
              {
                "name": "Group Rationality"
              }
            ]
          },
          {
            "title": "Your Price for Joining",
            "tags": [
              {
                "name": "Game Theory"
              },
              {
                "name": "Coordination / Cooperation"
              },
              {
                "name": "Group Rationality"
              }
            ]
          },
          {
            "title": "Schelling fences on slippery slopes",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Game Theory"
              },
              {
                "name": "Value Drift"
              }
            ]
          },
          {
            "title": "Schelling Categories, and Simple Membership Tests",
            "tags": [
              {
                "name": "Philosophy of Language"
              }
            ]
          },
          {
            "title": "The Schelling Choice is \"Rabbit\", not \"Stag\"",
            "tags": [
              {
                "name": "Game Theory"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Stag Hunt"
              }
            ]
          },
          {
            "title": "Classifying games like the Prisoner's Dilemma",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "AI"
              },
              {
                "name": "Game Theory"
              },
              {
                "name": "Prisoner's Dilemma"
              },
              {
                "name": "Stag Hunt"
              }
            ]
          },
          {
            "title": "The Pavlov Strategy",
            "tags": [
              {
                "name": "Game Theory"
              },
              {
                "name": "Prisoner's Dilemma"
              }
            ]
          },
          {
            "title": "Pavlov Generalizes",
            "tags": [
              {
                "name": "Prisoner's Dilemma"
              },
              {
                "name": "Game Theory"
              },
              {
                "name": "Decision Theory"
              }
            ]
          },
          {
            "title": "Most Prisoner's Dilemmas are Stag Hunts; Most Stag Hunts are Schelling Problems",
            "tags": [
              {
                "name": "Game Theory"
              },
              {
                "name": "Coordination / Cooperation"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Prisoner's Dilemma"
              },
              {
                "name": "Stag Hunt"
              }
            ]
          },
          {
            "title": "Bayesians vs. Barbarians",
            "tags": [
              {
                "name": "War"
              },
              {
                "name": "Group Rationality"
              },
              {
                "name": "Pitfalls of Rationality"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Coordination / Cooperation"
              }
            ]
          },
          {
            "title": "Noticing Frame Differences",
            "tags": [
              {
                "name": "Noticing"
              },
              {
                "name": "Conversation (topic)"
              },
              {
                "name": "Disagreement"
              },
              {
                "name": "Distinctions"
              },
              {
                "name": "Frames"
              }
            ]
          },
          {
            "title": "Propagating Facts into Aesthetics",
            "tags": [
              {
                "name": "Aesthetics"
              }
            ]
          },
          {
            "title": "Keep Your Beliefs Cruxy",
            "tags": [
              {
                "name": "Double-Crux"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "9TN3i7Q4PPdkx86hA",
    "title": "Pseudorandomness Contest",
    "curatedOrder": null,
    "contents": {
      "markdown": "In December 2020, I ran a pseudorandomness contest. Here’s how it worked:\n\n*   In Round 1, participants were invited to submit 150-bit strings of their own devising. They had 10 minutes to write down their string while using nothing but their own minds. I received 62 submissions.\n*   I then used a computer to generate 62 random 150-bit strings, and put all 124 strings in a random order. In Round 2, participants had to figure out which strings were human-generated and which were “truly” random. In particular, I asked for *probabilities* that each string was real, so participants could express their confidence rather than guessing “real” or “fake” for each string. I received 27 submissions for Round 2.\n\nThe analysis post (the last in the series) may be interesting to you even if you did not participate in the contest!"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Pseudorandomness contest, Round 1",
            "tags": [
              {
                "name": "Community"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Pseudorandomness contest, Round 2",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Community"
              }
            ]
          },
          {
            "title": "Pseudorandomness contest: prizes, results, and analysis",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Community"
              },
              {
                "name": "Probability & Statistics"
              },
              {
                "name": "Exercises / Problem-Sets"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "TjdhvTSptCYakw3Lc",
    "title": "Bayeswatch",
    "curatedOrder": null,
    "contents": null,
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Bayeswatch 1: Jewish Space Laser",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Bayeswatch 2: Puppy Muffins",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Bayeswatch 3: A Study in Scarlet",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Bayeswatch 4: Mousetrap",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Bayeswatch 5: Hivemind",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Bayeswatch 6: Mechwarrior",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Bayeswatch 6.5: Therapy",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Bayeswatch 7: Wildfire",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Fiction"
              },
              {
                "name": "AI Risk"
              }
            ]
          },
          {
            "title": "Bayeswatch 8: Antimatter",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Bayeswatch 9: Zombies",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Bayeswatch 9.5: Rest & Relaxation",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Bayeswatch 10: Spyware",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Bayeswatch 11: Parabellum",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Bayeswatch 12: The Singularity War",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Bayeswatch 13: Spaceship",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "Ea962TfANLkt6xs2Q",
    "title": "Linguistic Freedom: Map and Territory Revisted",
    "curatedOrder": null,
    "contents": {
      "markdown": "The [Map and Territory](https://www.lesswrong.com/tag/map-and-territory) is one of the most useful concepts that Less Wrong has popularised. One of its key lessons is that we have the linguistic freedom to choose our linguistic conventions we use; there's no fact written in the universe as to whether a tree stump that you sit on counts as a chair. That is, we have linguistic freedom. This idea has many uses, but some of its applications are non-obvious. This sequence will argue that far more is present in the map than you might think."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Linguistic Freedom",
            "tags": [
              {
                "name": "Map and Territory"
              },
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Natural Structures and Conditional Definitions",
            "tags": []
          },
          {
            "title": "Dissolving Sleeping Beauty",
            "tags": [
              {
                "name": "Sleeping Beauty Paradox"
              },
              {
                "name": "Dissolving the Question"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "weBHYgBXg9thEQNEe",
    "title": "Cryonics Signup Guide",
    "curatedOrder": null,
    "contents": {
      "markdown": "A sequence on the procedural knowledge aspect of signing up for cryonics – the concrete steps of what you need to do and how to do it."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Cryonics signup guide #1: Overview",
            "tags": [
              {
                "name": "Cryonics"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "#2: Neurocryopreservation vs whole-body preservation",
            "tags": [
              {
                "name": "Cryonics"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "#3: Choosing a cryonics provider",
            "tags": [
              {
                "name": "Cryonics"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "#4: Introduction to life insurance for cryonics",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Cryonics"
              }
            ]
          },
          {
            "title": "#4.1: Types of life insurance",
            "tags": [
              {
                "name": "Cryonics"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "#4.2: Cryonics-friendly life insurance carriers",
            "tags": [
              {
                "name": "World Optimization"
              },
              {
                "name": "Cryonics"
              }
            ]
          },
          {
            "title": "#4.3: Cryonics-friendly insurance agents",
            "tags": [
              {
                "name": "World Optimization"
              },
              {
                "name": "Cryonics"
              }
            ]
          },
          {
            "title": "#4.4: The insurance underwriting process",
            "tags": [
              {
                "name": "Cryonics"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "#5: Making your cryonics arrangements official",
            "tags": [
              {
                "name": "Cryonics"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "#6: Optional additional steps",
            "tags": [
              {
                "name": "Cryonics"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Appendices to cryonics signup sequence",
            "tags": [
              {
                "name": "Cryonics"
              },
              {
                "name": "Practical"
              },
              {
                "name": "World Optimization"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "TfPXpiwaESD65Mokx",
    "title": "NLP and other Self-Improvement",
    "curatedOrder": null,
    "contents": {
      "markdown": ""
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Empiricism in NLP : Test Operate Text Exit (TOTE)",
            "tags": [
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Not all communication is manipulation: Chaperones don't manipulate proteins",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Communication Cultures"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "dZMDxPBZgHzorNDTt",
    "title": "Takeoff and Takeover in the Past and Future",
    "curatedOrder": null,
    "contents": {
      "markdown": "Over the past two years I ended up writing multiple well-received posts about AI takeoff and AI takeover, usually involving historical case-studies to serve as precedents and analogies. Since they all fit a theme, I've bundled them together in a sequence.\n\nThe most important posts are \"The Date of AI Takeover...\" and \"Against GDP as a Metric...\" If you only read two posts, read those. If you only read three, read those + the \"Cortes, Pizarro, and Afonso... \" one. I've put them in suggested order of reading, but I have no evidence that this is the best order. You may prefer to read them in the order in which they were written, or in order of highest to lowest karma/score."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "The date of AI Takeover is not the day the AI takes over",
            "tags": [
              {
                "name": "AI Timelines"
              },
              {
                "name": "AI"
              },
              {
                "name": "AI Takeoff"
              }
            ]
          },
          {
            "title": "Cortés, Pizarro, and Afonso as Precedents for Takeover",
            "tags": [
              {
                "name": "History"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Lessons on AI Takeover from the conquistadors",
            "tags": [
              {
                "name": "History"
              },
              {
                "name": "AI"
              },
              {
                "name": "LessWrong Event Transcripts"
              }
            ]
          },
          {
            "title": "Soft takeoff can still lead to decisive strategic advantage",
            "tags": [
              {
                "name": "AI Takeoff"
              },
              {
                "name": "Industrial Revolution"
              },
              {
                "name": "AI Risk"
              },
              {
                "name": "AI Governance"
              }
            ]
          },
          {
            "title": "Review of Soft Takeoff Can Still Lead to DSA",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "AI Takeoff"
              },
              {
                "name": "LessWrong Review"
              }
            ]
          },
          {
            "title": "Persuasion Tools: AI takeover without AGI or agency?",
            "tags": [
              {
                "name": "World Optimization"
              },
              {
                "name": "AI"
              },
              {
                "name": "AI Persuasion"
              }
            ]
          },
          {
            "title": "Against GDP as a metric for timelines and takeoff speeds",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "AI Timelines"
              },
              {
                "name": "AI Takeoff"
              },
              {
                "name": "Center on Long-Term Risk (CLR)"
              }
            ]
          },
          {
            "title": "What 2026 looks like",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "Forecasts (Specific Predictions)"
              },
              {
                "name": "AI Timelines"
              },
              {
                "name": "AI Takeoff"
              },
              {
                "name": "AI Persuasion"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "NqMKtBufKW4Wht6rZ",
    "title": "Forecasting Newsletter",
    "curatedOrder": null,
    "contents": {
      "markdown": "A monthly newsletter, with a focus on experimental forecasting."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Forecasting Newsletter: April 2020",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "Newsletters"
              }
            ]
          },
          {
            "title": "Forecasting Newsletter: May 2020.",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "Newsletters"
              }
            ]
          },
          {
            "title": "Forecasting Newsletter. June 2020.",
            "tags": [
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "Newsletters"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Forecasting Newsletter: July 2020. ",
            "tags": [
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Newsletters"
              }
            ]
          },
          {
            "title": "Forecasting Newsletter: August 2020.",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "Newsletters"
              }
            ]
          },
          {
            "title": "Forecasting Newsletter: September 2020. ",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Forecasting & Prediction"
              }
            ]
          },
          {
            "title": "Forecasting Newsletter: October 2020.",
            "tags": [
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Practical"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Newsletters"
              }
            ]
          },
          {
            "title": "Forecasting Newsletter: November 2020",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Forecasting Newsletter: December 2020",
            "tags": [
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "2020: Forecasting in Review.",
            "tags": [
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Forecasting Newsletter: January 2021",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Forecasting Newsletter: February 2021",
            "tags": [
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Forecasting Newsletter: March 2021",
            "tags": [
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Forecasting Newsletter: April 2021",
            "tags": [
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "Newsletters"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Forecasting Newsletter: May 2021",
            "tags": [
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Forecasting Newsletter: June 2021",
            "tags": [
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Forecasting Newsletter: July 2021",
            "tags": [
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Forecasting Newsletter: August 2021",
            "tags": [
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Forecasting Newsletter: September 2021.",
            "tags": [
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Forecasting Newsletter: October 2021.",
            "tags": [
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Forecasting Newsletter: November 2021",
            "tags": [
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Forecasting Newsletter: December 2021",
            "tags": [
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Forecasting Newsletter: Looking back at 2021",
            "tags": [
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Forecasting Newsletter: January 2022",
            "tags": [
              {
                "name": "Prediction Markets"
              },
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "Newsletters"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Forecasting Newsletter: February 2022",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Forecasting Newsletter: April 2222",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Humor"
              }
            ]
          },
          {
            "title": "Forecasting Newsletter: March 2022",
            "tags": [
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "World Modeling"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "BooJ2h9gkHL7RnJ7q",
    "title": "Inner and Outer Alignment Failures in current forecasting systems",
    "curatedOrder": null,
    "contents": {
      "markdown": "Inner alignment problems (related to not aligning forecasts with \"optimize your comparative predictive accuracy\" enough):\n\n*   Discrete prizes for top positions, either in terms of money or in terms of prestige, lead to more extreme forecasts\n*   Large fees and capped amounts in PredictIt means its not worth it to correct their prediction markets when they are wrong\n\nOuter alignment failures (related to aligning forecasts with \"optimize your comparative predictive accuracy\" too much, instead of a better objective):\n\n*   Forecasters mislead other system participants with, e.g., fake polls\n*   Forecasters selectively pick easier questions (picking harder questions reduces your predictive accuracy)\n*   Forecasting systems have tricky difficulties with fixed-point problems (e.g., forecasts about elections affect elections, forecasts about Ebola spread affect measures taken to contain Ebola)\n*   Forecasters are incentivized to copy the community, rather than add new information\n*   Tricky problems with self-fulfilling prophecies (if Warren Buffet predicts a stock goes up, it probably goes up)\n*   Forecasting systems are incentivized to make a prediction and then make it happen (e.g., predicting a company is going to be more valuable because one intends to buy it and dispose of non-productive assets, predict a terrorist attack and then make it happen)\n*   Forecasting systems are incentivized to make the world more uniform in order to more easily predict it (e.g., make the population have surnames and identification numbers instead of local nicknames so that it's easier to conscript and tax them)"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "The Parable of Predict-O-Matic",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Myopia"
              },
              {
                "name": "Oracle AI"
              },
              {
                "name": "Parables & Fables"
              },
              {
                "name": "Self Fulfilling/Refuting Prophecies"
              }
            ]
          },
          {
            "title": "Random Thoughts on Predict-O-Matic",
            "tags": [
              {
                "name": "Myopia"
              },
              {
                "name": "Self Fulfilling/Refuting Prophecies"
              }
            ]
          },
          {
            "title": "Limits of Current US Prediction Markets (PredictIt Case Study)",
            "tags": [
              {
                "name": "Prediction Markets"
              },
              {
                "name": "Economics"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Betting"
              },
              {
                "name": "Efficient Market Hypothesis"
              }
            ]
          },
          {
            "title": "Incentive Problems With Current Forecasting Competitions.",
            "tags": [
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Real-Life Examples of Prediction Systems Interfering with the Real World (Predict-O-Matic Problems)",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "Self Fulfilling/Refuting Prophecies"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "TF77XsD5PbucbJsG3",
    "title": "Luna Lovegood",
    "curatedOrder": 10,
    "contents": {
      "markdown": ""
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "Luna Lovegood and the Chamber of Secrets - Part 1",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "HPMOR (discussion & meta)"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Luna Lovegood and the Chamber of Secrets - Part 2",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Luna Lovegood and the Chamber of Secrets - Part 3",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Luna Lovegood and the Chamber of Secrets - Part 4",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Luna Lovegood and the Chamber of Secrets - Part 5",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Luna Lovegood and the Chamber of Secrets - Part 6",
            "tags": [
              {
                "name": "HPMOR (discussion & meta)"
              },
              {
                "name": "Fiction"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Luna Lovegood and the Chamber of Secrets - Part 7",
            "tags": [
              {
                "name": "HPMOR (discussion & meta)"
              },
              {
                "name": "Fiction"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Luna Lovegood and the Chamber of Secrets - Part 8",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Luna Lovegood and the Chamber of Secrets - Part 9",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Luna Lovegood and the Chamber of Secrets - Part 10",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Luna Lovegood and the Chamber of Secrets - Part 11",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Luna Lovegood and the Chamber of Secrets - Part 12",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Fiction"
              },
              {
                "name": "HPMOR (discussion & meta)"
              }
            ]
          },
          {
            "title": "Luna Lovegood and the Chamber of Secrets - Part 13",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Fiction"
              },
              {
                "name": "HPMOR (discussion & meta)"
              }
            ]
          },
          {
            "title": "Luna Lovegood and the Fidelius Curse - Part 4",
            "tags": [
              {
                "name": "HPMOR (discussion & meta)"
              },
              {
                "name": "Fiction"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Luna Lovegood and the Fidelius Curse - Part 1",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "HPMOR (discussion & meta)"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Luna Lovegood and the Fidelius Curse - Part 2",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "HPMOR (discussion & meta)"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Luna Lovegood and the Fidelius Curse - Part 3",
            "tags": [
              {
                "name": "HPMOR (discussion & meta)"
              },
              {
                "name": "Fiction"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Luna Lovegood and the Fidelius Curse - Part 5",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "HPMOR (discussion & meta)"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Luna Lovegood and the Fidelius Curse - Part 6",
            "tags": [
              {
                "name": "HPMOR (discussion & meta)"
              },
              {
                "name": "Fiction"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Luna Lovegood and the Fidelius Curse - Part 7",
            "tags": [
              {
                "name": "HPMOR (discussion & meta)"
              },
              {
                "name": "Fiction"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Luna Lovegood and the Fidelius Curse - Part 8",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "HPMOR (discussion & meta)"
              }
            ]
          },
          {
            "title": "Luna Lovegood and the Fidelius Curse - Part 9",
            "tags": [
              {
                "name": "HPMOR (discussion & meta)"
              },
              {
                "name": "Fiction"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Luna Lovegood and the Fidelius Curse - Part 10",
            "tags": [
              {
                "name": "HPMOR (discussion & meta)"
              },
              {
                "name": "Fiction"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Luna Lovegood and the Fidelius Curse - Part 11",
            "tags": [
              {
                "name": "HPMOR (discussion & meta)"
              },
              {
                "name": "Fiction"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Luna Lovegood and the Fidelius Curse - Part 12",
            "tags": [
              {
                "name": "HPMOR (discussion & meta)"
              },
              {
                "name": "Fiction"
              },
              {
                "name": "Rationality"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "nWEqWdoZAca8kj5zM",
    "title": "Re-reading Rationality From AI To Zombies",
    "curatedOrder": null,
    "contents": {
      "markdown": "I first read The Sequences about eight years ago when I was a sophomore in college. They had a huge influence on me. When I read through them, I knew I found my tribe in the LessWrong community. But that was a long time ago, and I think I'd really benefit from re-reading them.\n\nMore specifically, I think I need to *actively engage* with them, not just passively consume them. Summarize, explain in my own words, comment on, critique, extend — stuff like that. Educational psychologists say that all of this is key for developing a real understanding of something, so that's what I'm going to do here. So then, don't think of this as some sort of authoritative resource. I'm just a guy.\n\nI guess this sorta goes without saying, but I would really welcome discussion in the comments. As I said, I'm really trying to engage with the material, and conversation is a great way to do that. For your benefit as well as mine! I think that this sort of active engagement is a big time low hanging fruit. Maybe I'll also set up video chat as a way to complement text-based chat.\n\nOf course, by participating on LessWrong in general, we are engaging with this material in some sense. But I think that it'd be useful to engage with it more directly. Or maybe I'm just jealous of the OGs from the Overcoming Bias days who were around when The Sequences were being written and got to participate in those discussions.\n\n[Tsuyoku Naritai!](https://www.lesswrong.com/tag/tsuyoku-naritai)"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Map and Territory: Summary and Thoughts",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Rationality A-Z (discussion & meta)"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "rDe8QE5NvXcZYzgZ3",
    "title": "Squiggle",
    "curatedOrder": null,
    "contents": {
      "markdown": "Posts about the in-development programming language, Squiggle.\n\n[https://squiggle-language.com/](https://squiggle-language.com/)"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Multivariate estimation & the Squiggly language",
            "tags": [
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "LessWrong Event Transcripts"
              },
              {
                "name": "Software Tools"
              },
              {
                "name": "Probability & Statistics"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Squiggle"
              }
            ]
          },
          {
            "title": "Squiggle: An Overview",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Practical"
              },
              {
                "name": "QURI"
              },
              {
                "name": "Squiggle"
              }
            ]
          },
          {
            "title": "Squiggle: Technical Overview",
            "tags": [
              {
                "name": "World Optimization"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "QURI"
              },
              {
                "name": "Squiggle"
              }
            ]
          },
          {
            "title": "Adjusting probabilities for the passage of time, using Squiggle",
            "tags": [
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "Squiggle"
              }
            ]
          },
          {
            "title": "Announcing Squiggle: Early Access",
            "tags": [
              {
                "name": "Programming"
              },
              {
                "name": "Practical"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Squiggle"
              },
              {
                "name": "QURI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "AaKNSG7caKMFmPWtn",
    "title": "The central limit theorems",
    "curatedOrder": null,
    "contents": {
      "markdown": "Understanding the central limit theorems in terms of convolutions."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "The central limit theorem in terms of convolutions",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Probability & Statistics"
              },
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "ET Jaynes"
              }
            ]
          },
          {
            "title": "Convolution as smoothing",
            "tags": [
              {
                "name": "Probability & Statistics"
              },
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "How long does it take to become Gaussian?",
            "tags": [
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "Probability & Statistics"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Finding the Central Limit Theorem in Bayes' rule",
            "tags": [
              {
                "name": "Bayes' Theorem"
              },
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "Probability & Statistics"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "World Modeling"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "ReFDRRfGDec4AadbE",
    "title": "Sunzi's《Methods of War》",
    "curatedOrder": null,
    "contents": null,
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Sunzi's《Methods of War》- Introduction",
            "tags": [
              {
                "name": "War"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Sunzi's《Methods of War》- War",
            "tags": [
              {
                "name": "War"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Sunzi's《Methods of War》- Planning Attacks",
            "tags": [
              {
                "name": "World Optimization"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "War"
              }
            ]
          },
          {
            "title": "Sunzi's《Methods of War》- The Army's Form",
            "tags": [
              {
                "name": "War"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Sunzi's《Methods of War》- Potential",
            "tags": [
              {
                "name": "War"
              },
              {
                "name": "Rationality"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "rencyawwfr4rfwt5C",
    "title": "COVID-19 Updates and Analysis",
    "curatedOrder": null,
    "contents": null,
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": []
      },
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": "March 2020"
        },
        "posts": [
          {
            "title": "Coronavirus is Here",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "What is a School?",
            "tags": [
              {
                "name": "Education"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Let My People Stay Home",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          }
        ]
      },
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": "April 2020"
        },
        "posts": [
          {
            "title": "Taking Initial Viral Load Seriously",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "On R0",
            "tags": [
              {
                "name": "Covid-19"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Seemingly Popular Covid-19 Model is Obvious Nonsense",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "My Covid-19 Thinking: 4/17",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "My Covid-19 Thinking: 4/23 pre-Cuomo Data",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "On New York’s Antibody Tests",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "On “COVID-19 Superspreader Events in 28 Countries: Critical Patterns and Lessons”",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid-19 4/30: Stuck in Limbo",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          }
        ]
      },
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": "May 2020"
        },
        "posts": [
          {
            "title": "SlateStarCodex 2020 Predictions: Buy, Sell, Hold",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Forecasting & Prediction"
              }
            ]
          },
          {
            "title": "Covid-19: New York’s Antibody Tests 2",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid-19 5/7: Fighting Limbo",
            "tags": [
              {
                "name": "Covid-19"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Covid-19: Comorbidity",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 5/21: Limbo Under",
            "tags": [
              {
                "name": "Covid-19"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Covid-19 5/29: Dumb Reopening",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid-19: My Current Model",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          }
        ]
      },
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": "June 2020"
        },
        "posts": [
          {
            "title": "Covid-19 6/4: The Eye of the Storm",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid-19 6/11: Bracing For a Second Wave",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid-19 6/18: The Virus Goes South",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 6/25: The Dam Breaks",
            "tags": [
              {
                "name": "Covid-19"
              },
              {
                "name": "World Modeling"
              }
            ]
          }
        ]
      },
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": "July 2020"
        },
        "posts": [
          {
            "title": "Covid 7/2: It Could Be Worse",
            "tags": [
              {
                "name": "Covid-19"
              },
              {
                "name": "Community"
              }
            ]
          },
          {
            "title": "Covid 7/9: Lies, Damn Lies and Death Rates",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid-19: Analysis of Mortality Data",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 7/16: Becoming the Mask",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 7/23: The Second Summit",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "New Paper on Herd Immunity Thresholds",
            "tags": [
              {
                "name": "Covid-19"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Covid 7/30: Whack a Mole",
            "tags": [
              {
                "name": "Covid-19"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Politics"
              }
            ]
          }
        ]
      },
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": "August 2020"
        },
        "posts": [
          {
            "title": "Covid 8/6: The Case of the Missing Data",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 8/13: Same As It Ever Was",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 8/20: A Little Progress",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 8/27: The Fall of the CDC",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          }
        ]
      },
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": "September 2020"
        },
        "posts": [
          {
            "title": "Covid 9/3: Meet the New CDC",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 9/10: Vitamin D",
            "tags": [
              {
                "name": "Covid-19"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Covid 9/17: It’s Worse",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 9/24: Until Morale Improves",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          }
        ]
      },
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": "October 2020"
        },
        "posts": [
          {
            "title": "Covid 10/1: The Long Haul",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 10/8: October Surprise",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 10/15: Playtime is Over",
            "tags": [
              {
                "name": "Covid-19"
              },
              {
                "name": "Practical"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Covid 10/22: Europe in Crisis",
            "tags": [
              {
                "name": "Covid-19"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Covid Covid Covid Covid Covid 10/29: All We Ever Talk About",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          }
        ]
      },
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": "November 2020"
        },
        "posts": [
          {
            "title": "Covid 11/5: Don’t Mention the War",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 11/12: The Winds of Winter",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 11/19: Don’t Do Stupid Things",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 11/26: Thanksgiving",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          }
        ]
      },
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": "December 2020"
        },
        "posts": [
          {
            "title": "Covid 12/3: Land of Confusion",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 12/10: Vaccine Approval Day in America",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 12/17: The First Dose",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 12/24: We’re F***ed, It’s Over",
            "tags": [
              {
                "name": "Covid-19"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Politics"
              }
            ]
          },
          {
            "title": "What evidence will tell us about the new strain? How are you updating?",
            "tags": [
              {
                "name": "Covid-19"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Covid 12/31: Meet the New Year",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          }
        ]
      },
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": "January 2021"
        },
        "posts": [
          {
            "title": "Fourth Wave Covid Toy Modeling",
            "tags": [
              {
                "name": "Covid-19"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Covid 1/7: The Fire of a Thousand Suns",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 1/14: To Launch a Thousand Shipments",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid: The Question of Immunity From Infection",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 1/21: Turning the Corner",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 1/28: Muddling Through",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          }
        ]
      },
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": "February 2021"
        },
        "posts": [
          {
            "title": "Covid 2/4: Safe and Effective Vaccines Aplenty",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 2/11: As Expected",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 2/18: Vaccines Still Work",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Judging Our April 2020 Covid-19 Predictions",
            "tags": [
              {
                "name": "Covid-19"
              },
              {
                "name": "Forecasts (Specific Predictions)"
              },
              {
                "name": "Postmortems & Retrospectives"
              }
            ]
          },
          {
            "title": "Covid 2/25: Holding Pattern",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          }
        ]
      },
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": "March 2021"
        },
        "posts": [
          {
            "title": "Covid 3/4: Declare Victory and Leave Home",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 3/12: New CDC Guidelines Available",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 3/18: An Expected Quantity of Blood Clots",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 3/25: Own Goals",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          }
        ]
      },
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": "April 2021"
        },
        "posts": [
          {
            "title": "Covid 4/1: Vaccine Passports",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 4/9: Another Vaccine Passport Objection",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 4/15: Are We Seriously Doing This Again",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 4/22: Crisis in India",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 4/29: Vaccination Slowdown",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          }
        ]
      },
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": "May 2021"
        },
        "posts": [
          {
            "title": "Covid 5/6: Vaccine Patent Suspension",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 5/13: Moving On",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 5/20: The Great Unmasking",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 5/27: The Final Countdown",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          }
        ]
      },
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": "June 2021"
        },
        "posts": [
          {
            "title": "Covid 6/3: No News is Good News",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 6/10: Somebody Else’s Problem",
            "tags": [
              {
                "name": "Covid-19"
              },
              {
                "name": "Politics"
              }
            ]
          },
          {
            "title": "Covid 6/17: One Last Scare",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 6/24: The Spanish Prisoner",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          }
        ]
      },
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": "July 2021"
        },
        "posts": [
          {
            "title": "Covid 7/1: Don’t Panic",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 7/8: Delta Takes Over",
            "tags": [
              {
                "name": "Covid-19"
              },
              {
                "name": "Politics"
              }
            ]
          },
          {
            "title": "Covid 7/15: Rates of Change",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 7/22: Error Correction",
            "tags": [
              {
                "name": "Covid-19"
              },
              {
                "name": "Politics"
              }
            ]
          },
          {
            "title": "Covid 7/29: You Play to Win the Game",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          }
        ]
      },
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": "August 2021"
        },
        "posts": [
          {
            "title": "Covid 8/5: Much Ado About Nothing",
            "tags": [
              {
                "name": "Covid-19"
              },
              {
                "name": "Politics"
              }
            ]
          },
          {
            "title": "Covid 8/12: The Worst Is Over",
            "tags": [
              {
                "name": "Covid-19"
              },
              {
                "name": "Politics"
              }
            ]
          },
          {
            "title": "Covid 8/19: Cracking the Booster",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 8/26: Full Vaccine Approval",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          }
        ]
      },
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": "September 2021"
        },
        "posts": [
          {
            "title": "Covid 9/2: Long Covid Analysis",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 9/9: Passing the Peak",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 9/17: Done Biden His Time",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 9/23: There Is a War",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 9/30: People Respond to Incentives",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          }
        ]
      },
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": "October 2021"
        },
        "posts": [
          {
            "title": "Covid 10/7: Steady as She Goes",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 10/14: Less Long Cvoid",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 10/21: Rogan vs. Gupta",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 10/28: An Unexpected Victory",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          }
        ]
      },
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": "November 2021"
        },
        "posts": [
          {
            "title": "Covid 11/4: The After Times",
            "tags": [
              {
                "name": "Covid-19"
              },
              {
                "name": "Politics"
              }
            ]
          },
          {
            "title": "Covid 11/11: Winter and Effective Treatments Are Coming",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 11/18: Paxlovid Remains Illegal",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Paxlovid Remains Illegal: 11/24 Update",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Covid 11/25: Another Thanksgiving",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Omicron Variant Post #1: We’re F***ed, It’s Never Over",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          },
          {
            "title": "Omicron Variant Post #2",
            "tags": [
              {
                "name": "Covid-19"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "o58ZMNaovdztbLfvN",
    "title": "Deconfusing Goal-Directedness",
    "curatedOrder": null,
    "contents": {
      "markdown": "A sequence about deconfusing goal-directedness."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Why You Should Care About Goal-Directedness",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Literature Review on Goal-Directedness",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Goal-Directedness"
              },
              {
                "name": "Literature Reviews"
              }
            ]
          },
          {
            "title": "Applications for Deconfusing Goal-Directedness",
            "tags": [
              {
                "name": "Goal-Directedness"
              },
              {
                "name": "Instrumental Convergence"
              },
              {
                "name": "Optimization"
              },
              {
                "name": "Inner Alignment"
              },
              {
                "name": "Deconfusion"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Goal-Directedness and Behavior, Redux",
            "tags": [
              {
                "name": "Deconfusion"
              },
              {
                "name": "Goal-Directedness"
              },
              {
                "name": "AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "B26RwutvaDa6hvJuP",
    "title": "The Grueling Subject",
    "curatedOrder": null,
    "contents": {
      "markdown": "Talking about politics is hard. It's hard to think well about the topic. It's important to get better at thinking about the topic even if it's a grueling subject."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "In Defense of Politics",
            "tags": [
              {
                "name": "Politics"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "How do you read the news critically?",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Journalism"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Beware of identifying with schools of thought",
            "tags": []
          },
          {
            "title": "A systematic error that lead to a bad policy response to COVID-19",
            "tags": [
              {
                "name": "Covid-19"
              },
              {
                "name": "World Optimization"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "wKPWFvdMyvgDWfusX",
    "title": "2020 Less Wrong Darwin Game",
    "curatedOrder": null,
    "contents": null,
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "The Darwin Game",
            "tags": [
              {
                "name": "Exercises / Problem-Sets"
              },
              {
                "name": "Evolution"
              },
              {
                "name": "Programming"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Game Theory"
              },
              {
                "name": "Prisoner's Dilemma"
              }
            ]
          },
          {
            "title": "The Darwin Game - Rounds 0 to 10",
            "tags": [
              {
                "name": "Game Theory"
              },
              {
                "name": "Programming"
              }
            ]
          },
          {
            "title": "The Darwin Game - Rounds 1 to 2",
            "tags": [
              {
                "name": "Prisoner's Dilemma"
              },
              {
                "name": "Game Theory"
              },
              {
                "name": "Programming"
              }
            ]
          },
          {
            "title": "The Darwin Game - Rounds 3 to 9",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "The Darwin Game - Rounds 10 to 20",
            "tags": [
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "The Darwin Game - Rounds 21-500",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Prisoner's Dilemma"
              }
            ]
          },
          {
            "title": "The Mutant Game - Rounds 11 to 30",
            "tags": [
              {
                "name": "Game Theory"
              },
              {
                "name": "Prisoner's Dilemma"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "The Mutant Game - Rounds 31 to 90",
            "tags": [
              {
                "name": "Prisoner's Dilemma"
              },
              {
                "name": "Game Theory"
              }
            ]
          },
          {
            "title": "The Mutant Game - Rounds 91 to 247",
            "tags": [
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "The Darwin Game - Conclusion",
            "tags": [
              {
                "name": "Game Theory"
              },
              {
                "name": "Community"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "2A7rrZ4ySx6R8mfoT",
    "title": "Cartesian Frames",
    "curatedOrder": 0,
    "contents": {
      "markdown": "Cartesian frames are a way to add a first-person perspective (with choices, uncertainty, and so on) on top of a set of possible worlds. This sequence introduces Cartesian frames and basic operations on frames."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Introduction to Cartesian Frames",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Embedded Agency"
              }
            ]
          },
          {
            "title": "Additive Operations on Cartesian Frames",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Embedded Agency"
              },
              {
                "name": "Category Theory"
              }
            ]
          },
          {
            "title": "Biextensional Equivalence",
            "tags": [
              {
                "name": "Embedded Agency"
              },
              {
                "name": "AI"
              },
              {
                "name": "Category Theory"
              }
            ]
          },
          {
            "title": "Controllables and Observables, Revisited",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Embedded Agency"
              }
            ]
          },
          {
            "title": "Functors and Coarse Worlds",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Embedded Agency"
              },
              {
                "name": "Abstraction"
              }
            ]
          },
          {
            "title": "Subagents of Cartesian Frames",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Subagents"
              },
              {
                "name": "Embedded Agency"
              }
            ]
          },
          {
            "title": "Multiplicative Operations on Cartesian Frames",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Embedded Agency"
              },
              {
                "name": "Category Theory"
              }
            ]
          },
          {
            "title": "Sub-Sums and Sub-Tensors",
            "tags": [
              {
                "name": "Embedded Agency"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Additive and Multiplicative Subagents",
            "tags": [
              {
                "name": "Embedded Agency"
              },
              {
                "name": "Subagents"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Committing, Assuming, Externalizing, and Internalizing",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Embedded Agency"
              },
              {
                "name": "Subagents"
              }
            ]
          },
          {
            "title": "Eight Definitions of Observability",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Embedded Agency"
              },
              {
                "name": "Subagents"
              }
            ]
          },
          {
            "title": "Time in Cartesian Frames",
            "tags": [
              {
                "name": "Embedded Agency"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Cartesian Frames and Factored Sets on ArXiv",
            "tags": [
              {
                "name": "Finite Factored Sets"
              },
              {
                "name": "World Modeling"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "nJzqnsZCfg2k4s2BP",
    "title": "Quantitative Finance",
    "curatedOrder": null,
    "contents": null,
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Why quantitative finance is so hard",
            "tags": [
              {
                "name": "Financial Investing"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Hypothesis Space Entropy",
            "tags": [
              {
                "name": "Probability & Statistics"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "The Kelly Criterion in 3D",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Betting"
              },
              {
                "name": "Kelly Criterion"
              },
              {
                "name": "Probability & Statistics"
              }
            ]
          },
          {
            "title": "How to Price a Futures Contract",
            "tags": [
              {
                "name": "World Optimization"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Financial Investing"
              }
            ]
          },
          {
            "title": "Alpha α and Beta β",
            "tags": [
              {
                "name": "Financial Investing"
              },
              {
                "name": "Practical"
              },
              {
                "name": "World Modeling"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "mzgtmmTKKn5MuCzFJ",
    "title": "AGI safety from first principles",
    "curatedOrder": 499,
    "contents": {
      "markdown": "In this report (also [available here as a PDF](https://drive.google.com/file/d/1uK7NhdSKprQKZnRjU58X7NLA1auXlWHt/view?usp=sharing)) I have attempted to put together the most compelling case for why the development of artificial general intelligence (AGI) might pose an existential threat. It stems from my dissatisfaction with existing arguments about the potential risks from AGI. Early work tends to be less relevant in the context of modern machine learning; more recent work is scattered and brief. I originally intended to just summarise other people's arguments, but as this report has grown, it's become more representative of my own views and less representative of anyone else's. So while it covers the standard ideas, I also think that it provides a new perspective on how to think about AGI - one which doesn't take any previous claims for granted, but attempts to work them out from first principles."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "AGI safety from first principles: Introduction",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "AGI safety from first principles: Superintelligence",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "AGI safety from first principles: Goals and Agency",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "AGI safety from first principles: Alignment",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "AGI safety from first principles: Control",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "AGI safety from first principles: Conclusion",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Commentary on AGI Safety from First Principles",
            "tags": [
              {
                "name": "AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "mFDCbtzb2st4j5BJQ",
    "title": "XiXiDu's AI Risk Interview Series",
    "curatedOrder": null,
    "contents": {
      "markdown": "From 2011 to 2013, [Alexander Kruel](http://kruel.co/) (XiXiDu) published a Q&A style interview series asking various people about their perception of artificial intelligence and possible risks associated with it.\n\nQuestions\n---------\n\nThe latest set of questions:\n\n*   Assuming beneficial political and economic development and that no global catastrophe halts progress, by what year would you assign a 10%/50%/90% chance of the development of artificial intelligence that is roughly as good as humans (or better, perhaps unevenly) at science, mathematics, engineering and programming?\n*   Once we build AI that is roughly as good as humans (or better, perhaps unevenly) at science, mathematics, engineering and programming, how much more difficult will it be for humans and/or AIs to build an AI which is substantially better at those activities than humans?\n*   Do you ever expect artificial intelligence to overwhelmingly outperform humans at typical academic research, in the way that they may soon overwhelmingly outperform humans at trivia contests, or do you expect that humans will always play an important role in scientific progress?\n*   What probability do you assign to the possibility of an AI with initially roughly professional human-level competence (or better, perhaps unevenly) at general reasoning (including science, mathematics, engineering and programming) to self-modify its way up to vastly superhuman capabilities within a matter of hours/days/< 5 years?\n*   How important is it to research risks associated with artificial intelligence that is good enough at general reasoning (including science, mathematics, engineering and programming) to be capable of radical self-modification, before attempting to build one?\n*   What probability do you assign to the possibility of human extinction within 100 years as a result of AI capable of self-modification (that is not provably non-dangerous, if that is even possible)? P(human extinction by AI | AI capable of self-modification and not provably non-dangerous is created)\n\nMail Template\n-------------\n\nThe exact wording of the email:\n\n> Subject: Questions regarding possible risks from artificial intelligence\n\n> Dear Professor/Dr NAME,\n\n> I am currently trying to learn more about the academic perception of artificial general intelligence and possible risks associated with it. Consequently I am curious about your opinion as a noted expert.\n\n> I would like to ask you a few questions and your permission to publish your possible answers in order to estimate the academic awareness and perception of risks from AI. I am not a journalist and do not represent any publication, nor do I maintain a formal academic relationship. I am conducting an informal interview for a community blog: lesswrong.com\n\n> Please let me know if you have any questions or if you are interested in third-party material that does expand on various aspects of my questions.\n\n> Here is a list of people that I had a chance to interview so far: NAMES\n\n> QUESTIONS\n\n> Yours sincerely,\n\n> NAME\n\n> ADDRESS\n\nExtra Interviews\n----------------\n\nThe interviews listed below have not been cross-posted to LessWrong:\n\n*   [Professor John E. Laird and Dr. Kristinn R. Thorisson](http://kruel.co/2012/08/15/qa-with-experts-on-risks-from-ai-5/)\n*   [Dr. Randal A. Koene and Alexey Potapov of AIDEUS](http://kruel.co/2012/12/17/qa-with-experts-on-risks-from-ai-6/)\n*   [Professor Larry Wasserman](http://kruel.co/2012/11/04/qa-with-larry-wasserman-on-risks-from-ai/)\n*   [Dr. Mark Changizi](http://kruel.co/2012/12/19/qa-with-mark-changizi-on-risks-from-ai/)\n*   [Dr. Matt Mahoney](http://kruel.co/2013/07/08/qa-with-matt-mahoney-on-risks-from-ai/)\n*   [Sir William Timothy Gowers](http://kruel.co/2013/07/16/qa-with-timothy-gowers-on-risks-from-ai/)\n\nSee Also (last updated 2013)\n----------------------------\n\n*   [Muehlhauser interview series on AGI](https://www.lesswrong.com/tag/muehlhauser-interview-series-on-agi)\n*   [When Will AI Be Created?](http://intelligence.org/2013/05/15/when-will-ai-be-created/)\n*   [AI timeline predictions: are we getting better?](http://lesswrong.com/lw/e36/ai_timeline_predictions_are_we_getting_better/)\n*   [Stuart Armstrong: How We’re Predicting AI](http://fora.tv/v/c16838), The Singularity Summit 2012\n*   [Experts on artificial general intelligence provide estimates for the future of AGI.](http://sethbaum.com/ac/2011_AI-Experts.html), Baum, Seth D., Ben Goertzel, and Ted G. Goertzel, 2011.\n*   [Machine Intelligence Survey](http://www.fhi.ox.ac.uk/news/2011/?a=21516), Sandberg, A. and Bostrom, N. (2011). Future of Humanity Institute, Oxford University."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Q&A with experts on risks from AI #1",
            "tags": [
              {
                "name": "Existential Risk"
              },
              {
                "name": "AI Risk"
              },
              {
                "name": "Q&A (format)"
              },
              {
                "name": "Interviews"
              }
            ]
          },
          {
            "title": "Q&A with experts on risks from AI #2",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "AI Risk"
              },
              {
                "name": "Q&A (format)"
              },
              {
                "name": "Interviews"
              }
            ]
          },
          {
            "title": "Q&A with experts on risks from AI #3",
            "tags": []
          },
          {
            "title": "Q&A with experts on risks from AI #4",
            "tags": []
          },
          {
            "title": "Q&A with Michael Littman on risks from AI",
            "tags": []
          },
          {
            "title": "Q&A with Shane Legg on risks from AI",
            "tags": [
              {
                "name": "Q&A (format)"
              }
            ]
          },
          {
            "title": "Q&A with Jürgen Schmidhuber on risks from AI",
            "tags": [
              {
                "name": "Q&A (format)"
              },
              {
                "name": "Interviews"
              },
              {
                "name": "AI Risk"
              }
            ]
          },
          {
            "title": "Q&A with Stan Franklin on risks from AI",
            "tags": [
              {
                "name": "AI Risk"
              },
              {
                "name": "Q&A (format)"
              },
              {
                "name": "Interviews"
              }
            ]
          },
          {
            "title": "Q&A with Abram Demski on risks from AI",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "AI Risk"
              },
              {
                "name": "Q&A (format)"
              },
              {
                "name": "Interviews"
              }
            ]
          },
          {
            "title": "Q&A with Richard Carrier on risks from AI",
            "tags": []
          }
        ]
      }
    ]
  },
  {
    "_id": "xezt7HYfpWR6nwp7Z",
    "title": "Factored Cognition",
    "curatedOrder": null,
    "contents": {
      "markdown": "Factored Cognition describes a process in which difficult problems are recursively decomposed into simpler problems. This sequence summarizes my conclusions from thinking about this topic for a few months."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": 1,
        "contents": {
          "markdown": "Before we get to the problem itself, first an introduction to the existing alignment proposals that make use of Factored Cognition:"
        },
        "posts": [
          {
            "title": "A guide to Iterated Amplification & Debate",
            "tags": [
              {
                "name": "Factored Cognition"
              },
              {
                "name": "Iterated Amplification "
              },
              {
                "name": "Humans Consulting HCH"
              },
              {
                "name": "Debate (AI safety technique)"
              },
              {
                "name": "AI Risk"
              },
              {
                "name": "AI"
              }
            ]
          }
        ]
      },
      {
        "title": null,
        "subtitle": null,
        "number": 2,
        "contents": {
          "markdown": "... and an attempt to characterize what makes something 'a subproblem' rather than 'a part of a large problem':"
        },
        "posts": [
          {
            "title": "Hiding Complexity",
            "tags": [
              {
                "name": "Factored Cognition"
              },
              {
                "name": "Rationality"
              }
            ]
          }
        ]
      },
      {
        "title": null,
        "subtitle": null,
        "number": 3,
        "contents": {
          "markdown": "A few more words about the sequence:"
        },
        "posts": [
          {
            "title": "Preface to the Sequence on Factored Cognition",
            "tags": [
              {
                "name": "Factored Cognition"
              },
              {
                "name": "AI"
              },
              {
                "name": "Rationality"
              }
            ]
          }
        ]
      },
      {
        "title": null,
        "subtitle": null,
        "number": 4,
        "contents": {
          "markdown": "For our first angle of attack, we use pure mathematics. We define a formal model and explore it as much as possible:"
        },
        "posts": [
          {
            "title": "Idealized Factored Cognition",
            "tags": [
              {
                "name": "Factored Cognition"
              },
              {
                "name": "AI"
              },
              {
                "name": "Humans Consulting HCH"
              },
              {
                "name": "Debate (AI safety technique)"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Traversing a Cognition Space",
            "tags": [
              {
                "name": "Factored Cognition"
              },
              {
                "name": "Debate (AI safety technique)"
              },
              {
                "name": "Rationality"
              }
            ]
          }
        ]
      },
      {
        "title": null,
        "subtitle": null,
        "number": 5,
        "contents": {
          "markdown": "Before switching gears, we briefly address some commonly misunderstood aspects about Factored Cognition:"
        },
        "posts": [
          {
            "title": "Clarifying Factored Cognition",
            "tags": [
              {
                "name": "Factored Cognition"
              },
              {
                "name": "Humans Consulting HCH"
              },
              {
                "name": "Debate (AI safety technique)"
              },
              {
                "name": "AI"
              }
            ]
          }
        ]
      },
      {
        "title": null,
        "subtitle": null,
        "number": 6,
        "contents": {
          "markdown": "Finally, we take a look at the human component that exists in both IDA and Debate. Our goal is to evaluate whether the human's task remains feasible as the schemes are applied to progressively harder problems:"
        },
        "posts": [
          {
            "title": "Intuition",
            "tags": [
              {
                "name": "Factored Cognition"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "FC final: Can Factored Cognition schemes scale?",
            "tags": [
              {
                "name": "Factored Cognition"
              },
              {
                "name": "Humans Consulting HCH"
              },
              {
                "name": "Debate (AI safety technique)"
              },
              {
                "name": "AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "SyNM8S9FbJjWyf3D6",
    "title": "Objective Dog Ratings",
    "curatedOrder": null,
    "contents": {
      "markdown": "  \n\nBecause they’re not all good dogs, Brent.\n\nOriginal posts [here](https://wmbsaltworks.wordpress.com/tag/theyre-not-all-good-dogs-brent-some-are-better-than-others/)."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Objective Dog Ratings: An Introduction & Explanation",
            "tags": [
              {
                "name": "Humor"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Objective Dog Ratings: The Irish Wolfhound",
            "tags": [
              {
                "name": "Humor"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Objective Dog Ratings: The Shiba Inu",
            "tags": [
              {
                "name": "Humor"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "CmrW8fCmSLK7E25sa",
    "title": "Infra-Bayesianism",
    "curatedOrder": null,
    "contents": {
      "markdown": "Infra-Bayesianism is a new approach to epistemology / decision theory / reinforcement learning theory, which builds on \"imprecise probability\" to solve the problem of prior misspecification / grain-of-truth / nonrealizability which plagues Bayesianism and Bayesian reinforcement learning. \n\nInfra-Bayesianism also naturally leads to an implementation of UDT, and (more speculatively at this stage) has applications to multi-agent theory, embedded agency and reflection. This sequence lays down the foundations of the approach."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Introduction To The Infra-Bayesianism Sequence",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Bayes' Theorem"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Infra-Bayesianism"
              }
            ]
          },
          {
            "title": "Basic Inframeasure Theory",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Infra-Bayesianism"
              }
            ]
          },
          {
            "title": "Belief Functions And Decision Theory",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "Infra-Bayesianism"
              }
            ]
          },
          {
            "title": "Less Basic Inframeasure Theory",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "AI"
              },
              {
                "name": "Infra-Bayesianism"
              }
            ]
          },
          {
            "title": "Inframeasures and Domain Theory",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Infra-Bayesianism"
              },
              {
                "name": "Domain Theory"
              }
            ]
          },
          {
            "title": "The Many Faces of Infra-Beliefs",
            "tags": [
              {
                "name": "Infra-Bayesianism"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Counterfactuals"
              }
            ]
          },
          {
            "title": "Infra-Miscellanea",
            "tags": [
              {
                "name": "Infra-Bayesianism"
              }
            ]
          },
          {
            "title": "Infra-Topology",
            "tags": [
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Proofs Section 1.1 (Initial results to LF-duality)",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "Infra-Bayesianism"
              },
              {
                "name": "Formal Proof"
              }
            ]
          },
          {
            "title": "Proofs Section 1.2 (Mixtures, Updates, Pushforwards)",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "Infra-Bayesianism"
              },
              {
                "name": "Formal Proof"
              }
            ]
          },
          {
            "title": "Proofs Section 2.1 (Theorem 1, Lemmas)",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Infra-Bayesianism"
              },
              {
                "name": "Formal Proof"
              }
            ]
          },
          {
            "title": "Proofs Section 2.2 (Isomorphism to Expectations)",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "Infra-Bayesianism"
              },
              {
                "name": "Formal Proof"
              }
            ]
          },
          {
            "title": "Proofs Section 2.3 (Updates, Decision Theory)",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "Infra-Bayesianism"
              },
              {
                "name": "Formal Proof"
              }
            ]
          },
          {
            "title": "LBIT Proofs 1: Propositions 1-9",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Formal Proof"
              }
            ]
          },
          {
            "title": "LBIT Proofs 2: Propositions 10-18",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Formal Proof"
              }
            ]
          },
          {
            "title": "LBIT Proofs 3: Propositions 19-22",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Formal Proof"
              }
            ]
          },
          {
            "title": "LBIT Proofs 4: Propositions 22-28",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Formal Proof"
              }
            ]
          },
          {
            "title": "LBIT Proofs 5: Propositions 29-38",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Formal Proof"
              }
            ]
          },
          {
            "title": "LBIT Proofs 6: Propositions 39-47",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Formal Proof"
              }
            ]
          },
          {
            "title": "LBIT Proofs 7: Propositions 48-52",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Formal Proof"
              }
            ]
          },
          {
            "title": "LBIT Proofs 8: Propositions 53-58",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Formal Proof"
              }
            ]
          },
          {
            "title": "Infra-Domain proofs 1",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Domain Theory"
              },
              {
                "name": "Formal Proof"
              }
            ]
          },
          {
            "title": "Infra-Domain Proofs 2",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Domain Theory"
              },
              {
                "name": "Formal Proof"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "mAx3ZygNGyoY7TNvB",
    "title": "Salticidae Philosophiae",
    "curatedOrder": null,
    "contents": {
      "markdown": "Abstracts, commentaries, and reviews of philosophical literature, mirrored from [my blog of the same name](https://saltphil.wordpress.com/). Not every article will be mirrored, so you may want to pop over there for scraps, articles whose commentary is pretty much \"This is completely, absolutely wrong,\" and so on."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "\"The Conspiracy against the Human Race,\" by Thomas Ligotti",
            "tags": [
              {
                "name": "Philosophy"
              },
              {
                "name": "Negative Utilitarianism"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Book Reviews"
              },
              {
                "name": "Summaries"
              }
            ]
          },
          {
            "title": "\"Technology and the Future of Persons\", by Lynne Rudder Baker (2013)",
            "tags": [
              {
                "name": "Philosophy"
              },
              {
                "name": "Consciousness"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Book Reviews"
              },
              {
                "name": "Summaries"
              }
            ]
          },
          {
            "title": "\"On Bullshit\" and \"On Truth,\" by Harry Frankfurt",
            "tags": [
              {
                "name": "Philosophy"
              },
              {
                "name": "Epistemology"
              },
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Deception"
              },
              {
                "name": "Book Reviews"
              },
              {
                "name": "Summaries"
              }
            ]
          },
          {
            "title": "\"How to Talk About Books You Haven't Read\", by Pierre Bayard",
            "tags": [
              {
                "name": "Book Reviews"
              },
              {
                "name": "Summaries"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "\"In the Dust of This Planet,\" by Eugene Thacker",
            "tags": [
              {
                "name": "Negative Utilitarianism"
              },
              {
                "name": "Philosophy"
              },
              {
                "name": "Book Reviews"
              },
              {
                "name": "Summaries"
              },
              {
                "name": "World Modeling"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "sSaQTybKvfGf4PDNh",
    "title": "Zen and Rationality",
    "curatedOrder": null,
    "contents": {
      "markdown": "A series of posts about the intersection of one author's experiences with decades of LW-style rationality practice and several years of Zen practice. Each post explores a way the two paths meet."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Zen and Rationality: Don't Know Mind",
            "tags": [
              {
                "name": "Buddhism"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Zen and Rationality: Trust in Mind",
            "tags": [
              {
                "name": "Buddhism"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Epistemology"
              }
            ]
          },
          {
            "title": "Zen and Rationality: Map and Territory",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Buddhism"
              },
              {
                "name": "Map and Territory"
              }
            ]
          },
          {
            "title": "Zen and Rationality: Just This Is It",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Buddhism"
              },
              {
                "name": "Focusing"
              }
            ]
          },
          {
            "title": "Zen and Rationality: Skillful Means",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Meditation"
              },
              {
                "name": "Buddhism"
              }
            ]
          },
          {
            "title": "Zen and Rationality: Karma",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Causality"
              },
              {
                "name": "Buddhism"
              }
            ]
          },
          {
            "title": "Zen and Rationality: Continuous Practice",
            "tags": [
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Zen and Rationality: Equanimity",
            "tags": [
              {
                "name": "Rationality"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "akMLzwcRdJNnmBoLa",
    "title": "Privacy Practices",
    "curatedOrder": null,
    "contents": {
      "markdown": ""
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "\"Can you keep this confidential? How do you know?\"",
            "tags": [
              {
                "name": "Robust Agents"
              },
              {
                "name": "Communication Cultures"
              },
              {
                "name": "Community"
              },
              {
                "name": "Privacy"
              }
            ]
          },
          {
            "title": "Parameters of Privacy",
            "tags": [
              {
                "name": "Communication Cultures"
              },
              {
                "name": "Community"
              },
              {
                "name": "Privacy"
              }
            ]
          },
          {
            "title": "Privacy and Manipulation",
            "tags": [
              {
                "name": "Privacy"
              },
              {
                "name": "Community"
              },
              {
                "name": "Communication Cultures"
              },
              {
                "name": "Relationships (Interpersonal)"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "boLPsyNwd6teK5key",
    "title": "Shaping safer goals",
    "curatedOrder": null,
    "contents": {
      "markdown": "How can we move the needle on AI safety? In this sequence I think through some approaches that don't rely on precise specifications - instead they involve \"shaping\" our agents to think in safer ways, and have safer motivations. This is particularly relevant to the prospect of training AGIs in multi-agent (or other open-ended) environments.\n\nNote that all of the techniques I propose here are speculative brainstorming; I'm not confident in any of them as research directions, although I'd be excited to see further exploration along these lines."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Multi-agent safety",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Safety via selection for obedience",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Competitive safety via gradated curricula",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "AGIs as collectives",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Safer sandboxing via collective separation",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Emergent modularity and safety",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Modularity"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "wnQWakxdRodnKm5kH",
    "title": "Staying Sane While Taking Ideas Seriously",
    "curatedOrder": null,
    "contents": {
      "markdown": "We have a meme in this community that it's essential to take ideas seriously, that you'll never make epistemic, or moral, or practical progress unless you consciously try to resolve the contradictions in your beliefs, the ones that other people just shrug off.\n\nI'm not disagreeing with that meme, but I note that we have a significant number of people who get burnt out, or worse, go off into various bizarre locked-off belief systems.\n\nSo how do we take ideas seriously while still keeping a saving throw for your motivation and sanity? Here's my thinking over the last few years, from epistemics to psychology to effective altruism, on how to keep a margin of safety while still aiming for the frontier of knowledge and of effectiveness."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Adding Up To Normality",
            "tags": [
              {
                "name": "Pitfalls of Rationality"
              },
              {
                "name": "Adding Up to Normality"
              },
              {
                "name": "Ontological Crisis"
              }
            ]
          },
          {
            "title": "Negotiating With Yourself",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Self-Deception"
              },
              {
                "name": "Motivations"
              },
              {
                "name": "LessWrong Event Transcripts"
              }
            ]
          },
          {
            "title": "Map Errors: The Good, The Bad, and The Territory",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Pitfalls of Rationality"
              }
            ]
          },
          {
            "title": "The Loudest Alarm Is Probably False",
            "tags": [
              {
                "name": "Self-Deception"
              },
              {
                "name": "Introspection"
              }
            ]
          },
          {
            "title": "Don't Make Your Problems Hide",
            "tags": [
              {
                "name": "Introspection"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Pitfalls of Rationality"
              }
            ]
          },
          {
            "title": "Roleplaying As Yourself",
            "tags": [
              {
                "name": "Heroic Responsibility"
              }
            ]
          },
          {
            "title": "The Real Standard",
            "tags": [
              {
                "name": "Effective Altruism"
              },
              {
                "name": "Slack"
              },
              {
                "name": "Scrupulosity"
              }
            ]
          },
          {
            "title": "Choosing the Zero Point",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "Effective Altruism"
              },
              {
                "name": "Utility Functions"
              },
              {
                "name": "Motivations"
              },
              {
                "name": "Reset (technique)"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "bQ32GY5waKWi88vdX",
    "title": "Naturalized Induction",
    "curatedOrder": null,
    "contents": {
      "markdown": "Naturalized induction is an open problem in Friendly AI: Build an algorithm for producing accurate generalizations and predictions from data sets, that treats itself, its data inputs, and its hypothesis outputs as reducible to its physical posits. More broadly, design a workable reasoning method that allows the reasoner to treat itself as fully embedded in the world it's reasoning about.\n\nNaturalized inductors are associated with naturalism in contrast to 'Cartesian' inductors, reasoners that assume a strict boundary between themselves and their environments. The standard example of an idealization of Cartesian induction is Solomonoff induction, an uncomputable but theoretically fruitful specification of a hypothesis space, prior probability distribution, and consistent reassignment of probabilities given data inputs. As Solomonoff induction is currently the leading contender for a formalization of universally correct — albeit physically unrealizable — inductive reasoning, an essential step in formally defining the problem of naturalized induction will be evaluating the limitations of Solomonoff inductors such as AIXI. \n\nSequece by [Rob Bensinger](https://www.lesswrong.com/users/robbbb), imported from the [wiki](https://wiki.lesswrong.com/wiki/Naturalized_induction). Additional material after the sequence: [Formalizing Two Problems of Realistic World-Models](https://intelligence.org/files/RealisticWorldModels.pdf) by [Nate Soares](https://www.lesswrong.com/users/so8res)."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Building Phenomenological Bridges",
            "tags": [
              {
                "name": "Consciousness"
              },
              {
                "name": "Zombies"
              },
              {
                "name": "Truth, Semantics, & Meaning"
              },
              {
                "name": "Map and Territory"
              }
            ]
          },
          {
            "title": "Bridge Collapse: Reductionism as Engineering Problem",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Reductionism"
              },
              {
                "name": "Map and Territory"
              }
            ]
          },
          {
            "title": "Can We Do Without Bridge Hypotheses?",
            "tags": [
              {
                "name": "Truth, Semantics, & Meaning"
              }
            ]
          },
          {
            "title": "Solomonoff Cartesianism",
            "tags": [
              {
                "name": "Solomonoff Induction"
              },
              {
                "name": "AIXI"
              }
            ]
          },
          {
            "title": "The Problem with AIXI",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "AIXI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "WZNq65bHHKwQasyP6",
    "title": "What You Can and Can't Learn from Games",
    "curatedOrder": null,
    "contents": {
      "markdown": "Competitive games can be one of the best areas for training certain types of skills. However, they also have some limitations and distinct weaknesses that are worth noting. This sequence will aim to demonstrate some of those strengths and weaknesses, using both theoretical arguments and practical examples/case studies.\n\nI have been world #1 by [Elo rating](https://en.wikipedia.org/wiki/Elo_rating_system) in multiple games (insofar as this was being tracked), won major tournaments online and in person, organized competitive events, written articles that have significantly advanced the community's understanding of some of the games I play, etc. I say this not merely to boast but rather to point out that I have some experience in high level competition (though I've never been a professional poker player or similar). Most of the games that I am best at are turn-based strategy games of one sort or another (generally card or miniatures games), though I dabble a bit in other genres. \\[1\\]\n\nIn general, I think games *can* be a great way to train certain aspects of one's mental skills, especially in the realm of strategy and practice. However, I also feel that they have some distinct weaknesses that can limit them as a training ground. This sequence will go into more detail on how I think that shakes out in actual practice, as well as describing some recommendations as to how one might use this."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": []
      }
    ]
  },
  {
    "_id": "qMtriMPLdriNkAfSJ",
    "title": "Short Stories",
    "curatedOrder": null,
    "contents": {
      "markdown": "All my stories are short. These are shorter than usual."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Zeno walks into a bar",
            "tags": [
              {
                "name": "Physics"
              },
              {
                "name": "Dialogue (format)"
              },
              {
                "name": "Paradoxes"
              },
              {
                "name": "Humor"
              }
            ]
          },
          {
            "title": "Matryoshka Faraday Box",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "The Nuclear Energy Alignment Problem",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Humor"
              }
            ]
          },
          {
            "title": "Purple Lipstick",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Effective Evil",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "Humor"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "To Change the World",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Deontological Evil",
            "tags": [
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "Fiction"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Anti-Corruption Market",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Prediction Markets"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "The Gospel of Martin Luther",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Moses and the Class Struggle",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "One master. One apprentice.",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Glass Puppet",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "The Mountain Troll",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Bayes' Theorem"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Dagger of Detect Evil",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Fiction"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "DTnoFhDm7ZT2ecJMw",
    "title": "Toying With Goal-Directedness",
    "curatedOrder": null,
    "contents": {
      "markdown": "We (Adam Shimi, Joe Collman, Michele Campolo and Sabrina Tang) are studying both how to formalize the intuitions behind goal-directedness, and what is its relevance to AI Safety. This sequence is here for the not fully polished posts that represent more the ideas of their specific author than a consensus inside the group."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Goal-directed = Model-based RL?",
            "tags": [
              {
                "name": "Goal-Directedness"
              }
            ]
          },
          {
            "title": "Focus: you are allowed to be bad at accomplishing your goals",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Goal-Directedness"
              }
            ]
          },
          {
            "title": "Goal-directedness is behavioral, not structural",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Goal-Directedness"
              }
            ]
          },
          {
            "title": "Locality of goals",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Goal-Directedness"
              }
            ]
          },
          {
            "title": "Goals and short descriptions",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Goal-Directedness"
              }
            ]
          },
          {
            "title": "Goal-Directedness: What Success Looks Like",
            "tags": [
              {
                "name": "Goal-Directedness"
              },
              {
                "name": "AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "wwcfhArpZt94pFkNG",
    "title": "A Practical Guide to Conflict Resolution",
    "curatedOrder": null,
    "contents": {
      "markdown": "This sequence is an attempt at an accessible, practical guide to resolving interpersonal conflict (with a focus on workplace conflicts). It draws on a lot of rationalist ideas without having any prerequisite readings."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "A Practical Guide to Conflict Resolution: Introduction",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "A Practical Guide to Conflict Resolution: Attitude",
            "tags": [
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "A Practical Guide to Conflict Resolution: Communication",
            "tags": [
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "A Practical Guide to Conflict Resolution: Comprehension",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "Steelmanning"
              },
              {
                "name": "Disagreement"
              },
              {
                "name": "Conversation (topic)"
              }
            ]
          },
          {
            "title": "Practical Conflict Resolution: A Taxonomy of Disagreement",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "Disagreement"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "T8PftwGSnxgxTzpip",
    "title": "Against Rationalization II",
    "curatedOrder": null,
    "contents": {
      "markdown": "Previously: [Eliezer's \"Against Rationalization\" sequence](https://www.lesswrong.com/s/GSqFqc646rsRd2oyz)\n\nThis sequence picks up where the previous left off, with a greater focus on specific tools and techniques to keep yourself from rationalizing."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Why a New Rationalization Sequence?",
            "tags": [
              {
                "name": "Rationalization"
              }
            ]
          },
          {
            "title": "Red Flags for Rationalization",
            "tags": [
              {
                "name": "Rationalization"
              }
            ]
          },
          {
            "title": "Avoiding Rationalization",
            "tags": [
              {
                "name": "Techniques"
              },
              {
                "name": "Rationalization"
              }
            ]
          },
          {
            "title": "Testing for Rationalization",
            "tags": [
              {
                "name": "Rationalization"
              }
            ]
          },
          {
            "title": "Using Expert Disagreement",
            "tags": [
              {
                "name": "Fermi Estimation"
              },
              {
                "name": "Rationalization"
              }
            ]
          },
          {
            "title": "Against Rationalization II: Sequence Recap",
            "tags": [
              {
                "name": "Rationalization"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "HmANELvkhAZ9eDxFS",
    "title": "Consequences of Logical Induction",
    "curatedOrder": null,
    "contents": {
      "markdown": "This sequence organizes some posts which I have made in an attempt to explain logical induction and make some of its consequences intuitive, or -- more speculatively -- question basic probabilistic and decision-theoretic principles in light of logical induction."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Toward a New Technical Explanation of Technical Explanation",
            "tags": [
              {
                "name": "Logical Induction"
              },
              {
                "name": "Gears-Level"
              },
              {
                "name": "Inside/Outside View"
              },
              {
                "name": "Epistemology"
              },
              {
                "name": "Logical Uncertainty"
              },
              {
                "name": "Problem of Old Evidence"
              }
            ]
          },
          {
            "title": "In Logical Time, All Games are Iterated Games",
            "tags": [
              {
                "name": "Game Theory"
              },
              {
                "name": "Logical Induction"
              },
              {
                "name": "Logical Uncertainty"
              }
            ]
          },
          {
            "title": "Do Sufficiently Advanced Agents Use Logic?",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Epistemology"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "An Orthodox Case Against Utility Functions",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "AI"
              },
              {
                "name": "Utility Functions"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Indexical Information"
              }
            ]
          },
          {
            "title": "What does it mean to apply decision theory?",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "AI"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Bounded Rationality"
              },
              {
                "name": "Law-Thinking"
              }
            ]
          },
          {
            "title": "Radical Probabilism [Transcript]",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Logical Induction"
              },
              {
                "name": "Bayes' Theorem"
              },
              {
                "name": "Transcripts"
              },
              {
                "name": "Epistemology"
              },
              {
                "name": "Logical Uncertainty"
              },
              {
                "name": "Radical Probabilism"
              }
            ]
          },
          {
            "title": "Radical Probabilism",
            "tags": [
              {
                "name": "Logical Induction"
              },
              {
                "name": "Epistemology"
              },
              {
                "name": "Bayes' Theorem"
              },
              {
                "name": "Probability & Statistics"
              },
              {
                "name": "Conservation of Expected Evidence"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Problem of Old Evidence"
              },
              {
                "name": "Radical Probabilism"
              },
              {
                "name": "Probabilistic Reasoning"
              }
            ]
          },
          {
            "title": "The Bayesian Tyrant",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "AI"
              },
              {
                "name": "Fiction"
              },
              {
                "name": "Prediction Markets"
              },
              {
                "name": "Betting"
              },
              {
                "name": "Calibration"
              },
              {
                "name": "Bayes' Theorem"
              },
              {
                "name": "Radical Probabilism"
              },
              {
                "name": "Parables & Fables"
              }
            ]
          },
          {
            "title": "Time Travel Markets for Intellectual Accounting",
            "tags": [
              {
                "name": "Radical Probabilism"
              },
              {
                "name": "Prediction Markets"
              },
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Probability vs Likelihood",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Distinctions"
              },
              {
                "name": "Probability & Statistics"
              }
            ]
          },
          {
            "title": "Reflective Bayesianism",
            "tags": [
              {
                "name": "Radical Probabilism"
              },
              {
                "name": "Epistemology"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "AI"
              },
              {
                "name": "Distinctions"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "ZnWZRqi5mhXxXaD6z",
    "title": "Through the Haskell Jungle",
    "curatedOrder": null,
    "contents": {
      "markdown": "Follow me as I explore the mysteries of advanced Haskell, in the hope of one day mastering it."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Welcome to the Haskell Jungle",
            "tags": [
              {
                "name": "Programming"
              }
            ]
          },
          {
            "title": "My Functor is Rich!",
            "tags": []
          }
        ]
      }
    ]
  },
  {
    "_id": "JWD7qZZ5A8CYe82uA",
    "title": "Lessons from Isaac",
    "curatedOrder": null,
    "contents": {
      "markdown": "Are Asimov's Robots about AI Safety, or not? Let's discover it together."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Lessons from Isaac: Poor Little Robbie",
            "tags": []
          },
          {
            "title": "Lessons from Isaac: Pitfalls of Reason",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Fiction"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "JsGa9AHEG3EgEq45s",
    "title": "Why do we think the way we do?",
    "curatedOrder": null,
    "contents": {
      "markdown": "That's the sequence about information processing in the brain and things that are related to it. What I was trying to achieve is create a model of the brain, which won't be precise, but useful to understand the main principles.\n\nThe work on this sequence is still in progress. If you found a bug, please report me."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Chapter 1: What's the Question?",
            "tags": []
          },
          {
            "title": "Chapter 2: What's Inside?",
            "tags": []
          },
          {
            "title": "Chapter 3: What's an Object?",
            "tags": []
          },
          {
            "title": "Chapter 4: What's the Problem?",
            "tags": []
          },
          {
            "title": "Chapter 5: How to Describe?",
            "tags": []
          },
          {
            "title": "Chapter 6: How does it Work?",
            "tags": []
          },
          {
            "title": "Chapter 7: How to Focus?",
            "tags": []
          },
          {
            "title": "Chapter 8: Why is this Important?",
            "tags": []
          },
          {
            "title": "Chapter 9: Why can it Select?",
            "tags": []
          },
          {
            "title": "Chapter 10: What does it Mean?",
            "tags": [
              {
                "name": "Psychology"
              },
              {
                "name": "World Modeling"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "r3dKPwpkkMnJPbjZE",
    "title": "Information hazards and downside risks",
    "curatedOrder": null,
    "contents": {
      "markdown": "In this sequence, we ([Convergence Analysis](https://www.convergenceanalysis.org/)) will seek to:\n* clarify the concepts of information hazards and downside risks\n* visually represent how they relate to each other and to other types of effects\n* suggest some models, insights, and rules-of-thumb to help with handling potential information hazards and downside risks\n* discuss related issues, like downside risks from the \"evolution\" of ideas\n\nWe hope you will find this sequence clear, interesting, and useful in your efforts to have a positive impact on the world.\n\nAdditional sources relevant to these topics can be found [here](https://forum.effectivealtruism.org/posts/EMKf4Gyee7BsY2RP8/michaela-s-shortform?commentId=dTghHNHmc5qf5znMQ) and [here](https://forum.effectivealtruism.org/posts/EMKf4Gyee7BsY2RP8/michaela-s-shortform?commentId=GLJdSeFpLQhg6p8cK)."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "What are information hazards?",
            "tags": [
              {
                "name": "Information Hazards"
              }
            ]
          },
          {
            "title": "Mapping downside risks and information hazards",
            "tags": [
              {
                "name": "Information Hazards"
              }
            ]
          },
          {
            "title": "Information hazards: Why you should care and what you can do",
            "tags": [
              {
                "name": "Information Hazards"
              }
            ]
          },
          {
            "title": "Memetic downside risks: How ideas can evolve and cause harm",
            "tags": [
              {
                "name": "Information Hazards"
              },
              {
                "name": "Memetics"
              }
            ]
          },
          {
            "title": "Good and bad ways to think about downside risks",
            "tags": [
              {
                "name": "Information Hazards"
              },
              {
                "name": "World Modeling"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "5MFN7FnvKFL9ynXXX",
    "title": "Filk",
    "curatedOrder": null,
    "contents": {
      "markdown": "Filk refers to a style of folk singing where songs are parodied, not always humorously, with the words changed to either be self referential or to be about a particular subject not normally sung about, like science fiction, [computers](http://www.poppyfields.net/filks/fullindex.html), or, in the case of this sequence, topics of interest to EAs and rationalists. This sequence is a collection of rationalist, EA, and adjacent filks posted on LessWrong."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Parfit's Escape (Filk)",
            "tags": [
              {
                "name": "Poetry"
              },
              {
                "name": "Fiction"
              },
              {
                "name": "Newcomb's Problem"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Art"
              },
              {
                "name": "Music"
              }
            ]
          },
          {
            "title": "Big Yellow Tractor (Filk)",
            "tags": [
              {
                "name": "Humor"
              },
              {
                "name": "Art"
              },
              {
                "name": "Poetry"
              },
              {
                "name": "Music"
              }
            ]
          },
          {
            "title": "Bayesiance (Filk)",
            "tags": [
              {
                "name": "Humor"
              },
              {
                "name": "Art"
              },
              {
                "name": "Poetry"
              },
              {
                "name": "Community"
              },
              {
                "name": "Music"
              }
            ]
          },
          {
            "title": "Oh No My AI (Filk)",
            "tags": [
              {
                "name": "Fiction (Topic)"
              },
              {
                "name": "Music"
              },
              {
                "name": "AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "d922gAtBM8JNzkKKJ",
    "title": "Training Regime",
    "curatedOrder": null,
    "contents": {
      "markdown": "My take on CFAR's take on applied rationality, compressed into 30 days. Each day has some number of exercises, few of which should require more than 15 minutes.\n\nThe goal is to provide a beginner's training regime for applied rationality.\n\n"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Training Regime Day 0: Introduction",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Techniques"
              }
            ]
          },
          {
            "title": "Training Regime Day 1: What is applied rationality?",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Techniques"
              }
            ]
          },
          {
            "title": "Training Regime Day 2: Searching for bugs",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Techniques"
              },
              {
                "name": "Debugging"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Training Regime Day 3: Tips and Tricks",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Techniques"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Training Regime Day 4:  Murphyjitsu",
            "tags": [
              {
                "name": "Techniques"
              },
              {
                "name": "Murphyjitsu"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Training Regime Day 5: TAPs",
            "tags": [
              {
                "name": "Trigger-Action Planning"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Training Regime Day 6: Seeking Sense",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Techniques"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Training Regime Day 7: Goal Factoring",
            "tags": [
              {
                "name": "Goal Factoring"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Techniques"
              }
            ]
          },
          {
            "title": "Training Regime Day 8: Noticing",
            "tags": [
              {
                "name": "Noticing"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Techniques"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Training Regime Day 9: Double-Crux",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Double-Crux"
              },
              {
                "name": "Techniques"
              }
            ]
          },
          {
            "title": "Training Regime Day 10: Systemization",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Systems Thinking"
              },
              {
                "name": "Techniques"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Planning & Decision-Making"
              }
            ]
          },
          {
            "title": "Training Regime Day 11: Socratic Ducking",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Techniques"
              }
            ]
          },
          {
            "title": "Training Regime Day 12: Focusing",
            "tags": [
              {
                "name": "Focusing"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Techniques"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Training Regime Day 13: Resolve Cycles",
            "tags": [
              {
                "name": "Debugging"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Techniques"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Training Regime Day 14: Traffic Jams",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Techniques"
              },
              {
                "name": "Planning & Decision-Making"
              }
            ]
          },
          {
            "title": "Training Regime Day 15: CoZE",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Comfort Zone Expansion (CoZE)"
              },
              {
                "name": "Techniques"
              }
            ]
          },
          {
            "title": "Training Regime Day 16: Hamming Questions",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Hamming Questions"
              },
              {
                "name": "Techniques"
              }
            ]
          },
          {
            "title": "Training Regime Day 17: Deflinching and Lines of Retreat",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Techniques"
              },
              {
                "name": "Trigger-Action Planning"
              },
              {
                "name": "Aversion"
              }
            ]
          },
          {
            "title": "Training Regime Day 18: Negative Visualization\n",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Aversion"
              },
              {
                "name": "Techniques"
              }
            ]
          },
          {
            "title": "Training Regime Day 19: Hamming Questions for Potted Plants",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Hamming Questions"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Techniques"
              }
            ]
          },
          {
            "title": "Training Regime Day 20: OODA Loop",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Planning & Decision-Making"
              },
              {
                "name": "Techniques"
              }
            ]
          },
          {
            "title": "Training Regime Day 21: Executing Intentions",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Techniques"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Training Regime Day 22: Murphyjitsu 2",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Murphyjitsu"
              },
              {
                "name": "Techniques"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Training Regime Day 23: TAPs 2",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Trigger-Action Planning"
              },
              {
                "name": "Techniques"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Training Regime Day 24: Resolve Cycles 2",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Debugging"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Techniques"
              }
            ]
          },
          {
            "title": "Training Regime Day 25: Recursive Self-Improvement\n",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Techniques"
              },
              {
                "name": "Self Improvement"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "TAPs for Tutoring",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Trigger-Action Planning"
              },
              {
                "name": "Distillation & Pedagogy"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "iRwYCpcAXuFD24tHh",
    "title": "Subagents and impact measures",
    "curatedOrder": null,
    "contents": {
      "markdown": "Looking at the ways that subagents can get around impact measures."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Subagents and impact measures, full and fully illustrated",
            "tags": [
              {
                "name": "Impact Measures"
              }
            ]
          },
          {
            "title": "Appendix: how a subagent could get powerful",
            "tags": [
              {
                "name": "Impact Measures"
              }
            ]
          },
          {
            "title": "Appendix: mathematics of indexical impact measures",
            "tags": [
              {
                "name": "Impact Measures"
              }
            ]
          },
          {
            "title": "Dynamic inconsistency of the inaction and initial state baseline",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Impact Measures"
              }
            ]
          },
          {
            "title": "Why is the impact penalty time-inconsistent?",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Impact Measures"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "xEFeCwk3pdYdeG2rL",
    "title": "Gears Which Turn The World",
    "curatedOrder": null,
    "contents": null,
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Technology Changes Constraints",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Progress Studies"
              },
              {
                "name": "Gears-Level"
              },
              {
                "name": "History"
              }
            ]
          },
          {
            "title": "Constraints & Slackness as a Worldview Generator",
            "tags": [
              {
                "name": "World Modeling Techniques"
              },
              {
                "name": "Gears-Level"
              }
            ]
          },
          {
            "title": "Material Goods as an Abundant Resource",
            "tags": [
              {
                "name": "Gears-Level"
              }
            ]
          },
          {
            "title": "Coordination as a Scarce Resource",
            "tags": [
              {
                "name": "Economics"
              },
              {
                "name": "Coordination / Cooperation"
              }
            ]
          },
          {
            "title": "Theory and Data as Constraints",
            "tags": [
              {
                "name": "Gears-Level"
              }
            ]
          },
          {
            "title": "Interfaces as a Scarce Resource",
            "tags": [
              {
                "name": "UI Design"
              },
              {
                "name": "Mechanism Design"
              }
            ]
          },
          {
            "title": "Transportation as a Constraint",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "History"
              },
              {
                "name": "Progress Studies"
              },
              {
                "name": "Economics"
              }
            ]
          },
          {
            "title": "When Money Is Abundant, Knowledge Is The Real Wealth",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Expertise (topic)"
              },
              {
                "name": "Economics"
              }
            ]
          },
          {
            "title": "What Money Cannot Buy",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Expertise (topic)"
              }
            ]
          },
          {
            "title": "Potential Bottlenecks to Taking Over The World",
            "tags": [
              {
                "name": "World Optimization"
              },
              {
                "name": "Rationality"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "uNdbAXtGdJ8wZWeNs",
    "title": "The LessWrong Review",
    "curatedOrder": null,
    "contents": {
      "markdown": "The LessWrong Review is an experimental process, wherein the entire LW community looks back to the *previous* year to evaluate which posts have withstood the tests of time. It included a Nominations step, Review step, and Voting step.\n\nAfterwards, the LessWrong team plans to take the information accumulated during the Review, and use it to compile a Best of 2018 book."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "The LessWrong 2018 Review",
            "tags": [
              {
                "name": "Babble and Prune"
              },
              {
                "name": "Intellectual Progress via LessWrong"
              },
              {
                "name": "LessWrong Review"
              }
            ]
          },
          {
            "title": "The Review Phase",
            "tags": [
              {
                "name": "Site Meta"
              },
              {
                "name": "LessWrong Review"
              }
            ]
          },
          {
            "title": "Quadratic voting for the 2018 Review",
            "tags": [
              {
                "name": "Voting Theory"
              },
              {
                "name": "Site Meta"
              },
              {
                "name": "Mechanism Design"
              },
              {
                "name": "LessWrong Review"
              }
            ]
          },
          {
            "title": "Voting Phase of 2018 LW Review ",
            "tags": [
              {
                "name": "Site Meta"
              },
              {
                "name": "Postmortems & Retrospectives"
              },
              {
                "name": "Voting Theory"
              },
              {
                "name": "LessWrong Review"
              }
            ]
          },
          {
            "title": "Please Critique Things for the Review!",
            "tags": [
              {
                "name": "Site Meta"
              },
              {
                "name": "LessWrong Review"
              }
            ]
          },
          {
            "title": "2018 Review: Voting Results!",
            "tags": [
              {
                "name": "Community"
              },
              {
                "name": "Site Meta"
              },
              {
                "name": "Epistemic Review"
              },
              {
                "name": "LessWrong Review"
              }
            ]
          },
          {
            "title": "Reviewing the Review",
            "tags": [
              {
                "name": "Site Meta"
              },
              {
                "name": "Postmortems & Retrospectives"
              },
              {
                "name": "LessWrong Review"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "knbhjv252HshMSwpt",
    "title": "If I were a well-intentioned AI...",
    "curatedOrder": null,
    "contents": {
      "markdown": "I look at how some of the major problems in AI alignment - Goodhart problems, distributional shift, mesaoptimising, etc.. - look from the perspective of a well-intentioned but ignorant AI. And if this perspective can suggest methods of safety improvements."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "If I were a well-intentioned AI...\nI: Image classifier",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Outer Alignment"
              },
              {
                "name": "Machine Learning  (ML)"
              },
              {
                "name": "Adversarial Examples"
              }
            ]
          },
          {
            "title": "If I were a well-intentioned AI...\nII: Acting in a world",
            "tags": [
              {
                "name": "Outer Alignment"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "If I were a well-intentioned AI...\nIII: Extremal Goodhart",
            "tags": [
              {
                "name": "Outer Alignment"
              },
              {
                "name": "AI"
              },
              {
                "name": "Goodhart's Law"
              }
            ]
          },
          {
            "title": "If I were a well-intentioned AI...\nIV: Mesa-optimising",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Mesa-Optimization"
              },
              {
                "name": "Inner Alignment"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "kNANcHLNtJt5qeuSS",
    "title": "Immoral Mazes",
    "curatedOrder": null,
    "contents": null,
    "chapters": [
      {
        "title": "Background",
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Meditations On Moloch",
            "tags": [
              {
                "name": "Moloch"
              },
              {
                "name": "Eldritch Analogies"
              },
              {
                "name": "Game Theory"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Social & Cultural Dynamics"
              },
              {
                "name": "Incentives"
              }
            ]
          },
          {
            "title": "Quotes from Moral Mazes",
            "tags": [
              {
                "name": "Mechanism Design"
              },
              {
                "name": "Game Theory"
              },
              {
                "name": "Moral Mazes"
              }
            ]
          },
          {
            "title": "Moral Mazes and Short Termism",
            "tags": [
              {
                "name": "Goodhart's Law"
              },
              {
                "name": "Moral Mazes"
              }
            ]
          }
        ]
      },
      {
        "title": "Immoral Mazes",
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Meditation Retreat: Immoral Mazes Sequence Introduction",
            "tags": [
              {
                "name": "Moral Mazes"
              },
              {
                "name": "Meditation"
              }
            ]
          },
          {
            "title": "Moloch Hasn’t Won",
            "tags": [
              {
                "name": "Game Theory"
              },
              {
                "name": "Mechanism Design"
              },
              {
                "name": "Moloch"
              },
              {
                "name": "Moral Mazes"
              }
            ]
          },
          {
            "title": "Perfect Competition",
            "tags": [
              {
                "name": "Economics"
              },
              {
                "name": "Moloch"
              },
              {
                "name": "Moral Mazes"
              }
            ]
          },
          {
            "title": "Imperfect Competition",
            "tags": [
              {
                "name": "Economics"
              },
              {
                "name": "Moral Mazes"
              }
            ]
          },
          {
            "title": "Does Big Business Hate Your Family?",
            "tags": [
              {
                "name": "Moral Mazes"
              }
            ]
          },
          {
            "title": "What is Life in an Immoral Maze?",
            "tags": [
              {
                "name": "Gears-Level"
              },
              {
                "name": "Moral Mazes"
              },
              {
                "name": "Careers"
              },
              {
                "name": "Slack"
              }
            ]
          },
          {
            "title": "Stripping Away the Protections",
            "tags": [
              {
                "name": "Economics"
              },
              {
                "name": "Moral Mazes"
              }
            ]
          },
          {
            "title": "What is Success in an Immoral Maze?",
            "tags": [
              {
                "name": "Moral Mazes"
              }
            ]
          },
          {
            "title": "How to Identify an Immoral Maze",
            "tags": [
              {
                "name": "Moral Mazes"
              }
            ]
          },
          {
            "title": "How to Escape From Immoral Mazes",
            "tags": [
              {
                "name": "Moral Mazes"
              },
              {
                "name": "Careers"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "The Road to Mazedom",
            "tags": [
              {
                "name": "Moral Mazes"
              },
              {
                "name": "Moloch"
              }
            ]
          },
          {
            "title": "How Doomed are Large Organizations?",
            "tags": [
              {
                "name": "Moral Mazes"
              },
              {
                "name": "Goodhart's Law"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Ten Causes of Mazedom",
            "tags": [
              {
                "name": "Moral Mazes"
              }
            ]
          },
          {
            "title": "Potential Ways to Fight Mazes",
            "tags": [
              {
                "name": "Moral Mazes"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Create a Full Alternative Stack",
            "tags": [
              {
                "name": "Moral Mazes"
              },
              {
                "name": "Coordination / Cooperation"
              }
            ]
          },
          {
            "title": "Protecting Large Projects Against Mazedom",
            "tags": [
              {
                "name": "Moral Mazes"
              },
              {
                "name": "Mechanism Design"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Mazes Sequence Roundup: Final Thoughts and Paths Forward",
            "tags": [
              {
                "name": "Moral Mazes"
              },
              {
                "name": "Moloch"
              },
              {
                "name": "Economics"
              },
              {
                "name": "Writing (communication method)"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "4NFwxwzLzpiikfkk3",
    "title": "Moral uncertainty",
    "curatedOrder": null,
    "contents": {
      "markdown": "In this sequence, I first overview key points from existing work on moral uncertainty - what is it? Why does it matter? How should we make decisions when morally uncertain?\n\nI then move on to two extensions of this work: How should we make decisions when _both morally and empirically_ uncertain? And how can we combine ideas covered thus far with established work on the value of information, to work out what moral (or empirical) learning to prioritise, and how much time and money to “spend” on it?\n\nI plan to later add a post on a different way of conceptualising moral uncertainty, which may be of relevance for AI alignment work.\n\n(I’m also considering later adding posts on:\n\n*   Various definitions, types, and sources of moral uncertainty.\n*   The idea of ignoring even very high credence in nihilism, because it’s never decision-relevant.\n*   Whether it could make sense to give moral realism disproportionate influence over our decisions (compared to antirealism), based on the idea that realism might view there as “more at stake” than antirealism does.\n\nI’d be interested in hearing whether people think those threads are likely to be worth pursuing.)\n\n_(Note: I first expanded and then abandoned my plans for this sequence, as I got busy with other things, so now there are likely some outdated/out-of-order overviews, references to what I'll cover in \"my next post\", etc..)_"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Morality vs related concepts",
            "tags": [
              {
                "name": "Decision Theory"
              },
              {
                "name": "Value Learning"
              },
              {
                "name": "Metaethics"
              },
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "Moral Uncertainty"
              },
              {
                "name": "Distinctions"
              }
            ]
          },
          {
            "title": "Moral uncertainty vs related concepts",
            "tags": [
              {
                "name": "Metaethics"
              },
              {
                "name": "Value Learning"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "Moral Uncertainty"
              },
              {
                "name": "Distinctions"
              }
            ]
          },
          {
            "title": "Moral uncertainty: What kind of 'should' is involved?",
            "tags": [
              {
                "name": "Metaethics"
              },
              {
                "name": "Value Learning"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "Moral Uncertainty"
              }
            ]
          },
          {
            "title": "Value uncertainty",
            "tags": [
              {
                "name": "Metaethics"
              },
              {
                "name": "Value Learning"
              },
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "Moral Uncertainty"
              }
            ]
          },
          {
            "title": "Making decisions under moral uncertainty",
            "tags": [
              {
                "name": "Value Learning"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "Moral Uncertainty"
              }
            ]
          },
          {
            "title": "Making decisions when both morally and empirically uncertain",
            "tags": [
              {
                "name": "Value Learning"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "Moral Uncertainty"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "5CNs9wmHWFQTNjFKo",
    "title": "Medical Paradigms",
    "curatedOrder": null,
    "contents": {
      "markdown": ""
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Prediction-based medicine (PBM)",
            "tags": [
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "Health / Medicine / Disease"
              }
            ]
          },
          {
            "title": "Taking vitamin D3 with K2 in the morning",
            "tags": [
              {
                "name": "Well-being"
              },
              {
                "name": "Health / Medicine / Disease"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "The Dogma of Evidence-based Medicine",
            "tags": [
              {
                "name": "Health / Medicine / Disease"
              },
              {
                "name": "Practice & Philosophy of Science"
              }
            ]
          },
          {
            "title": "Phage therapy in a post-antibiotics world",
            "tags": [
              {
                "name": "Health / Medicine / Disease"
              }
            ]
          },
          {
            "title": "Using the Quantified Self paradigma for COVID-19",
            "tags": [
              {
                "name": "Covid-19"
              },
              {
                "name": "Self Experimentation"
              }
            ]
          },
          {
            "title": "Anatomy, diseases and aging damage",
            "tags": [
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Hypothesis: lab mice have more active transposons then wild mice",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Aging"
              },
              {
                "name": "Transposons"
              }
            ]
          },
          {
            "title": "War on Cancer II",
            "tags": [
              {
                "name": "Health / Medicine / Disease"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Cancer"
              },
              {
                "name": "Transposons"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "C8wgFMCmoMNbvDSMP",
    "title": "Understanding Machine Learning",
    "curatedOrder": null,
    "contents": {
      "markdown": "My posts on the [Machine Learning textbook](https://www.amazon.com/Understanding-Machine-Learning-Theory-Algorithms/dp/1107057132) from [Miri's Research Guide](https://intelligence.org/research-guide/)."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Understanding Machine Learning (I)",
            "tags": [
              {
                "name": "Machine Learning  (ML)"
              }
            ]
          },
          {
            "title": "Understanding Machine Learning (II)",
            "tags": [
              {
                "name": "Machine Learning  (ML)"
              }
            ]
          },
          {
            "title": "Understanding Machine Learning (III)",
            "tags": [
              {
                "name": "Machine Learning  (ML)"
              }
            ]
          },
          {
            "title": "UML IV: Linear Predictors",
            "tags": [
              {
                "name": "Machine Learning  (ML)"
              }
            ]
          },
          {
            "title": "UML V: Convex Learning Problems",
            "tags": [
              {
                "name": "Machine Learning  (ML)"
              }
            ]
          },
          {
            "title": "UML VI: Stochastic Gradient Descent",
            "tags": [
              {
                "name": "Machine Learning  (ML)"
              }
            ]
          },
          {
            "title": "UML VII: Meta-Learning",
            "tags": [
              {
                "name": "Machine Learning  (ML)"
              }
            ]
          },
          {
            "title": "UML VIII: Linear Predictors (2)",
            "tags": [
              {
                "name": "Machine Learning  (ML)"
              }
            ]
          },
          {
            "title": "UML IX: Kernels and Boosting",
            "tags": [
              {
                "name": "Machine Learning  (ML)"
              }
            ]
          },
          {
            "title": "A Simple Introduction to Neural Networks",
            "tags": [
              {
                "name": "Machine Learning  (ML)"
              }
            ]
          },
          {
            "title": "UML XI: Nearest Neighbor Schemes",
            "tags": [
              {
                "name": "Machine Learning  (ML)"
              }
            ]
          },
          {
            "title": "UML XII: Dimensionality Reduction",
            "tags": [
              {
                "name": "Machine Learning  (ML)"
              }
            ]
          },
          {
            "title": "UML XIII: Online Learning and Clustering",
            "tags": [
              {
                "name": "Machine Learning  (ML)"
              }
            ]
          },
          {
            "title": "UML final",
            "tags": [
              {
                "name": "Machine Learning  (ML)"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "tXiWcokm9tpy8uApN",
    "title": "To Be Decided",
    "curatedOrder": null,
    "contents": {
      "markdown": "TBD is a quarterly-ish newsletter about deploying knowledge for impact, learning at scale, and making more thoughtful choices for ourselves and our organizations. It is authored by Ian David Moss."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "To Be Decided #1",
            "tags": []
          },
          {
            "title": "To Be Decided #2",
            "tags": []
          },
          {
            "title": "To Be Decided #3",
            "tags": []
          },
          {
            "title": "To Be Decided #4",
            "tags": []
          }
        ]
      }
    ]
  },
  {
    "_id": "nph3aw5iG45dTPhHG",
    "title": "Topology of Learning",
    "curatedOrder": null,
    "contents": {
      "markdown": "(These are the touched up notes from a class I took with CMU's [Kevin Kelly](http://www.andrew.cmu.edu/user/kk3n/homepage/kelly.html) this past semester on the Topology of Learning. Only partially optimized for legibility)\n\nDon't do your epistemology with Logic. Don't do it with Probability. Do it with Topology!"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "ToL: Introduction",
            "tags": []
          },
          {
            "title": "ToL: Foundations",
            "tags": []
          },
          {
            "title": "ToL: The Topological Connection",
            "tags": []
          },
          {
            "title": "ToL: This ONE WEIRD Trick to make you a GENIUS at Topology!",
            "tags": []
          },
          {
            "title": "ToL: Methods and Success",
            "tags": []
          }
        ]
      }
    ]
  },
  {
    "_id": "3xKXGh9RXaYTYZYgZ",
    "title": "Antimemetics",
    "curatedOrder": null,
    "contents": {
      "markdown": "How do you find out what you don't know you don't know?"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Invisible Choices, Made by Default",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "Software Tools"
              }
            ]
          },
          {
            "title": "Self-Keeping Secrets",
            "tags": [
              {
                "name": "Privacy"
              },
              {
                "name": "Ambition"
              },
              {
                "name": "Social & Cultural Dynamics"
              }
            ]
          },
          {
            "title": "Prospecting for Conceptual Holes",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Curiosity"
              },
              {
                "name": "Scholarship & Learning"
              }
            ]
          },
          {
            "title": "The Technique Taboo",
            "tags": [
              {
                "name": "Social & Cultural Dynamics"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Rationalist Taboo"
              }
            ]
          },
          {
            "title": "Antimemes",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Social & Cultural Dynamics"
              }
            ]
          },
          {
            "title": "Confabulation",
            "tags": [
              {
                "name": "Rationalization"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "The Inefficient Market Hypothesis",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Betting"
              },
              {
                "name": "Financial Investing"
              }
            ]
          },
          {
            "title": "Evading Mind Control",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "The Economics of Media",
            "tags": [
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Media Bias",
            "tags": [
              {
                "name": "World Optimization"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "We should not raise awareness",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Simulacrum Levels"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "p947tK8CoBbdpPtyK",
    "title": "Cooperation, Conflict, and Transformative Artificial Intelligence: A Research Agenda",
    "curatedOrder": null,
    "contents": {
      "markdown": "This is a sequence version of the [Center on Long-Term Risk's](https://longtermrisk.org/) research agenda on _Cooperation, Conflict, and Transformative Artificial Intelligence_. The agenda outlines what we think are the most promising avenues for developing technical and governance interventions aimed at avoiding conflict between transformative AI systems. We draw on international relations, game theory, behavioral economics, machine learning, decision theory, and formal epistemology.\n"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Preface to CLR's Research Agenda on Cooperation, Conflict, and TAI ",
            "tags": [
              {
                "name": "Suffering"
              },
              {
                "name": "Research Agendas"
              },
              {
                "name": "AI"
              },
              {
                "name": "Risks of Astronomical Suffering (S-risks)"
              },
              {
                "name": "Center on Long-Term Risk (CLR)"
              }
            ]
          },
          {
            "title": "Sections 1 & 2: Introduction, Strategy and Governance",
            "tags": [
              {
                "name": "Risks of Astronomical Suffering (S-risks)"
              },
              {
                "name": "Research Agendas"
              },
              {
                "name": "Game Theory"
              },
              {
                "name": "AI"
              },
              {
                "name": "Center on Long-Term Risk (CLR)"
              },
              {
                "name": "Coordination / Cooperation"
              }
            ]
          },
          {
            "title": "Sections 3 & 4: Credibility, Peaceful Bargaining Mechanisms ",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Risks of Astronomical Suffering (S-risks)"
              },
              {
                "name": "Research Agendas"
              },
              {
                "name": "Game Theory"
              },
              {
                "name": "Center on Long-Term Risk (CLR)"
              },
              {
                "name": "Coordination / Cooperation"
              }
            ]
          },
          {
            "title": "Sections 5 & 6: Contemporary Architectures, Humans in the Loop",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Risks of Astronomical Suffering (S-risks)"
              },
              {
                "name": "Game Theory"
              },
              {
                "name": "Research Agendas"
              },
              {
                "name": "Center on Long-Term Risk (CLR)"
              }
            ]
          },
          {
            "title": "Section 7: Foundations of Rational Agency",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Risks of Astronomical Suffering (S-risks)"
              },
              {
                "name": "Research Agendas"
              },
              {
                "name": "Game Theory"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Center on Long-Term Risk (CLR)"
              }
            ]
          },
          {
            "title": "Acknowledgements & References",
            "tags": [
              {
                "name": "Research Agendas"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "ehnG4mseKF6xALmQy",
    "title": "Abstraction 2020",
    "curatedOrder": null,
    "contents": {
      "markdown": "Research toward a theory of abstraction [suitable for embedded agency](https://www.lesswrong.com/posts/hLFD6qSN9MmQxKjG5/embedded-agency-via-abstraction).\n\nKey background concepts:\n\n*   [Causal DAGs with symmetry as a model of computation](https://www.lesswrong.com/posts/mZy6AMgCw9CPjNCoK/computational-model-causal-diagrams-with-symmetry)\n*   [The \"minimal map\" interpretation of probability](https://www.lesswrong.com/posts/Lz2nCYnBeaZyS68Xb/probability-as-minimal-map)\n\nBoth of these will be leveraged very heavily in this sequence, so it's worth checking them out before diving in.\n\nThis work is supported by a grant from the [long-term future fund](https://app.effectivealtruism.org/funds/far-future)."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "What is Abstraction?",
            "tags": [
              {
                "name": "Abstraction"
              }
            ]
          },
          {
            "title": "Causal Abstraction Toy Model: Medical Sensor",
            "tags": [
              {
                "name": "Abstraction"
              }
            ]
          },
          {
            "title": "Examples of Causal Abstraction",
            "tags": [
              {
                "name": "Abstraction"
              }
            ]
          },
          {
            "title": "Abstraction, Causality, and Embedded Maps: Here Be Monsters",
            "tags": [
              {
                "name": "Abstraction"
              }
            ]
          },
          {
            "title": "Causal Abstraction Intro",
            "tags": [
              {
                "name": "Abstraction"
              }
            ]
          },
          {
            "title": "Definitions of Causal Abstraction: Reviewing Beckers & Halpern",
            "tags": [
              {
                "name": "Abstraction"
              }
            ]
          },
          {
            "title": "How to Throw Away Information in Causal DAGs",
            "tags": [
              {
                "name": "Abstraction"
              }
            ]
          },
          {
            "title": "Example: Markov Chain",
            "tags": [
              {
                "name": "Abstraction"
              }
            ]
          },
          {
            "title": "Logical Representation of Causal Models",
            "tags": [
              {
                "name": "Causality"
              },
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "Abstraction"
              }
            ]
          },
          {
            "title": "(A -> B) -> A in Causal DAGs",
            "tags": [
              {
                "name": "Abstraction"
              }
            ]
          },
          {
            "title": "Formulating Reductive Agency in Causal Models",
            "tags": [
              {
                "name": "Abstraction"
              }
            ]
          },
          {
            "title": "Trace: Goals and Principles",
            "tags": [
              {
                "name": "Abstraction"
              }
            ]
          },
          {
            "title": "Trace README",
            "tags": [
              {
                "name": "Programming"
              },
              {
                "name": "AI"
              },
              {
                "name": "Abstraction"
              }
            ]
          },
          {
            "title": "Abstraction = Information at a Distance",
            "tags": [
              {
                "name": "Abstraction"
              }
            ]
          },
          {
            "title": "Mediation From a Distance",
            "tags": [
              {
                "name": "Abstraction"
              }
            ]
          },
          {
            "title": "Noise Simplifies",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Abstraction"
              }
            ]
          },
          {
            "title": "Integrating Hidden Variables Improves Approximation",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "AI"
              },
              {
                "name": "Abstraction"
              }
            ]
          },
          {
            "title": "Intuitions on Universal Behavior of Information at a Distance",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Intuition"
              },
              {
                "name": "Abstraction"
              }
            ]
          },
          {
            "title": "Motivating Abstraction-First Decision Theory",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Abstraction"
              }
            ]
          },
          {
            "title": "Writing Causal Models Like We Write Programs",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "World Modeling Techniques"
              },
              {
                "name": "Abstraction"
              }
            ]
          },
          {
            "title": "Pointing to a Flower",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Abstraction"
              }
            ]
          },
          {
            "title": "Public Static: What is Abstraction?",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Abstraction"
              }
            ]
          },
          {
            "title": "Cartesian Boundary as Abstraction Boundary",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Abstraction"
              }
            ]
          },
          {
            "title": "Causality Adds Up to Normality",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Abstraction"
              },
              {
                "name": "Adding Up to Normality"
              }
            ]
          },
          {
            "title": "The Indexing Problem",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Abstraction"
              }
            ]
          },
          {
            "title": "Abstraction, Evolution and Gears",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Gears-Level"
              },
              {
                "name": "Abstraction"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "sv2CwqTCso8wDdmmi",
    "title": "Formal Alignment",
    "curatedOrder": null,
    "contents": {
      "markdown": "Alignment is typical defined loosely as \"AI aligned with human intent, values, or preferences\". This developing sequence of posts is part of an investigation into means for formally stating alignment in a precise enough way that we can use mathematics to formally verify if a proposed alignment mechanism would achieve alignment."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Formally Stating the AI Alignment Problem",
            "tags": []
          },
          {
            "title": "Minimization of prediction error as a foundation for human values in AI alignment",
            "tags": [
              {
                "name": "Predictive Processing"
              },
              {
                "name": "Value Learning"
              }
            ]
          },
          {
            "title": "Values, Valence, and Alignment",
            "tags": [
              {
                "name": "Value Learning"
              }
            ]
          },
          {
            "title": "Towards deconfusing values",
            "tags": [
              {
                "name": "Value Learning"
              },
              {
                "name": "Motivations"
              }
            ]
          },
          {
            "title": "Deconfusing Human Values Research Agenda v1",
            "tags": [
              {
                "name": "Research Agendas"
              },
              {
                "name": "AI"
              },
              {
                "name": "Value Learning"
              },
              {
                "name": "Perceptual Control Theory"
              },
              {
                "name": "Metaethics"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "3hfjaztptwEt2cCve",
    "title": "Gears of Aging",
    "curatedOrder": null,
    "contents": {
      "markdown": "The goal of this sequence is to present [gears-level](https://www.lesswrong.com/posts/B7P97C27rvHPz3s9B/gears-in-understanding) models of various aspects of human aging."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Wrinkles",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Aging"
              },
              {
                "name": "Gears-Level"
              }
            ]
          },
          {
            "title": "Homeostasis and “Root Causes” in Aging",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Aging"
              },
              {
                "name": "World Modeling Techniques"
              },
              {
                "name": "Gears-Level"
              }
            ]
          },
          {
            "title": "The Lens, Progerias and Polycausality",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Aging"
              },
              {
                "name": "Gears-Level"
              }
            ]
          },
          {
            "title": "Adaptive Immune System Aging",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Aging"
              },
              {
                "name": "Gears-Level"
              }
            ]
          },
          {
            "title": "Highlights of Comparative and Evolutionary Aging",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Aging"
              }
            ]
          },
          {
            "title": "Core Pathways of Aging",
            "tags": [
              {
                "name": "World Optimization"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Aging"
              },
              {
                "name": "Human Genetics"
              },
              {
                "name": "Transposons"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "aQTBuq9X98m2KkWpx",
    "title": "Map and Territory Cross-Posts",
    "curatedOrder": null,
    "contents": {
      "markdown": "These are posts that appeared on the [Map and Territory](https://mapandterritory.org/) blog hosted on Medium. Map and Territory is a blog originally created when LessWrong 1.0 was at its nadir that hosted content from several rationalist bloggers, but over time and as LessWrong 2.0 took off, it only had content from G Gordon Worley III.\n\nOnly Gordon's posts have been copied over to LessWrong. Some of the other posts are linked here, but the content is missing and can only be found on the Medium blog."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Map and Territory: a new rationalist group blog",
            "tags": []
          },
          {
            "title": "In Defense of Kegan",
            "tags": []
          },
          {
            "title": "A Foundation for The Multipart Psyche",
            "tags": []
          },
          {
            "title": "Internalizing Existentialism",
            "tags": []
          },
          {
            "title": "Fluid Decision Making",
            "tags": []
          },
          {
            "title": "The Developmental Role of Play",
            "tags": [
              {
                "name": "Developmental Psychology"
              }
            ]
          },
          {
            "title": "Revealed and Stated Identity",
            "tags": []
          },
          {
            "title": "Debate and Dialectic",
            "tags": []
          },
          {
            "title": "Act into Fear and Abandon all Hope",
            "tags": [
              {
                "name": "Hope"
              }
            ]
          },
          {
            "title": "Nothing is Forbidden, but Some Things are Good",
            "tags": []
          },
          {
            "title": "Phenomenological Complexity Classes",
            "tags": []
          },
          {
            "title": "What Value Hermeneutics?",
            "tags": []
          },
          {
            "title": "What Value Epicycles?",
            "tags": []
          },
          {
            "title": "Unstaging Developmental Psychology",
            "tags": []
          },
          {
            "title": "The Personal Growth Cycle",
            "tags": []
          },
          {
            "title": "Angst, Ennui, and Guilt in Effective Altruism",
            "tags": []
          },
          {
            "title": "Developmental Psychology in The Age of Ems",
            "tags": [
              {
                "name": "Whole Brain Emulation"
              }
            ]
          },
          {
            "title": "What Value Subagents?",
            "tags": [
              {
                "name": "Subagents"
              }
            ]
          },
          {
            "title": "Inscrutable Ideas",
            "tags": []
          },
          {
            "title": "Embracing Metamodernism",
            "tags": []
          },
          {
            "title": "Is Feedback Suffering?",
            "tags": []
          },
          {
            "title": "Cognitive Empathy and Emotional Labor",
            "tags": []
          },
          {
            "title": "Regress Thyself to the Mean",
            "tags": []
          },
          {
            "title": "Doxa, Episteme, and Gnosis",
            "tags": []
          },
          {
            "title": "Avoiding AI Races Through Self-Regulation",
            "tags": []
          },
          {
            "title": "Evaluating Existing Approaches to AGI Alignment",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Suffering and Intractable Pain",
            "tags": [
              {
                "name": "Suffering"
              },
              {
                "name": "Consciousness"
              }
            ]
          },
          {
            "title": "Akrasia is confusion about what you want",
            "tags": [
              {
                "name": "Akrasia"
              },
              {
                "name": "Motivations"
              }
            ]
          },
          {
            "title": "Let Values Drift",
            "tags": [
              {
                "name": "Value Drift"
              }
            ]
          },
          {
            "title": "Scope Insensitivity Judo",
            "tags": [
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Meditation"
              },
              {
                "name": "Stoicism / Letting Go / Making Peace"
              },
              {
                "name": "Scope Insensitivity"
              }
            ]
          },
          {
            "title": "Normalization of Deviance",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "You are Dissociating (probably)",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Psychology"
              }
            ]
          },
          {
            "title": "Forcing yourself to keep your identity small is self-harm",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Identity"
              },
              {
                "name": "Subagents"
              },
              {
                "name": "Motivated Reasoning"
              },
              {
                "name": "Self-Deception"
              },
              {
                "name": "Internal Family Systems"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "CRvxidrCkp7YE7gSK",
    "title": "Phenomenological AI Alignment",
    "curatedOrder": null,
    "contents": {
      "markdown": "This is a series of post in which I laid out the foundations of what would become the research agenda of the [Phenomenological AI Safety Research Institute (PAISRI)](https://paisri.org/). Originally posted on the Map and Territory blog on Medium and linked on LessWrong, they have now been copied over to LessWrong to make it easier to engage with them and host them on a site with a stronger commitment to hosting AI safety related content long term.\n\nI no longer necessarily endorse everything in these posts as I have learned more, but I continue to endorse their spirit and consider them worth reading."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Towards an Axiological Approach to AI Alignment",
            "tags": []
          },
          {
            "title": "The World as Phenomena",
            "tags": []
          },
          {
            "title": "Methods of Phenomenology",
            "tags": [
              {
                "name": "Phenomenology"
              },
              {
                "name": "Consciousness"
              }
            ]
          },
          {
            "title": "Form and Feedback in Phenomenology",
            "tags": [
              {
                "name": "Phenomenology"
              },
              {
                "name": "Ontology"
              }
            ]
          },
          {
            "title": "Introduction to Noematology",
            "tags": []
          },
          {
            "title": "AI Alignment and Phenomenal Consciousness",
            "tags": []
          },
          {
            "title": "Computational Complexity of P-Zombies",
            "tags": []
          }
        ]
      }
    ]
  },
  {
    "_id": "BP8vfvg5RhXsBERX9",
    "title": "Changing your Mind With Memory Reconsolidation",
    "curatedOrder": null,
    "contents": {
      "markdown": "A practical, how to guide to \"actually changing your mind\" viewed through the lens of memory reconsolidation theory."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "A Framework for Internal Debugging",
            "tags": [
              {
                "name": "Subagents"
              },
              {
                "name": "Debugging"
              },
              {
                "name": "Memory Reconsolidation"
              }
            ]
          },
          {
            "title": "Book summary: Unlocking the Emotional Brain",
            "tags": [
              {
                "name": "Book Reviews"
              },
              {
                "name": "Subagents"
              },
              {
                "name": "Emotions"
              },
              {
                "name": "Neuroscience"
              },
              {
                "name": "Internal Double Crux"
              },
              {
                "name": "Alief"
              },
              {
                "name": "Motivations"
              },
              {
                "name": "Summaries"
              },
              {
                "name": "Memory Reconsolidation"
              },
              {
                "name": "Cached Thoughts"
              },
              {
                "name": "Therapy"
              },
              {
                "name": "Internal Family Systems"
              }
            ]
          },
          {
            "title": "A Practical Theory of Memory Reconsolidation",
            "tags": [
              {
                "name": "Memory Reconsolidation"
              }
            ]
          },
          {
            "title": "Practical Guidelines for Memory Reconsolidation",
            "tags": [
              {
                "name": "Memory Reconsolidation"
              },
              {
                "name": "Psychology"
              },
              {
                "name": "Self Improvement"
              },
              {
                "name": "Emotions"
              }
            ]
          },
          {
            "title": "The Hierarchy of Memory Reconsolidation Techniques",
            "tags": [
              {
                "name": "Memory Reconsolidation"
              }
            ]
          },
          {
            "title": "Reconsolidation Through Experience",
            "tags": [
              {
                "name": "Memory Reconsolidation"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Reconsolidation Through Questioning",
            "tags": [
              {
                "name": "Memory Reconsolidation"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "cSQHJPrpSvwt9dRyW",
    "title": "base-line to enlightenment - the physical route to better",
    "curatedOrder": null,
    "contents": {
      "markdown": "*   **How do you use your body?**\n*   **Does your posture feel good?**\n*   **Are you tension-free?**\n\nFind your anatomical \"Base-Line\". The key to better physical and mental health.\n===============================================================================\n\nPelvic floor - \"Base\"\n---------------------\n\nRectus abdominis **\\- \"**Line\"\n------------------------------\n\nThe body's core pillar of strength, from where all movement should originate.\n\nFocusing on these muscles builds the connection between body and mind. Feeling the positioning of your body in relation to your Base-Line facilitates self-improvement of posture.  Everything starts from Base-Line.\n\nLearn to fully utilise the 5 main muscles of movement:\n------------------------------------------------------\n\n**Pelvic floor** and **rectus abdominis**\n\nThink: stronger and longer with every breath in.\n\nUse the roll-down action whilst activating and elongating your Base-Line to feel the power of these muscles, supporting the rest of the body.\n\n**Gluteus maximus** and **rectus femoris**\n\nWork in tandem, connecting the legs to Base-Line support. The rectus femoris muscles correctly align the hip and knee joints when fully activated.\n\n**Trapezius**\n\nA sheet of muscle from mid-back to the back of the head, shoulder to shoulder. Supporting the head and arms through a full range of movement when free of physical restrictions.\n\nAnatomy of Alignment:\n---------------------\n\nThe **linea alba,** midline between the rectus abdominis muscles, from pubic symphysis to xiphoid process of the sternum. The primary anatomical guide for body alignment and balance.\n\nThe **nuchal & supraspinous ligaments,** midline between the trapezius muscles, our secondary guides for body alignment.\n\nThese structures should be able to align on the median plane. This is possible when the body has a full range of movement and is free of physical restrictions in connective tissues.\n\n*   _Look at the anatomy pictures & find the muscles on your body._\n*   _Can you feel a connection to them?_\n\nDevelop your sense of conscious proprioception.\n-----------------------------------------------\n\nIncrease your awareness of the sensory feedback from your body regarding your position, motion and balance.\n\nWork towards a full range of natural movement and a balanced and aligned body. Releasing the physical restrictions that cause tensions throughout the body.\n\nFeel the difference.\n\nThe physical route to enlightenment.\n\nA do-it-yourself process.\n\nAll the information you need is here. The rest is up to you. Time and effort required.\n\n_Based in anatomical \"fact\"._\n\n_I believe I know why so much of the world is in pain._\n\n_I am confident my theory will stand up to the severest scrutiny - if you have the curiosity enough to think about how you use your body._\n\n_It has been life-changing. From a depressed wreck to understanding the feeling of \"enlightenment\"._"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Body Alignment & Balance. Our Midline Anatomy & the Median Plane. \n",
            "tags": [
              {
                "name": "Focusing"
              },
              {
                "name": "Fact posts"
              },
              {
                "name": "Techniques"
              },
              {
                "name": "Human Bodies"
              }
            ]
          },
          {
            "title": "The Five Main Muscles for a Full Range of Natural Movement, Dynamic Alignment & Balance.",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "Fact posts"
              },
              {
                "name": "Human Bodies"
              },
              {
                "name": "Exercise (Physical)"
              },
              {
                "name": "Self Improvement"
              },
              {
                "name": "Health / Medicine / Disease"
              },
              {
                "name": "Habits"
              }
            ]
          },
          {
            "title": "The '5 Main Muscles of Movement' Made Easy.",
            "tags": [
              {
                "name": "Techniques"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Health / Medicine / Disease"
              },
              {
                "name": "Human Bodies"
              },
              {
                "name": "Exercise (Physical)"
              }
            ]
          },
          {
            "title": "Conscious  Proprioception.",
            "tags": [
              {
                "name": "Focusing"
              },
              {
                "name": "Well-being"
              },
              {
                "name": "Consciousness"
              },
              {
                "name": "Phenomenology"
              },
              {
                "name": "Human Bodies"
              },
              {
                "name": "Noticing"
              },
              {
                "name": "Qualia"
              },
              {
                "name": "Perception"
              }
            ]
          },
          {
            "title": "A Good Posture -  Muscles & Self-Awareness.",
            "tags": [
              {
                "name": "Focusing"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Self Experimentation"
              },
              {
                "name": "Life Extension"
              },
              {
                "name": "Human Bodies"
              },
              {
                "name": "Exercise (Physical)"
              },
              {
                "name": "Perception"
              }
            ]
          },
          {
            "title": "Fibromyalgia, Pain & Depression.  How much is due to physical misalignment?",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Health / Medicine / Disease"
              },
              {
                "name": "Human Bodies"
              },
              {
                "name": "Depression"
              },
              {
                "name": "Growth Stories"
              },
              {
                "name": "Self Improvement"
              },
              {
                "name": "Updated Beliefs (examples of)"
              }
            ]
          },
          {
            "title": "Chakras & Qi - Old Stories for the Base-Line Experience.  Improve your physical & mental health by connecting body and mind.\n",
            "tags": [
              {
                "name": "Consciousness"
              },
              {
                "name": "Identity"
              },
              {
                "name": "Phenomenology"
              },
              {
                "name": "Happiness"
              },
              {
                "name": "Perception"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "ShtpuCxQKMnJDARcE",
    "title": "The 'Meetup Writeups' Experiment",
    "curatedOrder": null,
    "contents": {
      "markdown": "In September 2019, I announced that I'd send 100 USD to anyone who wrote up the discussion from an in-person rationalist meetup and posted it on LessWrong, with the goal of helping to break down the silos separating the conversations in different geographical areas. This is a collection of the writeups that have been submitted, prefaced by the original post where I announced the incentives project and the reasoning behind it."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Meetups as Institutions for Intellectual Progress",
            "tags": [
              {
                "name": "Community"
              },
              {
                "name": "Meetups & Local Communities (topic)"
              },
              {
                "name": "Intellectual Progress (Society-Level)"
              },
              {
                "name": "Intellectual Progress (Individual-Level)"
              }
            ]
          },
          {
            "title": "Social Class",
            "tags": [
              {
                "name": "Meetups & Local Communities (topic)"
              }
            ]
          },
          {
            "title": "Meetup Notes: Ole Peters on ergodicity",
            "tags": [
              {
                "name": "Community"
              },
              {
                "name": "Betting"
              },
              {
                "name": "Risk Management"
              },
              {
                "name": "Meetups & Local Communities (topic)"
              }
            ]
          },
          {
            "title": "Kansas City Dojo Meetup: 11-5-19",
            "tags": []
          },
          {
            "title": "\nAustin meetup notes Nov. 16, 2019: SSC discussion",
            "tags": [
              {
                "name": "Meetups & Local Communities (topic)"
              }
            ]
          },
          {
            "title": "Saint Louis Meeting Notes 11/23/2019",
            "tags": [
              {
                "name": "Meetups & Local Communities (topic)"
              }
            ]
          },
          {
            "title": "Kansas City Dojo meetup 11-12-19",
            "tags": [
              {
                "name": "Meetups & Local Communities (topic)"
              }
            ]
          },
          {
            "title": "Kansas City Dojo meetup 11-19-19",
            "tags": [
              {
                "name": "Meetups & Local Communities (topic)"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "GTpv3mjKqFot9pxT3",
    "title": "LW Team Updates & Announcements",
    "curatedOrder": null,
    "contents": {
      "markdown": "This sequence contains the LessWrong's teams updates and announcements."
    },
    "chapters": [
      {
        "title": "Monthly Updates",
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "LW Team Updates - September 2019",
            "tags": [
              {
                "name": "Site Meta"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "LW Team Updates - October 2019",
            "tags": [
              {
                "name": "Site Meta"
              }
            ]
          },
          {
            "title": "LW Team Updates - November 2019 (Subscriptions & More)",
            "tags": [
              {
                "name": "Site Meta"
              }
            ]
          },
          {
            "title": "LW Team Updates - December 2019",
            "tags": [
              {
                "name": "Wiki/Tagging"
              },
              {
                "name": "LessWrong Review"
              }
            ]
          },
          {
            "title": "LW Team Updates: Pandemic Edition (March 2020)",
            "tags": [
              {
                "name": "Covid-19"
              },
              {
                "name": "Site Meta"
              }
            ]
          }
        ]
      },
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": []
      },
      {
        "title": "Feature Announcements",
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "[Site Update] Subscriptions, Bookmarks, & Pingbacks",
            "tags": [
              {
                "name": "Site Meta"
              }
            ]
          },
          {
            "title": "[Site Feature] Link Previews",
            "tags": [
              {
                "name": "Site Meta"
              }
            ]
          },
          {
            "title": "Karma-Change Notifications",
            "tags": [
              {
                "name": "Site Meta"
              }
            ]
          },
          {
            "title": "Recommendation Features on LessWrong",
            "tags": [
              {
                "name": "Mechanism Design"
              },
              {
                "name": "Site Meta"
              }
            ]
          },
          {
            "title": "[Site Update] Weekly/Monthly/Yearly on All Posts",
            "tags": [
              {
                "name": "Site Meta"
              }
            ]
          }
        ]
      },
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": "Misc Updates"
        },
        "posts": [
          {
            "title": "\nLW Update 2019-04-02 – Frontpage Rework",
            "tags": [
              {
                "name": "Site Meta"
              }
            ]
          },
          {
            "title": "LW Update 2018-12-06 – Table of Contents and Q&A",
            "tags": [
              {
                "name": "Site Meta"
              },
              {
                "name": "Public Discourse"
              }
            ]
          },
          {
            "title": "LW Update 2018-10-01 – Private Messaging Works",
            "tags": [
              {
                "name": "Site Meta"
              }
            ]
          },
          {
            "title": "LW Update 5/6/2018 – Meta and Moderation",
            "tags": [
              {
                "name": "Site Meta"
              },
              {
                "name": "LW Moderation"
              }
            ]
          },
          {
            "title": "LW Update 04/06/18 – QM Sequence Updated",
            "tags": [
              {
                "name": "Site Meta"
              }
            ]
          },
          {
            "title": "LW Update 3/14 – Community, Markdown and More",
            "tags": [
              {
                "name": "Site Meta"
              }
            ]
          },
          {
            "title": "LW Update 1/5/2018 – Comment Styling",
            "tags": [
              {
                "name": "Site Meta"
              }
            ]
          },
          {
            "title": "LW Migration Announcement",
            "tags": [
              {
                "name": "Site Meta"
              },
              {
                "name": "Hide From Untagged List"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "4Yrj9LSLKpHxzDFHW",
    "title": "Reflections on Premium Poker Tools",
    "curatedOrder": null,
    "contents": null,
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Reflections on Premium Poker Tools: Part 1 - My journey",
            "tags": [
              {
                "name": "Postmortems & Retrospectives"
              },
              {
                "name": "Programming"
              },
              {
                "name": "Startups"
              }
            ]
          },
          {
            "title": "Reflections on Premium Poker Tools: Part 2 - Deciding to call it quits",
            "tags": [
              {
                "name": "Postmortems & Retrospectives"
              },
              {
                "name": "Startups"
              }
            ]
          },
          {
            "title": "Reflections on Premium Poker Tools: Part 3 - What I've learned",
            "tags": [
              {
                "name": "Postmortems & Retrospectives"
              },
              {
                "name": "Startups"
              }
            ]
          },
          {
            "title": "Reflections on Premium Poker Tools: Part 4 - Smaller things that I've learned",
            "tags": [
              {
                "name": "Postmortems & Retrospectives"
              },
              {
                "name": "Startups"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "HeYtBkNbEe7wpjc6X",
    "title": "Partial Agency",
    "curatedOrder": null,
    "contents": {
      "markdown": "Here, I try to disassemble my concept of agency.\n\nImportant background which isn't quite part of the sequence:\n\n*   [Selection vs Control](https://www.lesswrong.com/posts/ZDZmopKquzHYPRNxq/selection-vs-control)"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Partial Agency",
            "tags": [
              {
                "name": "Myopia"
              }
            ]
          },
          {
            "title": "The Parable of Predict-O-Matic",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Myopia"
              },
              {
                "name": "Oracle AI"
              },
              {
                "name": "Parables & Fables"
              },
              {
                "name": "Self Fulfilling/Refuting Prophecies"
              }
            ]
          },
          {
            "title": "Random Thoughts on Predict-O-Matic",
            "tags": [
              {
                "name": "Myopia"
              },
              {
                "name": "Self Fulfilling/Refuting Prophecies"
              }
            ]
          },
          {
            "title": "Defining Myopia",
            "tags": [
              {
                "name": "Myopia"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Self Fulfilling/Refuting Prophecies"
              }
            ]
          },
          {
            "title": "The Credit Assignment Problem",
            "tags": [
              {
                "name": "Myopia"
              },
              {
                "name": "Optimization"
              }
            ]
          },
          {
            "title": "Bayesian Evolving-to-Extinction",
            "tags": [
              {
                "name": "Myopia"
              },
              {
                "name": "Bayes' Theorem"
              },
              {
                "name": "AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "8Kc3YamAyaACWXwb3",
    "title": "Concept Safety",
    "curatedOrder": null,
    "contents": {
      "markdown": "We can think of concepts and ontologies as tools for achieving our values. How does this influence our thinking on AI safety?"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Concept Safety: Producing similar AI-human concept spaces",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Outer Alignment"
              },
              {
                "name": "Neuroscience"
              },
              {
                "name": "Machine Learning  (ML)"
              }
            ]
          },
          {
            "title": "Concept Safety: The problem of alien concepts",
            "tags": []
          },
          {
            "title": "Concept Safety: What are concepts for, and how to deal with alien concepts",
            "tags": []
          },
          {
            "title": "Concept Safety: World-models as tools",
            "tags": []
          }
        ]
      }
    ]
  },
  {
    "_id": "YuTinYEzsyHmPoocw",
    "title": "AI Alignment Writing Day 2019",
    "curatedOrder": null,
    "contents": {
      "markdown": "On August 22nd 2019, all attendees of the MIRI Summer Fellows Program were given an entire day to write blogposts to the AI Alignment Forum with ideas they'd been thinking about. These are the posts that resulted, in chronological order."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Announcement: Writing Day Today (Thursday)",
            "tags": [
              {
                "name": "Community"
              }
            ]
          },
          {
            "title": "Markets are Universal for Logical Induction",
            "tags": [
              {
                "name": "Logical Induction"
              },
              {
                "name": "Logical Uncertainty"
              }
            ]
          },
          {
            "title": "Computational Model: Causal Diagrams with Symmetry",
            "tags": [
              {
                "name": "Causality"
              },
              {
                "name": "Solomonoff Induction"
              }
            ]
          },
          {
            "title": "Intentional Bucket Errors",
            "tags": [
              {
                "name": "Bucket Errors"
              }
            ]
          },
          {
            "title": "Embedded Naive Bayes",
            "tags": []
          },
          {
            "title": "Time Travel, AI and Transparent Newcomb",
            "tags": []
          },
          {
            "title": "Logical Counterfactuals and Proposition graphs, Part 1",
            "tags": [
              {
                "name": "Counterfactuals"
              }
            ]
          },
          {
            "title": "Why so much variance in human intelligence?",
            "tags": [
              {
                "name": "IQ and g-factor"
              }
            ]
          },
          {
            "title": "Towards a mechanistic understanding of corrigibility",
            "tags": [
              {
                "name": "Myopia"
              },
              {
                "name": "Corrigibility"
              },
              {
                "name": "Hansonian Pre-Rationality"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Logical Optimizers  ",
            "tags": []
          },
          {
            "title": "Deconfuse Yourself about Agency",
            "tags": []
          },
          {
            "title": "Thoughts from a Two Boxer",
            "tags": [
              {
                "name": "Newcomb's Problem"
              },
              {
                "name": "Decision Theory"
              }
            ]
          },
          {
            "title": "Analysis of a Secret Hitler Scenario",
            "tags": []
          },
          {
            "title": "The Commitment Races problem",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Game Theory"
              }
            ]
          },
          {
            "title": "Does Agent-like Behavior Imply Agent-like Architecture?",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Goal-Directedness"
              },
              {
                "name": "Agency"
              }
            ]
          },
          {
            "title": "Redefining Fast Takeoff",
            "tags": []
          },
          {
            "title": "Vaniver's View on Factored Cognition",
            "tags": [
              {
                "name": "Factored Cognition"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Tabooing 'Agent' for Prosaic Alignment",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Machine Learning  (ML)"
              }
            ]
          },
          {
            "title": "Creating Environments to Design and Test Embedded Agents",
            "tags": []
          },
          {
            "title": "Formalising decision theory is hard",
            "tags": [
              {
                "name": "Decision Theory"
              }
            ]
          },
          {
            "title": "Vague Thoughts and Questions about Agent Structures",
            "tags": []
          },
          {
            "title": "Towards an Intentional Research Agenda",
            "tags": [
              {
                "name": "Predictive Processing"
              },
              {
                "name": "Hansonian Pre-Rationality"
              },
              {
                "name": "Intentionality"
              }
            ]
          },
          {
            "title": "Metalignment: Deconfusing metaethics for AI alignment. ",
            "tags": []
          },
          {
            "title": "Torture and Dust Specks and Joy--Oh my!\n\nor: Non-Archimedean Utility Functions as Pseudograded Vector Spaces",
            "tags": []
          },
          {
            "title": "Soft takeoff can still lead to decisive strategic advantage",
            "tags": [
              {
                "name": "AI Takeoff"
              },
              {
                "name": "Industrial Revolution"
              },
              {
                "name": "AI Risk"
              },
              {
                "name": "AI Governance"
              }
            ]
          },
          {
            "title": "Algorithmic Similarity",
            "tags": [
              {
                "name": "Computer Science"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Thoughts on Retrieving Knowledge from Neural Networks",
            "tags": []
          },
          {
            "title": "Parables of Constraint and Actualization ",
            "tags": []
          },
          {
            "title": "When do utility functions constrain?",
            "tags": [
              {
                "name": "Utility Functions"
              }
            ]
          },
          {
            "title": "Actually updating",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Changing Your Mind"
              },
              {
                "name": "Subagents"
              }
            ]
          },
          {
            "title": "Understanding understanding",
            "tags": [
              {
                "name": "Transparency / Interpretability (ML & AI)"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Troll Bridge",
            "tags": [
              {
                "name": "Decision Theory"
              },
              {
                "name": "Embedded Agency"
              }
            ]
          },
          {
            "title": "Optimization Provenance",
            "tags": [
              {
                "name": "Optimization"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "GTEay24Lxm3xoE4hy",
    "title": "Novum Organum",
    "curatedOrder": null,
    "contents": {
      "markdown": "In 1620, Francis Bacon’s _[Novum Organum](https://en.wikipedia.org/wiki/Novum_Organum)_ was published. Though the work might be succinctly described as Bacon’s views on empiricism and [inductivism](https://en.wikipedia.org/wiki/Inductivism), it is far more than a list of experimental steps to be followed. It is an entire epistemology and philosophy—possibly _the_ epistemology and philosophy which underlay the [Scientific Revolution](https://en.wikipedia.org/wiki/Scientific_Revolution#Baconian_science).\n\nIn light of its value as a rationalist text, its historical influence on the progress of science, and its general expression of the philosophy and vision which guides LessWrong 2.0, the moderation team has seen fit to publish Novum Organum as a LessWrong sequence."
    },
    "chapters": [
      {
        "title": "Book 2",
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Nature's Hidden Processes and Structures (Novum Organum Book 2: 1-9)",
            "tags": []
          },
          {
            "title": "Tables of Presence, Nearby Absence, & Degrees of Intensity (Novum Organum Book 2: 10-14)",
            "tags": []
          },
          {
            "title": "A First Sketch of the Nature of Heat (Novum Organum Book 2: 15-25)",
            "tags": []
          }
        ]
      },
      {
        "title": "Book 1",
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Novum Organum: Introduction",
            "tags": [
              {
                "name": "Book Reviews"
              }
            ]
          },
          {
            "title": "Novum Organum: Preface",
            "tags": [
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "Epistemology"
              }
            ]
          },
          {
            "title": "The Inadequacy of Current Science (Novum Organum Book 1: 1-37)",
            "tags": [
              {
                "name": "Practice & Philosophy of Science"
              }
            ]
          },
          {
            "title": "Idols of the Mind Pt. 1 (Novum Organum Book 1: 38–52)",
            "tags": [
              {
                "name": "Book Reviews"
              }
            ]
          },
          {
            "title": "Idols of the Mind Pt. 2 (Novum Organum Book 1: 53-68)",
            "tags": [
              {
                "name": "Practice & Philosophy of Science"
              }
            ]
          },
          {
            "title": " 13 Causes of Bad Science (Novum Organum Book 1: 69-92)",
            "tags": [
              {
                "name": "Practice & Philosophy of Science"
              }
            ]
          },
          {
            "title": "The Baconian Method (Novum Organum Book 1: 93-107)",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Intellectual Progress (Society-Level)"
              }
            ]
          },
          {
            "title": "Reasons for Hope & Objection Preemption (Novum Organum Book 1: 108-130)",
            "tags": []
          }
        ]
      }
    ]
  },
  {
    "_id": "HknKjvSxbFAAQ3RdL",
    "title": "Forecasting Infrastructure",
    "curatedOrder": null,
    "contents": {
      "markdown": "A collection of resources detailing an approach for building out a robust forecasting ecosystem"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "AI Forecasting Dictionary (Forecasting infrastructure, part 1)",
            "tags": [
              {
                "name": "Forecasting & Prediction"
              }
            ]
          },
          {
            "title": "AI Forecasting Resolution Council (Forecasting infrastructure, part 2)",
            "tags": [
              {
                "name": "Forecasting & Prediction"
              }
            ]
          },
          {
            "title": "How to write good AI forecasting questions + Question Database (Forecasting infrastructure, part 3)",
            "tags": [
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "Technological Forecasting"
              }
            ]
          },
          {
            "title": "Running Effective Structured Forecasting Sessions",
            "tags": [
              {
                "name": "Forecasting & Prediction"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "Js5d6ddsCkAQskjbz",
    "title": "Logical Counterfactuals and Proposition graphs",
    "curatedOrder": null,
    "contents": {
      "markdown": "In this series of posts, I explore a potential way to formalize logical counterfactuals. To do this, I first come up with an alternate formalization of first order logic, where you don't think in terms of true or false, but in terms of similar or different. This makes proving a theorem equivalent to finding a path through an infinitely large maze."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Logical Counterfactuals and Proposition graphs, Part 1",
            "tags": [
              {
                "name": "Counterfactuals"
              }
            ]
          },
          {
            "title": "Logical Counterfactuals and Proposition graphs, Part 2",
            "tags": [
              {
                "name": "Counterfactuals"
              }
            ]
          },
          {
            "title": "Logical Counterfactuals and Proposition graphs, Part 3",
            "tags": [
              {
                "name": "Counterfactuals"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "KcAjdgamYDudXN2Ez",
    "title": "Transcript of Eric Weinstein / Peter Thiel Conversation",
    "curatedOrder": null,
    "contents": null,
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Peter Thiel/Eric Weinstein Transcript on Growth, Violence, and Stories",
            "tags": [
              {
                "name": "Narratives (stories)"
              },
              {
                "name": "Transcripts"
              }
            ]
          },
          {
            "title": "Stories About Academia",
            "tags": [
              {
                "name": "World Optimization"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Progress Studies"
              }
            ]
          },
          {
            "title": "Stories About Education",
            "tags": [
              {
                "name": "Education"
              }
            ]
          },
          {
            "title": "Political Violence and Distraction Theories",
            "tags": []
          },
          {
            "title": "Stories About Progress",
            "tags": [
              {
                "name": "Progress Studies"
              },
              {
                "name": "World Optimization"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "3qa3jAE9sqFqH9okL",
    "title": "AI Alignment Writing Day 2018",
    "curatedOrder": null,
    "contents": {
      "markdown": "On 10th July 2018, all attendees of the MIRI Summer Fellows Program were given an entire day to write blogposts to the AI Alignment Forum with ideas they'd been thinking about. These are the 28 posts that resulted, in chronological order."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Choosing to Choose?",
            "tags": []
          },
          {
            "title": "The Intentional Agency Experiment",
            "tags": []
          },
          {
            "title": "Two agents can have the same source code and optimise different utility functions",
            "tags": []
          },
          {
            "title": "Conditioning, Counterfactuals, Exploration, and Gears",
            "tags": [
              {
                "name": "Counterfactuals"
              }
            ]
          },
          {
            "title": "Probability is fake, frequency is real",
            "tags": [
              {
                "name": "Sleeping Beauty Paradox"
              }
            ]
          },
          {
            "title": "Repeated (and improved) Sleeping Beauty problem",
            "tags": [
              {
                "name": "Sleeping Beauty Paradox"
              }
            ]
          },
          {
            "title": "Logical Uncertainty and Functional Decision Theory",
            "tags": [
              {
                "name": "Logical Uncertainty"
              }
            ]
          },
          {
            "title": "A framework for thinking about wireheading",
            "tags": []
          },
          {
            "title": "Bayesian Probability is for things that are Space-like Separated from You",
            "tags": [
              {
                "name": "Bayes' Theorem"
              },
              {
                "name": "Logical Uncertainty"
              },
              {
                "name": "Bayesian Decision Theory"
              }
            ]
          },
          {
            "title": "A universal score for optimizers",
            "tags": []
          },
          {
            "title": "An environment for studying counterfactuals",
            "tags": [
              {
                "name": "Counterfactuals"
              }
            ]
          },
          {
            "title": "Mechanistic Transparency for Machine Learning",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Transparency / Interpretability (ML & AI)"
              }
            ]
          },
          {
            "title": "Bounding Goodhart's Law",
            "tags": [
              {
                "name": "Goodhart's Law"
              }
            ]
          },
          {
            "title": "A comment on the IDA-AlphaGoZero metaphor; capabilities versus alignment",
            "tags": [
              {
                "name": "DeepMind"
              },
              {
                "name": "Iterated Amplification "
              }
            ]
          },
          {
            "title": "Dependent Type Theory and Zero-Shot Reasoning",
            "tags": []
          },
          {
            "title": "Conceptual problems with utility functions",
            "tags": [
              {
                "name": "Utility Functions"
              }
            ]
          },
          {
            "title": "No, I won't go there, it feels like you're trying to Pascal-mug me",
            "tags": [
              {
                "name": "Pascal's Mugging"
              }
            ]
          },
          {
            "title": "Conditions under which misaligned subagents can (not) arise in classifiers",
            "tags": [
              {
                "name": "Subagents"
              }
            ]
          },
          {
            "title": "Complete Class: Consequentialist Foundations",
            "tags": [
              {
                "name": "Decision Theory"
              },
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Futarchy"
              }
            ]
          },
          {
            "title": "Clarifying Consequentialists in the Solomonoff Prior",
            "tags": [
              {
                "name": "Solomonoff Induction"
              }
            ]
          },
          {
            "title": "On the Role of Counterfactuals in Learning",
            "tags": [
              {
                "name": "Counterfactuals"
              }
            ]
          },
          {
            "title": "Agents That Learn From Human Behavior Can't Learn Human Values That Humans Haven't Learned Yet",
            "tags": [
              {
                "name": "Inverse Reinforcement Learning"
              },
              {
                "name": "Value Learning"
              }
            ]
          },
          {
            "title": "Decision-theoretic problems and Theories; An (Incomplete) comparative list",
            "tags": [
              {
                "name": "Decision Theory"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": " Mathematical Mindset",
            "tags": [
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Monk Treehouse: some problems defining simulation",
            "tags": []
          },
          {
            "title": "An Agent is a Worldline in Tegmark V",
            "tags": [
              {
                "name": "Definitions"
              },
              {
                "name": "Agency"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Generalized Kelly betting",
            "tags": [
              {
                "name": "Kelly Criterion"
              }
            ]
          },
          {
            "title": "Conceptual problems with utility functions, second attempt at explaining\n",
            "tags": []
          }
        ]
      },
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": []
      }
    ]
  },
  {
    "_id": "nMGrhBYXWjPhZoyNL",
    "title": "Daily Insights",
    "curatedOrder": null,
    "contents": {
      "markdown": "> _Docendo discimus_\n\nThis sequence recorded my progress learning concepts related to machine learning and AI alignment. With some exceptions, I intended to post an explanation of an important concept every day."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Walkthrough: The Transformer Architecture [Part 1/2]",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Walkthrough: The Transformer Architecture [Part 2/2]",
            "tags": []
          },
          {
            "title": "Understanding Batch Normalization",
            "tags": []
          },
          {
            "title": "Rethinking Batch Normalization",
            "tags": [
              {
                "name": "Machine Learning  (ML)"
              },
              {
                "name": "Computer Science"
              },
              {
                "name": "Gears-Level"
              }
            ]
          },
          {
            "title": "A Survey of Early Impact Measures",
            "tags": [
              {
                "name": "Impact Measures"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Understanding Recent Impact Measures",
            "tags": [
              {
                "name": "Impact Measures"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Four Ways An Impact Measure Could Help Alignment",
            "tags": [
              {
                "name": "Impact Measures"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Why Gradients Vanish and Explode",
            "tags": [
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "Machine Learning  (ML)"
              },
              {
                "name": "Computer Science"
              }
            ]
          },
          {
            "title": "A Primer on Matrix Calculus, Part 1: Basic review",
            "tags": [
              {
                "name": "Logic & Mathematics "
              }
            ]
          },
          {
            "title": "A Primer on Matrix Calculus, Part 2: Jacobians and other fun",
            "tags": [
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "Machine Learning  (ML)"
              }
            ]
          },
          {
            "title": "A Primer on Matrix Calculus, Part 3: The Chain Rule",
            "tags": []
          }
        ]
      }
    ]
  },
  {
    "_id": "hBFDRZCPLcrRDubgm",
    "title": "Keep your beliefs cruxy and your frames explicit",
    "curatedOrder": null,
    "contents": {
      "markdown": "Doublecrux is a valuable tool – it can help groups come to decisions, and it can enable individual thinkers to help each other form more accurate conclusions.\n\nUnfortunately it's often a time consuming tool. Some disagreements can take hours to resolve. Others take years. By default, most of our belief networks are a messy, impenetrable morass, and disentangling that takes time.\n\nBut the core skill of doublecrux – noticing what would actually change your mind – is something you can develop. And as you develop it, I've found it easier to a) figure out what I actually believe and why, b) develop belief structures that are easier for me to understand, update, and share.\n\nThis sequence explores when doublecrux is useful, what are some important subskills, and why they're worth cultivating."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "What product are you building?",
            "tags": [
              {
                "name": "Conversation (topic)"
              }
            ]
          },
          {
            "title": "Doublecrux is for Building Products",
            "tags": [
              {
                "name": "Double-Crux"
              }
            ]
          },
          {
            "title": "Keep Your Beliefs Cruxy",
            "tags": [
              {
                "name": "Double-Crux"
              }
            ]
          },
          {
            "title": "Noticing Frame Differences",
            "tags": [
              {
                "name": "Noticing"
              },
              {
                "name": "Conversation (topic)"
              },
              {
                "name": "Disagreement"
              },
              {
                "name": "Distinctions"
              },
              {
                "name": "Frames"
              }
            ]
          },
          {
            "title": "Picture Frames, Window Frames and Frameworks",
            "tags": [
              {
                "name": "Frames"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Karate Kid and Realistic Expectations for Disagreement Resolution",
            "tags": [
              {
                "name": "Inferential Distance"
              },
              {
                "name": "Disagreement"
              }
            ]
          },
          {
            "title": "Propagating Facts into Aesthetics",
            "tags": [
              {
                "name": "Aesthetics"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "onCRFFN7rGXTg3jyc",
    "title": "Model Comparison",
    "curatedOrder": null,
    "contents": {
      "markdown": "20 coin flips yield 16 heads and 4 tails. Is the coin biased? Given data on 20000 rolls of an imperfect die, can we deduce not just the die's bias, but the physical asymmetries of the die? Given a set of x-y data, should we use a linear or quadratic regression? These are questions of model comparison.\n\nThis sequence tackles model comparison from a Bayesian first-principles approach.\n\nOutline:\n\n*   [Very Short Introduction](https://www.lesswrong.com/s/onCRFFN7rGXTg3jyc/p/5mr8Qcqi6xWa6HCHw) is exactly what it sounds like. It introduces the main idea, and walks through a simple example: calculating the probability that a coin is biased, given some data. [Wolf's Dice](https://www.lesswrong.com/s/onCRFFN7rGXTg3jyc/p/zd89utY4afA59p58k) is a similar but more in-depth example, which also sets up for later.\n*   In [Wolf's Dice II](https://www.lesswrong.com/s/onCRFFN7rGXTg3jyc/p/QKnbbGDd2LbAPfgBh), we try to figure out not just the biases of a die, but what physical asymmetries give rise to those biases. This example comes up again later when discussing cross-validation.\n*   The next three posts talk about two methods to approximate Bayesian model comparison in practice: [Laplace approximation](https://www.lesswrong.com/s/onCRFFN7rGXTg3jyc/p/9BqvY7tpqrD4BC6dL) and [BIC](https://www.lesswrong.com/s/onCRFFN7rGXTg3jyc/p/bvM6zj9xv5sjkGrhZ). We also [compare their performance](https://www.lesswrong.com/s/onCRFFN7rGXTg3jyc/p/cJePhSbDvfBLfcxtK). These three posts are mainly for people who want to implement Bayesian model comparison on larger-scale problems (i.e. for machine learning) and need to understand the approximation trade-offs; others will likely want to skip them.\n*   Finally, we [compare Bayesian model comparison to cross-validation](https://www.lesswrong.com/s/onCRFFN7rGXTg3jyc/p/vFom2WsZkqCJPWqvZ). We talk about the different questions asked by each, and when one or the other should be used. We wrap up with some comments on what it means for two models to make different predictions, and why it matters in practice."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Very Short Introduction to Bayesian Model Comparison ",
            "tags": [
              {
                "name": "Bayes' Theorem"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Probability & Statistics"
              },
              {
                "name": "Occam's Razor"
              }
            ]
          },
          {
            "title": "Wolf's Dice",
            "tags": [
              {
                "name": "Probability & Statistics"
              }
            ]
          },
          {
            "title": "Wolf's Dice II: What Asymmetry?",
            "tags": [
              {
                "name": "Probability & Statistics"
              }
            ]
          },
          {
            "title": "Laplace Approximation",
            "tags": [
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "Probability & Statistics"
              },
              {
                "name": "Bayes' Theorem"
              }
            ]
          },
          {
            "title": "From Laplace to BIC",
            "tags": [
              {
                "name": "Probability & Statistics"
              }
            ]
          },
          {
            "title": "Bayesian Model Testing Comparisons",
            "tags": [
              {
                "name": "Probability & Statistics"
              }
            ]
          },
          {
            "title": "Cross-Validation vs Bayesian Model Comparison",
            "tags": [
              {
                "name": "Machine Learning  (ML)"
              },
              {
                "name": "Probability & Statistics"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "Qwgq6pBJ4YPRkHtZg",
    "title": "National Institute of Standards and Technology: AI Standards",
    "curatedOrder": null,
    "contents": {
      "markdown": "This sequence is to collect my write-ups on the NIST plan for AI standards."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "NIST: draft plan for AI standards development",
            "tags": []
          },
          {
            "title": "Outline of NIST draft plan for AI standards",
            "tags": []
          },
          {
            "title": "Offering public comment in the Federal rulemaking process",
            "tags": []
          }
        ]
      }
    ]
  },
  {
    "_id": "7CdoznhJaLEKHwvJW",
    "title": "Reframing Impact",
    "curatedOrder": null,
    "contents": {
      "markdown": "Why do some things seem like really big deals to us? Do most agents best achieve their goals by seeking power? How might we avert catastrophic incentives in the utility maximization framework? "
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Reframing Impact",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Impact Measures"
              },
              {
                "name": "Exercises / Problem-Sets"
              }
            ]
          }
        ]
      },
      {
        "title": "What is impact?",
        "subtitle": null,
        "number": 1,
        "contents": null,
        "posts": [
          {
            "title": "Value Impact",
            "tags": [
              {
                "name": "Impact Measures"
              },
              {
                "name": "Exercises / Problem-Sets"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Deducing Impact",
            "tags": [
              {
                "name": "Impact Measures"
              },
              {
                "name": "Exercises / Problem-Sets"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Attainable Utility Theory: Why Things Matter",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Impact Measures"
              }
            ]
          },
          {
            "title": "World State is the Wrong Abstraction for Impact",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Impact Measures"
              },
              {
                "name": "Exercises / Problem-Sets"
              }
            ]
          },
          {
            "title": "The Gears of Impact",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Impact Measures"
              }
            ]
          }
        ]
      },
      {
        "title": "How agents impact each other",
        "subtitle": null,
        "number": 2,
        "contents": null,
        "posts": [
          {
            "title": "Seeking Power is Often Convergently Instrumental in MDPs",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Instrumental Convergence"
              },
              {
                "name": "Myopia"
              }
            ]
          },
          {
            "title": "Attainable Utility Landscape: How The World Is Changed",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Impact Measures"
              },
              {
                "name": "Exercises / Problem-Sets"
              }
            ]
          },
          {
            "title": "The Catastrophic Convergence Conjecture",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Instrumental Convergence"
              },
              {
                "name": "Impact Measures"
              }
            ]
          },
          {
            "title": "Attainable Utility Preservation: Concepts",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Impact Measures"
              }
            ]
          }
        ]
      },
      {
        "title": "Regularizing impact",
        "subtitle": null,
        "number": 3,
        "contents": null,
        "posts": [
          {
            "title": "Attainable Utility Preservation: Empirical Results",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Impact Measures"
              }
            ]
          },
          {
            "title": "How Low Should Fruit Hang Before We Pick It?",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Impact Measures"
              }
            ]
          },
          {
            "title": "Attainable Utility Preservation: Scaling to Superhuman",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Impact Measures"
              }
            ]
          },
          {
            "title": "Reasons for Excitement about Impact of Impact Measure Research",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Impact Measures"
              }
            ]
          },
          {
            "title": "Conclusion to 'Reframing Impact'",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Impact Measures"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "zkF3gAvTqc6CmCa5A",
    "title": ">@Live!!FREE**USA vs England Live!Stream Reddit 2019",
    "curatedOrder": null,
    "contents": {
      "markdown": "  \n\n_This post is awaiting moderator approval_  \n\nGO LIVE🔴► [](https://sportsjewel44.blogspot.com/2019/07/england-usa.html) [**England vs USA live**  \nGO LIVE🔴► **England vs USA live**](http://v.ht/England-vs-USA)\n\nEngland: There's that scoring touch. For a team with England vs USA World Cup Women , Semifinals 2019 and England vs USA, you would expect at times the club to score more, and lately the team has. Over the last five World Cup Women , Semifinals 2019s, four of which have been victories with one draw, Barca has averaged three goals per World Cup Women , Semifinals 2019, boosted by the 5-0 win over England on june. 15. England vs USA has six goals in his last three England vs USA matches.\n\nUSA: This club hasn't been dominant in attack at all. In fact, out of the other 19 World Cup Women , Semifinals 2019 teams, only six teams have scored fewer, yet the club is in seventh. That's because of the defense, with USA surrendering 15 goals in 19 World Cup Women , Semifinals 2019s, the second best mark in the league. Goalkeeper David Soria has been the main. After not playing much at USA, he made the move to USA last year and has proven to be an important piece for one of the surprises of the season."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": []
      }
    ]
  },
  {
    "_id": "5ZFMzdxSjTEY2KKNk",
    "title": "Test",
    "curatedOrder": null,
    "contents": null,
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": []
      }
    ]
  },
  {
    "_id": "cpcEQpPMwgePj3jKa",
    "title": "Shortform feeds",
    "curatedOrder": null,
    "contents": {
      "markdown": "  \n\nNot yet in order. There's been an explosion in Shortforms, so this list probably isn't complete. Feel free to PM me if you notice one missing."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Ruby's Public Drafts & Working Notes",
            "tags": []
          },
          {
            "title": "Ikaxas' Shortform Feed",
            "tags": []
          },
          {
            "title": "zlrth's Shortform Feed",
            "tags": []
          },
          {
            "title": "Raemon's Shortform",
            "tags": [
              {
                "name": "Hide From Untagged List"
              }
            ]
          },
          {
            "title": "Eli's shortform feed",
            "tags": []
          },
          {
            "title": "Habryka's Shortform Feed",
            "tags": []
          },
          {
            "title": "Hazard's Shortform Feed",
            "tags": []
          },
          {
            "title": "DanielFilan's Shortform Feed",
            "tags": []
          },
          {
            "title": "Rob B's Shortform Feed",
            "tags": []
          },
          {
            "title": "NaiveTortoise's Short Form Feed",
            "tags": []
          },
          {
            "title": "thought: the problem with less wrong's epistemic health is that stuff isn't short form",
            "tags": []
          },
          {
            "title": "Owen's short-form blog",
            "tags": []
          },
          {
            "title": "Spiracular's Shortform Feed",
            "tags": []
          },
          {
            "title": "Matt Goldenberg's Short Form Feed",
            "tags": []
          },
          {
            "title": "steven0461's Shortform Feed",
            "tags": []
          },
          {
            "title": "Jimrandomh's Shortform",
            "tags": []
          },
          {
            "title": "TurnTrout's shortform feed",
            "tags": []
          },
          {
            "title": "benwr's unpolished thoughts",
            "tags": []
          },
          {
            "title": "Sayan's Braindump",
            "tags": []
          },
          {
            "title": "ike's Shortform",
            "tags": []
          },
          {
            "title": "ozziegooen's Shortform",
            "tags": []
          }
        ]
      }
    ]
  },
  {
    "_id": "r9tYkB2a8Fp4DN8yB",
    "title": "Risks from Learned Optimization",
    "curatedOrder": 1,
    "contents": {
      "markdown": "_This is a sequence version of the paper “[Risks from Learned Optimization in Advanced Machine Learning Systems](https://arxiv.org/abs/1906.01820)” by Evan Hubinger, Chris van Merwijk, Vladimir Mikulik, Joar Skalse, and Scott Garrabrant. Each post in the sequence corresponds to a different section of the paper. Evan Hubinger, Chris van Merwijk, Vladimir Mikulik, and Joar Skalse contributed equally to this sequence._\n\nThe goal of this sequence is to analyze the type of learned optimization that occurs when a learned model (such as a neural network) is itself an optimizer—a situation we refer to as _mesa-optimization,_ a neologism we introduce in this sequence. We believe that the possibility of mesa-optimization raises two important questions for the safety and transparency of advanced machine learning systems. First, under what circumstances will learned models be optimizers, including when they should not be? Second, when a learned model is an optimizer, what will its objective be—how will it differ from the loss function it was trained under—and how can it be aligned?"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Risks from Learned Optimization: Introduction",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Mesa-Optimization"
              },
              {
                "name": "Optimization"
              },
              {
                "name": "Inner Alignment"
              },
              {
                "name": "Outer Alignment"
              },
              {
                "name": "AI Risk"
              }
            ]
          },
          {
            "title": "Conditions for Mesa-Optimization",
            "tags": [
              {
                "name": "Mesa-Optimization"
              },
              {
                "name": "AI"
              },
              {
                "name": "AI Risk"
              }
            ]
          },
          {
            "title": "The Inner Alignment Problem",
            "tags": [
              {
                "name": "Mesa-Optimization"
              },
              {
                "name": "AI"
              },
              {
                "name": "Inner Alignment"
              },
              {
                "name": "AI Risk"
              }
            ]
          },
          {
            "title": "Deceptive Alignment",
            "tags": [
              {
                "name": "Mesa-Optimization"
              },
              {
                "name": "AI"
              },
              {
                "name": "AI Risk"
              }
            ]
          },
          {
            "title": "Risks from Learned Optimization: Conclusion and Related Work",
            "tags": [
              {
                "name": "Mesa-Optimization"
              },
              {
                "name": "AI"
              },
              {
                "name": "AI Risk"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "SBfqYgHf2zvxyKDtB",
    "title": "Alternate Alignment Ideas",
    "curatedOrder": null,
    "contents": {
      "markdown": "These are 'brainstorming' posts, around the theme of what it means for a system to be helpful to a human."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Stable Pointers to Value: An Agent Embedded in Its Own Utility Function",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Value Learning"
              },
              {
                "name": "The Pointers Problem"
              }
            ]
          },
          {
            "title": "Stable Pointers to Value II: Environmental Goals",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Value Learning"
              },
              {
                "name": "The Pointers Problem"
              }
            ]
          },
          {
            "title": "Stable Pointers to Value III: Recursive Quantilization",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Utility Functions"
              },
              {
                "name": "Mild Optimization"
              },
              {
                "name": "Value Learning"
              },
              {
                "name": "The Pointers Problem"
              }
            ]
          },
          {
            "title": "Policy Alignment",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Value Learning"
              }
            ]
          },
          {
            "title": "Non-Consequentialist Cooperation?",
            "tags": [
              {
                "name": "Value Learning"
              },
              {
                "name": "Consequentialism"
              },
              {
                "name": "Deontology"
              },
              {
                "name": "AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "FYMiCeXEgMzsB5stm",
    "title": "Concepts in formal epistemology",
    "curatedOrder": null,
    "contents": {
      "markdown": "A set of introductory posts on inference, probability, decision-making, and logic, originally written for Arbital in 2015–2017."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Interpretations of \"probability\"",
            "tags": [
              {
                "name": "Probability & Statistics"
              },
              {
                "name": "Bayes' Theorem"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Distinctions"
              }
            ]
          },
          {
            "title": "Correspondence visualizations for different interpretations of \"probability\"",
            "tags": [
              {
                "name": "Probability & Statistics"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Probability interpretations: Examples",
            "tags": [
              {
                "name": "Probability & Statistics"
              },
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "Logical Uncertainty"
              }
            ]
          },
          {
            "title": "Coherent decisions imply consistent utilities",
            "tags": [
              {
                "name": "Utility Functions"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Coherence Arguments"
              }
            ]
          },
          {
            "title": "A Semitechnical Introductory Dialogue on Solomonoff Induction",
            "tags": [
              {
                "name": "Solomonoff Induction"
              },
              {
                "name": "Occam's Razor"
              },
              {
                "name": "AI"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Dialogue (format)"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "96XzQgTL2HBNkBwL4",
    "title": "So You Want To Colonize The Universe",
    "curatedOrder": null,
    "contents": {
      "markdown": "A sequence of posts exploring how a distant civilization would colonize everything"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "So You Want to Colonize The Universe",
            "tags": [
              {
                "name": "Space Exploration & Colonization"
              },
              {
                "name": "Astronomy"
              }
            ]
          },
          {
            "title": "So You Want to Colonize the Universe Part 2: Deep Time Engineering",
            "tags": [
              {
                "name": "Space Exploration & Colonization"
              }
            ]
          },
          {
            "title": "So You Want To Colonize The Universe Part 3: Dust",
            "tags": [
              {
                "name": "Space Exploration & Colonization"
              }
            ]
          },
          {
            "title": "So You Want to Colonize The Universe Part 4: Velocity Changes and Energy",
            "tags": [
              {
                "name": "Space Exploration & Colonization"
              }
            ]
          },
          {
            "title": "So You Want to Colonize The Universe Part 5: The Actual Design",
            "tags": [
              {
                "name": "Space Exploration & Colonization"
              },
              {
                "name": "Identity"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "Yh4YsGDD9WYiZqRnf",
    "title": "Mechanism Design",
    "curatedOrder": null,
    "contents": {
      "markdown": "[Mechanism design](http://en.wikipedia.org/wiki/Mechanism_design) is the theory of how to construct institutions for strategic agents, spanning applications like voting systems, school admissions, regulation of monopolists, and auction design. Think of it as the engineering side of game theory, building algorithms for strategic agents.\n\nSequence by [badger](https://www.lesswrong.com/users/badger)."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "[Sequence announcement] Introduction to Mechanism Design",
            "tags": [
              {
                "name": "Mechanism Design"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Mechanism Design: Constructing Algorithms for Strategic Agents",
            "tags": [
              {
                "name": "Mechanism Design"
              },
              {
                "name": "Game Theory"
              }
            ]
          },
          {
            "title": "Incentive compatibility and the Revelation Principle",
            "tags": [
              {
                "name": "Mechanism Design"
              },
              {
                "name": "Incentives"
              }
            ]
          },
          {
            "title": "Strategyproof Mechanisms: Impossibilities",
            "tags": []
          },
          {
            "title": "Strategyproof Mechanisms: Possibilities",
            "tags": [
              {
                "name": "Mechanism Design"
              },
              {
                "name": "Voting Theory"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "9s8CgrX5C3AEw9ZM2",
    "title": "Decision Analysis",
    "curatedOrder": null,
    "contents": {
      "markdown": "An introduction to making decisions under uncertainly.\n\nSequence by [Vaniver](https://www.lesswrong.com/users/vaniver)."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Decision Analysis Sequence",
            "tags": [
              {
                "name": "Planning & Decision-Making"
              }
            ]
          },
          {
            "title": "5 Axioms of Decision Making",
            "tags": [
              {
                "name": "Planning & Decision-Making"
              },
              {
                "name": "Decision Theory"
              }
            ]
          },
          {
            "title": "Compressing Reality to Math",
            "tags": [
              {
                "name": "Planning & Decision-Making"
              },
              {
                "name": "Decision Theory"
              }
            ]
          },
          {
            "title": "Measures, Risk, Death, and War",
            "tags": [
              {
                "name": "Planning & Decision-Making"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Game Theory"
              }
            ]
          },
          {
            "title": "Value of Information: Four Examples",
            "tags": [
              {
                "name": "Value of Information"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Planning & Decision-Making"
              },
              {
                "name": "Careers"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "hs42Xd4joLcTP6uTb",
    "title": "Priming",
    "curatedOrder": null,
    "contents": {
      "markdown": "**Priming** is a psychological phenomenon that consists in early stimulus influencing later thoughts and behavior.\n\nBackground:\n\n*   [Anchoring and Adjustment](http://lesswrong.com/lw/j7/anchoring_and_adjustment/)\n*   [Priming and Contamination](http://lesswrong.com/lw/k3/priming_and_contamination/)\n\nSequence by [Scott Alexander](https://www.lesswrong.com/users/yvain), imported from the [wiki](https://wiki.lesswrong.com/wiki/Priming_and_Implicit_Association_(sequence)).\n\nSee also: [Seeing with Fresh Eyes](https://www.lesswrong.com/s/pmHZDpak4NeRLLLCw), [Affect Heuristic](https://wiki.lesswrong.com/wiki/Affect_heuristic), [Ugh Fields](https://wiki.lesswrong.com/wiki/Ugh_field), [Blue- and Yellow-Tinted Choices](https://www.lesswrong.com/posts/kjArXFinD3deRZNRu/blue-and-yellow-tinted-choices)."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Never Leave Your Room",
            "tags": [
              {
                "name": "Replication Crisis"
              },
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Priming"
              }
            ]
          },
          {
            "title": "Bogus Pipeline, Bona Fide Pipeline",
            "tags": [
              {
                "name": "Psychology"
              },
              {
                "name": "Empiricism"
              },
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Implicit Association Test (IAT)"
              },
              {
                "name": "Priming"
              }
            ]
          },
          {
            "title": "The Implicit Association Test",
            "tags": [
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Thingspace"
              },
              {
                "name": "Carving / Clustering Reality"
              },
              {
                "name": "Implicit Association Test (IAT)"
              },
              {
                "name": "Priming"
              }
            ]
          },
          {
            "title": "Fight Biases, or Route Around Them?",
            "tags": [
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Techniques"
              },
              {
                "name": "Priming"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "sdTckKmNM6zb7yGRt",
    "title": "Positivism and Self Deception",
    "curatedOrder": null,
    "contents": {
      "markdown": "Sequence by [Scott Alexander](https://www.lesswrong.com/users/yvain) on exactly what the title says. Imported from [the wiki](https://wiki.lesswrong.com/wiki/Positivism,_Self_Deception,_and_Neuroscience_(sequence)).\n\nSee also: [Priming](https://wiki.lesswrong.com/wiki/Priming), [The Science of Winning at Life](https://www.lesswrong.com/s/oi873FWi6pHWxswSa), [Alief](https://wiki.lesswrong.com/wiki/Alief), and [Connotation](https://wiki.lesswrong.com/wiki/Connotation)."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Simultaneously Right and Wrong",
            "tags": [
              {
                "name": "Self-Deception"
              },
              {
                "name": "Motivated Reasoning"
              },
              {
                "name": "Compartmentalization"
              }
            ]
          },
          {
            "title": "The Mystery of the Haunted Rationalist",
            "tags": [
              {
                "name": "Alief"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Compartmentalization"
              }
            ]
          },
          {
            "title": "The Apologist and the Revolutionary",
            "tags": [
              {
                "name": "Rationalization"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Psychiatry"
              }
            ]
          },
          {
            "title": "You May Already Be A Sinner",
            "tags": [
              {
                "name": "Decision Theory"
              },
              {
                "name": "Newcomb's Problem"
              },
              {
                "name": "Religion"
              }
            ]
          },
          {
            "title": "Talking Snakes: A Cautionary Tale",
            "tags": [
              {
                "name": "Updated Beliefs (examples of)"
              },
              {
                "name": "Fallacies"
              },
              {
                "name": "Religion"
              },
              {
                "name": "Absurdity Heuristic"
              }
            ]
          },
          {
            "title": "The Skeptic's Trilemma",
            "tags": [
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "History"
              },
              {
                "name": "Epistemology"
              }
            ]
          },
          {
            "title": "Are You a Solar Deity?",
            "tags": [
              {
                "name": "Religion"
              },
              {
                "name": "History"
              },
              {
                "name": "Narratives (stories)"
              }
            ]
          },
          {
            "title": "The \"Spot the Fakes\" Test",
            "tags": [
              {
                "name": "Replication Crisis"
              }
            ]
          },
          {
            "title": "How to Not Lose an Argument",
            "tags": [
              {
                "name": "Disagreement"
              },
              {
                "name": "Conversation (topic)"
              },
              {
                "name": "Tribalism"
              }
            ]
          },
          {
            "title": "The Power of Positivist Thinking",
            "tags": [
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "Anticipated Experiences"
              }
            ]
          },
          {
            "title": "When Truth Isn't Enough",
            "tags": [
              {
                "name": "Conversation (topic)"
              },
              {
                "name": "Signaling"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "vz9Zrj3oBGsttG3Jh",
    "title": "Kickstarter for Coordinated Action",
    "curatedOrder": null,
    "contents": {
      "markdown": "In [Inadequate Equilibria](https://www.lesswrong.com/s/oLGCcbnvabyibnG9d), the Visitor notes:\n\n> Coordination isn’t as simple as everyone jumping simultaneously every time one person shouts “Jump!” For coordinated action to be successful, you need to trust the institution that says what the action should be, and a m_ajority_ of people have to trust that institution, and they have to k_now_ that other people trust the institution, so that everyone e_xpects_ the coordinated action to occur at the critical time, so that it makes sense for them to act too.\n\n> That’s why we have policy prediction markets and… there doesn’t seem to be a word in your language for the t_imed-collective-action-threshold-conditional-commitment…h_old on, this cultural translator isn’t making any sense. “Kickstarter”? You have the key concept, but you use it mainly for making video games?\n\nShould there be a Kickstarter for Coordinated Action that isn't just for making video games? This series of questions and posts explores the details of that question."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Is there an assurance-contract website in work?",
            "tags": [
              {
                "name": "Quests / Projects Someone Should Do"
              },
              {
                "name": "Assurance contracts"
              }
            ]
          },
          {
            "title": "If a \"Kickstarter for Inadequate Equlibria\" was built, do you have a concrete inadequate equilibrium to fix?",
            "tags": [
              {
                "name": "Coordination / Cooperation"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Assurance contracts"
              }
            ]
          },
          {
            "title": "How could \"Kickstarter for Inadequate Equilibria\" be used for evil or turn out to be net-negative?",
            "tags": [
              {
                "name": "Coordination / Cooperation"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Assurance contracts"
              }
            ]
          },
          {
            "title": "Ideas for an action coordination website",
            "tags": [
              {
                "name": "World Optimization"
              },
              {
                "name": "Coordination / Cooperation"
              },
              {
                "name": "Software Tools"
              },
              {
                "name": "Commitment Mechanisms"
              },
              {
                "name": "Quests / Projects Someone Should Do"
              },
              {
                "name": "Assurance contracts"
              }
            ]
          },
          {
            "title": "Making a Crowdaction platform",
            "tags": [
              {
                "name": "Moloch"
              },
              {
                "name": "Commitment Mechanisms"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Slack"
              },
              {
                "name": "Assurance contracts"
              }
            ]
          },
          {
            "title": "Extracting Value from Inadequate Equilibria",
            "tags": [
              {
                "name": "World Optimization"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Assurance contracts"
              },
              {
                "name": "Commitment Mechanisms"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "YX6dCo6NSNQJDEwXR",
    "title": "Prediction-Driven Collaborative Reasoning Systems",
    "curatedOrder": null,
    "contents": {
      "markdown": "An exploration of Prediction-Driven Collaborative Reasoning Systems, or \"Predictive Reasoning Systems\" for short. This sequence is not strictly ordered. I recommend reading the first two posts for context, and the rest are independent (but similar in topic)"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "The Prediction Pyramid: Why Fundamental Work is Needed for Prediction Work",
            "tags": [
              {
                "name": "Forecasting & Prediction"
              }
            ]
          },
          {
            "title": "Predictive Reasoning Systems",
            "tags": [
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "Prediction Markets"
              },
              {
                "name": "Systems Thinking"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Prediction-Augmented Evaluation Systems",
            "tags": [
              {
                "name": "Mechanism Design"
              },
              {
                "name": "Prediction Markets"
              }
            ]
          },
          {
            "title": "What if people simply forecasted your future choices?",
            "tags": []
          },
          {
            "title": "Can We Place Trust in Post-AGI Forecasting Evaluations?",
            "tags": []
          },
          {
            "title": "Ideas for Next Generation Prediction Technologies",
            "tags": [
              {
                "name": "Forecasting & Prediction"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "59wjNdSYeakrjuubu",
    "title": "Assorted Maths",
    "curatedOrder": null,
    "contents": {
      "markdown": "A set of explanations of mathematical concepts."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Propositional Logic, Syntactic Implication",
            "tags": []
          }
        ]
      }
    ]
  },
  {
    "_id": "pKxyvLyhEFxHgogdD",
    "title": "A Hazardous Guide To Rationality",
    "curatedOrder": null,
    "contents": {
      "markdown": "The Sequences really are quality, but I can't always get my friends to read them. This sequence is going to be my own take on rationality. I won't be trying to copy the form or pattern of The Sequences, but given how much of my rationality it's the backing of and how good it is, many parts of this will be, \"Hazard rehashing a chunk of The Sequences\".\n\nStructure + Involvement Guidelines\n==================================\n\nI will be tossing up posts and outlines as I think of ideas. The plan is \"perpetual draft\" style. I will make specific \"STRUCTURE\" posts, which contain current plan for the structure and order of posts to come. I will keep structure posts separate from content posts, that way comments on structure posts can focus on structure, order, and prioritization of ideas, and content post comments can focus on the ideas themselves.\n\nIt's conceivable that if there's a lot of structure posts, and lots of good discussion there, and the content of the sequence actually shapes up to something cool, I'll make a separate sequence that stores all of the \"construction\" of the actual sequence. That way you can see of it got to now, but you engagement isn't cluttered with said history.\n\nGoals of this sequence\n======================\n\n*   Help me clarify my own understanding of what I think are some of the core/most useful ideas in rationality sphere.\n*   For my friends who I don't think will actually read the Sequences (but they should), have something shorter I can link them to that I think will give a Minimum Effective Dose of rationality (or at least make them interested enough to investigate more on their own).\n\n*   I'll be actively engaging several of them for feedback, and asking them questions about what makes the least sense, so I can have very specific people an inferential gaps in mind when writing this.\n\n*   Let me experiment with writing in perpetual draft mode. I've given the idea lip service, now it's time to try it.\n*   If there's much engagement from the LW commentariat, I'd love to actually incorporate other peoples feedback (ideas on what's important, common pitfalls, things that confused you in the past, concrete examples from your life).\n*   Be a not super controversial Rationality 101, so please, let me know what you think are the boldest assumption, inferential jumps, or claims I'm making.\n\n  \n\nRevision History\n================\n\nV0\n\n*   Split into three parts\n\n*   \"Here's a bunch of stuff about how you mind works that makes it hard to get to the truth\"\n*   \"Here's a bunch of stuff about how minds work given that they developed alongside dealing with other minds (that makes it hard to get to the truth)\"\n*   \"Here's actual rationality\"\n\n*   Thoughts on draft style\n\n*   Yikes, this was done fast.\n*   I will _definitely_ want to rethink the structure and order of things.\n\n*   TODO\n\n*   Add a \"oh, this is why you would even bother with these ideas (hint, you could become a Bayesian wizard)\"\n\n  \n\nV1\n\n*   Made \"structure\" vs \"content\" distinction\n\n*   Made that change more evident on current structure posts\n\n*   added \"why rationality?\"\n\nV2 (6-30-19)\n\n*   Added a rough draft of the \"Hazardous Guide to Words\" mini sequence"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Rationality: What's the point?",
            "tags": []
          },
          {
            "title": "STRUCTURE: A Hazardous Guide to Words",
            "tags": []
          },
          {
            "title": "Prereq: Cognitive Fusion",
            "tags": [
              {
                "name": "Cognitive Fusion"
              }
            ]
          },
          {
            "title": "Prereq: Question Substitution",
            "tags": []
          },
          {
            "title": "Where is the Meaning?",
            "tags": [
              {
                "name": "Truth, Semantics, & Meaning"
              },
              {
                "name": "Philosophy of Language"
              }
            ]
          },
          {
            "title": "Splitting Concepts",
            "tags": []
          },
          {
            "title": "Decisions are hard, words feel easier",
            "tags": []
          },
          {
            "title": "Arguing Definitions",
            "tags": []
          },
          {
            "title": "Defending points you don't care about",
            "tags": [
              {
                "name": "Bucket Errors"
              },
              {
                "name": "Conversation (topic)"
              },
              {
                "name": "Philosophy of Language"
              }
            ]
          },
          {
            "title": "Words Aren't Type Safe",
            "tags": [
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Computer Science"
              }
            ]
          },
          {
            "title": "STRUCTURE: A Crash Course in Your Brain",
            "tags": []
          },
          {
            "title": "STRUCTURE: How the Social Affects your rationality",
            "tags": []
          },
          {
            "title": "STRUCTURE: Reality and rational best practice",
            "tags": [
              {
                "name": "Valley of Bad Rationality"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "ZbmRyDN8TCpBTZSip",
    "title": "Multiagent Models of Mind",
    "curatedOrder": null,
    "contents": {
      "markdown": "A sequence of posts which tries to break down the functioning of the brain into a number of subsystems, communicating in part through the global neuronal workspace of consciousness."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "Sequence introduction: non-agent and multiagent models of mind",
            "tags": [
              {
                "name": "Subagents"
              }
            ]
          },
          {
            "title": "Book Summary: Consciousness and the Brain",
            "tags": [
              {
                "name": "Consciousness"
              },
              {
                "name": "Book Reviews"
              },
              {
                "name": "Subagents"
              },
              {
                "name": "Neuroscience"
              },
              {
                "name": "Summaries"
              },
              {
                "name": "Working Memory"
              }
            ]
          },
          {
            "title": "Building up to an Internal Family Systems model",
            "tags": [
              {
                "name": "Motivations"
              },
              {
                "name": "Subagents"
              },
              {
                "name": "Emotions"
              },
              {
                "name": "Therapy"
              },
              {
                "name": "Internal Family Systems"
              }
            ]
          },
          {
            "title": "Subagents, introspective awareness, and blending",
            "tags": [
              {
                "name": "Consciousness"
              },
              {
                "name": "Subagents"
              },
              {
                "name": "Meditation"
              },
              {
                "name": "Internal Family Systems"
              },
              {
                "name": "Cognitive Fusion"
              }
            ]
          },
          {
            "title": "Subagents, akrasia, and coherence in humans",
            "tags": [
              {
                "name": "Akrasia"
              },
              {
                "name": "Robust Agents"
              },
              {
                "name": "Subagents"
              },
              {
                "name": "Cached Thoughts"
              },
              {
                "name": "Slack"
              },
              {
                "name": "Internal Family Systems"
              }
            ]
          },
          {
            "title": "Integrating disagreeing subagents",
            "tags": [
              {
                "name": "Akrasia"
              },
              {
                "name": "Subagents"
              },
              {
                "name": "Internal Double Crux"
              },
              {
                "name": "Memory Reconsolidation"
              },
              {
                "name": "Therapy"
              },
              {
                "name": "Internal Alignment (Human)"
              },
              {
                "name": "Internal Family Systems"
              }
            ]
          },
          {
            "title": "Subagents, neural Turing machines, thought selection, and blindspots",
            "tags": [
              {
                "name": "Consciousness"
              },
              {
                "name": "Subagents"
              },
              {
                "name": "Neuroscience"
              }
            ]
          },
          {
            "title": "Subagents, trauma and rationality",
            "tags": [
              {
                "name": "Subagents"
              },
              {
                "name": "Emotions"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Aversion"
              }
            ]
          },
          {
            "title": "System 2 as working-memory augmented System 1 reasoning",
            "tags": [
              {
                "name": "Subagents"
              },
              {
                "name": "Dual Process Theory (System 1 & System 2)"
              }
            ]
          },
          {
            "title": "Book summary: Unlocking the Emotional Brain",
            "tags": [
              {
                "name": "Book Reviews"
              },
              {
                "name": "Subagents"
              },
              {
                "name": "Emotions"
              },
              {
                "name": "Neuroscience"
              },
              {
                "name": "Internal Double Crux"
              },
              {
                "name": "Alief"
              },
              {
                "name": "Motivations"
              },
              {
                "name": "Summaries"
              },
              {
                "name": "Memory Reconsolidation"
              },
              {
                "name": "Cached Thoughts"
              },
              {
                "name": "Therapy"
              },
              {
                "name": "Internal Family Systems"
              }
            ]
          },
          {
            "title": "A mechanistic model of meditation",
            "tags": [
              {
                "name": "Meditation"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Subagents"
              },
              {
                "name": "Attention"
              }
            ]
          },
          {
            "title": "A non-mystical explanation of insight meditation and the three characteristics of existence: introduction and preamble",
            "tags": [
              {
                "name": "Meditation"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Subagents"
              },
              {
                "name": "Consciousness"
              }
            ]
          },
          {
            "title": "A non-mystical explanation of \"no-self\" (three characteristics series)",
            "tags": [
              {
                "name": "Meditation"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Subagents"
              },
              {
                "name": "Identity"
              },
              {
                "name": "Personal Identity"
              },
              {
                "name": "Buddhism"
              }
            ]
          },
          {
            "title": "Craving, suffering, and predictive processing (three characteristics series)",
            "tags": [
              {
                "name": "Meditation"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Motivations"
              },
              {
                "name": "Motivated Reasoning"
              },
              {
                "name": "Subagents"
              },
              {
                "name": "Predictive Processing"
              },
              {
                "name": "Suffering"
              }
            ]
          },
          {
            "title": "From self to craving (three characteristics series)",
            "tags": [
              {
                "name": "Meditation"
              },
              {
                "name": "Motivations"
              },
              {
                "name": "Subagents"
              },
              {
                "name": "Suffering"
              },
              {
                "name": "Personal Identity"
              }
            ]
          },
          {
            "title": "On the construction of the self",
            "tags": [
              {
                "name": "Meditation"
              },
              {
                "name": "Consciousness"
              },
              {
                "name": "Identity"
              },
              {
                "name": "Subagents"
              },
              {
                "name": "Personal Identity"
              }
            ]
          },
          {
            "title": "Three characteristics: impermanence",
            "tags": [
              {
                "name": "Meditation"
              },
              {
                "name": "Consciousness"
              },
              {
                "name": "Subagents"
              },
              {
                "name": "Predictive Processing"
              }
            ]
          },
          {
            "title": "Beliefs as emotional strategies",
            "tags": [
              {
                "name": "Alief"
              },
              {
                "name": "Motivations"
              },
              {
                "name": "Motivated Reasoning"
              },
              {
                "name": "Free Will"
              },
              {
                "name": "Memory Reconsolidation"
              }
            ]
          },
          {
            "title": "My current take on Internal Family Systems “parts”",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Internal Family Systems"
              },
              {
                "name": "Subagents"
              },
              {
                "name": "Practical"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "yai5mppkuCHPQmzpN",
    "title": "Open Threads",
    "curatedOrder": null,
    "contents": {
      "markdown": "Each month, LessWrong hosts an Open Thread for low-key conversation.\n\nNOTE: this sequence has been deprecated in favor of the [Open Threads tag](https://www.lesswrong.com/tag/open-threads)."
    },
    "chapters": [
      {
        "title": "2020",
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Open & Welcome Thread - July 2020",
            "tags": [
              {
                "name": "Community"
              },
              {
                "name": "Open Threads"
              }
            ]
          },
          {
            "title": "Open & Welcome Thread - June 2020",
            "tags": [
              {
                "name": "Community"
              },
              {
                "name": "Open Threads"
              }
            ]
          },
          {
            "title": "Open & Welcome Thread—May 2020",
            "tags": [
              {
                "name": "Community"
              },
              {
                "name": "Open Threads"
              }
            ]
          },
          {
            "title": "Open & Welcome Thread - March 2020",
            "tags": [
              {
                "name": "Open Threads"
              }
            ]
          },
          {
            "title": "Open & Welcome Thread - February 2020",
            "tags": [
              {
                "name": "Open Threads"
              }
            ]
          },
          {
            "title": "Open & Welcome Thread - January 2020",
            "tags": [
              {
                "name": "Open Threads"
              }
            ]
          }
        ]
      },
      {
        "title": "2019",
        "subtitle": null,
        "number": 1,
        "contents": null,
        "posts": [
          {
            "title": "Open & Welcome Thread - December 2019",
            "tags": [
              {
                "name": "Open Threads"
              }
            ]
          },
          {
            "title": "Open & Welcome Thread - November 2019",
            "tags": [
              {
                "name": "Open Threads"
              }
            ]
          },
          {
            "title": "Open & Welcome Thread - October 2019",
            "tags": [
              {
                "name": "Open Threads"
              }
            ]
          },
          {
            "title": "Open & Welcome Thread - September 2019",
            "tags": [
              {
                "name": "Open Threads"
              }
            ]
          },
          {
            "title": "Open & Welcome Thread - August 2019",
            "tags": [
              {
                "name": "Open Threads"
              }
            ]
          },
          {
            "title": "Open Thread July 2019",
            "tags": [
              {
                "name": "Open Threads"
              }
            ]
          },
          {
            "title": "Welcome and Open Thread June 2019",
            "tags": [
              {
                "name": "Open Threads"
              }
            ]
          },
          {
            "title": "Open Thread May 2019",
            "tags": [
              {
                "name": "Open Threads"
              }
            ]
          },
          {
            "title": "Open Thread April 2019",
            "tags": [
              {
                "name": "Open Threads"
              }
            ]
          },
          {
            "title": "Open Thread March 2019",
            "tags": [
              {
                "name": "Open Threads"
              }
            ]
          },
          {
            "title": "Open Thread February 2019",
            "tags": [
              {
                "name": "Open Threads"
              }
            ]
          },
          {
            "title": "Open Thread January 2019",
            "tags": [
              {
                "name": "Open Threads"
              }
            ]
          }
        ]
      },
      {
        "title": "2018",
        "subtitle": null,
        "number": 2,
        "contents": null,
        "posts": [
          {
            "title": "Open and Welcome Thread December 2018",
            "tags": [
              {
                "name": "Open Threads"
              },
              {
                "name": "Welcome Threads"
              }
            ]
          },
          {
            "title": "Open Thread November 2018",
            "tags": [
              {
                "name": "Open Threads"
              }
            ]
          },
          {
            "title": "Open Thread September 2018",
            "tags": [
              {
                "name": "Open Threads"
              }
            ]
          },
          {
            "title": "Open Thread August 2018",
            "tags": [
              {
                "name": "Open Threads"
              }
            ]
          },
          {
            "title": "Open Thread July 2018",
            "tags": [
              {
                "name": "Open Threads"
              }
            ]
          },
          {
            "title": "Open Thread June 2018",
            "tags": [
              {
                "name": "Open Threads"
              }
            ]
          },
          {
            "title": "Open Thread May 2018",
            "tags": [
              {
                "name": "Open Threads"
              }
            ]
          },
          {
            "title": "Open Thread April 2018",
            "tags": [
              {
                "name": "Open Threads"
              }
            ]
          },
          {
            "title": "Open thread, February 2018",
            "tags": [
              {
                "name": "Open Threads"
              }
            ]
          },
          {
            "title": "Open Thread - January 2018",
            "tags": [
              {
                "name": "Open Threads"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "n44Fqx5W4BhMugCMS",
    "title": "Keith Stanovich: What Intelligence Tests Miss",
    "curatedOrder": null,
    "contents": {
      "markdown": "A summary of some of the main ideas in Keith Stanovich's book _[What Intelligence Tests Miss: The Psychology of Rational Thought](https://www.amazon.com/What-Intelligence-Tests-Miss-Psychology/dp/030012385X)._ The book discusses a number of concepts related to LW, taking the perspective of biases as a thing that prevent people from taking full advantage of their intelligence."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "What Cost for Irrationality?",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Case Study"
              }
            ]
          },
          {
            "title": "A Taxonomy of Bias: The Cognitive Miser",
            "tags": [
              {
                "name": "Summaries"
              },
              {
                "name": "Cognitive Science"
              },
              {
                "name": "Dual Process Theory (System 1 & System 2)"
              },
              {
                "name": "Heuristics & Biases"
              }
            ]
          },
          {
            "title": "A Taxonomy of Bias: Mindware Problems",
            "tags": []
          },
          {
            "title": "What Intelligence Tests Miss: The psychology of rational thought",
            "tags": [
              {
                "name": "IQ and g-factor"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "General Intelligence"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "qaDH2Fq8Qm87npmpg",
    "title": "INVESTIGATIONS INTO INFINITY",
    "curatedOrder": null,
    "contents": {
      "markdown": "This sequence will investigate infinities with the goal of understanding infinite ethics, but along the way it will delve into the nature of infinity more generally."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Summary: Surreal Decisions",
            "tags": [
              {
                "name": "Infinity"
              },
              {
                "name": "Academic Papers"
              },
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "Infinities In Ethics"
              }
            ]
          },
          {
            "title": "An Extensive Categorisation of Infinite Paradoxes",
            "tags": []
          }
        ]
      }
    ]
  },
  {
    "_id": "uLEjM2ij5y3CXXW6c",
    "title": "Filtered Evidence, Filtered Arguments",
    "curatedOrder": null,
    "contents": {
      "markdown": "This is a collection of posts relating to central confusions I have, or have had, about:\n\n*   Filtered evidence.\n*   Conservation of expected evidence.\n*   Outside view vs inside view.\n*   Motivated cognition."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Mistakes with Conservation of Expected Evidence",
            "tags": [
              {
                "name": "Conservation of Expected Evidence"
              },
              {
                "name": "Hansonian Pre-Rationality"
              },
              {
                "name": "Pitfalls of Rationality"
              },
              {
                "name": "Rationalization"
              },
              {
                "name": "Inside/Outside View"
              },
              {
                "name": "Humility"
              },
              {
                "name": "Anthropics"
              }
            ]
          },
          {
            "title": "Explanation vs Rationalization",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Rationalization"
              },
              {
                "name": "Conservation of Expected Evidence"
              },
              {
                "name": "Conversation (topic)"
              },
              {
                "name": "Gears-Level"
              },
              {
                "name": "Distinctions"
              }
            ]
          },
          {
            "title": "Timeless Modesty?",
            "tags": [
              {
                "name": "Inside/Outside View"
              },
              {
                "name": "Humility"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Epistemology"
              },
              {
                "name": "Gears-Level"
              },
              {
                "name": "Modest Epistemology"
              }
            ]
          },
          {
            "title": "Co-Proofs",
            "tags": [
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "Conservation of Expected Evidence"
              },
              {
                "name": "Probability & Statistics"
              }
            ]
          },
          {
            "title": "Thinking About Filtered Evidence Is (Very!) Hard",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Filtered Evidence"
              }
            ]
          },
          {
            "title": "Subtle Forms of Confirmation Bias",
            "tags": [
              {
                "name": "Confirmation Bias"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Gears Level & Policy Level",
            "tags": [
              {
                "name": "Gears-Level"
              },
              {
                "name": "Inside/Outside View"
              },
              {
                "name": "Distinctions"
              }
            ]
          },
          {
            "title": "Placing Yourself as an Instance of a Class",
            "tags": [
              {
                "name": "Inside/Outside View"
              },
              {
                "name": "Calibration"
              },
              {
                "name": "Humility"
              }
            ]
          },
          {
            "title": "The Problematic Third Person Perspective",
            "tags": [
              {
                "name": "Inside/Outside View"
              },
              {
                "name": "Epistemology"
              },
              {
                "name": "Conversation (topic)"
              }
            ]
          },
          {
            "title": "Confusions Concerning Pre-Rationality",
            "tags": [
              {
                "name": "Hansonian Pre-Rationality"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "fgHSwxFitysGKHH56",
    "title": "CDT=EDT?",
    "curatedOrder": null,
    "contents": {
      "markdown": "Mid-2017, I started to examine my reasons for thinking causality is a necessary ingredient in decision theory. I found grounds to reject all the arguments which had previously seemed to speak in favor of CDT, while at the same time, finding that EDT didn't always do what people claimed it did in problems like Newcomb. I began to develop arguments that CDT and EDT were, in the cases which (I claimed) should be of primary interest, the same decision theory."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Smoking Lesion Steelman",
            "tags": []
          },
          {
            "title": "Smoking Lesion Steelman II",
            "tags": []
          },
          {
            "title": "Smoking Lesion Steelman III: Revenge of the Tickle Defense",
            "tags": []
          },
          {
            "title": "Comparing LICDT and LIEDT",
            "tags": []
          },
          {
            "title": "\tMixed-Strategy Ratifiability Implies CDT=EDT",
            "tags": [
              {
                "name": "Decision Theory"
              }
            ]
          },
          {
            "title": "XOR Blackmail & Causality",
            "tags": []
          },
          {
            "title": "A Rationality Condition for CDT Is That It Equal EDT (Part 1)",
            "tags": [
              {
                "name": "Decision Theory"
              }
            ]
          },
          {
            "title": "A Rationality Condition for CDT Is That It Equal EDT (Part 2)",
            "tags": []
          },
          {
            "title": "Dutch-Booking CDT",
            "tags": [
              {
                "name": "Decision Theory"
              }
            ]
          },
          {
            "title": "CDT=EDT=UDT",
            "tags": [
              {
                "name": "Decision Theory"
              }
            ]
          },
          {
            "title": "Troll Bridge",
            "tags": [
              {
                "name": "Decision Theory"
              },
              {
                "name": "Embedded Agency"
              }
            ]
          },
          {
            "title": "Dutch-Booking CDT: Revised Argument",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Decision Theory"
              }
            ]
          },
          {
            "title": "My Current Take on Counterfactuals",
            "tags": [
              {
                "name": "Decision Theory"
              },
              {
                "name": "Counterfactuals"
              },
              {
                "name": "AI"
              },
              {
                "name": "Rationality"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "5WF3wmwvxX9TEbFXf",
    "title": "Fixed Points",
    "curatedOrder": null,
    "contents": {
      "markdown": "This is a sequence on Fixed Point Theorems, that includes ~30 exercises and examples of them being used in Agent Foundations research."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Fixed Point Exercises",
            "tags": [
              {
                "name": "Fixed Point Theorems"
              },
              {
                "name": "Exercises / Problem-Sets"
              }
            ]
          }
        ]
      },
      {
        "title": "Discussion",
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Fixed Point Discussion",
            "tags": [
              {
                "name": "Fixed Point Theorems"
              }
            ]
          }
        ]
      },
      {
        "title": "Exercises",
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Topological Fixed Point Exercises",
            "tags": [
              {
                "name": "Exercises / Problem-Sets"
              },
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "Fixed Point Theorems"
              }
            ]
          },
          {
            "title": "Diagonalization Fixed Point Exercises",
            "tags": [
              {
                "name": "Fixed Point Theorems"
              }
            ]
          },
          {
            "title": "Iteration Fixed Point Exercises",
            "tags": [
              {
                "name": "Fixed Point Theorems"
              }
            ]
          }
        ]
      },
      {
        "title": "Example Research Using Fixed Points",
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Hyperreal Brouwer",
            "tags": [
              {
                "name": "Game Theory"
              }
            ]
          },
          {
            "title": "Formal Open Problem in Decision Theory",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Game Theory"
              }
            ]
          },
          {
            "title": "The Ubiquitous Converse Lawvere Problem",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Game Theory"
              }
            ]
          },
          {
            "title": "Reflective oracles as a solution to the converse Lawvere problem",
            "tags": [
              {
                "name": "Oracle AI"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "W2fkmatEzyrmbbrDt",
    "title": "Metaethics",
    "curatedOrder": null,
    "contents": {
      "markdown": "Posts about metaethics from between June and August 2008.\n\nSequence by [Eliezer Yudkowsky](https://www.lesswrong.com/users/eliezer_yudkowsky), imported from [the wiki](https://wiki.lesswrong.com/wiki/Metaethics_sequence). Overlaps with [Value Theory](https://www.lesswrong.com/s/9bvAELWc8y2gYjRav) and [Seeing with Fresh Eyes](https://www.lesswrong.com/s/pmHZDpak4NeRLLLCw)."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Heading Toward Morality",
            "tags": [
              {
                "name": "Ethics & Morality"
              }
            ]
          },
          {
            "title": "No Universally Compelling Arguments",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Metaethics"
              }
            ]
          },
          {
            "title": "2-Place and 1-Place Words",
            "tags": [
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Mind Projection Fallacy"
              },
              {
                "name": "Map and Territory"
              }
            ]
          },
          {
            "title": "What Would You Do Without Morality?",
            "tags": [
              {
                "name": "Ethics & Morality"
              }
            ]
          },
          {
            "title": "The Moral Void",
            "tags": [
              {
                "name": "Metaethics"
              },
              {
                "name": "Ethics & Morality"
              }
            ]
          },
          {
            "title": "Created Already In Motion",
            "tags": [
              {
                "name": "Metaethics"
              }
            ]
          },
          {
            "title": "The Bedrock of Fairness",
            "tags": [
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Dialogue (format)"
              },
              {
                "name": "Metaethics"
              },
              {
                "name": "Fairness"
              }
            ]
          },
          {
            "title": "Moral Complexities",
            "tags": [
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "Metaethics"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Is Morality Preference?",
            "tags": [
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "Dialogue (format)"
              }
            ]
          },
          {
            "title": "Is Morality Given?",
            "tags": [
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "Metaethics"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Dialogue (format)"
              },
              {
                "name": "Adaptation Executors"
              }
            ]
          },
          {
            "title": "Where Recursive Justification Hits Bottom",
            "tags": [
              {
                "name": "Epistemology"
              },
              {
                "name": "Occam's Razor"
              },
              {
                "name": "Philosophy"
              },
              {
                "name": "Reflective Reasoning"
              },
              {
                "name": "The Problem of the Criterion"
              }
            ]
          },
          {
            "title": "My Kind of Reflection",
            "tags": [
              {
                "name": "Reflective Reasoning"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "The Genetic Fallacy",
            "tags": [
              {
                "name": "Fallacies"
              },
              {
                "name": "Rationalization"
              }
            ]
          },
          {
            "title": "Fundamental Doubts",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Epistemology"
              }
            ]
          },
          {
            "title": "Rebelling Within Nature",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "Evolutionary Psychology"
              }
            ]
          },
          {
            "title": "Probability is Subjectively Objective",
            "tags": [
              {
                "name": "Probability & Statistics"
              },
              {
                "name": "Bayes' Theorem"
              },
              {
                "name": "Bayesianism"
              }
            ]
          },
          {
            "title": "Whither Moral Progress?",
            "tags": [
              {
                "name": "Moral Uncertainty"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Metaethics"
              }
            ]
          },
          {
            "title": "The Gift We Give To Tomorrow",
            "tags": [
              {
                "name": "Evolutionary Psychology"
              },
              {
                "name": "Complexity of Value"
              },
              {
                "name": "Human Values"
              }
            ]
          },
          {
            "title": "Could Anything Be Right?",
            "tags": [
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "Metaethics"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Existential Angst Factory",
            "tags": [
              {
                "name": "Rationalization"
              },
              {
                "name": "Metaethics"
              },
              {
                "name": "Emotions"
              }
            ]
          },
          {
            "title": "Can Counterfactuals Be True?",
            "tags": [
              {
                "name": "Counterfactuals"
              }
            ]
          },
          {
            "title": "Math is Subjunctively Objective",
            "tags": [
              {
                "name": "Dialogue (format)"
              },
              {
                "name": "Truth, Semantics, & Meaning"
              }
            ]
          },
          {
            "title": "Does Your Morality Care What You Think?",
            "tags": [
              {
                "name": "Ethics & Morality"
              }
            ]
          },
          {
            "title": "Changing Your Metaethics",
            "tags": [
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "Metaethics"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Adding Up to Normality"
              }
            ]
          },
          {
            "title": "Setting Up Metaethics",
            "tags": [
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "Metaethics"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "The Meaning of Right",
            "tags": [
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "Metaethics"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Interpersonal Morality",
            "tags": [
              {
                "name": "Ethics & Morality"
              }
            ]
          },
          {
            "title": "Morality as Fixed Computation",
            "tags": [
              {
                "name": "Ethics & Morality"
              }
            ]
          },
          {
            "title": "Inseparably Right; or, Joy in the Merely Good",
            "tags": [
              {
                "name": "Metaethics"
              },
              {
                "name": "Ethics & Morality"
              }
            ]
          },
          {
            "title": "Sorting Pebbles Into Correct Heaps",
            "tags": [
              {
                "name": "Orthogonality Thesis"
              },
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Moral Error and Moral Disagreement",
            "tags": [
              {
                "name": "Metaethics"
              }
            ]
          },
          {
            "title": "Abstracted Idealized Dynamics",
            "tags": [
              {
                "name": "Ethics & Morality"
              }
            ]
          },
          {
            "title": "\"Arbitrary\"",
            "tags": [
              {
                "name": "Truth, Semantics, & Meaning"
              },
              {
                "name": "Philosophy of Language"
              }
            ]
          },
          {
            "title": "Is Fairness Arbitrary?",
            "tags": [
              {
                "name": "Metaethics"
              },
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Fairness"
              }
            ]
          },
          {
            "title": "The Bedrock of Morality: Arbitrary?",
            "tags": [
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "Fairness"
              }
            ]
          },
          {
            "title": "You Provably Can't Trust Yourself",
            "tags": [
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "Metaethics"
              },
              {
                "name": "Gödelian Logic"
              }
            ]
          },
          {
            "title": "No License To Be Human",
            "tags": [
              {
                "name": "Reflective Reasoning"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Invisible Frameworks",
            "tags": [
              {
                "name": "Human Values"
              },
              {
                "name": "Moral Uncertainty"
              },
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "Metaethics"
              },
              {
                "name": "Community"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "World Optimization"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "4dHMdK5TLN6xcqtyc",
    "title": "Value Learning",
    "curatedOrder": 2,
    "contents": {
      "markdown": "This is a sequence investigating the feasibility of one approach to AI alignment: value learning."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Preface to the sequence on value learning",
            "tags": [
              {
                "name": "Value Learning"
              }
            ]
          }
        ]
      },
      {
        "title": "Ambitious Value Learning",
        "subtitle": null,
        "number": 1,
        "contents": null,
        "posts": [
          {
            "title": "What is ambitious value learning?",
            "tags": [
              {
                "name": "Value Learning"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "The easy goal inference problem is still hard",
            "tags": [
              {
                "name": "Value Learning"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Humans can be assigned any values whatsoever…",
            "tags": [
              {
                "name": "Value Learning"
              },
              {
                "name": "Kolmogorov Complexity"
              }
            ]
          },
          {
            "title": "Latent Variables and Model Mis-Specification",
            "tags": [
              {
                "name": "Value Learning"
              },
              {
                "name": "Probability & Statistics"
              }
            ]
          },
          {
            "title": "Model Mis-specification and Inverse Reinforcement Learning",
            "tags": [
              {
                "name": "Value Learning"
              },
              {
                "name": "Inverse Reinforcement Learning"
              },
              {
                "name": "Reinforcement Learning"
              }
            ]
          },
          {
            "title": "Future directions for ambitious value learning",
            "tags": [
              {
                "name": "Value Learning"
              }
            ]
          }
        ]
      },
      {
        "title": "Goals vs Utility Functions",
        "subtitle": null,
        "number": 2,
        "contents": {
          "markdown": "Ambitious value learning aims to give the AI the correct utility function to avoid catastrophe. Given its difficulty, we revisit the arguments for utility functions in the first place."
        },
        "posts": [
          {
            "title": "Intuitions about goal-directed behavior",
            "tags": [
              {
                "name": "Value Learning"
              },
              {
                "name": "AI Risk"
              },
              {
                "name": "Goal-Directedness"
              }
            ]
          },
          {
            "title": "Coherence arguments do not entail goal-directed behavior",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Utility Functions"
              },
              {
                "name": "Value Learning"
              },
              {
                "name": "Goal-Directedness"
              },
              {
                "name": "Coherence Arguments"
              }
            ]
          },
          {
            "title": "Will humans build goal-directed agents?",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Goal-Directedness"
              }
            ]
          },
          {
            "title": "AI safety without goal-directed behavior",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Goal-Directedness"
              }
            ]
          }
        ]
      },
      {
        "title": "Narrow Value Learning",
        "subtitle": null,
        "number": 3,
        "contents": null,
        "posts": [
          {
            "title": "What is narrow value learning?",
            "tags": [
              {
                "name": "Value Learning"
              }
            ]
          },
          {
            "title": "Ambitious vs. narrow value learning",
            "tags": [
              {
                "name": "Value Learning"
              }
            ]
          },
          {
            "title": "Human-AI Interaction",
            "tags": [
              {
                "name": "Value Learning"
              }
            ]
          },
          {
            "title": "Reward uncertainty",
            "tags": [
              {
                "name": "Value Learning"
              }
            ]
          },
          {
            "title": "The human side of interaction",
            "tags": []
          },
          {
            "title": "Following human norms",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Value Learning"
              }
            ]
          },
          {
            "title": "Future directions for narrow value learning",
            "tags": [
              {
                "name": "Value Learning"
              }
            ]
          },
          {
            "title": "Conclusion to the sequence on value learning",
            "tags": [
              {
                "name": "Value Learning"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "Rm6oQRJJmhGCcLvxh",
    "title": "Embedded Agency",
    "curatedOrder": 495,
    "contents": {
      "markdown": "This is a sequence by Scott Garrabrant and Abram Demski on one current way of thinking about alignment: Embedded Agency."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Embedded Agents",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Research Agendas"
              },
              {
                "name": "Embedded Agency"
              }
            ]
          },
          {
            "title": "Decision Theory",
            "tags": [
              {
                "name": "Decision Theory"
              },
              {
                "name": "AI"
              },
              {
                "name": "Research Agendas"
              },
              {
                "name": "Embedded Agency"
              }
            ]
          },
          {
            "title": "Embedded World-Models",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Research Agendas"
              },
              {
                "name": "Embedded Agency"
              }
            ]
          },
          {
            "title": "Robust Delegation",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Research Agendas"
              },
              {
                "name": "Goodhart's Law"
              },
              {
                "name": "Value Learning"
              },
              {
                "name": "Robust Agents"
              },
              {
                "name": "Embedded Agency"
              },
              {
                "name": "The Pointers Problem"
              }
            ]
          },
          {
            "title": "Subsystem Alignment",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Research Agendas"
              },
              {
                "name": "Mesa-Optimization"
              },
              {
                "name": "Embedded Agency"
              }
            ]
          },
          {
            "title": "Embedded Curiosities",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Research Agendas"
              },
              {
                "name": "Embedded Agency"
              }
            ]
          }
        ]
      },
      {
        "title": "Full-Text Version",
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Embedded Agency (full-text version)",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Research Agendas"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Mesa-Optimization"
              },
              {
                "name": "Robust Agents"
              },
              {
                "name": "Goodhart's Law"
              },
              {
                "name": "Subagents"
              },
              {
                "name": "Embedded Agency"
              },
              {
                "name": "Spurious Counterfactuals"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "EmDuGeRw749sD3GKd",
    "title": "Iterated Amplification",
    "curatedOrder": 3,
    "contents": {
      "markdown": "This is a sequence curated by Paul Christiano on one current approach to alignment: Iterated Amplification."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": -1,
        "contents": null,
        "posts": [
          {
            "title": "Preface to the sequence on iterated amplification",
            "tags": [
              {
                "name": "Iterated Amplification "
              }
            ]
          }
        ]
      },
      {
        "title": "Problem statement",
        "subtitle": null,
        "number": 0,
        "contents": {
          "markdown": "The first part of this sequence clarifies the problem that iterated amplification is trying to solve, which is both narrower and broader than you might expect."
        },
        "posts": [
          {
            "title": "The Steering Problem",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Outer Alignment"
              }
            ]
          },
          {
            "title": "Clarifying \"AI Alignment\"",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Value Learning"
              }
            ]
          },
          {
            "title": "An unaligned benchmark",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "AI Risk"
              }
            ]
          },
          {
            "title": "Prosaic AI alignment",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Machine Learning  (ML)"
              }
            ]
          }
        ]
      },
      {
        "title": "Basic intuition",
        "subtitle": null,
        "number": 1,
        "contents": {
          "markdown": "The second part of the sequence outlines the basic intuitions that motivate iterated amplification. I think that these intuitions may be more important than the scheme itself, but they are considerably more informal."
        },
        "posts": [
          {
            "title": "Approval-directed agents",
            "tags": [
              {
                "name": "Iterated Amplification "
              }
            ]
          },
          {
            "title": "Approval-directed bootstrapping",
            "tags": [
              {
                "name": "Iterated Amplification "
              }
            ]
          },
          {
            "title": "Humans Consulting HCH",
            "tags": [
              {
                "name": "Iterated Amplification "
              },
              {
                "name": "Humans Consulting HCH"
              }
            ]
          },
          {
            "title": "Corrigibility",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Instrumental Convergence"
              },
              {
                "name": "Iterated Amplification "
              },
              {
                "name": "Corrigibility"
              }
            ]
          }
        ]
      },
      {
        "title": "The scheme",
        "subtitle": null,
        "number": 2,
        "contents": {
          "markdown": "The core of the sequence is the third section. Benign model-free RL describes iterated amplification, as a general outline into which we can substitute arbitrary algorithms for reward learning, amplification, and robustness. The first four posts all describe variants of this idea from different perspectives, and if you find that one of those descriptions is clearest for you then I recommend focusing on that one and skimming the others."
        },
        "posts": [
          {
            "title": "Iterated Distillation and Amplification",
            "tags": [
              {
                "name": "Iterated Amplification "
              }
            ]
          },
          {
            "title": "Benign model-free RL",
            "tags": [
              {
                "name": "Iterated Amplification "
              }
            ]
          },
          {
            "title": "Factored Cognition",
            "tags": [
              {
                "name": "Factored Cognition"
              },
              {
                "name": "Iterated Amplification "
              },
              {
                "name": "Ought"
              }
            ]
          },
          {
            "title": "Supervising strong learners\nby amplifying weak experts",
            "tags": [
              {
                "name": "Iterated Amplification "
              }
            ]
          },
          {
            "title": "AlphaGo Zero and capability amplification",
            "tags": [
              {
                "name": "DeepMind"
              },
              {
                "name": "Iterated Amplification "
              }
            ]
          }
        ]
      },
      {
        "title": "What needs doing",
        "subtitle": null,
        "number": 3,
        "contents": {
          "markdown": "The fourth part of the sequence describes some of the black boxes in iterated amplification and discusses what we would need to do to fill in those boxes. I think these are some of the most important open questions in AI alignment."
        },
        "posts": [
          {
            "title": "Directions and desiderata for AI alignment",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Iterated Amplification "
              }
            ]
          },
          {
            "title": "The reward engineering problem ",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Iterated Amplification "
              },
              {
                "name": "Reward Functions"
              }
            ]
          },
          {
            "title": "Capability amplification",
            "tags": [
              {
                "name": "Iterated Amplification "
              }
            ]
          },
          {
            "title": "Learning with catastrophes",
            "tags": [
              {
                "name": "Machine Learning  (ML)"
              },
              {
                "name": "AI"
              }
            ]
          }
        ]
      },
      {
        "title": "Possible approaches",
        "subtitle": null,
        "number": 4,
        "contents": {
          "markdown": "The fifth section of the sequence breaks down some of these problems further and describes some possible approaches."
        },
        "posts": [
          {
            "title": "Thoughts on reward engineering\n",
            "tags": [
              {
                "name": "Iterated Amplification "
              },
              {
                "name": "Reward Functions"
              }
            ]
          },
          {
            "title": "Techniques for optimizing worst-case performance",
            "tags": [
              {
                "name": "Iterated Amplification "
              },
              {
                "name": "Existential Risk"
              }
            ]
          },
          {
            "title": "Reliability amplification\n",
            "tags": [
              {
                "name": "Iterated Amplification "
              }
            ]
          },
          {
            "title": "Security amplification",
            "tags": [
              {
                "name": "Iterated Amplification "
              }
            ]
          },
          {
            "title": "Meta-execution",
            "tags": [
              {
                "name": "Iterated Amplification "
              },
              {
                "name": "Humans Consulting HCH"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "ePDpMhJoKCff6qnvh",
    "title": "Quantum Physics",
    "curatedOrder": null,
    "contents": {
      "markdown": "A _non-mysterious_ introduction to quantum mechanics, intended to be accessible to anyone who can grok algebra and complex numbers. Cleaning up the old confusion about QM is used to introduce basic issues in rationality (such as the technical version of [Occams Razor](https://wiki.lesswrong.com/wiki/Occam%27s_Razor)), epistemology, reductionism, naturalism, and philosophy of science. _Not_ dispensable reading, even though the exact reasons for the digression are hard to explain in advance of reading.\n\nSequence by [Eliezer Yudkowsky](https://www.lesswrong.com/users/eliezer_yudkowsky), imported from [the wiki](https://wiki.lesswrong.com/wiki/The_Quantum_Physics_Sequence). Overlaps with [Quantum Physics and Many Worlds](https://www.lesswrong.com/s/Kqs6GR7F5xziuSyGZ) and [Science and Rationality](https://www.lesswrong.com/s/fxynfGCSHpY4FmBZy)."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Quantum Explanations",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Physics"
              },
              {
                "name": "Writing (communication method)"
              },
              {
                "name": "Quantum Mechanics"
              },
              {
                "name": "Good Explanations (Advice)"
              }
            ]
          },
          {
            "title": "Configurations and Amplitude",
            "tags": [
              {
                "name": "Physics"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Quantum Mechanics"
              }
            ]
          },
          {
            "title": "Joint Configurations",
            "tags": [
              {
                "name": "Physics"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Quantum Mechanics"
              }
            ]
          },
          {
            "title": "Distinct Configurations",
            "tags": [
              {
                "name": "Physics"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Quantum Mechanics"
              }
            ]
          },
          {
            "title": "Where Philosophy Meets Science",
            "tags": [
              {
                "name": "Physics"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "Quantum Mechanics"
              }
            ]
          },
          {
            "title": "Can You Prove Two Particles Are Identical?",
            "tags": [
              {
                "name": "Physics"
              },
              {
                "name": "Philosophy"
              }
            ]
          },
          {
            "title": "Classical Configuration Spaces",
            "tags": [
              {
                "name": "Physics"
              }
            ]
          },
          {
            "title": "The Quantum Arena",
            "tags": [
              {
                "name": "Physics"
              }
            ]
          },
          {
            "title": "Feynman Paths",
            "tags": [
              {
                "name": "Physics"
              }
            ]
          },
          {
            "title": "No Individual Particles",
            "tags": [
              {
                "name": "Physics"
              }
            ]
          },
          {
            "title": "Identity Isn't In Specific Atoms",
            "tags": [
              {
                "name": "Physics"
              },
              {
                "name": "Personal Identity"
              }
            ]
          },
          {
            "title": "Decoherence",
            "tags": [
              {
                "name": "Physics"
              }
            ]
          },
          {
            "title": "The So-Called Heisenberg Uncertainty Principle",
            "tags": [
              {
                "name": "Physics"
              }
            ]
          },
          {
            "title": "Which Basis Is More Fundamental?",
            "tags": [
              {
                "name": "Physics"
              }
            ]
          },
          {
            "title": "Where Physics Meets Experience",
            "tags": [
              {
                "name": "Physics"
              },
              {
                "name": "Anthropics"
              },
              {
                "name": "Fiction"
              },
              {
                "name": "Parables & Fables"
              },
              {
                "name": "Consciousness"
              }
            ]
          },
          {
            "title": "Where Experience Confuses Physicists",
            "tags": [
              {
                "name": "Physics"
              },
              {
                "name": "Anthropics"
              },
              {
                "name": "Fiction"
              },
              {
                "name": "Parables & Fables"
              }
            ]
          },
          {
            "title": "On Being Decoherent",
            "tags": [
              {
                "name": "Physics"
              }
            ]
          },
          {
            "title": "The Conscious Sorites Paradox",
            "tags": [
              {
                "name": "Quantum Mechanics"
              },
              {
                "name": "Many-Worlds Interpretation"
              },
              {
                "name": "Physics"
              },
              {
                "name": "Consciousness"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Paradoxes"
              }
            ]
          },
          {
            "title": "Decoherence is Pointless",
            "tags": [
              {
                "name": "Physics"
              }
            ]
          },
          {
            "title": "Decoherent Essences",
            "tags": [
              {
                "name": "Physics"
              }
            ]
          },
          {
            "title": "The Born Probabilities",
            "tags": [
              {
                "name": "Physics"
              }
            ]
          },
          {
            "title": "Decoherence as Projection",
            "tags": [
              {
                "name": "Physics"
              }
            ]
          },
          {
            "title": "Entangled Photons",
            "tags": [
              {
                "name": "Physics"
              }
            ]
          },
          {
            "title": "Bell's Theorem: No EPR \"Reality\"",
            "tags": [
              {
                "name": "Physics"
              }
            ]
          },
          {
            "title": "Spooky Action at a Distance: The No-Communication Theorem",
            "tags": [
              {
                "name": "Physics"
              }
            ]
          },
          {
            "title": "Decoherence is Simple",
            "tags": [
              {
                "name": "Physics"
              },
              {
                "name": "Occam's Razor"
              },
              {
                "name": "Solomonoff Induction"
              },
              {
                "name": "Quantum Mechanics"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Decoherence is Falsifiable and Testable",
            "tags": [
              {
                "name": "Falsifiability"
              },
              {
                "name": "Physics"
              },
              {
                "name": "Bayes' Theorem"
              },
              {
                "name": "Quantum Mechanics"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Quantum Non-Realism",
            "tags": [
              {
                "name": "Physics"
              },
              {
                "name": "Quantum Mechanics"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Collapse Postulates",
            "tags": [
              {
                "name": "Physics"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Quantum Mechanics"
              }
            ]
          },
          {
            "title": "If Many-Worlds Had Come First",
            "tags": [
              {
                "name": "Physics"
              },
              {
                "name": "Fiction"
              },
              {
                "name": "Humor"
              },
              {
                "name": "Occam's Razor"
              },
              {
                "name": "Quantum Mechanics"
              },
              {
                "name": "Many-Worlds Interpretation"
              },
              {
                "name": "Parables & Fables"
              }
            ]
          },
          {
            "title": "Many Worlds, One Best Guess",
            "tags": [
              {
                "name": "Physics"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Quantum Mechanics"
              },
              {
                "name": "Many-Worlds Interpretation"
              }
            ]
          },
          {
            "title": "Living in Many Worlds",
            "tags": [
              {
                "name": "Physics"
              },
              {
                "name": "Planning & Decision-Making"
              },
              {
                "name": "Quantum Mechanics"
              },
              {
                "name": "Many-Worlds Interpretation"
              },
              {
                "name": "Adding Up to Normality"
              }
            ]
          },
          {
            "title": "Mach's Principle: Anti-Epiphenomenal Physics",
            "tags": [
              {
                "name": "Physics"
              },
              {
                "name": "History"
              }
            ]
          },
          {
            "title": "Relative Configuration Space",
            "tags": [
              {
                "name": "Quantum Mechanics"
              },
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "Physics"
              }
            ]
          },
          {
            "title": "Timeless Physics",
            "tags": [
              {
                "name": "Physics"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Timeless Physics"
              }
            ]
          },
          {
            "title": "Timeless Beauty",
            "tags": [
              {
                "name": "Timeless Physics"
              },
              {
                "name": "Physics"
              },
              {
                "name": "Aesthetics"
              }
            ]
          },
          {
            "title": "Timeless Causality",
            "tags": [
              {
                "name": "Causality"
              },
              {
                "name": "Timeless Physics"
              }
            ]
          },
          {
            "title": "Timeless Identity",
            "tags": [
              {
                "name": "Cryonics"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Personal Identity"
              },
              {
                "name": "Timeless Physics"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Thou Art Physics",
            "tags": [
              {
                "name": "Physics"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Timeless Control",
            "tags": [
              {
                "name": "Causality"
              },
              {
                "name": "Physics"
              },
              {
                "name": "Counterfactuals"
              },
              {
                "name": "Timeless Physics"
              }
            ]
          },
          {
            "title": "The Failures of Eld Science",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "Babble and Prune"
              }
            ]
          },
          {
            "title": "The Dilemma: Science or Bayes?",
            "tags": [
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Science Doesn't Trust Your Rationality",
            "tags": [
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "When Science Can't Help",
            "tags": [
              {
                "name": "Practice & Philosophy of Science"
              }
            ]
          },
          {
            "title": "Science Isn't Strict Enough",
            "tags": [
              {
                "name": "Practice & Philosophy of Science"
              }
            ]
          },
          {
            "title": "Do Scientists Already Know This Stuff?",
            "tags": [
              {
                "name": "Practice & Philosophy of Science"
              }
            ]
          },
          {
            "title": "No Safe Defense, Not Even Science",
            "tags": [
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Courage"
              },
              {
                "name": "Trust"
              }
            ]
          },
          {
            "title": "Changing the Definition of Science",
            "tags": [
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "Bayesianism"
              }
            ]
          },
          {
            "title": "Faster Than Science",
            "tags": [
              {
                "name": "Practice & Philosophy of Science"
              }
            ]
          },
          {
            "title": "Einstein's Speed",
            "tags": [
              {
                "name": "Physics"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Practice & Philosophy of Science"
              }
            ]
          },
          {
            "title": "That Alien Message",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "AI Boxing (Containment)"
              },
              {
                "name": "AI"
              },
              {
                "name": "Simulation Hypothesis"
              },
              {
                "name": "Bayesianism"
              },
              {
                "name": "Parables & Fables"
              }
            ]
          },
          {
            "title": "My Childhood Role Model",
            "tags": [
              {
                "name": "Fiction (Topic)"
              },
              {
                "name": "General Intelligence"
              },
              {
                "name": "Tsuyoku Naritai"
              }
            ]
          },
          {
            "title": "Einstein's Superpowers",
            "tags": [
              {
                "name": "Ambition"
              },
              {
                "name": "Humility"
              }
            ]
          },
          {
            "title": "Class Project",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Why Quantum?",
            "tags": [
              {
                "name": "Physics"
              },
              {
                "name": "Postmortems & Retrospectives"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "d3WgHDBAPYYScp5Em",
    "title": "Fun Theory",
    "curatedOrder": null,
    "contents": {
      "markdown": "A concrete theory of transhuman values. How much fun is there in the universe? Will we ever run out of fun? Are we having fun yet? Could we be having more fun? Part of the [complexity of value](https://wiki.lesswrong.com/wiki/Complexity_of_value) thesis.\n\nAlso forms part of the fully general answer to religious theodicy.\n\nSequence by [Eliezer Yudkowsky](https://www.lesswrong.com/users/eliezer_yudkowsky), imported from [the wiki](https://wiki.lesswrong.com/wiki/The_Fun_Theory_Sequence). Overlaps with [Value Theory](https://www.lesswrong.com/s/9bvAELWc8y2gYjRav)."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "The Fun Theory Sequence",
            "tags": [
              {
                "name": "Well-being"
              },
              {
                "name": "Fun Theory"
              }
            ]
          },
          {
            "title": "Prolegomena to a Theory of Fun",
            "tags": [
              {
                "name": "Fun Theory"
              },
              {
                "name": "Happiness"
              }
            ]
          },
          {
            "title": "High Challenge",
            "tags": [
              {
                "name": "Complexity of Value"
              },
              {
                "name": "Fun Theory"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Skill Building"
              }
            ]
          },
          {
            "title": "Complex Novelty",
            "tags": [
              {
                "name": "Fun Theory"
              }
            ]
          },
          {
            "title": "Continuous Improvement",
            "tags": [
              {
                "name": "Fun Theory"
              }
            ]
          },
          {
            "title": "Sensual Experience",
            "tags": [
              {
                "name": "Fun Theory"
              },
              {
                "name": "Human Bodies"
              },
              {
                "name": "Embodiment"
              }
            ]
          },
          {
            "title": "Living By Your Own Strength",
            "tags": [
              {
                "name": "History"
              },
              {
                "name": "Fun Theory"
              },
              {
                "name": "Education"
              }
            ]
          },
          {
            "title": "Free to Optimize",
            "tags": [
              {
                "name": "Fun Theory"
              },
              {
                "name": "Autonomy and Choice"
              }
            ]
          },
          {
            "title": "Harmful Options",
            "tags": [
              {
                "name": "Fun Theory"
              },
              {
                "name": "Bounded Rationality"
              },
              {
                "name": "Akrasia"
              }
            ]
          },
          {
            "title": "Devil's Offers",
            "tags": [
              {
                "name": "Fun Theory"
              },
              {
                "name": "Fiction (Topic)"
              }
            ]
          },
          {
            "title": "Nonperson Predicates",
            "tags": [
              {
                "name": "Consciousness"
              },
              {
                "name": "Zombies"
              },
              {
                "name": "AI"
              },
              {
                "name": "AI Risk"
              },
              {
                "name": "Mind Crime"
              }
            ]
          },
          {
            "title": "Amputation of Destiny",
            "tags": [
              {
                "name": "Fun Theory"
              },
              {
                "name": "Fiction (Topic)"
              },
              {
                "name": "Transhumanism"
              }
            ]
          },
          {
            "title": "Nonsentient Optimizers",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Consciousness"
              },
              {
                "name": "Free Will"
              }
            ]
          },
          {
            "title": "Can't Unbirth a Child",
            "tags": [
              {
                "name": "Futurism"
              },
              {
                "name": "Complexity of Value"
              },
              {
                "name": "Fun Theory"
              }
            ]
          },
          {
            "title": "Dunbar's Function",
            "tags": [
              {
                "name": "Social & Cultural Dynamics"
              },
              {
                "name": "Tribalism"
              }
            ]
          },
          {
            "title": "In Praise of Boredom",
            "tags": [
              {
                "name": "Fun Theory"
              },
              {
                "name": "Complexity of Value"
              }
            ]
          },
          {
            "title": "Sympathetic Minds",
            "tags": [
              {
                "name": "Complexity of Value"
              },
              {
                "name": "Evolutionary Psychology"
              }
            ]
          },
          {
            "title": "Interpersonal Entanglement",
            "tags": [
              {
                "name": "Sex & Gender"
              }
            ]
          },
          {
            "title": "Failed Utopia #4-2",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Sex & Gender"
              },
              {
                "name": "Fun Theory"
              },
              {
                "name": "Parables & Fables"
              }
            ]
          },
          {
            "title": "Growing Up is Hard",
            "tags": [
              {
                "name": "Intelligence Amplification"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Evolution"
              }
            ]
          },
          {
            "title": "Changing Emotions",
            "tags": [
              {
                "name": "Sex & Gender"
              }
            ]
          },
          {
            "title": "Emotional Involvement",
            "tags": [
              {
                "name": "Fun Theory"
              }
            ]
          },
          {
            "title": "Serious Stories",
            "tags": [
              {
                "name": "Narratives (stories)"
              }
            ]
          },
          {
            "title": "Eutopia is Scary",
            "tags": [
              {
                "name": "Futurism"
              },
              {
                "name": "Fiction (Topic)"
              },
              {
                "name": "Ontological Crisis"
              }
            ]
          },
          {
            "title": "Building Weirdtopia",
            "tags": [
              {
                "name": "Futurism"
              },
              {
                "name": "Fun Theory"
              }
            ]
          },
          {
            "title": "Justified Expectation of Pleasant Surprises",
            "tags": [
              {
                "name": "Gaming (videogames/tabletop)"
              },
              {
                "name": "Fun Theory"
              }
            ]
          },
          {
            "title": "Seduced by Imagination",
            "tags": [
              {
                "name": "Fun Theory"
              },
              {
                "name": "Pitfalls of Rationality"
              }
            ]
          },
          {
            "title": "Justified Expectation of Pleasant Surprises",
            "tags": [
              {
                "name": "Gaming (videogames/tabletop)"
              },
              {
                "name": "Fun Theory"
              }
            ]
          },
          {
            "title": "Seduced by Imagination",
            "tags": [
              {
                "name": "Fun Theory"
              },
              {
                "name": "Pitfalls of Rationality"
              }
            ]
          },
          {
            "title": "The Uses of Fun (Theory)",
            "tags": [
              {
                "name": "Fun Theory"
              }
            ]
          },
          {
            "title": "Higher Purpose",
            "tags": [
              {
                "name": "Motivations"
              },
              {
                "name": "Altruism"
              },
              {
                "name": "Ambition"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "AmFb5xWbPWWQyQ244",
    "title": "Ethical Injunctions",
    "curatedOrder": null,
    "contents": {
      "markdown": "**Ethical injunctions** are rules not to do something even when it's the right thing to do. (That is, you refrain \"even when your brain has computed it's the right thing to do\", but this will just _seem like_ \"the right thing to do\".)\n\nFor example, you shouldn't rob banks even if you plan to give the money to a good cause.\n\nThis is to protect you from your own cleverness (especially taking bad black swan bets), and the [Corrupted hardware](https://wiki.lesswrong.com/wiki/Corrupted_hardware) you're running on.\n\nSequence by [Eliezer Yudkowsky](https://www.lesswrong.com/users/eliezer_yudkowsky), imported from [the wiki](https://wiki.lesswrong.com/wiki/Ethical_Injunctions). Overlaps with [Quantified Humanism](https://www.lesswrong.com/s/waF2Pomid7YHjfEDt) and [Against Rationalization](https://www.lesswrong.com/s/GSqFqc646rsRd2oyz)."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Why Does Power Corrupt?",
            "tags": [
              {
                "name": "Motivations"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Ends Don't Justify Means (Among Humans)",
            "tags": [
              {
                "name": "Self-Deception"
              },
              {
                "name": "Deontology"
              },
              {
                "name": "Consequentialism"
              },
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "Evolutionary Psychology"
              },
              {
                "name": "Decision Theory"
              }
            ]
          },
          {
            "title": "Entangled Truths, Contagious Lies",
            "tags": [
              {
                "name": "Deception"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Protected From Myself",
            "tags": [
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "Moral Uncertainty"
              },
              {
                "name": "Honesty"
              },
              {
                "name": "Deontology"
              },
              {
                "name": "Appeal to Consequence"
              }
            ]
          },
          {
            "title": "Ethical Inhibitions",
            "tags": [
              {
                "name": "Evolutionary Psychology"
              },
              {
                "name": "Ethics & Morality"
              }
            ]
          },
          {
            "title": "Ethical Injunctions",
            "tags": [
              {
                "name": "Deontology"
              },
              {
                "name": "AI"
              },
              {
                "name": "Self-Deception"
              }
            ]
          },
          {
            "title": "Prices or Bindings?",
            "tags": [
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "Deontology"
              }
            ]
          },
          {
            "title": "Ethics Notes",
            "tags": [
              {
                "name": "Metaethics"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Honesty"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "LAop879LCQWrM5YnE",
    "title": "The Bayesian Conspiracy",
    "curatedOrder": null,
    "contents": {
      "markdown": "The _beisutsukai_ are members of a secret society, also known as the Bayesian Conspiracy.\n\nDerived from \"beisu\", a Japanese transliteration of Bayes (though more accurate Japanese pronunciation would be bei-zu, not bei-su), plus \"tsukai\", Japanese \"user\", therefore \"Bayes-user\". A casual, shortened pronunciation would probably come out \"bayes-tskai\"."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Initiation Ceremony",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "The Failures of Eld Science",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "Babble and Prune"
              }
            ]
          },
          {
            "title": "Class Project",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "The Ritual",
            "tags": [
              {
                "name": "Ritual"
              },
              {
                "name": "Fiction"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Final Words",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "dT7CKGXwq9vt76CeX",
    "title": "Alignment Newsletter",
    "curatedOrder": null,
    "contents": {
      "markdown": "I publish the Alignment Newsletter, a weekly publication with recent content relevant to AI alignment. See [here](https://rohinshah.com/alignment-newsletter/) for more details. Quick links: [email signup form](http://eepurl.com/dqMSZj), [RSS feed](https://us18.campaign-archive.com/feed?u=1d1821210cc4f04d1e05c4fa6&id=dbac5de515), [spreadsheet](https://docs.google.com/spreadsheets/d/1PwWbWZ6FPqAgZWOoOcXM8N_tUCuxpEyMbN1NYYC02aM/edit?usp=sharing) of all summaries."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "The Alignment Newsletter #1: 04/09/18",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "The Alignment Newsletter #2: 04/16/18",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "The Alignment Newsletter #3: 04/23/18",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "The Alignment Newsletter #4: 04/30/18",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "The Alignment Newsletter #5: 05/07/18",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "The Alignment Newsletter #6: 05/14/18",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "The Alignment Newsletter #7: 05/21/18",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "The Alignment Newsletter #8: 05/28/18",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "The Alignment Newsletter #9: 06/04/18",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "The Alignment Newsletter #10: 06/11/18",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "The Alignment Newsletter #11: 06/18/18",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "The Alignment Newsletter #12: 06/25/18",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #13: 07/02/18",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "OpenAI"
              },
              {
                "name": "Gaming (videogames/tabletop)"
              },
              {
                "name": "AI Risk"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #14",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #15: 07/16/18",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #16: 07/23/18",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #17",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #18",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #19",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #20",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #21",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #22",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #23",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #24",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #25",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #26",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #27",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #28",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #29",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #30",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #31",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #32",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #33",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #34",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #35",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #36",
            "tags": [
              {
                "name": "Factored Cognition"
              },
              {
                "name": "AI"
              },
              {
                "name": "Newsletters"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #37",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #38",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #39",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #40",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #41",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #42",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #43",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #44",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #45",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #46",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #47",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #48",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #49",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #50",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #51",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #52",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter One Year Retrospective",
            "tags": [
              {
                "name": "Postmortems & Retrospectives"
              },
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Alignment Newsletter #53",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #54] Boxing a finite-horizon AI system to keep it unambitious",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #55] Regulatory markets and international standards as a means of ensuring beneficial AI",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #56] Should ML researchers stop running experiments before making hypotheses?",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #57] Why we should focus on robustness in AI safety, and the analogous problems in programming",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #58] Mesa optimization: what it is, and why we should care",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "Mesa-Optimization"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #59] How arguments for AI risk have changed over time",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #60] A new AI challenge: Minecraft agents that assist human players in creative mode",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #61] AI policy and governance, from two people in the field",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI Governance"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #62] Are adversarial examples caused by real but imperceptible features?",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              },
              {
                "name": "Adversarial Examples"
              }
            ]
          },
          {
            "title": "[AN #63] How architecture search, meta learning, and environment design could lead to general intelligence",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #64]: Using Deep RL and Reward Uncertainty to Incentivize Preference Learning",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #65]: Learning useful skills by watching humans “play”",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #66]: Decomposing robustness into capability robustness and alignment robustness",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #67]: Creating environments in which to study inner alignment failures",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              },
              {
                "name": "Inner Alignment"
              }
            ]
          },
          {
            "title": "[AN #68]: The attainable utility theory of impact",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              },
              {
                "name": "Impact Measures"
              }
            ]
          },
          {
            "title": "[AN #69] Stuart Russell's new book on why we need to replace the standard model of AI",
            "tags": [
              {
                "name": "Center for Human-Compatible AI (CHAI)"
              },
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #70]: Agents that help humans who are still learning about their own preferences",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #71]: Avoiding reward tampering through current-RF optimization",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #72]: Alignment, robustness, methodology, and system building as research priorities for AI safety",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #73]: Detecting catastrophic failures by learning how agents tend to break",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #74]: Separating beneficial AI into competence, alignment, and coping with impacts",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #75]: Solving Atari and Go with learned game models, and thoughts from a MIRI employee",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #76]: How dataset size affects robustness, and benchmarking safe exploration by measuring constraint violations",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #77]: Double descent: a unification of statistical theory and modern ML practice",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #78] Formalizing power and instrumental convergence, and the end-of-year AI safety charity comparison",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #79]: Recursive reward modeling as an alignment technique integrated with deep RL",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #80]: Why AI risk might be solved without additional intervention from longtermists",
            "tags": [
              {
                "name": "AI Risk"
              },
              {
                "name": "AI"
              },
              {
                "name": "Newsletters"
              }
            ]
          },
          {
            "title": "[AN #81]: Universality as a potential solution to conceptual difficulties in intent alignment",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #82]: How OpenAI Five distributed their training computation",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #83]: Sample-efficient deep learning with ReMixMatch",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #84] Reviewing AI alignment work in 2018-19",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #85]: The normative questions we should be asking for AI alignment, and a surprisingly good chatbot",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #86]: Improving debate and factored cognition through human experiments",
            "tags": [
              {
                "name": "Ought"
              },
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #87]: What might happen as deep learning scales even further?",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #88]: How the principal-agent literature relates to AI risk",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #89]: A unifying formalism for preference learning algorithms",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #90]: How search landscapes can contain self-reinforcing feedback loops",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #91]: Concepts, implementations, problems, and a benchmark for impact measurement",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #92]: Learning good representations with contrastive predictive coding",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #93]: The Precipice we’re standing at, and how we can back away from it",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              },
              {
                "name": "Existential Risk"
              }
            ]
          },
          {
            "title": "[AN #94]: AI alignment as translation between humans and machines",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Newsletters"
              }
            ]
          },
          {
            "title": "[AN #95]: A framework for thinking about how to make AI go well",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Newsletters"
              }
            ]
          },
          {
            "title": "[AN #96]: Buck and I discuss/argue about AI Alignment",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Newsletters"
              }
            ]
          },
          {
            "title": "[AN #97]: Are there historical examples of large, robust discontinuities?",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "AI Takeoff"
              },
              {
                "name": "Newsletters"
              }
            ]
          },
          {
            "title": "[AN #98]: Understanding neural net training by seeing which gradients were helpful",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Newsletters"
              }
            ]
          },
          {
            "title": "[AN #99]: Doubling times for the efficiency of AI algorithms",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Newsletters"
              }
            ]
          },
          {
            "title": "[AN #100]: What might go wrong if you learn a reward function while acting",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Newsletters"
              }
            ]
          },
          {
            "title": "[AN #101]: Why we should rigorously measure and forecast AI progress",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Newsletters"
              }
            ]
          },
          {
            "title": "[AN #102]: Meta learning by GPT-3, and a list of full proposals for AI alignment",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Newsletters"
              },
              {
                "name": "GPT"
              }
            ]
          },
          {
            "title": "[AN #103]: ARCHES: an agenda for existential safety, and combining natural language with deep RL",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Newsletters"
              }
            ]
          },
          {
            "title": "[AN #104]: The perils of inaccessible information, and what we can learn about AI alignment from COVID",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Newsletters"
              }
            ]
          },
          {
            "title": "[AN #105]: The economic trajectory of humanity, and what we might mean by optimization",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Newsletters"
              }
            ]
          },
          {
            "title": "[AN #106]: Evaluating generalization ability of learned reward models",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Newsletters"
              }
            ]
          },
          {
            "title": "[AN #107]: The convergent instrumental subgoals of goal-directed agents",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Newsletters"
              }
            ]
          },
          {
            "title": "[AN #108]: Why we should scrutinize arguments for AI risk",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Newsletters"
              }
            ]
          },
          {
            "title": "[AN #109]: Teaching neural nets to generalize the way humans would",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Newsletters"
              }
            ]
          },
          {
            "title": "[AN #110]: Learning features from human feedback to enable reward learning",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Newsletters"
              }
            ]
          },
          {
            "title": "[AN #111]: The Circuits hypotheses for deep learning",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Newsletters"
              }
            ]
          },
          {
            "title": "[AN #112]: Engineering a Safer World",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #113]: Checking the ethical intuitions of large language models",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Newsletters"
              },
              {
                "name": "Language Models"
              }
            ]
          },
          {
            "title": "[AN #114]: Theory-inspired safety solutions for powerful Bayesian RL agents",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Newsletters"
              }
            ]
          },
          {
            "title": "[AN #115]: AI safety research problems in the AI-GA framework",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #116]: How to make explanations of neurons compositional",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Newsletters"
              }
            ]
          },
          {
            "title": "[AN #117]: How neural nets would fare under the TEVV framework",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #118]: Risks, solutions, and prioritization in a world with many AI systems",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #119]: AI safety when agents are shaped by environments, not rewards",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #120]: Tracing the intellectual roots of AI and AI alignment",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #121]: Forecasting transformative AI timelines using biological anchors",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "Transformative AI"
              }
            ]
          },
          {
            "title": "[AN #122]: Arguing for AGI-driven existential risk from first principles",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #123]: Inferring what is valuable in order to align recommender systems",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Newsletters"
              }
            ]
          },
          {
            "title": "[AN #124]: Provably safe exploration through shielding",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #125]: Neural network scaling laws across multiple modalities",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Newsletters"
              }
            ]
          },
          {
            "title": "[AN #126]: Avoiding wireheading by decoupling action feedback from action effects",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #127]: Rethinking agency: Cartesian frames as a formalization of ways to carve up the world into an agent and its environment",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Newsletters"
              }
            ]
          },
          {
            "title": "[AN #128]: Prioritizing research on AI existential safety based on its application to governance demands",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #129]: Explaining double descent by measuring bias and variance",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #130]: A new AI x-risk podcast, and reviews of the field",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #131]: Formalizing the argument of ignored attributes in a utility function",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #132]: Complex and subtly incorrect arguments as an obstacle to debate",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #133]: Building machines that can cooperate (with humans, institutions, or other machines)",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Newsletters"
              }
            ]
          },
          {
            "title": "[AN #134]: Underspecification as a cause of fragility to distribution shift",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #135]: Five properties of goal-directed systems",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #136]: How well will GPT-N perform on downstream tasks?",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Newsletters"
              }
            ]
          },
          {
            "title": "[AN #137]: Quantifying the benefits of pretraining on downstream task performance",
            "tags": []
          },
          {
            "title": "[AN #138]: Why AI governance should find problems rather than just solving them",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #139]: How the simplicity of reality explains the success of neural nets",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #140]: Theoretical models that predict scaling laws",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #141]: The case for practicing alignment work on GPT-3 and other large models",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #142]: The quest to understand a network well enough to reimplement it by hand",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #143]: How to make embedded agents that reason probabilistically about their environments",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #144]: How language models can also be finetuned for non-language tasks",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Language Models"
              }
            ]
          },
          {
            "title": "Alignment Newsletter Three Year Retrospective",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #145]: Our three year anniversary!",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #146]: Plausible stories of how we might fail to avert an existential catastrophe",
            "tags": [
              {
                "name": "Autonomous Weapons"
              }
            ]
          },
          {
            "title": "[AN #147]: An overview of the interpretability landscape",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #148]: Analyzing generalization across more axes than just accuracy or loss",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #149]: The newsletter's editorial policy",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #150]: The subtypes of Cooperative AI research",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Coordination / Cooperation"
              }
            ]
          },
          {
            "title": "[AN #151]: How sparsity in the final layer makes a neural net debuggable",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #152]: How we’ve overestimated few-shot learning capabilities",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #153]: Experiments that demonstrate failures of objective robustness",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #154]: What economic growth theory has to say about transformative AI",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #155]: A Minecraft benchmark for algorithms that learn without reward functions",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #156]: The scaling hypothesis: a plan for building AGI",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #157]: Measuring misalignment in the technology underlying Copilot",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #158]: Should we be optimistic about generalization?",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #159]: Building agents that know how to experiment, by training on procedurally generated games",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #160]: Building AIs that learn and think like people",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #161]: Creating generalizable reward functions for multiple tasks by learning a model of functional similarity",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #162]: Foundation models: a paradigm shift within AI",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #163]: Using finite factored sets for causal and temporal inference",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Finite Factored Sets"
              }
            ]
          },
          {
            "title": "[AN #164]: How well can language models write code?",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Language Models"
              }
            ]
          },
          {
            "title": "[AN #165]: When large models are more likely to lie",
            "tags": [
              {
                "name": "Treacherous Turn"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #166]: Is it crazy to claim we're in the most important century?",
            "tags": [
              {
                "name": "Newsletters"
              }
            ]
          },
          {
            "title": "[AN #167]: Concrete ML safety problems and their relevance to x-risk",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #168]: Four technical topics for which Open Phil is soliciting grant proposals",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #169]: Collaborating with humans without human data",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #170]: Analyzing the argument for risk from power-seeking AI",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Newsletters"
              }
            ]
          },
          {
            "title": "[AN #171]: Disagreements between alignment \"optimists\" and \"pessimists\"",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #172] Sorry for the long hiatus!",
            "tags": [
              {
                "name": "Newsletters"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "[AN #173] Recent language model results from DeepMind",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Newsletters"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "qWoFR4ytMpQ5vw3FT",
    "title": "Three Worlds Collide",
    "curatedOrder": 1,
    "contents": {
      "markdown": "> \"The kind of classic fifties-era first-contact story that Jonathan Swift might have written, if Jonathan Swift had had a background in game theory.\"  \n>       \\-\\- (Hugo nominee) Peter Watts, \"[In Praise of Baby-Eating](http://www.rifters.com/crawl/?p=266)\"\n\n  \n\n_Three Worlds Collide_ is a story I wrote to illustrate some points on naturalistic metaethics and diverse other issues of rational conduct.  It grew, as such things do, into a small novella.  On publication, it proved widely popular and widely criticized.  Be warned that the story, as it wrote itself, ended up containing some profanity and PG-13 content.\n\n(PDF is [here](http://robinhanson.typepad.com/files/three-worlds-collide.pdf). Old contents post with comments is [here](https://www.lesswrong.com/posts/HawFh7RvDM4RyoJ2d/three-worlds-collide-0-8).)"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": 0,
        "contents": null,
        "posts": [
          {
            "title": "The Baby-Eating Aliens (1/8)",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "War and/or Peace (2/8)",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "The Super Happy People (3/8)",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Happiness"
              },
              {
                "name": "Fun Theory"
              }
            ]
          },
          {
            "title": "Interlude with the Confessor (4/8)",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Three Worlds Decide (5/8)",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Normal Ending: Last Tears (6/8)",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "True Ending: Sacrificial Fire (7/8)",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Epilogue: Atonement (8/8)",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "zucjLBpQ9S9eWPWGu",
    "title": "Share Models, Not Beliefs",
    "curatedOrder": null,
    "contents": {
      "markdown": "An in-progress sequence in praise of both having models and being disagreeable."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": 0,
        "contents": null,
        "posts": [
          {
            "title": "A Sketch of Good Communication",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Conversation (topic)"
              },
              {
                "name": "Anticipated Experiences"
              }
            ]
          },
          {
            "title": "Hold On To The Curiosity",
            "tags": [
              {
                "name": "Curiosity"
              }
            ]
          },
          {
            "title": "Form Your Own Opinions",
            "tags": [
              {
                "name": "Epistemology"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Disagreement"
              }
            ]
          },
          {
            "title": "Goodhart Taxonomy: Agreement",
            "tags": [
              {
                "name": "Goodhart's Law"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "h8DebDmuode4TMcRj",
    "title": "LW Open Source Guide",
    "curatedOrder": null,
    "contents": {
      "markdown": "LessWrong is open source. If you'd like to help out, or have noticed an annoying bug that you'd like to take matters into your own hands and fix, this is the place to learn how to get started."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "LW Open Source – Getting Started",
            "tags": [
              {
                "name": "Site Meta"
              },
              {
                "name": "Programming"
              }
            ]
          },
          {
            "title": "LW Open Source – Overview of the Codebase",
            "tags": [
              {
                "name": "Site Meta"
              },
              {
                "name": "Programming"
              }
            ]
          },
          {
            "title": "GraphQL tutorial for LessWrong and Effective Altruism Forum",
            "tags": [
              {
                "name": "Site Meta"
              },
              {
                "name": "Programming"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "ZBNBTSMAXbyJwJoKY",
    "title": "Voting Theory Primer for Rationalists",
    "curatedOrder": null,
    "contents": null,
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "A voting theory primer for rationalists",
            "tags": [
              {
                "name": "Voting Theory"
              },
              {
                "name": "Mechanism Design"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "5 general voting pathologies: lesser names of Moloch",
            "tags": [
              {
                "name": "Moloch"
              },
              {
                "name": "Voting Theory"
              }
            ]
          },
          {
            "title": "Multi-winner Voting: a question of Alignment",
            "tags": [
              {
                "name": "Voting Theory"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "KGYLvTqFiFE2CpHfJ",
    "title": "Becoming Stronger",
    "curatedOrder": null,
    "contents": {
      "markdown": "> You can never have enough books.\n\n  \n\nMy journey through the [MIRI research guide](https://intelligence.org/research-guide/)."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Set Up for Success: Insights from 'Naïve Set Theory'",
            "tags": [
              {
                "name": "Scholarship & Learning"
              },
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "Book Reviews"
              },
              {
                "name": "Summaries"
              }
            ]
          },
          {
            "title": "Lightness and Unease",
            "tags": [
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "The Art of the Artificial: Insights from 'Artificial Intelligence: A Modern Approach'",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Book Reviews"
              },
              {
                "name": "Scholarship & Learning"
              },
              {
                "name": "Dark Arts"
              }
            ]
          },
          {
            "title": "The First Rung: Insights from 'Linear Algebra Done Right'",
            "tags": [
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "Scholarship & Learning"
              },
              {
                "name": "Book Reviews"
              }
            ]
          },
          {
            "title": "Internalizing Internal Double Crux",
            "tags": [
              {
                "name": "Subagents"
              },
              {
                "name": "Internal Double Crux"
              }
            ]
          },
          {
            "title": "Confounded No Longer: Insights from 'All of Statistics'",
            "tags": [
              {
                "name": "Book Reviews"
              },
              {
                "name": "Probability & Statistics"
              },
              {
                "name": "Summaries"
              }
            ]
          },
          {
            "title": "Into the Kiln: Insights from Tao's 'Analysis I'",
            "tags": [
              {
                "name": "Logic & Mathematics "
              }
            ]
          },
          {
            "title": "Swimming Upstream: A Case Study in Instrumental Rationality",
            "tags": [
              {
                "name": "AI Risk"
              },
              {
                "name": "Heroic Responsibility"
              },
              {
                "name": "Center for Human-Compatible AI (CHAI)"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Case Study"
              },
              {
                "name": "Growth Stories"
              }
            ]
          },
          {
            "title": "Making a Difference Tempore: Insights from 'Reinforcement Learning: An Introduction'",
            "tags": [
              {
                "name": "Machine Learning  (ML)"
              },
              {
                "name": "Book Reviews"
              },
              {
                "name": "Summaries"
              },
              {
                "name": "Reinforcement Learning"
              }
            ]
          },
          {
            "title": "Turning Up the Heat: Insights from Tao's 'Analysis II'",
            "tags": [
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "Book Reviews"
              },
              {
                "name": "Summaries"
              }
            ]
          },
          {
            "title": "And My Axiom! Insights from 'Computability and Logic'",
            "tags": [
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "Computer Science"
              },
              {
                "name": "Book Reviews"
              },
              {
                "name": "Summaries"
              }
            ]
          },
          {
            "title": "Judgment Day: Insights from 'Judgment in Managerial Decision Making'",
            "tags": [
              {
                "name": "Scholarship & Learning"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Continuous Improvement: Insights from 'Topology'",
            "tags": [
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "Book Reviews"
              },
              {
                "name": "Summaries"
              }
            ]
          },
          {
            "title": "ODE to Joy: Insights from 'A First Course in Ordinary Differential Equations'",
            "tags": [
              {
                "name": "Scholarship & Learning"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "A Kernel of Truth: Insights from 'A Friendly Approach to Functional Analysis'",
            "tags": [
              {
                "name": "Scholarship & Learning"
              },
              {
                "name": "Book Reviews"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Logic & Mathematics "
              }
            ]
          },
          {
            "title": "Problem relaxation as a tactic",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "AI"
              },
              {
                "name": "Techniques"
              }
            ]
          },
          {
            "title": "Insights from Euclid's 'Elements'",
            "tags": [
              {
                "name": "Scholarship & Learning"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Logic & Mathematics "
              }
            ]
          },
          {
            "title": "Lessons I've Learned from Self-Teaching",
            "tags": [
              {
                "name": "Scholarship & Learning"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Spaced Repetition"
              }
            ]
          },
          {
            "title": "Insights from Modern Principles of Economics",
            "tags": [
              {
                "name": "Economics"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Book Reviews"
              }
            ]
          },
          {
            "title": "Do a cost-benefit analysis of your technology usage",
            "tags": [
              {
                "name": "Social Media"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Self-Deception"
              },
              {
                "name": "Self Improvement"
              }
            ]
          },
          {
            "title": "Looking back on my alignment PhD",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Growth Stories"
              },
              {
                "name": "Postmortems & Retrospectives"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "HXkpm9b8o964jbQ89",
    "title": "Slack and the Sabbath ",
    "curatedOrder": 1,
    "contents": {
      "markdown": "A series of meditations on freedom to do the things you care about.\n\n> Some things are fundamentally Out to Get You.\n\n> They seek resources at your expense. Fees are hidden. Extra options are foisted upon you. Things are made intentionally worse, forcing you to pay to make it less worse. Everything is data to sell you something, rather than an opportunity to help you.\n\n> When something is out to get you, if you aren't careful, it can take all your resources - your time, you money, your attention.\n\n> This matters, more deeply than you might realize. It's not just that you need your resources. You need enough resources to have slack: freedom from constraints that might bind you.\n\n> Slack means margin of error. You can relax. You can explore and pursue opportunities. You can plan for the long term. You can stick to principles and do the right thing."
    },
    "chapters": [
      {
        "title": "Main Sequence",
        "subtitle": null,
        "number": 0,
        "contents": null,
        "posts": [
          {
            "title": "Out to Get You",
            "tags": [
              {
                "name": "Game Theory"
              },
              {
                "name": "Moral Mazes"
              },
              {
                "name": "Planning & Decision-Making"
              },
              {
                "name": "Slack"
              }
            ]
          },
          {
            "title": "Play in Easy Mode",
            "tags": []
          },
          {
            "title": "Play in Hard Mode",
            "tags": []
          },
          {
            "title": "Slack",
            "tags": [
              {
                "name": "Slack"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Bring Back the Sabbath",
            "tags": [
              {
                "name": "Slack"
              },
              {
                "name": "Ritual"
              },
              {
                "name": "Sabbath"
              }
            ]
          },
          {
            "title": "Sabbath Commentary",
            "tags": [
              {
                "name": "Slack"
              },
              {
                "name": "Sabbath"
              },
              {
                "name": "Cooking"
              }
            ]
          }
        ]
      },
      {
        "title": "Community Discussion",
        "subtitle": null,
        "number": 1,
        "contents": null,
        "posts": [
          {
            "title": "Sabbath hard and go home",
            "tags": [
              {
                "name": "Slack"
              },
              {
                "name": "Meditation"
              },
              {
                "name": "Well-being"
              },
              {
                "name": "Self Experimentation"
              },
              {
                "name": "Ritual"
              },
              {
                "name": "Sabbath"
              }
            ]
          },
          {
            "title": "Confessions of a Slacker",
            "tags": [
              {
                "name": "Slack"
              }
            ]
          },
          {
            "title": "Slack for your belief system",
            "tags": [
              {
                "name": "Slack"
              }
            ]
          },
          {
            "title": "Sacred Cash",
            "tags": [
              {
                "name": "Slack"
              },
              {
                "name": "Social & Cultural Dynamics"
              }
            ]
          },
          {
            "title": "Guarding Slack vs Substance",
            "tags": [
              {
                "name": "Slack"
              },
              {
                "name": "Goodhart's Law"
              }
            ]
          },
          {
            "title": "The Amish, and Strategic Norms around Technology",
            "tags": [
              {
                "name": "Book Reviews"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "ZNNi2uNx9E6iwGKKG",
    "title": "Introduction to Game Theory",
    "curatedOrder": 1,
    "contents": {
      "markdown": "This sequence of posts is a primer on game theory intended at an introductory level. Because it is introductory, Less Wrong veterans may find some parts boring, obvious, or simplistic - although hopefully nothing is so simplistic as to be outright wrong.\n\nParts of this sequence draw heavily upon material from _[The Art of Strategy](http://www.amazon.com/The-Art-Strategy-Theorists-Business/dp/0393062430)_ by Avinash Dixit and Barry Nalebuff, and it may in part be considered a (very favorable) review of the book accompanied by an exploration of its content. I have tried to include enough material to be useful, but not so much material that it becomes a plagiarism rather than a review (it's probably a bad idea to pick a legal fight with people who write books called _The Art of Strategy_.) Therefore, for the most complete and engaging presentation of this material, I highly recommend the original book.\n\nSpecial thanks to Luke for his book recommendation and his strong encouragement to write this."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Backward Reasoning Over Decision Trees",
            "tags": [
              {
                "name": "Game Theory"
              }
            ]
          },
          {
            "title": "Nash Equilibria and Schelling Points",
            "tags": [
              {
                "name": "Game Theory"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Introduction to Prisoners' Dilemma",
            "tags": [
              {
                "name": "Game Theory"
              },
              {
                "name": "Prisoner's Dilemma"
              }
            ]
          },
          {
            "title": "Real World Solutions to Prisoners' Dilemmas",
            "tags": [
              {
                "name": "Game Theory"
              },
              {
                "name": "Prisoner's Dilemma"
              }
            ]
          },
          {
            "title": "Interlude for Behavioral Economics",
            "tags": [
              {
                "name": "Game Theory"
              }
            ]
          },
          {
            "title": "What Is Signaling, Really?",
            "tags": [
              {
                "name": "Signaling"
              },
              {
                "name": "Game Theory"
              }
            ]
          },
          {
            "title": "Bargaining and Auctions",
            "tags": [
              {
                "name": "Game Theory"
              }
            ]
          },
          {
            "title": "Imperfect Voting Systems",
            "tags": [
              {
                "name": "Voting Theory"
              },
              {
                "name": "Game Theory"
              }
            ]
          },
          {
            "title": "Game Theory As A Dark Art",
            "tags": [
              {
                "name": "Game Theory"
              },
              {
                "name": "Dark Arts"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "HcMcHb6Cz7R9RdC5D",
    "title": "Hufflepuff Cynicism",
    "curatedOrder": null,
    "contents": {
      "markdown": "I describe a position which I call Hufflepuff Cynicism. This position is a _possible_ response to the contradictions inherent in dealing with an irrational and disingenuous world. Perhaps not the _best_ response. It does resolve certain problems, though."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Hufflepuff Cynicism",
            "tags": [
              {
                "name": "Community"
              },
              {
                "name": "Honesty"
              },
              {
                "name": "Social Reality"
              },
              {
                "name": "Simulacrum Levels"
              }
            ]
          },
          {
            "title": "Hufflepuff Cynicism on Crocker's Rule",
            "tags": [
              {
                "name": "Conversation (topic)"
              },
              {
                "name": "Communication Cultures"
              },
              {
                "name": "Disagreement"
              }
            ]
          },
          {
            "title": "Hufflepuff Cynicism on Hypocrisy",
            "tags": [
              {
                "name": "Hypocrisy"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "aoLetzM8xnBPqKBGj",
    "title": "Tensions in Truthseeking",
    "curatedOrder": null,
    "contents": {
      "markdown": "Why did LessWrong 1.0 die? Why has much progress since then happened in more private venues? Why do people who seem to earnestly care about truth keep talking past each other, or viewing each other with distrust?\n\nThis sequence is me working through a lot of those questions, ultimately trying to answer a question: how do we build a platform enabling intellectual progress?"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Tensions in Truthseeking ",
            "tags": [
              {
                "name": "Group Rationality"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "The Archipelago Model of Community Standards",
            "tags": [
              {
                "name": "Group Rationality"
              },
              {
                "name": "Community"
              }
            ]
          },
          {
            "title": "Musings on Double Crux (and \"Productive Disagreement\")",
            "tags": [
              {
                "name": "Double-Crux"
              }
            ]
          },
          {
            "title": "Common vs Expert Jargon ",
            "tags": [
              {
                "name": "Conversation (topic)"
              },
              {
                "name": "Terminology / Jargon (meta)"
              },
              {
                "name": "Distinctions"
              }
            ]
          },
          {
            "title": "Writing That Provokes Comments",
            "tags": [
              {
                "name": "Writing (communication method)"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Writing Down Conversations",
            "tags": [
              {
                "name": "Conversation (topic)"
              },
              {
                "name": "Writing (communication method)"
              }
            ]
          },
          {
            "title": "Demon Threads",
            "tags": [
              {
                "name": "Communication Cultures"
              },
              {
                "name": "Eldritch Analogies"
              },
              {
                "name": "Demon Threads"
              },
              {
                "name": "Moderation (topic)"
              }
            ]
          },
          {
            "title": "Taking it Private: Short Circuiting Demon Threads (working example)",
            "tags": [
              {
                "name": "Disagreement"
              },
              {
                "name": "Communication Cultures"
              },
              {
                "name": "Demon Threads"
              }
            ]
          },
          {
            "title": "Meta-tations on Moderation: Towards Public Archipelago",
            "tags": [
              {
                "name": "Site Meta"
              },
              {
                "name": "Community"
              },
              {
                "name": "Conversation (topic)"
              },
              {
                "name": "Disagreement"
              },
              {
                "name": "LW Moderation"
              },
              {
                "name": "Moderation (topic)"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "4C33PKt2cQdA7oyfJ",
    "title": "Murphy's Quest",
    "curatedOrder": null,
    "contents": {
      "markdown": "_Everything that can go wrong will go wrong._\n\nHuge props to lifelonglearner for cover art.\n\nFull text available in [PDF](https://radimentary.files.wordpress.com/2018/03/murphys-quest1.pdf)."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Murphy’s Quest Ch 1: Exposure Therapy",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Humor"
              }
            ]
          },
          {
            "title": "Murphy’s Quest Ch 2: Empiricism",
            "tags": [
              {
                "name": "Empiricism"
              }
            ]
          },
          {
            "title": "Murphy’s Quest Ch 3: Murphyjitsu",
            "tags": [
              {
                "name": "Murphyjitsu"
              },
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Murphy’s Quest Ch 4: Noticing Confusion",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Humor"
              }
            ]
          },
          {
            "title": "Murphy’s Quest Ch 5: Fail Gracefully",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Murphy’s Quest Ch 6: Perverse Incentives",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Murphy’s Quest Ch 7: Outside the Box",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Murphy’s Quest Ch 8: False Pentachotomy",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Humor"
              }
            ]
          },
          {
            "title": "Murphy’s Quest Ch 9: Double Crux",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Murphy’s Quest Ch 10: Gears-Like Models",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Murphy’s Quest Ch 11: Resolve",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Murphy’s Quest Ch 12: Meta-Contrarianism",
            "tags": [
              {
                "name": "Contrarianism"
              }
            ]
          },
          {
            "title": "Murphy’s Quest Ch 13: Existential Risk",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Murphy’s Quest Postmorterm",
            "tags": [
              {
                "name": "Postmortems & Retrospectives"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "ynMFrq9K5iNMfSZNg",
    "title": "Living Luminously",
    "curatedOrder": 0,
    "contents": {
      "markdown": "[Luminosity](https://wiki.lesswrong.com/wiki/Luminosity), as used here, is self-awareness. A luminous mental state is one that you have and know that you have. It could be an [emotion](https://wiki.lesswrong.com/wiki/Emotion), a [belief](https://wiki.lesswrong.com/wiki/Belief) or [alief](https://wiki.lesswrong.com/wiki/Alief), a disposition, a [quale](https://wiki.lesswrong.com/index.php?title=Qualia&action=edit&redlink=1), a memory - anything that might happen or be stored in your brain. What's going on in your head?"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": []
      },
      {
        "title": "Background Material",
        "subtitle": null,
        "number": 0,
        "contents": null,
        "posts": [
          {
            "title": "Sorting Out Sticky Brains",
            "tags": [
              {
                "name": "Alief"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Mental Crystallography",
            "tags": [
              {
                "name": "Inferential Distance"
              }
            ]
          },
          {
            "title": "Generalizing From One Example",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Inferential Distance"
              },
              {
                "name": "Fallacies"
              },
              {
                "name": "Typical Mind Fallacy"
              },
              {
                "name": "Psychiatry"
              }
            ]
          }
        ]
      },
      {
        "title": "Living Luminously",
        "subtitle": null,
        "number": 1,
        "contents": null,
        "posts": [
          {
            "title": "Living Luminously",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "Introspection"
              },
              {
                "name": "Alief"
              },
              {
                "name": "Luminosity"
              }
            ]
          },
          {
            "title": "You Are Likely To Be Eaten By A Grue",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Introspection"
              },
              {
                "name": "Luminosity"
              }
            ]
          },
          {
            "title": "Let There Be Light",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Introspection"
              }
            ]
          },
          {
            "title": "The ABC's of Luminosity",
            "tags": [
              {
                "name": "Introspection"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Luminosity"
              }
            ]
          },
          {
            "title": "Lights, Camera, Action!",
            "tags": [
              {
                "name": "Introspection"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "The Spotlight",
            "tags": [
              {
                "name": "Introspection"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Highlights and Shadows",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Introspection"
              }
            ]
          },
          {
            "title": "City of Lights",
            "tags": [
              {
                "name": "Subagents"
              },
              {
                "name": "Introspection"
              },
              {
                "name": "Internal Family Systems"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Lampshading",
            "tags": [
              {
                "name": "Introspection"
              },
              {
                "name": "Rationality"
              }
            ]
          }
        ]
      },
      {
        "title": "Bonus Posts",
        "subtitle": null,
        "number": 2,
        "contents": null,
        "posts": [
          {
            "title": "Ureshiku Naritai",
            "tags": [
              {
                "name": "Emotions"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Well-being"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Happiness"
              },
              {
                "name": "Reset (technique)"
              }
            ]
          },
          {
            "title": "A Suite of Pragmatic Considerations in Favor of Niceness",
            "tags": [
              {
                "name": "Emotions"
              },
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Community"
              },
              {
                "name": "Group Rationality"
              },
              {
                "name": "Virtues"
              }
            ]
          },
          {
            "title": "On Enjoying Disagreeable Company",
            "tags": [
              {
                "name": "Relationships (Interpersonal)"
              },
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Happiness"
              }
            ]
          },
          {
            "title": "Seven Shiny Stories",
            "tags": [
              {
                "name": "Subagents"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "G2GDw3m4MJ5ixSM92",
    "title": "The Blue-Minimizing Robot",
    "curatedOrder": 1,
    "contents": {
      "markdown": "A sequence on models of the human mind, drawing on psychology and neuroscience to discuss motivation, learning and behaviour."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": []
      },
      {
        "title": null,
        "subtitle": null,
        "number": 0,
        "contents": null,
        "posts": [
          {
            "title": "The Blue-Minimizing Robot",
            "tags": [
              {
                "name": "Motivations"
              },
              {
                "name": "Robotics"
              },
              {
                "name": "Ontological Crisis"
              }
            ]
          },
          {
            "title": "Basics of Animal Reinforcement",
            "tags": [
              {
                "name": "Psychology"
              }
            ]
          },
          {
            "title": "Basics of Human Reinforcement",
            "tags": [
              {
                "name": "Psychology"
              }
            ]
          },
          {
            "title": "Time and Effort Discounting",
            "tags": [
              {
                "name": "Utility Functions"
              }
            ]
          },
          {
            "title": "Wanting vs. Liking Revisited",
            "tags": [
              {
                "name": "Happiness"
              },
              {
                "name": "Psychology"
              },
              {
                "name": "Cognitive Science"
              },
              {
                "name": "Distinctions"
              }
            ]
          },
          {
            "title": "Prospect Theory: A Framework for Understanding Cognitive Biases",
            "tags": [
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Physical and Mental Behavior",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Motivations"
              },
              {
                "name": "Anticipated Experiences"
              }
            ]
          },
          {
            "title": "Voluntary Behavior, Conscious Thoughts",
            "tags": [
              {
                "name": "Psychology"
              },
              {
                "name": "Consciousness"
              }
            ]
          },
          {
            "title": "Trivers on Self-Deception",
            "tags": [
              {
                "name": "Self-Deception"
              },
              {
                "name": "Evolutionary Psychology"
              },
              {
                "name": "Signaling"
              }
            ]
          },
          {
            "title": "To what degree do we have goals?",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Motivations"
              }
            ]
          },
          {
            "title": "The limits of introspection",
            "tags": [
              {
                "name": "Introspection"
              }
            ]
          },
          {
            "title": "Ego syntonic thoughts and values",
            "tags": [
              {
                "name": "Motivations"
              }
            ]
          },
          {
            "title": "Approving reinforces low-effort behaviors",
            "tags": [
              {
                "name": "Modeling People"
              }
            ]
          },
          {
            "title": "Connectionism: Modeling the mind with neural networks",
            "tags": [
              {
                "name": "Neuroscience"
              },
              {
                "name": "Machine Learning  (ML)"
              }
            ]
          },
          {
            "title": "Secrets of the eliminati",
            "tags": [
              {
                "name": "Goal Factoring"
              },
              {
                "name": "Motivations"
              }
            ]
          },
          {
            "title": "Tendencies in reflective equilibrium",
            "tags": [
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Utility Functions"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "qRxTKm7DAftSuTGvj",
    "title": "Hammertime",
    "curatedOrder": null,
    "contents": {
      "markdown": "_If all you have is a hammer, everything looks like a nail._\n\nThirty days of instrumental rationality practice.\n\nKey word: systematic."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": 0,
        "contents": null,
        "posts": [
          {
            "title": "Hammers and Nails",
            "tags": [
              {
                "name": "Techniques"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "More Dakka"
              },
              {
                "name": "Taking Ideas Seriously"
              }
            ]
          },
          {
            "title": "Hammertime Day 1: Bug Hunt",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "Self Experimentation"
              },
              {
                "name": "Exercises / Problem-Sets"
              },
              {
                "name": "Life Improvements"
              }
            ]
          },
          {
            "title": "Hammertime Day 2: Yoda Timers",
            "tags": [
              {
                "name": "Five minute timers"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Exercises / Problem-Sets"
              }
            ]
          },
          {
            "title": "Hammertime Day 3: TAPs",
            "tags": [
              {
                "name": "Summoning Sapience"
              },
              {
                "name": "Trigger-Action Planning"
              },
              {
                "name": "Exercises / Problem-Sets"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Hammertime Day 4: Design",
            "tags": [
              {
                "name": "Exercises / Problem-Sets"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Five minute timers"
              },
              {
                "name": "Intentionality"
              }
            ]
          },
          {
            "title": "Hammertime Day 5: Comfort Zone Expansion",
            "tags": [
              {
                "name": "Comfort Zone Expansion (CoZE)"
              },
              {
                "name": "Exercises / Problem-Sets"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Hammertime Day 6: Mantras",
            "tags": [
              {
                "name": "Litanies & Mantras"
              },
              {
                "name": "Exercises / Problem-Sets"
              }
            ]
          },
          {
            "title": "Hammertime Day 7: Aversion Factoring",
            "tags": [
              {
                "name": "Goal Factoring"
              },
              {
                "name": "Exercises / Problem-Sets"
              }
            ]
          },
          {
            "title": "Hammertime Day 8: Sunk Cost Faith",
            "tags": [
              {
                "name": "Sunk-Cost Fallacy"
              },
              {
                "name": "Exercises / Problem-Sets"
              }
            ]
          },
          {
            "title": "Hammertime Day 9: Time Calibration",
            "tags": [
              {
                "name": "Exercises / Problem-Sets"
              },
              {
                "name": "Calibration"
              }
            ]
          },
          {
            "title": "Hammertime Day 10: Murphyjitsu",
            "tags": [
              {
                "name": "Murphyjitsu"
              },
              {
                "name": "Exercises / Problem-Sets"
              },
              {
                "name": "Inner Simulator / Suprise-o-meter"
              }
            ]
          },
          {
            "title": "Hammertime Intermission and Open Thread",
            "tags": [
              {
                "name": "Open Threads"
              }
            ]
          },
          {
            "title": "Bug Hunt 2",
            "tags": [
              {
                "name": "Pica"
              },
              {
                "name": "Ambition"
              },
              {
                "name": "Exercises / Problem-Sets"
              }
            ]
          },
          {
            "title": "Yoda Timers 2",
            "tags": [
              {
                "name": "Five minute timers"
              },
              {
                "name": "Exercises / Problem-Sets"
              }
            ]
          },
          {
            "title": "TAPs 2",
            "tags": [
              {
                "name": "Trigger-Action Planning"
              },
              {
                "name": "Exercises / Problem-Sets"
              },
              {
                "name": "Summoning Sapience"
              }
            ]
          },
          {
            "title": "Design 2",
            "tags": [
              {
                "name": "Exercises / Problem-Sets"
              }
            ]
          },
          {
            "title": "CoZE 2",
            "tags": [
              {
                "name": "Comfort Zone Expansion (CoZE)"
              },
              {
                "name": "Exercises / Problem-Sets"
              },
              {
                "name": "Try Things"
              }
            ]
          },
          {
            "title": "Three Miniatures",
            "tags": [
              {
                "name": "Exercises / Problem-Sets"
              }
            ]
          },
          {
            "title": "Focusing",
            "tags": [
              {
                "name": "Focusing"
              },
              {
                "name": "Exercises / Problem-Sets"
              }
            ]
          },
          {
            "title": "Goal Factoring",
            "tags": [
              {
                "name": "Goal Factoring"
              },
              {
                "name": "Exercises / Problem-Sets"
              }
            ]
          },
          {
            "title": "TDT for Humans",
            "tags": [
              {
                "name": "Decision Theory"
              },
              {
                "name": "Subagents"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Planning & Decision-Making"
              },
              {
                "name": "Exercises / Problem-Sets"
              }
            ]
          },
          {
            "title": "Friendship",
            "tags": [
              {
                "name": "Relationships (Interpersonal)"
              },
              {
                "name": "Exercises / Problem-Sets"
              }
            ]
          },
          {
            "title": "Hammertime Intermission #2",
            "tags": [
              {
                "name": "Open Threads"
              }
            ]
          },
          {
            "title": "Bug Hunt 3",
            "tags": [
              {
                "name": "Hamming Questions"
              },
              {
                "name": "Exercises / Problem-Sets"
              }
            ]
          },
          {
            "title": "Yoda Timers 3: Speed",
            "tags": [
              {
                "name": "Five minute timers"
              },
              {
                "name": "Exercises / Problem-Sets"
              }
            ]
          },
          {
            "title": "TAPs 3: Reductionism",
            "tags": [
              {
                "name": "Trigger-Action Planning"
              },
              {
                "name": "Exercises / Problem-Sets"
              }
            ]
          },
          {
            "title": "Design 3: Intentionality",
            "tags": [
              {
                "name": "Exercises / Problem-Sets"
              }
            ]
          },
          {
            "title": "CoZE 3: Empiricism",
            "tags": [
              {
                "name": "Exercises / Problem-Sets"
              },
              {
                "name": "Empiricism"
              }
            ]
          },
          {
            "title": "Silence",
            "tags": [
              {
                "name": "Subagents"
              },
              {
                "name": "Introspection"
              },
              {
                "name": "Pica"
              },
              {
                "name": "Consciousness"
              },
              {
                "name": "Exercises / Problem-Sets"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Virtues"
              }
            ]
          },
          {
            "title": "Internal Double Crux",
            "tags": [
              {
                "name": "Focusing"
              },
              {
                "name": "Internal Double Crux"
              },
              {
                "name": "Exercises / Problem-Sets"
              },
              {
                "name": "Techniques"
              }
            ]
          },
          {
            "title": "Reductionism Revisited",
            "tags": [
              {
                "name": "Reductionism"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Techniques"
              },
              {
                "name": "Procrastination"
              }
            ]
          },
          {
            "title": "The Strategic Level",
            "tags": [
              {
                "name": "Exercises / Problem-Sets"
              }
            ]
          },
          {
            "title": "Hammertime Final Exam",
            "tags": [
              {
                "name": "Center for Applied Rationality (CFAR)"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Exercises / Problem-Sets"
              }
            ]
          },
          {
            "title": "Hammertime Postmortem",
            "tags": [
              {
                "name": "Postmortems & Retrospectives"
              },
              {
                "name": "Practical"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "pC6DYFLPMTCbEwH8W",
    "title": "Babble and Prune",
    "curatedOrder": 1,
    "contents": {
      "markdown": "How do babies learn language? How did Moses compute the ten Commandments? How did Shakespeare write _Hamlet_?\n\nBabble and Prune is an ancient mythological story, a psychological model, a new religion for a post-religion age, that answers all these questions and more.\n\nTwo Gods - Babble and Prune, Artist and Critic, Generator and Discriminator - are locked in eternal conflict over your mind. Babble creates a constant stream of coarse material, while Prune cuts these ideas harshly without the slightest hint of remorse. Only you, chosen hero, can restore the balance between these two ancient deities, and in doing so maximize your creative output.\n\nIt is time to reclaim your birthright, hero: go forth and babble!"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": []
      },
      {
        "title": null,
        "subtitle": null,
        "number": 0,
        "contents": null,
        "posts": [
          {
            "title": "Babble",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Poetry"
              },
              {
                "name": "Babble and Prune"
              }
            ]
          },
          {
            "title": "More Babble",
            "tags": [
              {
                "name": "Babble and Prune"
              }
            ]
          },
          {
            "title": "Prune",
            "tags": [
              {
                "name": "Babble and Prune"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Subagents"
              }
            ]
          },
          {
            "title": "Circumambulation",
            "tags": [
              {
                "name": "Babble and Prune"
              }
            ]
          },
          {
            "title": "Write",
            "tags": [
              {
                "name": "Babble and Prune"
              },
              {
                "name": "Writing (communication method)"
              },
              {
                "name": "Scholarship & Learning"
              },
              {
                "name": "Note-Taking"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "oyZGWX9WkgWzEDt6M",
    "title": "Project Hufflepuff",
    "curatedOrder": null,
    "contents": {
      "markdown": "\"_Clever kids in Ravenclaw, evil kids in Slytherin, wannabe heroes in Gryffindor, and everyone who does the actual work in Hufflepuff.”_\n\nIn 2016, it seemed to me that the rationality community tended to miss some cluster of skills that pattern matched to \"things Hufflepuffs are good at\" - comradery, reliability, trustworthiness, willingness to do physical work, willingness to stick with things for a long time, etc.\n\nIt seemed like we not only weren't very good at this on average, but that something actively filters this sort of person away. So I wanted to paint a vision of what it meant to be a _rationalist hufflepuff_, who embodied the virtues in the original sequences while _also_ being the sort of person able to be deeply reliable.\n\nAs of 2018, I've refactored this vision a bit, but I think it still contains a lot of useful insights. Everything I thought then I still think now, but rather than the solution being a \"and therefore, Project Hufflepuff\", the solution is \"and therefore, Public Archipelago\". (Where my island in the archipelago will expect people to be leveling up at conscientiousness and trustworthiness, as well as truthseeking and agency)"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Project Hufflepuff: Planting the Flag",
            "tags": [
              {
                "name": "Community"
              }
            ]
          },
          {
            "title": "What exactly is the \"Rationality Community?\"",
            "tags": [
              {
                "name": "Community"
              }
            ]
          },
          {
            "title": "Straw Hufflepuffs and Lone Heroes",
            "tags": [
              {
                "name": "Community"
              }
            ]
          },
          {
            "title": "Background Reading: The Real Hufflepuff Sequence Was The Posts We Made Along The Way",
            "tags": [
              {
                "name": "Community"
              },
              {
                "name": "Communication Cultures"
              }
            ]
          },
          {
            "title": "Notes from the Hufflepuff Unconference",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "Community"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "SqFbMbtxGybdS2gRs",
    "title": "Highly Advanced Epistemology 101 for Beginners",
    "curatedOrder": 1,
    "contents": {
      "markdown": "These essays include a discussion of truth, formal logic, causality, and metaethics, and are a good way for more ambitious readers to quickly get up to speed."
    },
    "chapters": [
      {
        "title": "Introduction",
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "The Useful Idea of Truth",
            "tags": [
              {
                "name": "Mind Projection Fallacy"
              },
              {
                "name": "Causality"
              },
              {
                "name": "Definitions"
              },
              {
                "name": "Truth, Semantics, & Meaning"
              },
              {
                "name": "Map and Territory"
              }
            ]
          },
          {
            "title": "Skill: The Map is Not the Territory",
            "tags": [
              {
                "name": "Map and Territory"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Distinctions"
              }
            ]
          },
          {
            "title": "Rationality: Appreciating Cognitive Algorithms",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Alief"
              },
              {
                "name": "Truth, Semantics, & Meaning"
              }
            ]
          },
          {
            "title": "Firewalling the Optimal from the Rational",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Community"
              },
              {
                "name": "Pitfalls of Rationality"
              },
              {
                "name": "Distinctions"
              }
            ]
          }
        ]
      },
      {
        "title": "Physics and Causality",
        "subtitle": null,
        "number": 1,
        "contents": null,
        "posts": [
          {
            "title": "The Fabric of Real Things",
            "tags": [
              {
                "name": "Truth, Semantics, & Meaning"
              },
              {
                "name": "Philosophy of Language"
              }
            ]
          },
          {
            "title": "Causal Diagrams and Causal Models",
            "tags": [
              {
                "name": "Causality"
              }
            ]
          },
          {
            "title": "Stuff That Makes Stuff Happen",
            "tags": [
              {
                "name": "Causality"
              }
            ]
          },
          {
            "title": "Causal Reference",
            "tags": [
              {
                "name": "Causality"
              }
            ]
          },
          {
            "title": "Causal Universes",
            "tags": [
              {
                "name": "Causality"
              }
            ]
          }
        ]
      },
      {
        "title": "Mathematics and Logic",
        "subtitle": null,
        "number": 2,
        "contents": null,
        "posts": [
          {
            "title": "Proofs, Implications, and Models",
            "tags": [
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "Social Reality"
              },
              {
                "name": "Disagreement"
              },
              {
                "name": "Formal Proof"
              }
            ]
          },
          {
            "title": "Logical Pinpointing",
            "tags": [
              {
                "name": "Truth, Semantics, & Meaning"
              },
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "Dialogue (format)"
              }
            ]
          },
          {
            "title": "Standard and Nonstandard Numbers",
            "tags": [
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "Dialogue (format)"
              }
            ]
          },
          {
            "title": "Godel's Completeness and Incompleteness Theorems",
            "tags": [
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "Gödelian Logic"
              }
            ]
          },
          {
            "title": "Second-Order Logic: The Controversy",
            "tags": [
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "Gödelian Logic"
              }
            ]
          }
        ]
      },
      {
        "title": "Mixed Reference",
        "subtitle": null,
        "number": 3,
        "contents": null,
        "posts": [
          {
            "title": "Mixed Reference: The Great Reductionist Project",
            "tags": [
              {
                "name": "Truth, Semantics, & Meaning"
              },
              {
                "name": "Epistemology"
              },
              {
                "name": "Map and Territory"
              },
              {
                "name": "Reductionism"
              }
            ]
          },
          {
            "title": "By Which It May Be Judged",
            "tags": [
              {
                "name": "Map and Territory"
              },
              {
                "name": "Truth, Semantics, & Meaning"
              },
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "Epistemology"
              },
              {
                "name": "Fairness"
              },
              {
                "name": "Metaethics"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "9rRrzkBaXcivjZtZS",
    "title": "Instrumental Rationality",
    "curatedOrder": null,
    "contents": {
      "markdown": "A combination of evidence-backed techniques and more speculative essays, all focused on bringing rationality to practical everday uses. In particular, the sequence features two in-depth primers on the current psychological literature on planning and habits."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Instrumental Rationality 1: Starting Advice",
            "tags": []
          },
          {
            "title": "Instrumental Rationality 2: Planning 101",
            "tags": [
              {
                "name": "Planning & Decision-Making"
              },
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Inside/Outside View"
              },
              {
                "name": "Murphyjitsu"
              }
            ]
          },
          {
            "title": "Instrumental Rationality 3: Interlude I ",
            "tags": []
          },
          {
            "title": "Instrumental Rationality 4.1: Modeling Habits",
            "tags": []
          },
          {
            "title": "Instrumental Rationality 4.2: Creating Habits",
            "tags": [
              {
                "name": "Trigger-Action Planning"
              }
            ]
          },
          {
            "title": "Instrumental Rationality 4.3: Breaking Habits and Conclusion",
            "tags": []
          },
          {
            "title": "Instrumental Rationality 5: Interlude II",
            "tags": []
          },
          {
            "title": "Instrumental Rationality 6: Attractor Theory",
            "tags": []
          },
          {
            "title": "Instrumental Rationality 7: Closing Disclaimer",
            "tags": []
          },
          {
            "title": "Instrumental Rationality: Postmortem",
            "tags": [
              {
                "name": "Postmortems & Retrospectives"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "cuFK7pjwdDEoQewid",
    "title": "Philosophy Corner",
    "curatedOrder": null,
    "contents": {
      "markdown": "Regular posts on topics I think are interesting from a LW perspective."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Philosophy of Numbers (part 1)",
            "tags": [
              {
                "name": "Truth, Semantics, & Meaning"
              },
              {
                "name": "Philosophy"
              },
              {
                "name": "Logic & Mathematics "
              }
            ]
          },
          {
            "title": "Philosophy of Numbers (part 2)",
            "tags": [
              {
                "name": "Truth, Semantics, & Meaning"
              },
              {
                "name": "Philosophy"
              },
              {
                "name": "Logic & Mathematics "
              }
            ]
          },
          {
            "title": "Dan Dennett on Stances ",
            "tags": []
          },
          {
            "title": "Empirical philosophy and inversions",
            "tags": [
              {
                "name": "Philosophy"
              },
              {
                "name": "Consciousness"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "3bbvzoRA8n6ZgbiyK",
    "title": "Rational Ritual",
    "curatedOrder": null,
    "contents": {
      "markdown": "Ritual and rationality are often seen in opposition. This is for good reason - ritual can reinforce beliefs if used carelessly. But rituals and traditions are also an important part of the human experience, which we needn't sacrifice if we're thoughtful about it."
    },
    "chapters": [
      {
        "title": "Winter Solstice",
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": "On the longest night of year, reflect upon humanity's journey.\n\n_Once upon a time there was darkness, and so we created light._  \n_Once upon a time there was cold, and so we created shelter and heat._  \n_Once upon a time there was hunger, and so we developed agriculture._  \n_Once upon a time there was disease, and so we developed medicine._  \n_Once upon a time there was suffering, and so we helped, as best we could._\n\n_There is still hunger and sickness and suffering. Our work is not yet done._\n\n_But we have come far. And tonight, we gather to celebrate the story of humanity._"
        },
        "posts": [
          {
            "title": "On Rationalist Solstice and Epistemic Caution",
            "tags": [
              {
                "name": "Secular Solstice"
              },
              {
                "name": "Ritual"
              }
            ]
          },
          {
            "title": "Ritual Report: NYC Less Wrong Solstice Celebration",
            "tags": [
              {
                "name": "Secular Solstice"
              },
              {
                "name": "Community"
              },
              {
                "name": "Ritual"
              }
            ]
          },
          {
            "title": "The Value (and Danger) of Ritual",
            "tags": [
              {
                "name": "Ritual"
              },
              {
                "name": "Secular Solstice"
              }
            ]
          },
          {
            "title": "Designing Ritual",
            "tags": [
              {
                "name": "Ritual"
              },
              {
                "name": "Secular Solstice"
              },
              {
                "name": "Community"
              }
            ]
          },
          {
            "title": "Clumping Solstice Singalongs in Groups of 2-4",
            "tags": [
              {
                "name": "Secular Solstice"
              },
              {
                "name": "Community"
              },
              {
                "name": "Music"
              }
            ]
          },
          {
            "title": "Ritual Report 2012: Life, Death, Light, Darkness, and Love.",
            "tags": [
              {
                "name": "Secular Solstice"
              }
            ]
          },
          {
            "title": "Solstice 2015: What Memes May Come? (Part I)",
            "tags": [
              {
                "name": "Secular Solstice"
              }
            ]
          },
          {
            "title": "Solstice 2015: What Memes May Come (Part II - Atheism, Rationality and Death)",
            "tags": [
              {
                "name": "Secular Solstice"
              }
            ]
          }
        ]
      },
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": []
      },
      {
        "title": "Summer Solstice",
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": "On the longest day of the year, celebrate everything glorious about being an embodied human in the here-and-now. Explore. Build. Make Art.\n\nFind your way to the top of the world or the edge of the world. As sun sets, look out upon the beauty around you."
        },
        "posts": [
          {
            "title": "The Summer Solstice Paradox",
            "tags": [
              {
                "name": "Secular Solstice"
              },
              {
                "name": "Ritual"
              }
            ]
          },
          {
            "title": "Visions of Summer Solstice",
            "tags": [
              {
                "name": "Secular Solstice"
              },
              {
                "name": "Ritual"
              }
            ]
          },
          {
            "title": "Stories of Summer Solstice ",
            "tags": [
              {
                "name": "Secular Solstice"
              },
              {
                "name": "Ritual"
              }
            ]
          }
        ]
      },
      {
        "title": "Other Ritual",
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Funeral Ritual",
            "tags": [
              {
                "name": "Ritual"
              },
              {
                "name": "Grieving"
              },
              {
                "name": "Death"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "yFvZa9wkv5JoqhM8F",
    "title": "Rationality and Philosophy",
    "curatedOrder": 1,
    "contents": {
      "markdown": "A sequence examining the implications of rationality and cognitive science for philosophical method."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Less Wrong Rationality and Mainstream Philosophy",
            "tags": [
              {
                "name": "Site Meta"
              },
              {
                "name": "Scholarship & Learning"
              },
              {
                "name": "Philosophy"
              }
            ]
          },
          {
            "title": "Philosophy: A Diseased Discipline",
            "tags": [
              {
                "name": "Philosophy"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "How You Make Judgments: The Elephant and its Rider",
            "tags": [
              {
                "name": "Dual Process Theory (System 1 & System 2)"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Heuristics & Biases"
              }
            ]
          },
          {
            "title": "Your Evolved Intuitions",
            "tags": [
              {
                "name": "Evolution"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Intuition"
              }
            ]
          },
          {
            "title": "Intuition and Unconscious Learning",
            "tags": [
              {
                "name": "Intuition"
              }
            ]
          },
          {
            "title": "When Intuitions Are Useful",
            "tags": [
              {
                "name": "Intuition"
              }
            ]
          },
          {
            "title": "Concepts Don't Work That Way",
            "tags": [
              {
                "name": "Philosophy"
              },
              {
                "name": "Cognitive Science"
              },
              {
                "name": "History"
              },
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Book Reviews"
              }
            ]
          },
          {
            "title": "Living Metaphorically",
            "tags": [
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Philosophy"
              },
              {
                "name": "Cognitive Science"
              }
            ]
          },
          {
            "title": "Intuitions Aren't Shared That Way",
            "tags": [
              {
                "name": "Intuition"
              }
            ]
          },
          {
            "title": "Philosophy Needs to Trust Your Rationality Even Though It Shouldn't",
            "tags": [
              {
                "name": "Philosophy"
              }
            ]
          },
          {
            "title": "Train Philosophers with Pearl and Kahneman, not Plato and Kant",
            "tags": [
              {
                "name": "Philosophy"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "XipJ7DMjYyriAm7fr",
    "title": "Decision Theory: Newcomb's Problem",
    "curatedOrder": 1,
    "contents": {
      "markdown": "Decisions need to be modeled with some structure in order to be scrutinized and systematically improved; simply \"intuiting\" the answers to decision problems by ad-hoc methods is not conducive to thorough analysis.\n\nFor this, we formulate decision theories. This sequence, themed with an analysis of Newcomb's problem, is a consolidated summary and context for the many decision theory discussions found on LessWrong at the time of writing."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Decision theory: An outline of some upcoming posts",
            "tags": [
              {
                "name": "Decision Theory"
              }
            ]
          },
          {
            "title": "Confusion about Newcomb is confusion about counterfactuals",
            "tags": [
              {
                "name": "Decision Theory"
              },
              {
                "name": "Newcomb's Problem"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Decision theory: Why we need to reduce “could”, “would”, “should”",
            "tags": [
              {
                "name": "Decision Theory"
              }
            ]
          },
          {
            "title": "Decision theory: Why Pearl helps reduce “could” and “would”, but still leaves us with at least three alternatives",
            "tags": [
              {
                "name": "Decision Theory"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "oi873FWi6pHWxswSa",
    "title": "The Science of Winning at Life",
    "curatedOrder": 1,
    "contents": {
      "markdown": "A [sequence](https://wiki.lesswrong.com/wiki/Sequence) summarizing scientifically-backed advice for \"[winning](https://wiki.lesswrong.com/wiki/Winning)\" at everyday life: in one's productivity, in one's relationships, in one's emotions, etc. Each post concludes with footnotes and a long list of references from the academic literature."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Scientific Self-Help: The State of Our Knowledge",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "Well-being"
              },
              {
                "name": "Happiness"
              }
            ]
          },
          {
            "title": "How to Beat Procrastination",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "Akrasia"
              },
              {
                "name": "Procrastination"
              },
              {
                "name": "Self Improvement"
              },
              {
                "name": "Productivity"
              }
            ]
          },
          {
            "title": "My Algorithm for Beating Procrastination",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "Akrasia"
              },
              {
                "name": "Procrastination"
              },
              {
                "name": "Algorithms"
              }
            ]
          },
          {
            "title": "How to Be Happy",
            "tags": [
              {
                "name": "Well-being"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Gratitude"
              },
              {
                "name": "Happiness"
              }
            ]
          },
          {
            "title": "The Good News of Situationist Psychology",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Heuristics & Biases"
              }
            ]
          },
          {
            "title": "The Power of Reinforcement",
            "tags": [
              {
                "name": "Mechanism Design"
              },
              {
                "name": "Emotions"
              },
              {
                "name": "Conversation (topic)"
              },
              {
                "name": "Neuroscience"
              }
            ]
          },
          {
            "title": "Rational Romantic Relationships, Part 1: Relationship Styles and Attraction Basics",
            "tags": [
              {
                "name": "Relationships (Interpersonal)"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "bQgRsy23biR52poMf",
    "title": "No-Nonsense Metaethics",
    "curatedOrder": 1,
    "contents": {
      "markdown": "Years ago, I wrote an unfinished sequence of posts called \"[No-Nonsense Metaethics](https://wiki.lesswrong.com/wiki/No-Nonsense_Metaethics).\" My last post, [Pluralistic Moral Reductionism](https://www.lesserwrong.com/posts/3zDX3f3QTepNeZHGc/pluralistic-moral-reductionism), said I would next explore \"empathic metaethics,\" but I never got around to writing those posts. Recently, I wrote a high-level summary of some initial thoughts on \"empathic metaethics\" in [section 6.1.2](https://www.openphilanthropy.org/2017-report-consciousness-and-moral-patienthood#ExtremeEffort) of a report prepared for my employer, the [Open Philanthropy Project](https://www.openphilanthropy.org/). With my employer's permission, I've adapted that section for publication here, so that it can serve as the long-overdue concluding post in my sequence on metaethics."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Heading Toward: No-Nonsense Metaethics",
            "tags": [
              {
                "name": "Metaethics"
              }
            ]
          },
          {
            "title": "What is Metaethics?",
            "tags": [
              {
                "name": "Ethics & Morality"
              }
            ]
          },
          {
            "title": "Conceptual Analysis and Moral Theory",
            "tags": [
              {
                "name": "Metaethics"
              },
              {
                "name": "Philosophy of Language"
              }
            ]
          },
          {
            "title": "Pluralistic Moral Reductionism",
            "tags": [
              {
                "name": "Metaethics"
              },
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "Philosophy of Language"
              }
            ]
          },
          {
            "title": "Quick thoughts on empathic metaethics",
            "tags": [
              {
                "name": "Metaethics"
              },
              {
                "name": "Human Values"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "GcZCMu7ZYHpJCh5bx",
    "title": "The Darwin Game",
    "curatedOrder": null,
    "contents": null,
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "The Darwin Game",
            "tags": [
              {
                "name": "Game Theory"
              },
              {
                "name": "Programming"
              }
            ]
          },
          {
            "title": "The Darwin Pregame",
            "tags": [
              {
                "name": "Game Theory"
              },
              {
                "name": "Coordination / Cooperation"
              }
            ]
          },
          {
            "title": "The Darwin Results",
            "tags": [
              {
                "name": "Game Theory"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Programming"
              },
              {
                "name": "Coordination / Cooperation"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "WPgA9x5ZvKu9oYvgB",
    "title": "Drawing Less Wrong",
    "curatedOrder": null,
    "contents": {
      "markdown": "Drawing has a number of subskills, many of which bear a surprisingly close relationship to core rationality skills. (Note: this sequence ended rather abruptly, but I recommend following up with \"Drawing on the Right Side of the Brain\".)"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Drawing Less Wrong: An Introduction",
            "tags": [
              {
                "name": "Art"
              },
              {
                "name": "Education"
              }
            ]
          },
          {
            "title": "Drawing Less Wrong: Should You Learn to Draw?",
            "tags": [
              {
                "name": "Art"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Drawing Less Wrong: Overview of Skills, and Relevance to Rationality",
            "tags": [
              {
                "name": "Art"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Drawing Less Wrong: Observing Reality",
            "tags": [
              {
                "name": "Art"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Drawing Less Wrong: Technical Skill",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "Art"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "oLGCcbnvabyibnG9d",
    "title": "Inadequate Equilibria",
    "curatedOrder": 1,
    "contents": {
      "markdown": "Inadequate Equilibria is a book about a generalized notion of efficient markets, and how we can use this notion to guess where society will or won’t be effective at pursuing some widely desired goal."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Inadequacy and Modesty",
            "tags": [
              {
                "name": "Humility"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Efficient Market Hypothesis"
              },
              {
                "name": "Economics"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Incentives"
              },
              {
                "name": "Modest Epistemology"
              }
            ]
          },
          {
            "title": "An Equilibrium of No Free Energy",
            "tags": [
              {
                "name": "Moloch"
              },
              {
                "name": "Efficient Market Hypothesis"
              },
              {
                "name": "Lighting"
              },
              {
                "name": "Incentives"
              }
            ]
          },
          {
            "title": "Moloch's Toolbox (1/2)",
            "tags": [
              {
                "name": "Moloch"
              },
              {
                "name": "Efficient Market Hypothesis"
              },
              {
                "name": "Expertise (topic)"
              },
              {
                "name": "dath ilan"
              }
            ]
          },
          {
            "title": "Moloch's Toolbox (2/2)",
            "tags": [
              {
                "name": "Efficient Market Hypothesis"
              },
              {
                "name": "Moloch"
              },
              {
                "name": "dath ilan"
              }
            ]
          },
          {
            "title": "Living in an Inadequate World",
            "tags": [
              {
                "name": "Moloch"
              },
              {
                "name": "Economics"
              },
              {
                "name": "Social & Cultural Dynamics"
              },
              {
                "name": "Incentives"
              }
            ]
          },
          {
            "title": "Blind Empiricism",
            "tags": [
              {
                "name": "Empiricism"
              }
            ]
          },
          {
            "title": "Against Modest Epistemology",
            "tags": [
              {
                "name": "Disagreement"
              },
              {
                "name": "Inside/Outside View"
              },
              {
                "name": "Epistemology"
              },
              {
                "name": "Underconfidence"
              },
              {
                "name": "Modest Epistemology"
              }
            ]
          },
          {
            "title": "Status Regulation and Anxious Underconfidence",
            "tags": [
              {
                "name": "Social Status"
              },
              {
                "name": "Social & Cultural Dynamics"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Emotions"
              },
              {
                "name": "Aumann's Agreement Theorem"
              },
              {
                "name": "Underconfidence"
              }
            ]
          },
          {
            "title": "Against Shooting Yourself in the Foot",
            "tags": [
              {
                "name": "Humility"
              },
              {
                "name": "Pitfalls of Rationality"
              },
              {
                "name": "Underconfidence"
              },
              {
                "name": "Modest Epistemology"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "k5MPpr72eiGknaS7F",
    "title": "Hypotheses and Hunches",
    "curatedOrder": null,
    "contents": {
      "markdown": ""
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": 0,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "The Atomic Bomb Considered As Hungarian High School Science Fair Project",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "IQ and g-factor"
              },
              {
                "name": "Human Genetics"
              }
            ]
          },
          {
            "title": "It’s Bayes All The Way Up",
            "tags": [
              {
                "name": "Bayes' Theorem"
              },
              {
                "name": "Neuroscience"
              },
              {
                "name": "Predictive Processing"
              }
            ]
          },
          {
            "title": "Why Are Transgender People Immune To Optical Illusions?",
            "tags": [
              {
                "name": "Sex & Gender"
              }
            ]
          }
        ]
      },
      {
        "title": "Interlude",
        "subtitle": null,
        "number": 1,
        "contents": null,
        "posts": [
          {
            "title": "The Case Of The Suffocating Woman",
            "tags": []
          }
        ]
      }
    ]
  },
  {
    "_id": "TQW9brvXJ5Fajorr4",
    "title": "Probability and Predictions",
    "curatedOrder": null,
    "contents": {
      "markdown": "Nearly everyone is very very very overconfident. We know this from [experiments](http://www.researchgate.net/profile/Baruch_Fischhoff/publication/230726569_Knowing_with_certainty_the_appropriateness_of_extreme_confidence/links/00b4952b854b29281c000000.pdf) where people answer true/false trivia questions, then are asked to state how confident they are in their answer. If people’s confidence was well-calibrated, someone who said they were 99% confident (ie only 1% chance they’re wrong) would get the question wrong only 1% of the time. In fact, people who say they are 99% confident get the question wrong about 20% of the time.\n\nIt gets worse. People who say there’s only a 1 in 100,000 chance they’re wrong? Wrong 15% of the time. One in a million? Wrong 5% of the time. They’re not just overconfident, they are *fifty thousand times* as confident as they should be."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": 0,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "The Pyramid And The Garden",
            "tags": [
              {
                "name": "Epistemology"
              },
              {
                "name": "Replication Crisis"
              },
              {
                "name": "Probability & Statistics"
              }
            ]
          },
          {
            "title": "On Overconfidence",
            "tags": [
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "If It’s Worth Doing, It’s Worth Doing With Made-Up Statistics",
            "tags": [
              {
                "name": "Probability & Statistics"
              },
              {
                "name": "Bayes' Theorem"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Planning & Decision-Making"
              }
            ]
          },
          {
            "title": "Techniques for probability estimates",
            "tags": [
              {
                "name": "Probability & Statistics"
              },
              {
                "name": "Betting"
              },
              {
                "name": "Introspection"
              }
            ]
          },
          {
            "title": "Confidence levels inside and outside an argument",
            "tags": [
              {
                "name": "Probability & Statistics"
              },
              {
                "name": "Forecasting & Prediction"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Inside/Outside View"
              },
              {
                "name": "Distinctions"
              },
              {
                "name": "Explicit Reasoning"
              }
            ]
          }
        ]
      },
      {
        "title": "Interlude",
        "subtitle": null,
        "number": 1,
        "contents": null,
        "posts": [
          {
            "title": "The Logician And The God-Emperor",
            "tags": [
              {
                "name": "Parables & Fables"
              }
            ]
          },
          {
            "title": "Reverse Psychology",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Psychiatry"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "pvim9PZJ6qHRTMqD3",
    "title": "The Craft and the Community",
    "curatedOrder": null,
    "contents": {
      "markdown": "Discusses rationality groups and group rationality, raising the questions:\n\n*   Can rationality be learned and taught?\n*   If so, how much improvement is possible?\n\nHow can we be confident we're seeing a real effect in a rationality intervention, and picking out the right cause?\n\n*   What community norms would make this process of bettering ourselves easier?\n*   Can we effectively collaborate on large-scale problems without sacrificing our freedom of thought and conduct?\n\nAbove all: What’s missing? What should be in the next generation of rationality primers—the ones that replace this text, improve on its style, test its prescriptions, supplement its content, and branch out in altogether new directions?"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Raising the Sanity Waterline",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Community"
              },
              {
                "name": "Public Discourse"
              },
              {
                "name": "Social & Cultural Dynamics"
              }
            ]
          },
          {
            "title": "A Sense That More Is Possible",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Rationality Verification"
              }
            ]
          },
          {
            "title": "Epistemic Viciousness",
            "tags": [
              {
                "name": "Epistemology"
              },
              {
                "name": "Education"
              },
              {
                "name": "Religion"
              },
              {
                "name": "Groupthink"
              },
              {
                "name": "Rationality Verification"
              }
            ]
          },
          {
            "title": "Schools Proliferating Without Evidence",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Rationality Verification"
              }
            ]
          },
          {
            "title": "3 Levels of Rationality Verification",
            "tags": [
              {
                "name": "Mechanism Design"
              },
              {
                "name": "Empiricism"
              },
              {
                "name": "Skill / Expertise Assessment"
              },
              {
                "name": "Skill Building"
              },
              {
                "name": "Rationality Verification"
              }
            ]
          },
          {
            "title": "Why Our Kind Can't Cooperate",
            "tags": [
              {
                "name": "Coordination / Cooperation"
              },
              {
                "name": "Social & Cultural Dynamics"
              },
              {
                "name": "Community"
              },
              {
                "name": "Group Rationality"
              }
            ]
          },
          {
            "title": "Tolerate Tolerance",
            "tags": [
              {
                "name": "Coordination / Cooperation"
              },
              {
                "name": "Social & Cultural Dynamics"
              }
            ]
          },
          {
            "title": "Your Price for Joining",
            "tags": [
              {
                "name": "Game Theory"
              },
              {
                "name": "Coordination / Cooperation"
              },
              {
                "name": "Group Rationality"
              }
            ]
          },
          {
            "title": "Can Humanism Match Religion's Output?",
            "tags": [
              {
                "name": "Akrasia"
              },
              {
                "name": "Motivations"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Community"
              },
              {
                "name": "Religion"
              }
            ]
          },
          {
            "title": "Church vs. Taskforce",
            "tags": [
              {
                "name": "Community"
              },
              {
                "name": "Religion"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Group Rationality"
              },
              {
                "name": "Distinctions"
              }
            ]
          },
          {
            "title": "Rationality: Common Interest of Many Causes",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Instrumental Convergence"
              },
              {
                "name": "Community"
              }
            ]
          },
          {
            "title": "Helpless Individuals",
            "tags": [
              {
                "name": "Group Rationality"
              },
              {
                "name": "Social & Cultural Dynamics"
              }
            ]
          },
          {
            "title": "Money: The Unit of Caring",
            "tags": [
              {
                "name": "Consequentialism"
              },
              {
                "name": "Effective Altruism"
              },
              {
                "name": "Economics"
              },
              {
                "name": "Shut Up and Multiply"
              }
            ]
          },
          {
            "title": "Purchase Fuzzies and Utilons Separately",
            "tags": [
              {
                "name": "Motivations"
              },
              {
                "name": "Effective Altruism"
              },
              {
                "name": "Fuzzies"
              },
              {
                "name": "Shut Up and Multiply"
              }
            ]
          },
          {
            "title": "Bystander Apathy",
            "tags": [
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Bystander Effect"
              }
            ]
          },
          {
            "title": "Collective Apathy and the Internet",
            "tags": [
              {
                "name": "Public Discourse"
              },
              {
                "name": "Altruism"
              },
              {
                "name": "Coordination / Cooperation"
              },
              {
                "name": "Bystander Effect"
              }
            ]
          },
          {
            "title": "Incremental Progress and the Valley",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Pitfalls of Rationality"
              },
              {
                "name": "Valley of Bad Rationality"
              }
            ]
          },
          {
            "title": "Bayesians vs. Barbarians",
            "tags": [
              {
                "name": "War"
              },
              {
                "name": "Group Rationality"
              },
              {
                "name": "Pitfalls of Rationality"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Coordination / Cooperation"
              }
            ]
          },
          {
            "title": "Beware of Other-Optimizing",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "Principles"
              }
            ]
          },
          {
            "title": "Practical Advice Backed By Deep Theories",
            "tags": [
              {
                "name": "Practical"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Scholarship & Learning"
              }
            ]
          },
          {
            "title": "The Sin of Underconfidence",
            "tags": [
              {
                "name": "Ambition"
              },
              {
                "name": "Pitfalls of Rationality"
              },
              {
                "name": "Humility"
              },
              {
                "name": "Calibration"
              },
              {
                "name": "Underconfidence"
              }
            ]
          },
          {
            "title": "Go Forth and Create the Art!",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Community"
              },
              {
                "name": "Group Rationality"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "3szfzHZr7EYGSWt92",
    "title": "Challenging the Difficult",
    "curatedOrder": null,
    "contents": {
      "markdown": "This sequences asks what it takes to solve a truly difficult problem—including demands that go beyond epistemic rationality."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Trying to Try",
            "tags": [
              {
                "name": "Heroic Responsibility"
              },
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Planning & Decision-Making"
              },
              {
                "name": "Map and Territory"
              }
            ]
          },
          {
            "title": "Use the Try Harder, Luke",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "More Dakka"
              },
              {
                "name": "Five minute timers"
              }
            ]
          },
          {
            "title": "On Doing the Impossible",
            "tags": [
              {
                "name": "Hamming Questions"
              },
              {
                "name": "Ambition"
              }
            ]
          },
          {
            "title": "Make an Extraordinary Effort",
            "tags": [
              {
                "name": "Ambition"
              },
              {
                "name": "Tsuyoku Naritai"
              }
            ]
          },
          {
            "title": "Shut up and do the impossible!",
            "tags": [
              {
                "name": "Heroic Responsibility"
              },
              {
                "name": "Ambition"
              },
              {
                "name": "Tsuyoku Naritai"
              }
            ]
          },
          {
            "title": "Final Words",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "SXurf2mWFw8LX2mkG",
    "title": "Yudkowsky's Coming of Age",
    "curatedOrder": null,
    "contents": {
      "markdown": "This sequence provides a last in-depth illustration of the dynamics of irrational belief, this time spotlighting the author’s own intellectual history."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Beginnings: An Introduction",
            "tags": []
          },
          {
            "title": "My Childhood Death Spiral",
            "tags": [
              {
                "name": "Growth Stories"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Affective Death Spiral"
              }
            ]
          },
          {
            "title": "My Best and Worst Mistake",
            "tags": [
              {
                "name": "Growth Stories"
              },
              {
                "name": "General Intelligence"
              }
            ]
          },
          {
            "title": "Raised in Technophilia",
            "tags": [
              {
                "name": "Growth Stories"
              }
            ]
          },
          {
            "title": "A Prodigy of Refutation",
            "tags": [
              {
                "name": "Growth Stories"
              },
              {
                "name": "Steelmanning"
              }
            ]
          },
          {
            "title": "The Sheer Folly of Callow Youth",
            "tags": [
              {
                "name": "Growth Stories"
              },
              {
                "name": "Metaethics"
              },
              {
                "name": "Noticing Confusion"
              }
            ]
          },
          {
            "title": "That Tiny Note of Discord",
            "tags": [
              {
                "name": "Noticing"
              },
              {
                "name": "Noticing Confusion"
              }
            ]
          },
          {
            "title": "Fighting a Rearguard Action Against the Truth",
            "tags": [
              {
                "name": "Growth Stories"
              },
              {
                "name": "Changing Your Mind"
              }
            ]
          },
          {
            "title": "My Naturalistic Awakening",
            "tags": [
              {
                "name": "Growth Stories"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "The Level Above Mine",
            "tags": [
              {
                "name": "Ambition"
              },
              {
                "name": "Self Improvement"
              }
            ]
          },
          {
            "title": "The Magnitude of His Own Folly",
            "tags": [
              {
                "name": "AI Risk"
              },
              {
                "name": "Growth Stories"
              },
              {
                "name": "Heroic Responsibility"
              }
            ]
          },
          {
            "title": "Beyond the Reach of God",
            "tags": [
              {
                "name": "World Optimization"
              },
              {
                "name": "Religion"
              },
              {
                "name": "Courage"
              }
            ]
          },
          {
            "title": "My Bayesian Enlightenment",
            "tags": [
              {
                "name": "Bayes' Theorem"
              },
              {
                "name": "Law-Thinking"
              },
              {
                "name": "Growth Stories"
              },
              {
                "name": "Updated Beliefs (examples of)"
              },
              {
                "name": "Bayesianism"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "waF2Pomid7YHjfEDt",
    "title": "Quantified Humanism",
    "curatedOrder": null,
    "contents": {
      "markdown": "On the tricky question of how we should apply such theories to our ordinary moral intuitions and decision-making."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": 0,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "One Life Against the World",
            "tags": [
              {
                "name": "Effective Altruism"
              },
              {
                "name": "Consequentialism"
              },
              {
                "name": "Altruism"
              },
              {
                "name": "Scope Insensitivity"
              },
              {
                "name": "Shut Up and Multiply"
              }
            ]
          },
          {
            "title": "The Allais Paradox",
            "tags": [
              {
                "name": "Paradoxes"
              },
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Utility Functions"
              }
            ]
          },
          {
            "title": "Zut Allais!",
            "tags": [
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Utility Functions"
              },
              {
                "name": "Intuition"
              }
            ]
          },
          {
            "title": "Feeling Moral",
            "tags": [
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "Consequentialism"
              },
              {
                "name": "Heuristics & Biases"
              }
            ]
          },
          {
            "title": "The \"Intuitions\" Behind \"Utilitarianism\"",
            "tags": [
              {
                "name": "Philosophy"
              },
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "Intuition"
              },
              {
                "name": "Shut Up and Multiply"
              }
            ]
          },
          {
            "title": "Ends Don't Justify Means (Among Humans)",
            "tags": [
              {
                "name": "Self-Deception"
              },
              {
                "name": "Deontology"
              },
              {
                "name": "Consequentialism"
              },
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "Evolutionary Psychology"
              },
              {
                "name": "Decision Theory"
              }
            ]
          },
          {
            "title": "Ethical Injunctions",
            "tags": [
              {
                "name": "Deontology"
              },
              {
                "name": "AI"
              },
              {
                "name": "Self-Deception"
              }
            ]
          },
          {
            "title": "Something to Protect",
            "tags": [
              {
                "name": "World Optimization"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Motivations"
              },
              {
                "name": "Heroic Responsibility"
              },
              {
                "name": "Something To Protect"
              }
            ]
          },
          {
            "title": "When (Not) To Use Probabilities",
            "tags": [
              {
                "name": "Probability & Statistics"
              },
              {
                "name": "Bayes' Theorem"
              },
              {
                "name": "Intuition"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Bayesianism"
              }
            ]
          },
          {
            "title": "Newcomb's Problem and Regret of Rationality",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Decision Theory"
              },
              {
                "name": "Newcomb's Problem"
              },
              {
                "name": "Pre-Commitment"
              },
              {
                "name": "One-Boxing"
              },
              {
                "name": "Conditional Consistency"
              },
              {
                "name": "Two-Boxing"
              },
              {
                "name": "Bayesianism"
              },
              {
                "name": "Something To Protect"
              }
            ]
          }
        ]
      },
      {
        "title": "Interlude",
        "subtitle": null,
        "number": 1,
        "contents": null,
        "posts": [
          {
            "title": "Twelve Virtues of Rationality",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Rationality"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "9bvAELWc8y2gYjRav",
    "title": "Value Theory",
    "curatedOrder": null,
    "contents": {
      "markdown": "On obstacles to developing a new theory, and some intuitively desirable features of such a theory."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": 0,
        "contents": null,
        "posts": [
          {
            "title": "Where Recursive Justification Hits Bottom",
            "tags": [
              {
                "name": "Epistemology"
              },
              {
                "name": "Occam's Razor"
              },
              {
                "name": "Philosophy"
              },
              {
                "name": "Reflective Reasoning"
              },
              {
                "name": "The Problem of the Criterion"
              }
            ]
          },
          {
            "title": "My Kind of Reflection",
            "tags": [
              {
                "name": "Reflective Reasoning"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "No Universally Compelling Arguments",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Metaethics"
              }
            ]
          },
          {
            "title": "Created Already In Motion",
            "tags": [
              {
                "name": "Metaethics"
              }
            ]
          },
          {
            "title": "Sorting Pebbles Into Correct Heaps",
            "tags": [
              {
                "name": "Orthogonality Thesis"
              },
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "2-Place and 1-Place Words",
            "tags": [
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Mind Projection Fallacy"
              },
              {
                "name": "Map and Territory"
              }
            ]
          },
          {
            "title": "What Would You Do Without Morality?",
            "tags": [
              {
                "name": "Ethics & Morality"
              }
            ]
          },
          {
            "title": "Changing Your Metaethics",
            "tags": [
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "Metaethics"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Adding Up to Normality"
              }
            ]
          },
          {
            "title": "Could Anything Be Right?",
            "tags": [
              {
                "name": "Ethics & Morality"
              },
              {
                "name": "Metaethics"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Morality as Fixed Computation",
            "tags": [
              {
                "name": "Ethics & Morality"
              }
            ]
          },
          {
            "title": "Magical Categories",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Machine Learning  (ML)"
              },
              {
                "name": "Paperclip Maximizer"
              }
            ]
          },
          {
            "title": "The True Prisoner's Dilemma",
            "tags": [
              {
                "name": "Game Theory"
              },
              {
                "name": "Prisoner's Dilemma"
              },
              {
                "name": "Paperclip Maximizer"
              }
            ]
          },
          {
            "title": "Sympathetic Minds",
            "tags": [
              {
                "name": "Complexity of Value"
              },
              {
                "name": "Evolutionary Psychology"
              }
            ]
          },
          {
            "title": "High Challenge",
            "tags": [
              {
                "name": "Complexity of Value"
              },
              {
                "name": "Fun Theory"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Skill Building"
              }
            ]
          },
          {
            "title": "Serious Stories",
            "tags": [
              {
                "name": "Narratives (stories)"
              }
            ]
          },
          {
            "title": "Value is Fragile",
            "tags": [
              {
                "name": "Complexity of Value"
              },
              {
                "name": "Human Values"
              }
            ]
          },
          {
            "title": "The Gift We Give To Tomorrow",
            "tags": [
              {
                "name": "Evolutionary Psychology"
              },
              {
                "name": "Complexity of Value"
              },
              {
                "name": "Human Values"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "fqh9TLuoquxpducDb",
    "title": "Fake Preferences",
    "curatedOrder": null,
    "contents": {
      "markdown": "On failed attempts at theories of value."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Ends: An Introduction",
            "tags": [
              {
                "name": "Human Values"
              }
            ]
          },
          {
            "title": "Not for the Sake of Happiness (Alone)",
            "tags": [
              {
                "name": "Well-being"
              },
              {
                "name": "Happiness"
              },
              {
                "name": "Fuzzies"
              }
            ]
          },
          {
            "title": "Fake Selfishness",
            "tags": [
              {
                "name": "Motivations"
              }
            ]
          },
          {
            "title": "Fake Morality",
            "tags": [
              {
                "name": "Ethics & Morality"
              }
            ]
          },
          {
            "title": "Fake Utility Functions",
            "tags": [
              {
                "name": "Complexity of Value"
              },
              {
                "name": "Utility Functions"
              }
            ]
          },
          {
            "title": "Detached Lever Fallacy",
            "tags": [
              {
                "name": "Mind Projection Fallacy"
              },
              {
                "name": "AI"
              },
              {
                "name": "Evolutionary Psychology"
              },
              {
                "name": "Rationalist Taboo"
              }
            ]
          },
          {
            "title": "Dreams of AI Design",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Gears-Level"
              }
            ]
          },
          {
            "title": "The Design Space of Minds-In-General",
            "tags": [
              {
                "name": "Mind Space"
              },
              {
                "name": "Carving / Clustering Reality"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "fxynfGCSHpY4FmBZy",
    "title": "Science and Rationality",
    "curatedOrder": null,
    "contents": {
      "markdown": "The final sequence in this book tie these ideas together, and draws some conclusions on the strength of our scientific institutions."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": 0,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "The Failures of Eld Science",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "Babble and Prune"
              }
            ]
          },
          {
            "title": "The Dilemma: Science or Bayes?",
            "tags": [
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Science Doesn't Trust Your Rationality",
            "tags": [
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "When Science Can't Help",
            "tags": [
              {
                "name": "Practice & Philosophy of Science"
              }
            ]
          },
          {
            "title": "Science Isn't Strict Enough",
            "tags": [
              {
                "name": "Practice & Philosophy of Science"
              }
            ]
          },
          {
            "title": "Do Scientists Already Know This Stuff?",
            "tags": [
              {
                "name": "Practice & Philosophy of Science"
              }
            ]
          },
          {
            "title": "No Safe Defense, Not Even Science",
            "tags": [
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Courage"
              },
              {
                "name": "Trust"
              }
            ]
          },
          {
            "title": "Changing the Definition of Science",
            "tags": [
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "Bayesianism"
              }
            ]
          },
          {
            "title": "Faster Than Science",
            "tags": [
              {
                "name": "Practice & Philosophy of Science"
              }
            ]
          },
          {
            "title": "Einstein's Speed",
            "tags": [
              {
                "name": "Physics"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Practice & Philosophy of Science"
              }
            ]
          },
          {
            "title": "That Alien Message",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "AI Boxing (Containment)"
              },
              {
                "name": "AI"
              },
              {
                "name": "Simulation Hypothesis"
              },
              {
                "name": "Bayesianism"
              },
              {
                "name": "Parables & Fables"
              }
            ]
          },
          {
            "title": "My Childhood Role Model",
            "tags": [
              {
                "name": "Fiction (Topic)"
              },
              {
                "name": "General Intelligence"
              },
              {
                "name": "Tsuyoku Naritai"
              }
            ]
          },
          {
            "title": "Einstein's Superpowers",
            "tags": [
              {
                "name": "Ambition"
              },
              {
                "name": "Humility"
              }
            ]
          },
          {
            "title": "Class Project",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Rationality"
              }
            ]
          }
        ]
      },
      {
        "title": "Interlude",
        "subtitle": null,
        "number": 1,
        "contents": null,
        "posts": [
          {
            "title": "A Technical Explanation of Technical Explanation",
            "tags": [
              {
                "name": "Bayes' Theorem"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "Kqs6GR7F5xziuSyGZ",
    "title": "Quantum Physics and Many Worlds",
    "curatedOrder": null,
    "contents": {
      "markdown": "Quantum mechanics is our best mathematical model of the universe to date, powerfully confirmed by a century of tests. However, interpreting what the experimental results _mean_ \\- how and when the Schrödinger equation and Born's rule interact - is a topic of much contention, with the main disagreement being between the Everett and the Copenhagen interpretations.\n\nYudkowsky uses this scientific controversy as a proving ground for some central ideas from previous sequences: map-territory distinctions, mysterious answers, Bayesianism, and Occam’s Razor."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Quantum Explanations",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Physics"
              },
              {
                "name": "Writing (communication method)"
              },
              {
                "name": "Quantum Mechanics"
              },
              {
                "name": "Good Explanations (Advice)"
              }
            ]
          },
          {
            "title": "Configurations and Amplitude",
            "tags": [
              {
                "name": "Physics"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Quantum Mechanics"
              }
            ]
          },
          {
            "title": "Joint Configurations",
            "tags": [
              {
                "name": "Physics"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Quantum Mechanics"
              }
            ]
          },
          {
            "title": "Distinct Configurations",
            "tags": [
              {
                "name": "Physics"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Quantum Mechanics"
              }
            ]
          },
          {
            "title": "Collapse Postulates",
            "tags": [
              {
                "name": "Physics"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Quantum Mechanics"
              }
            ]
          },
          {
            "title": "Decoherence is Simple",
            "tags": [
              {
                "name": "Physics"
              },
              {
                "name": "Occam's Razor"
              },
              {
                "name": "Solomonoff Induction"
              },
              {
                "name": "Quantum Mechanics"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Decoherence is Falsifiable and Testable",
            "tags": [
              {
                "name": "Falsifiability"
              },
              {
                "name": "Physics"
              },
              {
                "name": "Bayes' Theorem"
              },
              {
                "name": "Quantum Mechanics"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Privileging the Hypothesis",
            "tags": [
              {
                "name": "Confirmation Bias"
              },
              {
                "name": "Motivated Reasoning"
              },
              {
                "name": "Practice & Philosophy of Science"
              }
            ]
          },
          {
            "title": "Living in Many Worlds",
            "tags": [
              {
                "name": "Physics"
              },
              {
                "name": "Planning & Decision-Making"
              },
              {
                "name": "Quantum Mechanics"
              },
              {
                "name": "Many-Worlds Interpretation"
              },
              {
                "name": "Adding Up to Normality"
              }
            ]
          },
          {
            "title": "Quantum Non-Realism",
            "tags": [
              {
                "name": "Physics"
              },
              {
                "name": "Quantum Mechanics"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "If Many-Worlds Had Come First",
            "tags": [
              {
                "name": "Physics"
              },
              {
                "name": "Fiction"
              },
              {
                "name": "Humor"
              },
              {
                "name": "Occam's Razor"
              },
              {
                "name": "Quantum Mechanics"
              },
              {
                "name": "Many-Worlds Interpretation"
              },
              {
                "name": "Parables & Fables"
              }
            ]
          },
          {
            "title": "Where Philosophy Meets Science",
            "tags": [
              {
                "name": "Physics"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "Quantum Mechanics"
              }
            ]
          },
          {
            "title": "Thou Art Physics",
            "tags": [
              {
                "name": "Physics"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Many Worlds, One Best Guess",
            "tags": [
              {
                "name": "Physics"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Quantum Mechanics"
              },
              {
                "name": "Many-Worlds Interpretation"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "FqgKAHZAiZn9JAjDo",
    "title": "Physicalism 201",
    "curatedOrder": null,
    "contents": {
      "markdown": "Can we ever know what it’s like to be a bat? Traditional dualism, with its immaterial souls freely floating around violating physical laws, may be false; but what about the weaker thesis, that consciousness is a “further fact” not fully explainable by the physical facts? A number of philosophers and scientists have found this line of reasoning persuasive. If we feel this argument’s intuitive force, should we grant its conclusion and ditch physicalism?\n\nWe certainly shouldn’t reject it just because it sounds strange or feels vaguely unscientific. But how does the argument stand up to a technical understanding of how explanation and belief work? Are there any hints we can take from the history of science, or from our understanding of the physical mechanisms underlying evidence? This is the question that this sequence will attempt to answer."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Hand vs. Fingers",
            "tags": [
              {
                "name": "Reductionism"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Angry Atoms",
            "tags": [
              {
                "name": "Reductionism"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Heat vs. Motion",
            "tags": [
              {
                "name": "Physics"
              },
              {
                "name": "Map and Territory"
              },
              {
                "name": "Reductionism"
              }
            ]
          },
          {
            "title": "Brain Breakthrough! It's Made of Neurons!",
            "tags": [
              {
                "name": "Humor"
              },
              {
                "name": "April Fool's"
              }
            ]
          },
          {
            "title": "When Anthropomorphism Became Stupid",
            "tags": [
              {
                "name": "Intellectual Progress (Society-Level)"
              },
              {
                "name": "General Intelligence"
              }
            ]
          },
          {
            "title": "A Priori",
            "tags": [
              {
                "name": "Philosophy"
              },
              {
                "name": "Truth, Semantics, & Meaning"
              },
              {
                "name": "Occam's Razor"
              },
              {
                "name": "Bayesianism"
              },
              {
                "name": "Priors"
              }
            ]
          },
          {
            "title": "Reductive Reference",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "References (Language)"
              }
            ]
          },
          {
            "title": "Zombies! Zombies?",
            "tags": [
              {
                "name": "Consciousness"
              },
              {
                "name": "Zombies"
              }
            ]
          },
          {
            "title": "Zombie Responses",
            "tags": [
              {
                "name": "Zombies"
              }
            ]
          },
          {
            "title": "The Generalized Anti-Zombie Principle",
            "tags": [
              {
                "name": "Zombies"
              },
              {
                "name": "Consciousness"
              },
              {
                "name": "Causality"
              }
            ]
          },
          {
            "title": "GAZP vs. GLUT",
            "tags": [
              {
                "name": "Zombies"
              },
              {
                "name": "Consciousness"
              }
            ]
          },
          {
            "title": "Belief in the Implied Invisible",
            "tags": [
              {
                "name": "Physics"
              },
              {
                "name": "Occam's Razor"
              },
              {
                "name": "Solomonoff Induction"
              },
              {
                "name": "Anticipated Experiences"
              }
            ]
          },
          {
            "title": "Zombies: The Movie",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Zombies"
              },
              {
                "name": "Humor"
              },
              {
                "name": "Parables & Fables"
              },
              {
                "name": "Consciousness"
              },
              {
                "name": "The Hard Problem of Consciousness"
              }
            ]
          },
          {
            "title": "Excluding the Supernatural",
            "tags": [
              {
                "name": "Reductionism"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Psychic Powers",
            "tags": [
              {
                "name": "Occam's Razor"
              },
              {
                "name": "Reductionism"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "6BFkmEgre7uwhDxDR",
    "title": "Joy in the Merely Real",
    "curatedOrder": null,
    "contents": {
      "markdown": "..Do not all charms fly\n\nAt the mere touch of cold philosophy?\n\nThere was an awful rainbow once in heaven:\n\nWe know her woof, her texture; she is given\n\nIn the dull catalogue of common things.\n\n> —John Keats, Lamia"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "Joy in the Merely Real",
            "tags": [
              {
                "name": "Reductionism"
              },
              {
                "name": "Emotions"
              },
              {
                "name": "Fun Theory"
              }
            ]
          },
          {
            "title": "Joy in Discovery",
            "tags": [
              {
                "name": "Emotions"
              },
              {
                "name": "Motivations"
              },
              {
                "name": "Social Status"
              }
            ]
          },
          {
            "title": "Bind Yourself to Reality",
            "tags": [
              {
                "name": "Contact with Reality"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "If You Demand Magic, Magic Won't Help",
            "tags": [
              {
                "name": "Fiction (Topic)"
              },
              {
                "name": "Emotions"
              },
              {
                "name": "Aesthetics"
              }
            ]
          },
          {
            "title": "Mundane Magic",
            "tags": [
              {
                "name": "Aesthetics"
              },
              {
                "name": "Reductionism"
              }
            ]
          },
          {
            "title": "The Beauty of Settled Science",
            "tags": [
              {
                "name": "Scholarship & Learning"
              },
              {
                "name": "Replication Crisis"
              }
            ]
          },
          {
            "title": "Amazing Breakthrough Day: April 1st",
            "tags": [
              {
                "name": "Humor"
              },
              {
                "name": "April Fool's"
              }
            ]
          },
          {
            "title": "Is Humanism A Religion-Substitute?",
            "tags": [
              {
                "name": "Religion"
              },
              {
                "name": "Community"
              },
              {
                "name": "Art"
              },
              {
                "name": "Ritual"
              }
            ]
          },
          {
            "title": "Scarcity",
            "tags": [
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Dark Arts"
              },
              {
                "name": "Censorship"
              }
            ]
          },
          {
            "title": "The Sacred Mundane",
            "tags": [
              {
                "name": "Religion"
              }
            ]
          },
          {
            "title": "To Spread Science, Keep It Secret",
            "tags": [
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "World Optimization"
              }
            ]
          },
          {
            "title": "Initiation Ceremony",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "p3TndjYbdYaiWwm9x",
    "title": "Reductionism 101",
    "curatedOrder": null,
    "contents": null,
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Dissolving the Question",
            "tags": [
              {
                "name": "Introspection"
              },
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Philosophy"
              },
              {
                "name": "Dissolving the Question"
              }
            ]
          },
          {
            "title": "Wrong Questions",
            "tags": [
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Cognitive Reduction"
              }
            ]
          },
          {
            "title": "Righting a Wrong Question",
            "tags": [
              {
                "name": "Introspection"
              },
              {
                "name": "Causality"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Mind Projection Fallacy",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Fallacies"
              },
              {
                "name": "Mind Projection Fallacy"
              },
              {
                "name": "Map and Territory"
              }
            ]
          },
          {
            "title": "Probability is in the Mind",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Mind Projection Fallacy"
              },
              {
                "name": "Bayes' Theorem"
              },
              {
                "name": "Map and Territory"
              },
              {
                "name": "Bayesianism"
              }
            ]
          },
          {
            "title": "The Quotation is not the Referent",
            "tags": [
              {
                "name": "Map and Territory"
              },
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "References (Language)"
              },
              {
                "name": "Distinctions"
              }
            ]
          },
          {
            "title": "Qualitatively Confused",
            "tags": [
              {
                "name": "Bayes' Theorem"
              },
              {
                "name": "Calibration"
              },
              {
                "name": "Bayesianism"
              }
            ]
          },
          {
            "title": "Think Like Reality",
            "tags": [
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Chaotic Inversion",
            "tags": [
              {
                "name": "Productivity"
              },
              {
                "name": "Mind Projection Fallacy"
              },
              {
                "name": "Akrasia"
              },
              {
                "name": "Willpower"
              }
            ]
          },
          {
            "title": "Reductionism",
            "tags": [
              {
                "name": "Truth, Semantics, & Meaning"
              },
              {
                "name": "Map and Territory"
              },
              {
                "name": "Reductionism"
              }
            ]
          },
          {
            "title": "Explaining vs. Explaining Away",
            "tags": [
              {
                "name": "Causality"
              },
              {
                "name": "Reductionism"
              },
              {
                "name": "Physics"
              },
              {
                "name": "Emotions"
              }
            ]
          },
          {
            "title": "Fake Reductionism",
            "tags": [
              {
                "name": "Reductionism"
              },
              {
                "name": "Emotions"
              },
              {
                "name": "Distinctions"
              }
            ]
          },
          {
            "title": "Savanna Poets",
            "tags": [
              {
                "name": "Art"
              },
              {
                "name": "Narratives (stories)"
              },
              {
                "name": "Aesthetics"
              },
              {
                "name": "Poetry"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "oFePMp9rKftEeZDDr",
    "title": "Lawful Truth",
    "curatedOrder": null,
    "contents": {
      "markdown": "Just as it was useful to contrast humans as goal-oriented systems with inhuman processes in evolutionary biology and artificial intelligence, it will be useful in the coming sequences of essays to contrast humans as physical systems with inhuman processes that aren’t mind-like.\n\nWe humans are, after all, built out of inhuman parts. The world of atoms looks nothing like the world as we ordinarily think of it, and certainly looks nothing like the world’s conscious denizens as we ordinarily think of them. As Giulio Giorello put the point in an interview with Daniel Dennett: “Yes, we have a soul. But it’s made of lots of tiny robots.\"\n\nWe start with a sequence on the basic links between physics and human cognition."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "The World: An Introduction",
            "tags": []
          },
          {
            "title": "Universal Fire",
            "tags": [
              {
                "name": "Law-Thinking"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Fiction (Topic)"
              }
            ]
          },
          {
            "title": "Universal Law",
            "tags": [
              {
                "name": "Law-Thinking"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Absurdity Heuristic"
              }
            ]
          },
          {
            "title": "Is Reality Ugly?",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Law-Thinking"
              }
            ]
          },
          {
            "title": "Beautiful Probability",
            "tags": [
              {
                "name": "Law-Thinking"
              },
              {
                "name": "Probability & Statistics"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Bayes' Theorem"
              },
              {
                "name": "Bayesianism"
              }
            ]
          },
          {
            "title": "Outside the Laboratory",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Law-Thinking"
              },
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "Religion"
              },
              {
                "name": "Compartmentalization"
              }
            ]
          },
          {
            "title": "The Second Law of Thermodynamics, and Engines of Cognition",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Law-Thinking"
              },
              {
                "name": "Physics"
              },
              {
                "name": "Probability & Statistics"
              },
              {
                "name": "Information Theory"
              },
              {
                "name": "Bayesianism"
              }
            ]
          },
          {
            "title": "Perpetual Motion Beliefs",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Law-Thinking"
              },
              {
                "name": "Bayesianism"
              }
            ]
          },
          {
            "title": "Searching for Bayes-Structure",
            "tags": [
              {
                "name": "Law-Thinking"
              },
              {
                "name": "Bayes' Theorem"
              },
              {
                "name": "Information Theory"
              },
              {
                "name": "Bayesianism"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "SGB7Y5WERh4skwtnb",
    "title": "A Human's Guide to Words",
    "curatedOrder": null,
    "contents": {
      "markdown": "This sequence discusses the basic relationship between cognition and concept formation. [37 Ways That Words Can Be Wrong](http://lesswrong.com/lw/od/37_ways_that_words_can_be_wrong/) is a guide to the sequence."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": 0,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "The Parable of the Dagger",
            "tags": [
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Parables & Fables"
              }
            ]
          },
          {
            "title": "The Parable of Hemlock",
            "tags": [
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "Words as Hidden Inferences",
            "tags": [
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Rationalist Taboo"
              },
              {
                "name": "Cognitive Reduction"
              }
            ]
          },
          {
            "title": "Extensions and Intensions",
            "tags": [
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Distinctions"
              }
            ]
          },
          {
            "title": "Similarity Clusters",
            "tags": [
              {
                "name": "Philosophy of Language"
              }
            ]
          },
          {
            "title": "Typicality and Asymmetrical Similarity",
            "tags": [
              {
                "name": "Philosophy of Language"
              }
            ]
          },
          {
            "title": "The Cluster Structure of Thingspace",
            "tags": [
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Thingspace"
              },
              {
                "name": "Carving / Clustering Reality"
              }
            ]
          },
          {
            "title": "Disguised Queries",
            "tags": [
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Parables & Fables"
              }
            ]
          },
          {
            "title": "Neural Categories",
            "tags": [
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Cognitive Reduction"
              }
            ]
          },
          {
            "title": "How An Algorithm Feels From Inside",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Cognitive Reduction"
              }
            ]
          },
          {
            "title": "Disputing Definitions",
            "tags": [
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Rationalist Taboo"
              }
            ]
          },
          {
            "title": "Feel the Meaning",
            "tags": [
              {
                "name": "Philosophy of Language"
              }
            ]
          },
          {
            "title": "The Argument from Common Usage",
            "tags": [
              {
                "name": "Philosophy of Language"
              }
            ]
          },
          {
            "title": "Empty Labels",
            "tags": [
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Cognitive Reduction"
              }
            ]
          },
          {
            "title": "Taboo Your Words",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Disagreement"
              },
              {
                "name": "Conversation (topic)"
              },
              {
                "name": "Techniques"
              },
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Rationalist Taboo"
              }
            ]
          },
          {
            "title": "Replace the Symbol with the Substance",
            "tags": [
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Map and Territory"
              },
              {
                "name": "Techniques"
              },
              {
                "name": "Rationalist Taboo"
              }
            ]
          },
          {
            "title": "Fallacies of Compression",
            "tags": [
              {
                "name": "Bucket Errors"
              },
              {
                "name": "Map and Territory"
              },
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Fallacy of Gray"
              },
              {
                "name": "Distinctions"
              }
            ]
          },
          {
            "title": "Categorizing Has Consequences",
            "tags": [
              {
                "name": "Philosophy of Language"
              }
            ]
          },
          {
            "title": "Sneaking in Connotations",
            "tags": [
              {
                "name": "Philosophy of Language"
              }
            ]
          },
          {
            "title": "Arguing \"By Definition\"",
            "tags": [
              {
                "name": "Philosophy of Language"
              }
            ]
          },
          {
            "title": "Where to Draw the Boundary?",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Philosophy of Language"
              }
            ]
          },
          {
            "title": "Entropy, and Short Codes",
            "tags": [
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Information Theory"
              }
            ]
          },
          {
            "title": "Mutual Information, and Density in Thingspace",
            "tags": [
              {
                "name": "Information Theory"
              },
              {
                "name": "Thingspace"
              }
            ]
          },
          {
            "title": "Superexponential Conceptspace, and Simple Words",
            "tags": [
              {
                "name": "Carving / Clustering Reality"
              },
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Thingspace"
              }
            ]
          },
          {
            "title": "Conditional Independence, and Naive Bayes",
            "tags": [
              {
                "name": "Information Theory"
              }
            ]
          },
          {
            "title": "Words as Mental Paintbrush Handles",
            "tags": [
              {
                "name": "Neuroscience"
              },
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Illusion of Transparency"
              }
            ]
          },
          {
            "title": "Variable Question Fallacies",
            "tags": [
              {
                "name": "Philosophy of Language"
              }
            ]
          },
          {
            "title": "37 Ways That Words Can Be Wrong",
            "tags": [
              {
                "name": "Philosophy of Language"
              }
            ]
          }
        ]
      },
      {
        "title": "Interlude",
        "subtitle": null,
        "number": 1,
        "contents": null,
        "posts": [
          {
            "title": "An Intuitive Explanation of Bayes's Theorem",
            "tags": [
              {
                "name": "Bayes' Theorem"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Needs Fixup"
              },
              {
                "name": "Probability & Statistics"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "3HyeNiEpvbQQaqeoH",
    "title": "Fragile Purposes",
    "curatedOrder": null,
    "contents": {
      "markdown": "This sequence abstracts from human cognition and evolution to the idea of minds and goal-directed systems at their most general. These essays serve the secondary purpose of explaining the author’s general approach to philosophy and the science of rationality, which is strongly informed by his work in AI."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Belief in Intelligence",
            "tags": [
              {
                "name": "General Intelligence"
              }
            ]
          },
          {
            "title": "Humans in Funny Suits",
            "tags": [
              {
                "name": "Fiction (Topic)"
              },
              {
                "name": "Evolution"
              },
              {
                "name": "Human Universal"
              }
            ]
          },
          {
            "title": "Optimization and the Intelligence Explosion",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Intelligence Explosion"
              }
            ]
          },
          {
            "title": "Ghosts in the Machine",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Causality"
              },
              {
                "name": "Homunculus Fallacy"
              }
            ]
          },
          {
            "title": "Artificial Addition",
            "tags": [
              {
                "name": "General Intelligence"
              },
              {
                "name": "AI"
              },
              {
                "name": "Anticipated Experiences"
              },
              {
                "name": "Gears-Level"
              }
            ]
          },
          {
            "title": "Terminal Values and Instrumental Values",
            "tags": [
              {
                "name": "Utility Functions"
              },
              {
                "name": "Complexity of Value"
              },
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Bayesianism"
              },
              {
                "name": "Distinctions"
              }
            ]
          },
          {
            "title": "Leaky Generalizations",
            "tags": [
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Complexity of Value"
              }
            ]
          },
          {
            "title": "The Hidden Complexity of Wishes",
            "tags": [
              {
                "name": "Complexity of Value"
              },
              {
                "name": "AI Risk"
              },
              {
                "name": "Parables & Fables"
              }
            ]
          },
          {
            "title": "Anthropomorphic Optimism",
            "tags": [
              {
                "name": "Evolution"
              },
              {
                "name": "Confirmation Bias"
              },
              {
                "name": "Orthogonality Thesis"
              },
              {
                "name": "Complexity of Value"
              },
              {
                "name": "Typical Mind Fallacy"
              },
              {
                "name": "Group Selection"
              }
            ]
          },
          {
            "title": "Lost Purposes",
            "tags": [
              {
                "name": "Politics"
              },
              {
                "name": "Moloch"
              },
              {
                "name": "Signaling"
              },
              {
                "name": "Moral Mazes"
              },
              {
                "name": "Lost Purposes"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "MH2b8NfWv22dBtrs8",
    "title": "The Simple Math of Evolution",
    "curatedOrder": null,
    "contents": {
      "markdown": "The first sequence of _The Machine in the Ghost_ aims to communicate the dissonance and divergence between our hereditary history, our present-day biology, and our ultimate aspirations. This will require digging deeper than is common in introductions to evolution for non-biologists, which often restrict their attention to surface-level features of natural selection."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Minds: An Introduction",
            "tags": [
              {
                "name": "Bounded Rationality"
              },
              {
                "name": "Embedded Agency"
              },
              {
                "name": "Evolutionary Psychology"
              }
            ]
          },
          {
            "title": "The Power of Intelligence",
            "tags": [
              {
                "name": "General Intelligence"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "An Alien God",
            "tags": [
              {
                "name": "Eldritch Analogies"
              },
              {
                "name": "Evolution"
              },
              {
                "name": "Religion"
              }
            ]
          },
          {
            "title": "The Wonder of Evolution",
            "tags": [
              {
                "name": "Evolution"
              }
            ]
          },
          {
            "title": "Evolutions Are Stupid (But Work Anyway)",
            "tags": [
              {
                "name": "Evolution"
              }
            ]
          },
          {
            "title": "No Evolutions for Corporations or Nanodevices",
            "tags": [
              {
                "name": "Evolution"
              }
            ]
          },
          {
            "title": "Evolving to Extinction",
            "tags": [
              {
                "name": "Evolution"
              },
              {
                "name": "Group Selection"
              }
            ]
          },
          {
            "title": "The Tragedy of Group Selectionism",
            "tags": [
              {
                "name": "Evolution"
              },
              {
                "name": "Group Selection"
              }
            ]
          },
          {
            "title": "Fake Optimization Criteria",
            "tags": [
              {
                "name": "Optimization"
              },
              {
                "name": "Motivated Reasoning"
              }
            ]
          },
          {
            "title": "Adaptation-Executers, not Fitness-Maximizers",
            "tags": [
              {
                "name": "Superstimuli"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Evolution"
              },
              {
                "name": "General Intelligence"
              },
              {
                "name": "Adaptation Executors"
              }
            ]
          },
          {
            "title": "Evolutionary Psychology",
            "tags": [
              {
                "name": "Evolution"
              },
              {
                "name": "Evolutionary Psychology"
              },
              {
                "name": "Adaptation Executors"
              }
            ]
          },
          {
            "title": "An Especially Elegant Evpsych Experiment",
            "tags": [
              {
                "name": "Evolutionary Psychology"
              }
            ]
          },
          {
            "title": "Superstimuli and the Collapse of Western Civilization",
            "tags": [
              {
                "name": "Superstimuli"
              },
              {
                "name": "Evolution"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Akrasia"
              }
            ]
          },
          {
            "title": "Thou Art Godshatter",
            "tags": [
              {
                "name": "Evolution"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Evolutionary Psychology"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "5bZZZJ5psXrrD5BGb",
    "title": "Letting Go",
    "curatedOrder": null,
    "contents": {
      "markdown": "Our natural state isn’t to change our minds like a Bayesian would. Getting the people in opposing tribes to notice what they’re really seeing won’t be as easy as reciting the axioms of probability theory to them. As Luke Muehlhauser writes, in [The Power of Agency](http://lesswrong.com/lw/5i8/the_power_of_agency/):\n\n> You are not a Bayesian homunculus whose reasoning is “corrupted” by cognitive biases.\n> \n> You just are cognitive biases.\n\nConfirmation bias, status quo bias, correspondence bias, and the like are not tacked on to our reasoning; they are its very substance.\n\nThat doesn’t mean that debiasing is impossible. We aren’t perfect calculators underneath all our arithmetic errors, either. Many of our mathematical limitations result from very deep facts about how the human brain works. Yet we can train our mathematical abilities; we can learn when to trust and distrust our mathematical intuitions, and share our knowledge, and help one another; we can shape our environments to make things easier on us, and build tools to offload much of the work.\n\nOur biases are part of us. But there is a shadow of Bayesianism present in us as well, a flawed apparatus that really can bring us closer to truth. No homunculus—but still, some truth. Enough, perhaps, to get started."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": 0,
        "contents": null,
        "posts": [
          {
            "title": "Singlethink",
            "tags": [
              {
                "name": "Self-Deception"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "The Importance of Saying \"Oops\"",
            "tags": [
              {
                "name": "Honesty"
              },
              {
                "name": "Self-Deception"
              },
              {
                "name": "Epistemology"
              },
              {
                "name": "Changing Your Mind"
              }
            ]
          },
          {
            "title": "The Crackpot Offer",
            "tags": [
              {
                "name": "Logic & Mathematics "
              },
              {
                "name": "Sunk-Cost Fallacy"
              },
              {
                "name": "Confirmation Bias"
              }
            ]
          },
          {
            "title": "Just Lose Hope Already",
            "tags": [
              {
                "name": "Motivated Reasoning"
              },
              {
                "name": "Rationalization"
              },
              {
                "name": "Hope"
              }
            ]
          },
          {
            "title": "The Proper Use of Doubt",
            "tags": [
              {
                "name": "Religion"
              },
              {
                "name": "Curiosity"
              },
              {
                "name": "Motivated Reasoning"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Modest Epistemology"
              },
              {
                "name": "Distinctions"
              }
            ]
          },
          {
            "title": "You Can Face Reality",
            "tags": [
              {
                "name": "Poetry"
              },
              {
                "name": "Litanies & Mantras"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Courage"
              }
            ]
          },
          {
            "title": "The Meditation on Curiosity",
            "tags": [
              {
                "name": "Curiosity"
              },
              {
                "name": "Litany of Tarski"
              }
            ]
          },
          {
            "title": "No One Can Exempt You From Rationality's Laws",
            "tags": [
              {
                "name": "Map and Territory"
              },
              {
                "name": "Physics"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Bayesianism"
              }
            ]
          },
          {
            "title": "Leave a Line of Retreat",
            "tags": [
              {
                "name": "Techniques"
              },
              {
                "name": "Changing Your Mind"
              },
              {
                "name": "Courage"
              },
              {
                "name": "Religion"
              }
            ]
          },
          {
            "title": "Crisis of Faith",
            "tags": [
              {
                "name": "Religion"
              },
              {
                "name": "Hamming Questions"
              }
            ]
          },
          {
            "title": "The Ritual",
            "tags": [
              {
                "name": "Ritual"
              },
              {
                "name": "Fiction"
              },
              {
                "name": "Rationality"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "M3TJ2fTCzoQq66NBJ",
    "title": "Death Spirals",
    "curatedOrder": null,
    "contents": {
      "markdown": "Leveling up in rationality means encountering a lot of interesting and powerful new ideas. In many cases, it also means making friends who you can bounce ideas off of and finding communities that encourage you to better yourself. This sequence discusses some important hazards that can afflict groups united around common interests and amazing shiny ideas, which will need to be overcome if we’re to get the full benefits out of rationalist communities."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "The Affect Heuristic",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Affect Heuristic"
              }
            ]
          },
          {
            "title": "Evaluability (And Cheap Holiday Shopping)",
            "tags": [
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Dark Arts"
              }
            ]
          },
          {
            "title": "Unbounded Scales, Huge Jury Awards, & Futurism",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Technological Forecasting"
              },
              {
                "name": "Futurism"
              }
            ]
          },
          {
            "title": "The Halo Effect",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Affect Heuristic"
              },
              {
                "name": "Halo Effect"
              }
            ]
          },
          {
            "title": "Superhero Bias",
            "tags": [
              {
                "name": "Affect Heuristic"
              },
              {
                "name": "Heuristics & Biases"
              }
            ]
          },
          {
            "title": "Affective Death Spirals",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Affect Heuristic"
              },
              {
                "name": "Emotions"
              },
              {
                "name": "Affective Death Spiral"
              }
            ]
          },
          {
            "title": "Resist the Happy Death Spiral",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Emotions"
              },
              {
                "name": "Affect Heuristic"
              },
              {
                "name": "Fallacies"
              },
              {
                "name": "Affective Death Spiral"
              }
            ]
          },
          {
            "title": "Uncritical Supercriticality",
            "tags": [
              {
                "name": "Groupthink"
              },
              {
                "name": "Affective Death Spiral"
              }
            ]
          },
          {
            "title": "Evaporative Cooling of Group Beliefs",
            "tags": [
              {
                "name": "Groupthink"
              },
              {
                "name": "Social & Cultural Dynamics"
              }
            ]
          },
          {
            "title": "When None Dare Urge Restraint",
            "tags": [
              {
                "name": "Groupthink"
              },
              {
                "name": "Politics"
              },
              {
                "name": "War"
              },
              {
                "name": "History"
              },
              {
                "name": "Affective Death Spiral"
              }
            ]
          },
          {
            "title": "Every Cause Wants To Be A Cult",
            "tags": [
              {
                "name": "Community"
              },
              {
                "name": "Social & Cultural Dynamics"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Tribalism"
              },
              {
                "name": "Cults"
              },
              {
                "name": "Affective Death Spiral"
              }
            ]
          },
          {
            "title": "Two Cult Koans",
            "tags": [
              {
                "name": "Groupthink"
              },
              {
                "name": "Fiction"
              },
              {
                "name": "Humor"
              },
              {
                "name": "Courage"
              },
              {
                "name": "Cults"
              }
            ]
          },
          {
            "title": "Asch's Conformity Experiment",
            "tags": [
              {
                "name": "Groupthink"
              },
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Social Reality"
              },
              {
                "name": "Social & Cultural Dynamics"
              },
              {
                "name": "Conformity Bias"
              }
            ]
          },
          {
            "title": "On Expressing Your Concerns",
            "tags": [
              {
                "name": "Groupthink"
              },
              {
                "name": "Social Reality"
              },
              {
                "name": "Courage"
              },
              {
                "name": "Conformity Bias"
              }
            ]
          },
          {
            "title": "Lonely Dissent",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Social Reality"
              },
              {
                "name": "Groupthink"
              },
              {
                "name": "Social & Cultural Dynamics"
              },
              {
                "name": "Courage"
              },
              {
                "name": "Conformity Bias"
              }
            ]
          },
          {
            "title": "Cultish Countercultishness",
            "tags": [
              {
                "name": "Groupthink"
              },
              {
                "name": "Pitfalls of Rationality"
              },
              {
                "name": "Affective Death Spiral"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "pmHZDpak4NeRLLLCw",
    "title": "Seeing with Fresh Eyes",
    "curatedOrder": null,
    "contents": {
      "markdown": "On the challenge of recognizing evidence that doesn’t fit our expectations and assumptions."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Anchoring and Adjustment",
            "tags": [
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Priming"
              },
              {
                "name": "Anchoring"
              }
            ]
          },
          {
            "title": "Priming and Contamination",
            "tags": [
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Priming"
              }
            ]
          },
          {
            "title": "Do We Believe Everything We're Told?",
            "tags": [
              {
                "name": "Cognitive Science"
              },
              {
                "name": "Heuristics & Biases"
              }
            ]
          },
          {
            "title": "Cached Thoughts",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Cached Thoughts"
              }
            ]
          },
          {
            "title": "Original Seeing",
            "tags": [
              {
                "name": "Writing (communication method)"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Cached Thoughts"
              }
            ]
          },
          {
            "title": "The Virtue of Narrowness",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Reductionism"
              }
            ]
          },
          {
            "title": "Stranger Than History",
            "tags": [
              {
                "name": "History"
              },
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Fiction (Topic)"
              },
              {
                "name": "Absurdity Heuristic"
              },
              {
                "name": "Hindsight Bias"
              }
            ]
          },
          {
            "title": "The Logical Fallacy of Generalization from Fictional Evidence",
            "tags": [
              {
                "name": "Fiction (Topic)"
              },
              {
                "name": "Fallacies"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Generalization From Fictional Evidence"
              }
            ]
          },
          {
            "title": "We Change Our Minds Less Often Than We Think",
            "tags": [
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Calibration"
              }
            ]
          },
          {
            "title": "Hold Off On Proposing Solutions",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Problem-solving (skills and techniques)"
              },
              {
                "name": "Problem Formulation & Conceptualization"
              }
            ]
          },
          {
            "title": "The Genetic Fallacy",
            "tags": [
              {
                "name": "Fallacies"
              },
              {
                "name": "Rationalization"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "qqFS6Kw5fmPyzkLby",
    "title": "Against Doublethink",
    "curatedOrder": null,
    "contents": {
      "markdown": "This short sequence explores another cognitive pattern that hinders our ability to update on evidence: George Orwell's 'doublethink' - the attempt to deceive oneself."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Doublethink (Choosing to be Biased)",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Self-Deception"
              }
            ]
          },
          {
            "title": "No, Really, I've Deceived Myself",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Self-Deception"
              },
              {
                "name": "Needs Fixup"
              },
              {
                "name": "Religion"
              }
            ]
          },
          {
            "title": "Belief in Self-Deception",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Self-Deception"
              },
              {
                "name": "Needs Fixup"
              },
              {
                "name": "Litany of Tarski"
              },
              {
                "name": "Anticipated Experiences"
              }
            ]
          },
          {
            "title": "Moore's Paradox",
            "tags": [
              {
                "name": "Paradoxes"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Needs Fixup"
              }
            ]
          },
          {
            "title": "Don't Believe You'll Self-Deceive",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Self-Deception"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "GSqFqc646rsRd2oyz",
    "title": "Against Rationalization",
    "curatedOrder": null,
    "contents": {
      "markdown": "The last sequence focused in on how feeling tribal often distorts our ability to reason. Now we'll explore one particular cognitive mechanism that causes this: much of our reasoning process is really rationalization—story-telling that makes our current beliefs feel more coherent and justified, without necessarily improving their accuracy."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Knowing About Biases Can Hurt People",
            "tags": [
              {
                "name": "Rationalization"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Information Hazards"
              },
              {
                "name": "Pitfalls of Rationality"
              },
              {
                "name": "Fallacies"
              },
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Valley of Bad Rationality"
              },
              {
                "name": "Motivational Intro Posts"
              }
            ]
          },
          {
            "title": "Update Yourself Incrementally",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Rationalization"
              },
              {
                "name": "Changing Your Mind"
              },
              {
                "name": "Conservation of Expected Evidence"
              },
              {
                "name": "Probabilistic Reasoning"
              }
            ]
          },
          {
            "title": "One Argument Against An Army",
            "tags": [
              {
                "name": "Rationalization"
              },
              {
                "name": "Motivated Reasoning"
              }
            ]
          },
          {
            "title": "The Bottom Line",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Rationalization"
              },
              {
                "name": "Filtered Evidence"
              },
              {
                "name": "Litany of Tarski"
              }
            ]
          },
          {
            "title": "What Evidence Filtered Evidence?",
            "tags": [
              {
                "name": "Filtered Evidence"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Rationalization"
              }
            ]
          },
          {
            "title": "Rationalization",
            "tags": [
              {
                "name": "Rationalization"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "A Rational Argument",
            "tags": [
              {
                "name": "Rationalization"
              },
              {
                "name": "Filtered Evidence"
              },
              {
                "name": "Politics"
              }
            ]
          },
          {
            "title": "Avoiding Your Belief's Real Weak Points",
            "tags": [
              {
                "name": "Religion"
              },
              {
                "name": "Motivated Reasoning"
              },
              {
                "name": "Noticing"
              }
            ]
          },
          {
            "title": "Motivated Stopping and Motivated Continuation",
            "tags": [
              {
                "name": "Motivated Reasoning"
              }
            ]
          },
          {
            "title": "Fake Justification",
            "tags": [
              {
                "name": "Motivated Reasoning"
              },
              {
                "name": "Rationalization"
              },
              {
                "name": "Religion"
              }
            ]
          },
          {
            "title": "Is That Your True Rejection?",
            "tags": [
              {
                "name": "Rationalization"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Motivated Reasoning"
              },
              {
                "name": "Motivations"
              },
              {
                "name": "Conversation (topic)"
              }
            ]
          },
          {
            "title": "Entangled Truths, Contagious Lies",
            "tags": [
              {
                "name": "Deception"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Of Lies and Black Swan Blowups",
            "tags": [
              {
                "name": "Black Swans"
              },
              {
                "name": "Deception"
              }
            ]
          },
          {
            "title": "Dark Side Epistemology",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Dark Arts"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "3ELrPerFTSo75WnrH",
    "title": "Politics and Rationality",
    "curatedOrder": null,
    "contents": {
      "markdown": "Now we move into a murkier area. Mainstream national politics, as debated by TV pundits, is famous for its angry, unproductive discussions. On the face of it, there’s something surprising about that. Why do we take political disagreements so personally, even when the machinery and effects of national politics are so distant from us in space or in time? For that matter, why do we not become more careful and rigorous with the evidence when we’re dealing with issues we deem important?"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Politics is the Mind-Killer",
            "tags": [
              {
                "name": "Politics"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Tribalism"
              },
              {
                "name": "Social & Cultural Dynamics"
              }
            ]
          },
          {
            "title": "Policy Debates Should Not Appear One-Sided",
            "tags": [
              {
                "name": "Politics"
              },
              {
                "name": "Libertarianism"
              },
              {
                "name": "Conflict vs Mistake"
              }
            ]
          },
          {
            "title": "The Scales of Justice, the Notebook of Rationality",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Affect Heuristic"
              }
            ]
          },
          {
            "title": "Correspondence Bias",
            "tags": [
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Motivations"
              },
              {
                "name": "Correspondence Bias"
              }
            ]
          },
          {
            "title": "Are Your Enemies Innately Evil?",
            "tags": [
              {
                "name": "Politics"
              },
              {
                "name": "Motivations"
              },
              {
                "name": "Social & Cultural Dynamics"
              },
              {
                "name": "Correspondence Bias"
              }
            ]
          },
          {
            "title": "Reversed Stupidity Is Not Intelligence",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Epistemology"
              },
              {
                "name": "Principles"
              },
              {
                "name": "Reversed Stupidity Is Not Intelligence"
              },
              {
                "name": "Distinctions"
              },
              {
                "name": "Steelmanning"
              }
            ]
          },
          {
            "title": "Argument Screens Off Authority",
            "tags": [
              {
                "name": "Epistemology"
              },
              {
                "name": "Social Status"
              }
            ]
          },
          {
            "title": "Hug the Query",
            "tags": [
              {
                "name": "Anticipated Experiences"
              }
            ]
          },
          {
            "title": "Rationality and the English Language",
            "tags": [
              {
                "name": "Writing (communication method)"
              },
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Human Evil and Muddled Thinking",
            "tags": [
              {
                "name": "Rationality"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "FrqfoG3LJeCZs96Ym",
    "title": "Overly Convenient Excuses",
    "curatedOrder": null,
    "contents": {
      "markdown": "This sequence focuses on questions that are as probabilistically clear-cut as questions get. The Bayes-optimal answer is often infeasible to compute, but errors like confirmation bias can take root even in cases where the available evidence is overwhelming and we have plenty of time to think things over."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "Rationality: An Introduction",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Rationality A-Z (discussion & meta)"
              },
              {
                "name": "Heuristics & Biases"
              }
            ]
          },
          {
            "title": "Tsuyoku Naritai! (I Want To Become Stronger)",
            "tags": [
              {
                "name": "Ambition"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Something To Protect"
              },
              {
                "name": "Tsuyoku Naritai"
              },
              {
                "name": "Motivational Intro Posts"
              }
            ]
          },
          {
            "title": "The Proper Use of Humility",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Humility"
              },
              {
                "name": "Distinctions"
              }
            ]
          },
          {
            "title": "Tsuyoku vs. the Egalitarian Instinct",
            "tags": [
              {
                "name": "Ambition"
              },
              {
                "name": "Tsuyoku Naritai"
              }
            ]
          },
          {
            "title": "The Third Alternative",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Self-Deception"
              },
              {
                "name": "Fallacies"
              },
              {
                "name": "Motivations"
              },
              {
                "name": "Defensibility"
              }
            ]
          },
          {
            "title": "Lotteries: A Waste of Hope",
            "tags": [
              {
                "name": "Probability & Statistics"
              },
              {
                "name": "Superstimuli"
              },
              {
                "name": "Hope"
              }
            ]
          },
          {
            "title": "New Improved Lottery",
            "tags": [
              {
                "name": "Emotions"
              },
              {
                "name": "Probability & Statistics"
              },
              {
                "name": "Superstimuli"
              }
            ]
          },
          {
            "title": "But There's Still A Chance, Right?",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Fallacy of Gray"
              }
            ]
          },
          {
            "title": "The Fallacy of Gray",
            "tags": [
              {
                "name": "Fallacies"
              },
              {
                "name": "Fallacy of Gray"
              }
            ]
          },
          {
            "title": "Absolute Authority",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Bayes' Theorem"
              },
              {
                "name": "Probabilistic Reasoning"
              },
              {
                "name": "Reversed Stupidity Is Not Intelligence"
              }
            ]
          },
          {
            "title": "How to Convince Me That 2 + 2 = 3",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Epistemology"
              },
              {
                "name": "Logic & Mathematics "
              }
            ]
          },
          {
            "title": "Infinite Certainty",
            "tags": [
              {
                "name": "Epistemology"
              },
              {
                "name": "Bayes' Theorem"
              }
            ]
          },
          {
            "title": "0 And 1 Are Not Probabilities",
            "tags": [
              {
                "name": "Probability & Statistics"
              }
            ]
          },
          {
            "title": "Your Rationality is My Business",
            "tags": [
              {
                "name": "Politics"
              },
              {
                "name": "Self-Deception"
              },
              {
                "name": "Rationality"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "5uZQHpecjn7955faL",
    "title": "Mysterious Answers",
    "curatedOrder": null,
    "contents": {
      "markdown": "This sequence asks whether science resolves the problems raised so far. Scientists base their models on repeatable experiments, not speculation or hearsay. And science has an excellent track record compared to anecdote, religion, and . . . pretty much everything else. Do we still need to worry about “fake” beliefs, confirmation bias, hindsight bias, and the like when we’re working with a community of people who want to explain phenomena, not just tell appealing stories?"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": 0,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "Fake Explanations",
            "tags": [
              {
                "name": "Anticipated Experiences"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Guessing the Teacher's Password",
            "tags": [
              {
                "name": "Problem-solving (skills and techniques)"
              },
              {
                "name": "Anticipated Experiences"
              },
              {
                "name": "Education"
              }
            ]
          },
          {
            "title": "Science as Attire",
            "tags": [
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "Signaling"
              },
              {
                "name": "Tribalism"
              }
            ]
          },
          {
            "title": "Fake Causality",
            "tags": [
              {
                "name": "Causality"
              }
            ]
          },
          {
            "title": "Semantic Stopsigns",
            "tags": [
              {
                "name": "Confirmation Bias"
              },
              {
                "name": "Paradoxes"
              }
            ]
          },
          {
            "title": "Mysterious Answers to Mysterious Questions",
            "tags": [
              {
                "name": "Reductionism"
              },
              {
                "name": "Mind Projection Fallacy"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Map and Territory"
              }
            ]
          },
          {
            "title": "The Futility of Emergence",
            "tags": [
              {
                "name": "Anticipated Experiences"
              },
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Gears-Level"
              },
              {
                "name": "Emergent Behavior"
              }
            ]
          },
          {
            "title": "Say Not \"Complexity\"",
            "tags": [
              {
                "name": "Anticipated Experiences"
              }
            ]
          },
          {
            "title": "Positive Bias: Look Into the Dark",
            "tags": [
              {
                "name": "Confirmation Bias"
              }
            ]
          },
          {
            "title": "Lawful Uncertainty",
            "tags": [
              {
                "name": "Calibration"
              },
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Bayesianism"
              }
            ]
          },
          {
            "title": "My Wild and Reckless Youth",
            "tags": [
              {
                "name": "Growth Stories"
              },
              {
                "name": "Anticipated Experiences"
              }
            ]
          },
          {
            "title": "Failing to Learn from History",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "History"
              }
            ]
          },
          {
            "title": "Making History Available",
            "tags": [
              {
                "name": "History"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Generalization From Fictional Evidence"
              },
              {
                "name": "Availability Heuristic"
              }
            ]
          },
          {
            "title": "Explain/Worship/Ignore?",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Distinctions"
              }
            ]
          },
          {
            "title": "\"Science\" as Curiosity-Stopper",
            "tags": [
              {
                "name": "Curiosity"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Truly Part Of You",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Anticipated Experiences"
              },
              {
                "name": "Techniques"
              }
            ]
          }
        ]
      },
      {
        "title": "Interlude",
        "subtitle": null,
        "number": 1,
        "contents": null,
        "posts": [
          {
            "title": "The Simple Truth",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Humor"
              },
              {
                "name": "Anticipated Experiences"
              },
              {
                "name": "Causality"
              },
              {
                "name": "Truth, Semantics, & Meaning"
              },
              {
                "name": "Map and Territory"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "zpCiuR4T343j9WkcK",
    "title": "Noticing Confusion",
    "curatedOrder": null,
    "contents": {
      "markdown": ""
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "Focus Your Uncertainty",
            "tags": [
              {
                "name": "Noticing"
              }
            ]
          },
          {
            "title": "What is Evidence?",
            "tags": [
              {
                "name": "Epistemology"
              },
              {
                "name": "Causality"
              },
              {
                "name": "Anticipated Experiences"
              }
            ]
          },
          {
            "title": "Scientific Evidence, Legal Evidence, Rational Evidence",
            "tags": [
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Empiricism"
              },
              {
                "name": "Law and Legal systems"
              },
              {
                "name": "Distinctions"
              }
            ]
          },
          {
            "title": "How Much Evidence Does It Take?",
            "tags": [
              {
                "name": "Bayes' Theorem"
              },
              {
                "name": "Epistemology"
              }
            ]
          },
          {
            "title": "Einstein's Arrogance",
            "tags": [
              {
                "name": "Bayes' Theorem"
              },
              {
                "name": "Physics"
              },
              {
                "name": "History"
              },
              {
                "name": "Practice & Philosophy of Science"
              }
            ]
          },
          {
            "title": "Occam's Razor",
            "tags": [
              {
                "name": "Occam's Razor"
              },
              {
                "name": "Principles"
              }
            ]
          },
          {
            "title": "Your Strength as a Rationalist",
            "tags": [
              {
                "name": "Rationalization"
              },
              {
                "name": "Noticing"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Absence of Evidence Is Evidence of Absence",
            "tags": [
              {
                "name": "Conservation of Expected Evidence"
              }
            ]
          },
          {
            "title": "Conservation of Expected Evidence",
            "tags": [
              {
                "name": "Conservation of Expected Evidence"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Bayes' Theorem"
              }
            ]
          },
          {
            "title": "Hindsight Devalues Science",
            "tags": [
              {
                "name": "Fallacies"
              },
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Hindsight Bias"
              }
            ]
          },
          {
            "title": "Illusion of Transparency:  Why No One Understands You",
            "tags": [
              {
                "name": "Conversation (topic)"
              },
              {
                "name": "Inferential Distance"
              },
              {
                "name": "Calibration"
              },
              {
                "name": "Illusion of Transparency"
              }
            ]
          },
          {
            "title": "Expecting Short Inferential Distances",
            "tags": [
              {
                "name": "Inferential Distance"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Evolutionary Psychology"
              },
              {
                "name": "Conversation (topic)"
              },
              {
                "name": "Public Discourse"
              },
              {
                "name": "Illusion of Transparency"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "7gRSERQZbqTuLX5re",
    "title": "Fake Beliefs",
    "curatedOrder": null,
    "contents": {
      "markdown": "An account of irrationality would be incomplete if it provided no theory about how rationality works—or if its “theory” only consisted of vague truisms, with no precise explanatory mechanism. This sequence asks why it’s useful to base one’s behavior on “rational” expectations, and what it feels like to do so."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Making Beliefs Pay Rent (in Anticipated Experiences)",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Anticipated Experiences"
              },
              {
                "name": "Epistemology"
              },
              {
                "name": "Empiricism"
              },
              {
                "name": "Principles"
              }
            ]
          },
          {
            "title": "A Fable of Science and Politics",
            "tags": [
              {
                "name": "Politics"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Fiction"
              },
              {
                "name": "Blues & Greens (metaphor)"
              },
              {
                "name": "Tribalism"
              },
              {
                "name": "Parables & Fables"
              },
              {
                "name": "Litany of Tarski"
              }
            ]
          },
          {
            "title": "Belief in Belief",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Self-Deception"
              },
              {
                "name": "Alief"
              },
              {
                "name": "Motivated Reasoning"
              },
              {
                "name": "Anticipated Experiences"
              },
              {
                "name": "Religion"
              }
            ]
          },
          {
            "title": "Religion's Claim to be Non-Disprovable",
            "tags": [
              {
                "name": "Religion"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Professing and Cheering",
            "tags": [
              {
                "name": "Social Reality"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Social & Cultural Dynamics"
              },
              {
                "name": "Religion"
              },
              {
                "name": "Motivations"
              },
              {
                "name": "Tribalism"
              }
            ]
          },
          {
            "title": "Belief as Attire",
            "tags": [
              {
                "name": "Social Reality"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Motivations"
              },
              {
                "name": "Motivated Reasoning"
              },
              {
                "name": "Tribalism"
              }
            ]
          },
          {
            "title": "Pretending to be Wise",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Signaling"
              },
              {
                "name": "Social Status"
              }
            ]
          },
          {
            "title": "Applause Lights",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Anticipated Experiences"
              },
              {
                "name": "Tribalism"
              },
              {
                "name": "Social & Cultural Dynamics"
              },
              {
                "name": "Reversal Test"
              },
              {
                "name": "Applause Light"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "5g5TkQTe9rmPS5vvM",
    "title": "Predictably Wrong",
    "curatedOrder": 504,
    "contents": {
      "markdown": "This, the first book of \"Rationality: AI to Zombies\" (also known as \"The Sequences\"), begins with cognitive bias. The rest of the book won’t stick to just this topic; bad habits and bad ideas matter, even when they arise from our minds’ contents as opposed to our minds’ structure.\n\nIt is cognitive bias, however, that provides the clearest and most direct glimpse into the stuff of our psychology, into the shape of our heuristics and the logic of our limitations. It is with bias that we will begin."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Preface",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Postmortems & Retrospectives"
              },
              {
                "name": "Rationality A-Z (discussion & meta)"
              }
            ]
          },
          {
            "title": "Biases: An Introduction",
            "tags": [
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Rationality"
              }
            ]
          },
          {
            "title": "Scope Insensitivity",
            "tags": [
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Altruism"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Scope Insensitivity"
              }
            ]
          },
          {
            "title": "The Martial Art of Rationality",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Cultural knowledge"
              },
              {
                "name": "Habits"
              },
              {
                "name": "Rationality Verification"
              },
              {
                "name": "Motivational Intro Posts"
              }
            ]
          },
          {
            "title": "Availability",
            "tags": [
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Availability Heuristic"
              }
            ]
          },
          {
            "title": "What's a Bias?",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Heuristics & Biases"
              }
            ]
          },
          {
            "title": "Burdensome Details",
            "tags": [
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Fallacies"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Conjunction Fallacy"
              }
            ]
          },
          {
            "title": "What Do We Mean By \"Rationality\"?",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Definitions"
              },
              {
                "name": "Distinctions"
              },
              {
                "name": "Motivational Intro Posts"
              }
            ]
          },
          {
            "title": "Planning Fallacy",
            "tags": [
              {
                "name": "Fallacies"
              },
              {
                "name": "Heuristics & Biases"
              },
              {
                "name": "Planning & Decision-Making"
              },
              {
                "name": "Inside/Outside View"
              },
              {
                "name": "Planning Fallacy"
              }
            ]
          },
          {
            "title": "Why Truth?",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Truth, Semantics, & Meaning"
              },
              {
                "name": "Emotions"
              }
            ]
          },
          {
            "title": "Feeling Rational",
            "tags": [
              {
                "name": "Dual Process Theory (System 1 & System 2)"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Emotions"
              }
            ]
          },
          {
            "title": "The Lens That Sees Its Flaws",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Gears-Level"
              },
              {
                "name": "Epistemology"
              },
              {
                "name": "Map and Territory"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "WnTvZdXz2q9ySfr4o",
    "title": "Parables and Prayers",
    "curatedOrder": null,
    "contents": {
      "markdown": ""
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": 0,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "Burdens",
            "tags": [
              {
                "name": "Psychiatry"
              },
              {
                "name": "Social & Cultural Dynamics"
              },
              {
                "name": "Depression"
              }
            ]
          },
          {
            "title": "The Parable Of The Talents",
            "tags": [
              {
                "name": "Heroic Responsibility"
              },
              {
                "name": "Scrupulosity"
              }
            ]
          },
          {
            "title": "Nobody Is Perfect, Everything Is Commensurable",
            "tags": [
              {
                "name": "Politics"
              },
              {
                "name": "Altruism"
              },
              {
                "name": "Emotions"
              }
            ]
          }
        ]
      },
      {
        "title": "Interlude",
        "subtitle": null,
        "number": 1,
        "contents": null,
        "posts": [
          {
            "title": "Answer to Job",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Religion"
              },
              {
                "name": "Consequentialism"
              }
            ]
          },
          {
            "title": "Universal Love, Said The Cactus Person",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "The Goddess of Everything Else",
            "tags": [
              {
                "name": "Eldritch Analogies"
              },
              {
                "name": "Fiction"
              },
              {
                "name": "Parables & Fables"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "TKDT2Mt6dDMH8AsZW",
    "title": "Futurism and Forecasting",
    "curatedOrder": null,
    "contents": {
      "markdown": "A sequence of futurism discussion that includes AGI, brain emulations and the Fermi paradox."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Superintelligence FAQ",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "AI Risk"
              },
              {
                "name": "Q&A (format)"
              },
              {
                "name": "Superintelligence"
              }
            ]
          },
          {
            "title": "AI Researchers On AI Risk",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "Should AI Be Open?",
            "tags": [
              {
                "name": "AI"
              }
            ]
          },
          {
            "title": "SSC Journal Club: AI Timelines",
            "tags": [
              {
                "name": "AI"
              },
              {
                "name": "Academic Papers"
              },
              {
                "name": "AI Timelines"
              }
            ]
          },
          {
            "title": "Where The Falling Einstein Meets The Rising Mouse",
            "tags": []
          },
          {
            "title": "Don’t Fear The Filter",
            "tags": [
              {
                "name": "Great Filter"
              },
              {
                "name": "AI"
              },
              {
                "name": "Existential Risk"
              }
            ]
          },
          {
            "title": "Book Review: Age of Em",
            "tags": [
              {
                "name": "Book Reviews"
              },
              {
                "name": "Whole Brain Emulation"
              }
            ]
          },
          {
            "title": "Ascended Economy?",
            "tags": [
              {
                "name": "Futurism"
              }
            ]
          }
        ]
      },
      {
        "title": "Interlude",
        "subtitle": null,
        "number": 1,
        "contents": null,
        "posts": [
          {
            "title": "G.K. Chesterton On AI Risk",
            "tags": [
              {
                "name": "Chesterton's Fence"
              },
              {
                "name": "Humor"
              },
              {
                "name": "AI Risk"
              }
            ]
          },
          {
            "title": "[REPOST] The Demiurge’s Older Brother",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Acausal Trade"
              },
              {
                "name": "Values handshakes"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "xmDeR64CivZiTAcLx",
    "title": "Community and Cooperation",
    "curatedOrder": null,
    "contents": null,
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": 0,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "In Favor of Niceness, Community, and Civilization",
            "tags": [
              {
                "name": "Eldritch Analogies"
              },
              {
                "name": "Community"
              },
              {
                "name": "Conflict vs Mistake"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Social & Cultural Dynamics"
              }
            ]
          },
          {
            "title": "Guided By The Beauty Of Our Weapons",
            "tags": [
              {
                "name": "Politics"
              },
              {
                "name": "Social & Cultural Dynamics"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Adversarial Collaboration"
              },
              {
                "name": "Asymmetric Weapons"
              }
            ]
          },
          {
            "title": "The Ideology Is Not The Movement",
            "tags": [
              {
                "name": "Social & Cultural Dynamics"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Politics"
              }
            ]
          },
          {
            "title": "Archipelago and Atomic Communitarianism",
            "tags": [
              {
                "name": "World Optimization"
              },
              {
                "name": "Social & Cultural Dynamics"
              }
            ]
          },
          {
            "title": "Meditations On Moloch",
            "tags": [
              {
                "name": "Moloch"
              },
              {
                "name": "Eldritch Analogies"
              },
              {
                "name": "Game Theory"
              },
              {
                "name": "World Optimization"
              },
              {
                "name": "Social & Cultural Dynamics"
              },
              {
                "name": "Incentives"
              }
            ]
          }
        ]
      },
      {
        "title": "Interlude",
        "subtitle": null,
        "number": 1,
        "contents": null,
        "posts": [
          {
            "title": "Five Planets In Search Of A Sci-Fi Story",
            "tags": []
          },
          {
            "title": "It Was You Who Made My Blue Eyes Blue",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Common Knowledge"
              },
              {
                "name": "Parables & Fables"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "zfXAcwLnGocsCsriG",
    "title": "Economics and Efficiency",
    "curatedOrder": null,
    "contents": {
      "markdown": ""
    },
    "chapters": [
      {
        "title": "Marginally Important Econ Questions",
        "subtitle": null,
        "number": 0,
        "contents": null,
        "posts": [
          {
            "title": "Against Tulip Subsidies",
            "tags": [
              {
                "name": "Economics"
              }
            ]
          },
          {
            "title": "Considerations On Cost Disease",
            "tags": [
              {
                "name": "Cost Disease"
              },
              {
                "name": "Economics"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Highlights From The Comments On Cost Disease",
            "tags": [
              {
                "name": "Cost Disease"
              },
              {
                "name": "Economics"
              }
            ]
          },
          {
            "title": "The Price Of Glee In China",
            "tags": [
              {
                "name": "Economics"
              },
              {
                "name": "China"
              }
            ]
          },
          {
            "title": "Things Probably Matter",
            "tags": [
              {
                "name": "Economics"
              }
            ]
          },
          {
            "title": "How The West Was Won",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Social & Cultural Dynamics"
              },
              {
                "name": "Industrial Revolution"
              }
            ]
          }
        ]
      },
      {
        "title": "Interlude",
        "subtitle": null,
        "number": 1,
        "contents": null,
        "posts": [
          {
            "title": "The Lizard People Of Alpha Draconis 1 Decided To Build An Ansible",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "A Modern Myth",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "B384FrQNrxSq4hZoS",
    "title": "Research and Reviews",
    "curatedOrder": null,
    "contents": {
      "markdown": "Synthesising scientific knowledge to answer a policy question is difficult. This sequence is a series of attempts to do just that, with intricate and winding literature reviews."
    },
    "chapters": [
      {
        "title": "Much More Than You Wanted to Know",
        "subtitle": null,
        "number": 0,
        "contents": null,
        "posts": [
          {
            "title": "Marijuana: Much More Than You Wanted To Know",
            "tags": [
              {
                "name": "Fact posts"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Wheat: Much More Than You Wanted To Know",
            "tags": [
              {
                "name": "Fact posts"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "SSRIs: Much More Than You Wanted To Know",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Fact posts"
              },
              {
                "name": "Health / Medicine / Disease"
              }
            ]
          },
          {
            "title": "Alcoholics Anonymous: Much More Than You Wanted To Know",
            "tags": []
          },
          {
            "title": "Prescriptions, Paradoxes, and Perversities",
            "tags": [
              {
                "name": "Psychiatry"
              }
            ]
          },
          {
            "title": "Guns And States",
            "tags": []
          },
          {
            "title": "Teachers: Much More Than You Wanted To Know",
            "tags": [
              {
                "name": "Fact posts"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Antidepressant Pharmacogenomics: Much More Than You Wanted To Know",
            "tags": []
          }
        ]
      },
      {
        "title": "Interlude",
        "subtitle": null,
        "number": 1,
        "contents": null,
        "posts": [
          {
            "title": "A Story With Zombies",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Humor"
              }
            ]
          },
          {
            "title": "Asches to Asches",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Conformity Bias"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "BQBqPowfxjvoee8jw",
    "title": "Studies and Statistics",
    "curatedOrder": null,
    "contents": {
      "markdown": "  \nAquinas famously [said](http://en.wikipedia.org/wiki/Homo_unius_libri): beware the man of one book. I would add: beware the man of one study.\n\nFor example, take medical research. Suppose a certain drug is weakly effective against a certain disease. After a few years, a bunch of different research groups have gotten their hands on it and done all sorts of different studies. In the best case scenario the average study will find the true result – that it’s weakly effective.\n\nBut there are also about 5 studies that find that the drug is very good, and 5 studies missing the sign entirely and finding that the drug is actively bad. There’s even 1 study finding that the drug is very bad, maybe seriously dangerous."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": 0,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "Beware The Man Of One Study",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "Principles"
              }
            ]
          },
          {
            "title": "Debunked And Well-Refuted",
            "tags": [
              {
                "name": "Distinctions"
              },
              {
                "name": "Probability & Statistics"
              }
            ]
          },
          {
            "title": "Noisy Poll Results And Reptilian Muslim Climatologists from Mars",
            "tags": [
              {
                "name": "Social & Cultural Dynamics"
              },
              {
                "name": "Probability & Statistics"
              },
              {
                "name": "World Modeling"
              }
            ]
          },
          {
            "title": "Two Dark Side Statistics Papers",
            "tags": [
              {
                "name": "Dark Arts"
              },
              {
                "name": "Probability & Statistics"
              }
            ]
          },
          {
            "title": "The Control Group Is Out Of Control",
            "tags": [
              {
                "name": "Replication Crisis"
              }
            ]
          },
          {
            "title": "The Cowpox of Doubt",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Community"
              },
              {
                "name": "Pitfalls of Rationality"
              }
            ]
          },
          {
            "title": "How Common Are Science Failures?",
            "tags": [
              {
                "name": "Consensus"
              }
            ]
          },
          {
            "title": "Learning To Love Scientific Consensus",
            "tags": [
              {
                "name": "Intellectual Progress (Society-Level)"
              },
              {
                "name": "Scholarship & Learning"
              },
              {
                "name": "Replication Crisis"
              },
              {
                "name": "Implicit Association Test (IAT)"
              },
              {
                "name": "Consensus"
              }
            ]
          }
        ]
      },
      {
        "title": "Interlude",
        "subtitle": null,
        "number": 1,
        "contents": null,
        "posts": [
          {
            "title": "My IRB Nightmare",
            "tags": [
              {
                "name": "Health / Medicine / Disease"
              },
              {
                "name": "Practice & Philosophy of Science"
              },
              {
                "name": "Postmortems & Retrospectives"
              },
              {
                "name": "Bureaucracy"
              }
            ]
          },
          {
            "title": "The Study of Anglophysics",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "NHXY86jBahi968uW4",
    "title": "Categorisation and Concepts",
    "curatedOrder": null,
    "contents": {
      "markdown": "\"The essay “How An Algorithm Feels From The Inside” is a gift that keeps on giving. You can get a reputation as a daring and original thinker just by copy-pasting it at different arguments with a couple of appropriate words substituted for one another, mad-libs like. It is the solution to something like 25% of extant philosophical problems.\""
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": 0,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "Diseased thinking: dissolving questions about disease",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Health / Medicine / Disease"
              },
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Carving / Clustering Reality"
              },
              {
                "name": "Reversal Test"
              },
              {
                "name": "Motivational Intro Posts"
              }
            ]
          },
          {
            "title": "The Categories Were Made For Man, Not Man For The Categories",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Philosophy of Language"
              },
              {
                "name": "Distinctions"
              }
            ]
          },
          {
            "title": "The noncentral fallacy - the worst argument in the world?",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Conversation (topic)"
              },
              {
                "name": "Fallacies"
              },
              {
                "name": "Motivational Intro Posts"
              }
            ]
          },
          {
            "title": "Ethnic Tension And Meaningless Arguments",
            "tags": [
              {
                "name": "World Modeling"
              },
              {
                "name": "Social & Cultural Dynamics"
              },
              {
                "name": "Anticipated Experiences"
              },
              {
                "name": "Tribalism"
              }
            ]
          }
        ]
      },
      {
        "title": "Interlude",
        "subtitle": null,
        "number": 1,
        "contents": null,
        "posts": [
          {
            "title": "The Moral Of The Story",
            "tags": [
              {
                "name": "Humor"
              },
              {
                "name": "Fiction"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "XsMTxdQ6fprAQMoKi",
    "title": "Argument and Analysis",
    "curatedOrder": 499,
    "contents": {
      "markdown": "A sequence of essays by Scott Alexander on how arguments work, how to use them, and how to misuse them."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": 0,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "Eight Short Studies On Excuses",
            "tags": [
              {
                "name": "Game Theory"
              },
              {
                "name": "Rationality"
              },
              {
                "name": "Practical"
              },
              {
                "name": "Whole Brain Emulation"
              },
              {
                "name": "AI Risk"
              }
            ]
          },
          {
            "title": "Schelling fences on slippery slopes",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Game Theory"
              },
              {
                "name": "Value Drift"
              }
            ]
          },
          {
            "title": "Intellectual Hipsters and Meta-Contrarianism",
            "tags": [
              {
                "name": "Signaling"
              },
              {
                "name": "Social Status"
              },
              {
                "name": "Social & Cultural Dynamics"
              },
              {
                "name": "Contrarianism"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Intellectual Fashion"
              }
            ]
          },
          {
            "title": "Cardiologists and Chinese Robbers",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Fallacies"
              }
            ]
          },
          {
            "title": "All Debates Are Bravery Debates",
            "tags": [
              {
                "name": "Social & Cultural Dynamics"
              },
              {
                "name": "Practical"
              }
            ]
          },
          {
            "title": "The Virtue of Silence",
            "tags": [
              {
                "name": "Virtues"
              },
              {
                "name": "Social & Cultural Dynamics"
              }
            ]
          },
          {
            "title": "Proving Too Much",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Fallacies"
              }
            ]
          },
          {
            "title": "Beware Isolated Demands For Rigor",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Fiction"
              },
              {
                "name": "Principles"
              }
            ]
          }
        ]
      },
      {
        "title": "Interlude",
        "subtitle": null,
        "number": 1,
        "contents": null,
        "posts": [
          {
            "title": "Transhumanist Fables",
            "tags": [
              {
                "name": "Transhumanism"
              },
              {
                "name": "Humor"
              },
              {
                "name": "Parables & Fables"
              }
            ]
          },
          {
            "title": "…And I Show You How Deep The Rabbit Hole Goes",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Humor"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "SyvHDEqbCmB3va7HJ",
    "title": "4: HJG and the Phoenix's Call",
    "curatedOrder": null,
    "contents": {
      "markdown": "If you're five hours past your bedtime and still reading this, may I suggest getting some sleep? The fic will still be here tomorrow... unless, you know, something bad happens to it and the next morning there's just a 404 at this address and you're left with nothing but a fading memory and an eternal regret that you didn't stay awake longer and keep reading while you still had the chance... but hey, how probable is that?"
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Chapter 64: Omake Files 4, Alternate Parallels",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 65: Contagious Lies",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 66: Self Actualization, Pt 1",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 67: Self Actualization, Pt 2",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 68: Self Actualization, Pt 3",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 69: Self Actualization, Pt 4",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 70: Self Actualization, Pt 5",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 71: Self Actualization, Pt 6",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 72: SA, Plausible Deniability, Pt 7",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 73: SA, The Sacred and the Mundane, Pt 8",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 74: SA, Escalation of Conflicts, Pt 9",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 75: Self Actualization Final, Responsibility",
            "tags": [
              {
                "name": "Heroic Responsibility"
              },
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 76: Interlude with the Confessor: Sunk Costs",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 77: SA, Aftermaths: Surface Appearances",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 78: Taboo Tradeoffs Prelude: Cheating",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 79: Taboo Tradeoffs, Pt 1",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 80: Taboo Tradeoffs, Pt 2, The Horns Effect",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 81: Taboo Tradeoffs, Pt 3",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 82: Taboo Tradeoffs, Final",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 83: Taboo Tradeoffs, Aftermath 1",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 84: Taboo Tradeoffs, Aftermath 2",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 85: Taboo Tradeoffs, Aftermath 3, Distance",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "2jyo5h7xkyPiMD3AA",
    "title": "5: HJPEV and the Last Enemy",
    "curatedOrder": null,
    "contents": {
      "markdown": "\"Is there some amazing rational thing you do when your mind's running in all different directions?\" she managed.\n\n\"My own approach is usually to identify the different desires, give them names, conceive of them as separate individuals, and let them argue it out inside my head. So far the main persistent ones are my Hufflepuff, Ravenclaw, Gryffindor, and Slytherin sides, my Inner Critic, and my simulated copies of you, Neville, Draco, Professor McGonagall, Professor Flitwick, Professor Quirrell, Dad, Mum, Richard Feynman, and Douglas Hofstadter.\"\n\nHermione considered trying this before her Common Sense warned that it might be a dangerous sort of thing to pretend. \"There's a copy of me inside your head?\"\n\n\"Of course there is!\" Harry said. The boy suddenly looked a bit more vulnerable. \"You mean there isn't a copy of me living in your head?\"\n\nThere was, she realized; and not only that, it talked in Harry's exact voice."
    },
    "chapters": [
      {
        "title": "HJPEV and the Last Enemy",
        "subtitle": "Chapters 86 - 99",
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Chapter 86: Multiple Hypothesis Testing",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 87: Hedonic Awareness",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Hedonism"
              }
            ]
          },
          {
            "title": "Chapter 88: Time Pressure, Pt 1",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 89: Time Pressure, Pt 2",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 90: Roles, Pt 1",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Heroic Responsibility"
              }
            ]
          },
          {
            "title": "Chapter 91: Roles, Pt 2",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 92: Roles, Pt 3",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 93: Roles, Pt 4",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 94: Roles, Pt 5",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 95: Roles, Pt 6",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 96: Roles, Pt 7",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 97: Roles, Pt 8",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 98: Roles, Final",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 99: Roles, Aftermath",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "fhRcCn2AcDCYW8PHB",
    "title": "3: HJPEV and the Shadows of Death",
    "curatedOrder": null,
    "contents": {
      "markdown": "Professor Flitwick had silently passed Harry a folded parchment during Charms class that Monday, and the note had said that Harry was to visit the Headmaster at his convenience and in such fashion that no one else would notice, especially not Draco Malfoy or Professor Quirrell. His one-time password for the gargoyle would be \"squeamish ossifrage\". This had been accompanied by a remarkably artistic ink drawing of Professor Flitwick staring at him sternly, the eyes of which occasionally blinked; and at the bottom of the note, underlined three times, was the phrase DON'T GET INTO TROUBLE."
    },
    "chapters": [
      {
        "title": "Book the Third",
        "subtitle": "Chapters 38 - 63",
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Chapter 38: The Cardinal Sin",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 39: Pretending to be Wise, Pt 1",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 40: Pretending to be Wise, Pt 2",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 41: Frontal Override",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 42: Courage",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 43: Humanism, Pt 1",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 44: Humanism, Pt 2",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 45: Humanism, Pt 3",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 46: Humanism, Pt 4",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 47: Personhood Theory",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 48: Utilitarian Priorities",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 49: Prior Information",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Priors"
              }
            ]
          },
          {
            "title": "Chapter 50: Self Centeredness",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 51: Title Redacted, Pt 1",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 52: The Stanford Prison Experiment, Pt 2",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 53: The Stanford Prison Experiment, Pt 3",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 54: The Stanford Prison Experiment, Pt 4",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 55: The Stanford Prison Experiment, Pt 5",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 56: TSPE, Constrained Optimization",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 57: TSPE, Constrained Cognition, Pt 7",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 58: TSPE, Constrained Cognition, Pt 8",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 59: TSPE, Curiosity, Pt 9",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 60: The Stanford Prison Experiment, Pt 10",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 61: TSPE, Secrecy and Openness, Pt 11",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 62: The Stanford Prison Experiment, Final",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 63: TSPE, Aftermaths",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "EBuZhwCrYuJGp7ax4",
    "title": "2: HJPEV and the Professor's Games",
    "curatedOrder": null,
    "contents": {
      "markdown": "\"Hey, did you think going to the Moon was easy? Be glad this just involves changing your mind sometimes, and not a human sacrifice!\"\n\n\"Human sacrifice would be way easier!\"\n\nThere was a slight pause, and then the figure nodded. \"Fair point.\"\n\n\\- Harry and Draco discuss learning science"
    },
    "chapters": [
      {
        "title": "Book the Second",
        "subtitle": "Chapters 21 - 37",
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Chapter 22: The Scientific Method",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 23: Belief in Belief",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 24: Machiavellian Intelligence Hypothesis",
            "tags": [
              {
                "name": "General Intelligence"
              },
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 25: Hold Off on Proposing Solutions",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Five minute timers"
              }
            ]
          },
          {
            "title": "Chapter 26: Noticing Confusion",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 27: Empathy",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 28: Reductionism",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 29: Egocentric Bias",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 30: Working in Group, Pt 1",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 31: Working in Groups, Pt 2",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 32: Interlude: Personal Financial Management",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 33: Coordination Problems, Pt 1",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 34: Coordination Problems, Pt 2",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 35: Coordination Problems, Pt 3",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 36: Status Differentials",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 37: Interlude: Crossing the Boundary",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "u7ciTcKteyx2hqdBh",
    "title": "6: HJPEV and the Philosopher's Stone",
    "curatedOrder": null,
    "contents": {
      "markdown": "Harry stared at the bodies and tried to think. There was no time for doubts, for caveats, no brakes or second-guessing just take the first thoughts and run with them\n\nIn the back of Harry's mind, fragments of abstract thought flitted past, heuristics of problem-solving that there was no time to rehearse in words. In wordless flashes they shot past, to set up the object-level problem.\n\n_\\- the first place to look for a problem is whatever aspect of the situation seems most improbable_\n\n_\\- simple explanations are more probable, eliminate separate improbabilities that must be postulated -_\n\n_\\- what do I notice I am confused by -_"
    },
    "chapters": [
      {
        "title": "Book the Last",
        "subtitle": "Chapters 100 - 122",
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Chapter 100: Precautionary Measures, Pt 1",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 101: Precautionary Measures, Pt 2",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 102: Caring",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 103: Tests",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 104: The Truth, Pt 1, Riddles and Answers",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 105: The Truth, Pt 2",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 106: The Truth, Pt 3",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 107: The Truth, Pt 4",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 108: The Truth, Pt 5, Answers and Riddles",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 109: Reflections",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 110: Reflections, Pt 2",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 111: Failure, Pt 1",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 112: Failure, Pt 2",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 113: Final Exam",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 114: Shut Up and Do The Impossible",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 115: Shut Up and Do The Impossible, Pt 2",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 116: Aftermath, Something to Protect, Pt 0",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 117: Something to Protect: Minerva McGonagall",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Something To Protect"
              }
            ]
          },
          {
            "title": "Chapter 118: Something to Protect: Professor Quirrell",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 119: Something to Protect: Albus Dumbledore",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Something To Protect"
              }
            ]
          },
          {
            "title": "Chapter 120: Something to Protect: Draco Malfoy",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 121: Something to Protect: Severus Snape",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Something To Protect"
              }
            ]
          },
          {
            "title": "Chapter 122: Something to Protect: Hermione Granger",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Something To Protect"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "PtgH6ALi5CoJnPmGS",
    "title": "The Methods of Rationality",
    "curatedOrder": 502,
    "contents": {
      "markdown": "Harry: You can't DO that!\n\nMinerva McGonagall: It's only a transfiguration; an animagus transformation, to be exact—\n\nHarry: You turned into a cat! A SMALL cat! You violated Conservation of Energy! That's not just an arbitrary rule – rejecting it destroys unitarity and then you get FTL signaling! And cats are COMPLICATED! How can you go on thinking using a cat-sized brain?\n\nMinerva: Magic.\n\nHarry: Magic isn't enough to do that! You'd have to be a god!\n\n—Harry's first encounter with magic"
    },
    "chapters": [
      {
        "title": "Book the First",
        "subtitle": "Chapters 1 - 20",
        "number": null,
        "contents": null,
        "posts": [
          {
            "title": "Chapter 1: A Day of Very Low Probability",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 2: Everything I Believe is False",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 3: Comparing Reality To Its Alternatives",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 4: The Efficient Market Hypothesis",
            "tags": [
              {
                "name": "Financial Investing"
              },
              {
                "name": "Fiction"
              },
              {
                "name": "Efficient Market Hypothesis"
              }
            ]
          },
          {
            "title": "Chapter 5: The Fundamental Attribution Error",
            "tags": [
              {
                "name": "Fiction"
              },
              {
                "name": "Correspondence Bias"
              }
            ]
          },
          {
            "title": "Chapter 6: The Planning Fallacy",
            "tags": [
              {
                "name": "Planning & Decision-Making"
              },
              {
                "name": "Fiction"
              },
              {
                "name": "Planning Fallacy"
              }
            ]
          },
          {
            "title": "Chapter 7: Reciprocation",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 8: Positive Bias",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 9: Title Redacted, Part 1",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 10: Self Awareness, Part II",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 11: Omake Files 1, 2, 3",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 12: Impulse Control",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 13: Asking the Wrong Questions",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 14: The Unknown and the Unknowable",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 15: Conscientiousness",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 16: Lateral Thinking",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 17: Locating the Hypothesis",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 18: Dominance Hierarchies",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 19: Delayed Gratification",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 20: Bayes's Theorem",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          },
          {
            "title": "Chapter 21: Rationalization",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "5ZhfGb9Sw98A9HdTQ",
    "title": "This is a new sequence",
    "curatedOrder": null,
    "contents": {
      "markdown": "It is quite good, you should read it."
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": -2,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "'An objective defense of Bayesianism'",
            "tags": []
          }
        ]
      },
      {
        "title": "This is a chapter",
        "subtitle": "A quite good one at that",
        "number": -1,
        "contents": {
          "markdown": "It _has text,_ **in all kinds of formats.**"
        },
        "posts": [
          {
            "title": "Bayes' Theorem Illustrated (My Way)",
            "tags": [
              {
                "name": "Bayes' Theorem"
              },
              {
                "name": "Bayesian Decision Theory"
              }
            ]
          },
          {
            "title": "Schelling fences on slippery slopes",
            "tags": [
              {
                "name": "Rationality"
              },
              {
                "name": "Game Theory"
              },
              {
                "name": "Value Drift"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    "_id": "rNuPrZvabXe2MaZv8",
    "title": "Politics and Pragmatics",
    "curatedOrder": null,
    "contents": {
      "markdown": ""
    },
    "chapters": [
      {
        "title": null,
        "subtitle": null,
        "number": 0,
        "contents": {
          "markdown": ""
        },
        "posts": [
          {
            "title": "I Can Tolerate Anything Except The Outgroup",
            "tags": [
              {
                "name": "Politics"
              },
              {
                "name": "Social & Cultural Dynamics"
              },
              {
                "name": "World Modeling"
              },
              {
                "name": "Tribalism"
              }
            ]
          },
          {
            "title": "Book Review: Albion’s Seed",
            "tags": [
              {
                "name": "Book Reviews"
              },
              {
                "name": "History"
              }
            ]
          },
          {
            "title": "Albion’s Seed, Genotyped",
            "tags": [
              {
                "name": "Human Genetics"
              }
            ]
          },
          {
            "title": "Society Is Fixed, Biology Is Mutable",
            "tags": [
              {
                "name": "Biology"
              },
              {
                "name": "Social & Cultural Dynamics"
              },
              {
                "name": "Distinctions"
              }
            ]
          }
        ]
      },
      {
        "title": "Interlude",
        "subtitle": null,
        "number": 1,
        "contents": null,
        "posts": [
          {
            "title": "A Philosopher Walks Into A Coffee Shop",
            "tags": [
              {
                "name": "Philosophy"
              },
              {
                "name": "Humor"
              }
            ]
          },
          {
            "title": "The Witching Hour",
            "tags": [
              {
                "name": "Fiction"
              }
            ]
          }
        ]
      }
    ]
  }
]