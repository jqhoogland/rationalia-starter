---
_id: io2ExA7GEeTgHFTFW
title: Center on Long-Term Risk (CLR)
href: https://www.lesswrong.com/tag/center-on-long-term-risk-clr
slug: center-on-long-term-risk-clr
type: tag
tags:
  - LessWrong
  - Concept
  - Tag
synchedAt: '2022-09-01T09:42:16.975Z'
status: todo
---

# Center on Long-Term Risk (CLR)

The **Center on Long-Term Risk**, formerly *Foundational Research Institute,* is an [[Effective Altruism|effective altruist]] is a research group affiliated with the Swiss/German [Effective Altruism Foundation](https://ea-foundation.org/). It investigates cooperative strategies to reduce [[Risks of Astronomical Suffering (S-risks)|risks of astronomical suffering]] in humanity's future (s-risks). This includes not only (post-)human suffering, but also the suffering of non-human animals and potential digital sentience. Their research is interdisciplinary, drawing on insights from [[Artificial General Intelligence|artificial intelligence]], [anthropic reasoning](https://wiki.lesswrong.com/wiki/anthropic_reasoning), international relations, sociology, philosophy, and other fields.

## **See also**

- [[Risks of Astronomical Suffering (S-risks)|Suffering risk]] (`= [[Risks of Astronomical Suffering (S-risks)|Suffering risk]].status`)
- [[Abolitionism]] (`= [[Abolitionism]].status`)

## **External links**

- [CLR website](https://longtermrisk.org/)
- [Effective Altruism Wiki article on FRI](http://archive.is/aZjiv)


%%

% START
Basic (and reversed card)
What is **Center on Long-Term Risk (CLR)**?
Back: {TODO}
Tags: LessWrong
END

%%
	
