---
title: Thoughts in Philosophy of Science of AI alignment
type: sequence
tags:
  - LessWrong
  - Sequence
---

In this series of posts, I introduce ideas in the “*philosophy of science of AI alignment*". 

Philosophy of science is concerned with the epistemic foundations, methods, and implications of science in general or the science of a specific domain. Accordingly, leading questions of this series include: what is the epistemic nature of the alignment problem? What epistemic strategies appear promising, and conditional a on which epistemic assumptions? Other posts aim to introduce or clarify language for talking more clearly about the problem, about the existing research landscape, or about what progress might look like. Some posts more specifically explore and develop epistemic assumptions underlying the research direction pursued by [PIBBSS](https://www.pibbss.ai/). 

This sequence is a collection of related ideas rather than a series of posts with a signle red thread/coherent arch; it is a "living" project in that I expect to be adding new posts over an undefined amount of time.

# Chapters

## Thoughts in Philosophy of Science of AI alignment

- [[Epistemic Artefacts of (conceptual) AI alignment research]]
- [[AI alignment as “navigating the space of intelligent behaviour”]]