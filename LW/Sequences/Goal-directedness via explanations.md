---
_id: BvbzaXhDasgRYqPdp
title: Goal-directedness via explanations
type: sequence
tags:
  - LessWrong
  - Sequence
synchedAt: '2022-08-29T11:15:19.700Z'
---
# Goal-directedness via explanations

This sequence records an ongoing attempt to formalize the concept of "goal-directedness", as an eventual foundation for analysing philosophical arguments for the risks from AI which are based on this concept.

*Above, a selection of images generated on craiyon.com in response to the prompts "AI Goal-directed" and "Goal-directed AI". It was mildly interesting to observe that the former produced images with darker, blue-green backgrounds, while the latter produced white backgrounds.*

# Chapters

## Goal-directedness via explanations

- [[Goal-directedness— my baseline beliefs]]
- [[Goal-directedness— exploring explanations]]
- [[Goal-directedness— imperfect reasoning, limited knowledge and inaccurate beliefs]]
- [[Goal-directedness— tackling complexity]]
- [[Goal-directedness— relativising complexity]]