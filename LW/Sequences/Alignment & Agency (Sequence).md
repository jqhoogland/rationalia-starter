---
_id: PKKsrXtuptWzaKCjr
title: Alignment & Agency
curatedOrder: null
type: sequence
tags:
  - LessWrong
  - Sequence
aliases:
  - Alignment & Agency
synchedAt: '2022-08-29T17:16:36.963Z'
status: todo
---

# Alignment & Agency

## Chapters

### Alignment & Agency

- [[An Orthodox Case Against Utility Functions]]
- [[The Pointers Problem— Human Values Are A Function Of Humans' Latent Variables]]
- [[Alignment By Default]]
- [[An overview of 11 proposals for building safe advanced AI]]
- [[The ground of optimization]]
- [[Search versus design]]
- [[Inner Alignment— Explain like I'm 12 Edition]]
- [[Inaccessible information]]
- [[AGI safety from first principles— Introduction]]
