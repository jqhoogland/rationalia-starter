---
_id: PKKsrXtuptWzaKCjr
title: Alignment & Agency
curatedOrder: null
type: sequence
tags:
  - LessWrong
  - Sequence
aliases:
  - Alignment & Agency
synchedAt: '2022-08-29T17:16:36.963Z'
status: todo
---

# Alignment & Agency

## Chapters

### Alignment & Agency

- [[An Orthodox Case Against Utility Functions]] (`= [[An Orthodox Case Against Utility Functions]].status`)
- [[The Pointers Problem— Human Values Are A Function Of Humans' Latent Variables]] (`= [[The Pointers Problem— Human Values Are A Function Of Humans' Latent Variables]].status`)
- [[Alignment By Default]] (`= [[Alignment By Default]].status`)
- [[An overview of 11 proposals for building safe advanced AI]] (`= [[An overview of 11 proposals for building safe advanced AI]].status`)
- [[The ground of optimization]] (`= [[The ground of optimization]].status`)
- [[Search versus design]] (`= [[Search versus design]].status`)
- [[Inner Alignment— Explain like I'm 12 Edition]] (`= [[Inner Alignment— Explain like I'm 12 Edition]].status`)
- [[Inaccessible information]] (`= [[Inaccessible information]].status`)
- [[AGI safety from first principles— Introduction]] (`= [[AGI safety from first principles— Introduction]].status`)
