---
_id: EcKbpm4f7fBwhxRZs
title: Takeoff & Takeover
curatedOrder: null
type: sequence
tags:
  - LessWrong
  - Sequence
aliases:
  - Takeoff & Takeover
  - Takeoff
  - Takeover
synchedAt: '2022-08-29T17:16:42.660Z'
status: todo
---

# Takeoff & Takeover

> Imagine an advanced society, with complex structures more intricate and intelligent than anything that exists today – a society which nevertheless lacks any being that is conscious, or whose welfare has moral significance. In a sense, this would be an uninhabited society. It would be a society of economic miracles and technological awesomeness, with nobody there to benefit. A Disneyland with no children.
>
> – Nick Bostrom

## Chapters

### Takeoff & Takeover

- [[Draft report on AI timelines]] (`= [[Draft report on AI timelines]].status`)
- [[An overview of 11 proposals for building safe advanced AI]] (`= [[An overview of 11 proposals for building safe advanced AI]].status`)
- [[Cortés, Pizarro, and Afonso as Precedents for Takeover]] (`= [[Cortés, Pizarro, and Afonso as Precedents for Takeover]].status`)
- [[Nuclear war is unlikely to cause human extinction]] (`= [[Nuclear war is unlikely to cause human extinction]].status`)
- [[Reply to Eliezer on Biological Anchors]] (`= [[Reply to Eliezer on Biological Anchors]].status`)
- [[Biology-Inspired AGI Timelines— The Trick That Never Works]] (`= [[Biology-Inspired AGI Timelines— The Trick That Never Works]].status`)
- [[Against GDP as a metric for timelines and takeoff speeds]] (`= [[Against GDP as a metric for timelines and takeoff speeds]].status`)
- [[The date of AI Takeover is not the day the AI takes over]] (`= [[The date of AI Takeover is not the day the AI takes over]].status`)
- [[Some AI research areas and their relevance to existential safety]] (`= [[Some AI research areas and their relevance to existential safety]].status`)
