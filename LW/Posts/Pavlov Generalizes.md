---
_id: XTgkhjNTEi97WHMi6
title: Pavlov Generalizes
author: null
url: null
slug: pavlov-generalizes
type: post
tags:
  - LessWrong
  - Concept
  - Post
  - Prisoner's_Dilemma
  - Game_Theory
  - Decision_Theory
href: https://www.lesswrong.com/posts/XTgkhjNTEi97WHMi6/pavlov-generalizes
chapter: null
synchedAt: '2022-09-01T09:25:43.826Z'
status: todo
---

# Pavlov Generalizes


# Related

- [[Prisoner's Dilemma]]
- [[Game Theory]]
- [[Decision Theory]]
- [[The Pavlov Strategy]]
- "[cooperation/coordination/bargaining](https://www.alignmentforum.org/posts/5bd75cc58225bf067037554e/distributed-cooperation)"
- "[logical time](https://www.alignmentforum.org/posts/dKAJqBDZRMMsaaYo5/in-logical-time-all-games-are-iterated-games)"
- "[Achieving Pareto Optimality Through Distributed Learning](https://ora.ox.ac.uk/objects/uuid:cb98a552-448b-4f53-87da-730421921bdd/download_file?safe_filename=paper557.pdf&file_format=application%2Fpdf&type_of_work=Working+paper)"
- "[MTG color wheel](https://medium.com/s/story/the-mtg-color-wheel-c9700a7cf36d)"
- "[discuss AI alignment](https://www.alignmentforum.org/posts/9CKBtxWtjvminNTmC/how-the-mtg-color-wheel-explains-ai-safety)"
- "[Sarah discusses some of them](https://www.lesswrong.com/posts/2meuc3kPRkBcRpj3R/contrite-strategies-and-the-need-for-standards)"
- "[LÃ¶bian handshake](https://arxiv.org/abs/1401.5577)"
- "[in this post](https://www.alignmentforum.org/posts/5bd75cc58225bf067037536c/prediction-based-robust-cooperation)"
- "[Agent Simulates Predictor](https://www.alignmentforum.org/posts/5bd75cc58225bf0670374f4f/agents-that-can-predict-their-newcomb-predictor)"
- "[Decision Theory is for Making Bad Outcomes Inconsistent](https://intelligence.org/2017/04/07/decisions-are-for-making-bad-outcomes-inconsistent/)"
- "[The Happy Dance Problem](https://www.alignmentforum.org/posts/5bd75cc58225bf067037550e/the-happy-dance-problem)"