---
_id: yEa7kwoMpsBgaBCgb
title: Towards a New Impact Measure
author: TurnTrout
url: null
slug: towards-a-new-impact-measure
type: post
tags:
  - LessWrong
  - Concept
  - Post
  - Impact_Measures
href: https://www.lesswrong.com/posts/yEa7kwoMpsBgaBCgb/towards-a-new-impact-measure
sequence: Epistemology
chapter: null
synchedAt: '2022-09-01T09:08:27.233Z'
status: todo
collection: Best of LessWrong
book: A Map That Reflects the Territory
---

# Towards a New Impact Measure


# Related

- [[Impact Measures]]
- "[low impact](https://arbital.com/p/low_impact/)"
- "[corrigibility](https://arbital.com/p/corrigibility/)"
- "[basic AI drives](https://selfawaresystems.files.wordpress.com/2008/01/ai_drives_final.pdf)"
- "[Worrying about the Vase: Whitelisting](https://www.lesswrong.com/posts/H7KB44oKoSjSCkpzL/worrying-about-the-vase-whitelisting)"
- "[Overcoming Clinginess in Impact Measures](https://www.lesswrong.com/posts/DvmhXysefEyEvXuXS/overcoming-clinginess-in-impact-measures)"
- "[Impact Measure Desiderata](https://www.lesswrong.com/posts/c2oM7qytRByv6ZFtz/impact-measure-desiderata)"
- "[advanced agent](https://arbital.com/p/advanced_agent/)"
- "[Safe Impact Measure](https://arbital.com/p/4l/)"
- "[Methodology of Unbounded Analysis](https://arbital.com/p/unbounded_analysis/)"
- "[Executable Philosophy](https://arbital.com/p/executable_philosophy/)"
- "[Cohen et al.](https://cs.anu.edu.au/courses/CSPROJECTS/18S1/reports/u6357432.pdf)"
- "[clinginess](https://www.lesswrong.com/posts/H7KB44oKoSjSCkpzL/worrying-about-the-vase-whitelisting)"
- "[stasis](https://www.lesswrong.com/posts/H7KB44oKoSjSCkpzL/worrying-about-the-vase-whitelisting)"
- "[almost never](https://vkrakovna.wordpress.com/2018/04/02/specification-gaming-examples-in-ai/)"
- [[37 Ways That Words Can Be Wrong]]
- "[the desiderata I recently proposed](https://www.lesswrong.com/posts/c2oM7qytRByv6ZFtz/impact-measure-desiderata)"
- "[extended](https://www.gleech.org/grids/)"
- "[AI safety grid worlds](https://deepmind.com/blog/specifying-ai-safety-problems/)"
- "[code](https://github.com/alexander-turner/attainable-utility-preservation)"
- "[relative reachability](https://arxiv.org/abs/1806.01186)"
- "[showing it can learn to play _e.g._ tic-tac-toe and rock-paper-scissors](https://jair.org/index.php/jair/article/view/10685/25533)"
- "[whitelisting](https://www.lesswrong.com/posts/H7KB44oKoSjSCkpzL/worrying-about-the-vase-whitelisting)"
- [[Robustness to Scale]]
- "[approval incentive](https://arbital.com/p/approval_directed_agents/)"
- "[Mild Optimization](https://arbital.com/p/soft_optimizer/)"
- "[other-izer](https://arbital.com/p/otherizer/)"
- "[computronium](https://en.wikipedia.org/wiki/Computronium)"
- "[value-laden](https://arbital.com/p/value_laden/)"
- "[clinginess / scapegoating tradeoff](https://www.lesswrong.com/posts/DvmhXysefEyEvXuXS/overcoming-clinginess-in-impact-measures)"
- "[complex notions of value](https://wiki.lesswrong.com/wiki/Complexity_of_value)"
- "[Goodhart's curse](https://arbital.com/p/goodharts_curse/)"
- "[CHAI](https://humancompatible.ai/)"
- "[BERI](http://existence.org/)"
- "[their extension of the AI safety gridworlds for side effects](https://www.gleech.org/grids/)"