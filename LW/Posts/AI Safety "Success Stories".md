---
_id: bnY3L48TtDrKTzGRb
title: AI Safety "Success Stories"
author: Wei_Dai
url: null
slug: ai-safety-success-stories
type: post
tags:
  - LessWrong
  - Concept
  - Post
  - AI_Risk
  - AI_Success Models
  - AI_Success_Models
href: https://www.lesswrong.com/posts/bnY3L48TtDrKTzGRb/ai-safety-success-stories
sequence: Failure
chapter: null
synchedAt: '2022-09-01T09:35:05.492Z'
status: todo
collection: Best of LessWrong
book: The Engines of Cognition
---

# AI Safety "Success Stories"


# Related

- [[AI Risk]]
- [[AI Success Models]]
- "[Friendly AI](https://wiki.lesswrong.com/wiki/Friendly_artificial_intelligence)"
- "[task AGI](https://arbital.com/p/task_agi/)"
- "[pivotal](https://arbital.com/p/pivotal/)"
- "[short-term preferences](greaterwrong.com/posts/BKM8uQS6QdJPZLqCr/towards-a-mechanistic-understanding-of-corrigibility#Act_Based_Corrigibility)"
- "[1](https://www.greaterwrong.com/posts/pZhDWxDmwzuSwLjou/asymptotically-benign-agi/comment/aRBJ3M8f52Fm5pMty)"
- "[2](https://www.greaterwrong.com/posts/cSzaxcmeYW6z7cgtc/contest-usd1-000-for-good-questions-to-ask-to-an-oracle-ai/comment/JMABP4HCXFvAX8JXw)"