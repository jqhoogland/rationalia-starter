---
_id: uXH4r6MmKPedk8rMA
title: Gradient hacking
author: null
url: null
slug: gradient-hacking
type: post
tags:
  - LessWrong
  - Concept
  - Post
  - Mesa-Optimization
  - Inner_Alignment
  - Transparency_/ Interpretability (ML & AI)
  - AI
  - Gradient_Hacking
  - Transparency_/_Interpretability_(ML_&_AI)
href: https://www.lesswrong.com/posts/uXH4r6MmKPedk8rMA/gradient-hacking
sequence: Incentives
chapter: null
synchedAt: '2022-09-01T09:28:31.254Z'
status: todo
collection: Best of LessWrong
book: The Engines of Cognition
---

# Gradient Hacking


# Related

- [[Mesa-Optimization]]
- [[Inner Alignment]]
- [[Transparency / Interpretability (ML & AI)]]
- [[AI]]
- [[Gradient Hacking]]
- "[deceptively aligned](https://www.alignmentforum.org/s/r9tYkB2a8Fp4DN8yB/p/zthDPAjh9w6Ytbeks)"
- "[Risks from Learned Optimization](https://arxiv.org/abs/1906.01820)"
- "[the following footnote](https://www.alignmentforum.org/s/r9tYkB2a8Fp4DN8yB/p/zthDPAjh9w6Ytbeks#fn-xsRHpadWKiBheq9EK-12)"
- "[optimization provenance](https://www.alignmentforum.org/posts/Zj2PgP5A8vY2G3gYw/optimization-provenance)"