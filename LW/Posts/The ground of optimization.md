---
_id: znfkdCoHMANwqc2WE
title: The ground of optimization
author: null
url: null
slug: the-ground-of-optimization-1
type: post
tags:
  - LessWrong
  - Concept
  - Post
  - AI
  - World_Modeling
  - General_Intelligence
  - Optimization
  - Selection_vs Control
  - Selection_vs_Control
href: https://www.lesswrong.com/posts/znfkdCoHMANwqc2WE/the-ground-of-optimization-1
sequence: Alignment & Agency
chapter: null
synchedAt: '2022-09-01T09:08:43.695Z'
status: todo
collection: Best of LessWrong
---

# The Ground of Optimization


# Related

- [[AI]]
- [[World Modeling]]
- [[General Intelligence]]
- [[Optimization]]
- [[Selection vs Control]]
- "[*Measuring Optimization Power*](https://www.lesswrong.com/posts/Q4hLMDrFd8fbteeZ8/measuring-optimization-power)"
- "[written](https://www.fhi.ox.ac.uk/reframing)"
- "[written](https://intelligence.org/embedded-agency/)"
- "[can only grow so tall](https://www.calacademy.org/explore-science/trees-can-only-grow-so-tall)"
- "[pointed out](https://www.lesswrong.com/posts/26eupx3Byc8swRS7f/bottle-caps-aren-t-optimisers)"
- "[asks](https://www.lesswrong.com/posts/26eupx3Byc8swRS7f/bottle-caps-aren-t-optimisers)"
- "[Yudkowskyâ€™s definition of optimization](https://www.lesswrong.com/posts/Q4hLMDrFd8fbteeZ8/measuring-optimization-power)"