---
_id: AHhCrJ2KpTjsCSwbt
title: 'Inner Alignment: Explain like I''m 12 Edition'
author: null
url: null
slug: inner-alignment-explain-like-i-m-12-edition
type: post
tags:
  - LessWrong
  - Concept
  - Post
  - Inner_Alignment
  - AI
  - Mesa-Optimization
href: >-
  https://www.lesswrong.com/posts/AHhCrJ2KpTjsCSwbt/inner-alignment-explain-like-i-m-12-edition
sequence: Alignment & Agency
chapter: null
synchedAt: '2022-09-01T09:27:40.944Z'
status: todo
collection: Best of LessWrong
---

# Inner Alignment: Explain Like I'm 12 Edition


# Related

- [[Inner Alignment]]
- [[AI]]
- [[Mesa-Optimization]]
- "[Risks from Learned Optimization in Advanced Machine Learning Systems](https://arxiv.org/abs/1906.01820)"
- "[LW sequence](https://www.lesswrong.com/s/r9tYkB2a8Fp4DN8yB)"
- "[Future of Life podcast](https://futureoflife.org/2020/07/01/evan-hubinger-on-inner-alignment-outer-alignment-and-proposals-for-building-safe-advanced-ai/)"
- "[Miri](https://intelligence.org/team/)"
- "[LW](https://www.lesswrong.com/users/evhub)"
- "[neural network](https://www.lesswrong.com/posts/Madwb2t79LGrLqWLH/a-simple-introduction-to-neural-networks)"
- "[very complicated reasons](https://ordinaryideas.wordpress.com/2016/11/30/what-does-the-universal-prior-actually-look-like/)"
- "[Superintelligence](https://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/0198739834/ref=sr_1_1?dchild=1&keywords=superintelligence&qid=1595696791&sr=8-1)"
- "[a follow-up post](https://www.lesswrong.com/posts/FDJnZt8Ks2djouQTZ/how-do-we-become-confident-in-the-safety-of-a-machine)"
- "[fourth part](https://www.lesswrong.com/s/r9tYkB2a8Fp4DN8yB/p/zthDPAjh9w6Ytbeks)"
- "[LW](https://www.lesswrong.com/users/buck)"
- "[Blaise Pascal](https://en.wikipedia.org/wiki/Blaise_Pascal)"
- [[An overview of 11 proposals for building safe advanced AI]]
- "[Inner Alignment in the brain](https://www.lesswrong.com/posts/DWFx2Cmsvd4uCKkZ4/inner-alignment-in-the-brain)"