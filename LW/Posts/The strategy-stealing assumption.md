---
_id: nRAMpjnb6Z4Qv3imF
title: The strategy-stealing assumption
author: null
url: null
slug: the-strategy-stealing-assumption
type: post
tags:
  - LessWrong
  - Concept
  - Post
  - AI_Risk
  - AI
href: >-
  https://www.lesswrong.com/posts/nRAMpjnb6Z4Qv3imF/the-strategy-stealing-assumption
sequence: Failure
chapter: null
synchedAt: '2022-09-01T09:08:42.704Z'
status: todo
collection: Best of LessWrong
book: The Engines of Cognition
---

# The Strategy-stealing Assumption


# Related

- [[AI Risk]]
- [[AI]]
- "[Strategies for Coalitions in Unit-Sum Games](https://www.lesswrong.com/posts/5bd75cc58225bf0670375325/strategies-for-coalitions-in-unit-sum-games)"
- "[quantitatively this doesnâ€™t seem like a big consideration](https://rationalaltruist.com/2013/04/30/astronomical-waste/)"
- "[I find it much less clear under what conditions I should empathize with AI](https://ai-alignment.com/sympathizing-with-ai-e11a4bf5ef6e)"
- "[Why might the future be good?](https://rationalaltruist.com/2013/02/27/why-will-they-be-happy/)"
- "[here](https://ai-alignment.com/a-possible-stance-for-ai-control-research-fe9cf717fc1b)"