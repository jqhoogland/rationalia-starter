---
_id: RQpNHSiWaXTvDxt6R
title: Coherent decisions imply consistent utilities
author: Eliezer Yudkowsky
url: null
slug: coherent-decisions-imply-consistent-utilities
type: post
tags:
  - LessWrong
  - Concept
  - Post
  - Utility_Functions
  - Decision_Theory
  - World_Modeling
  - Coherence_Arguments
href: >-
  https://www.lesswrong.com/posts/RQpNHSiWaXTvDxt6R/coherent-decisions-imply-consistent-utilities
sequence: Modularity
chapter: null
synchedAt: '2022-09-01T09:32:44.087Z'
status: todo
collection: Best of LessWrong
book: The Engines of Cognition
---

# Coherent Decisions Imply Consistent Utilities


# Related

- [[Utility Functions]]
- [[Decision Theory]]
- [[World Modeling]]
- [[Coherence Arguments]]
- "[probability theory](https://arbital.com/p/probability_theory/)"
- "[The Psychology of the Unthinkable: Taboo Trade-Offs, Forbidden Base Rates, and Heretical Counterfactuals](http://scholar.harvard.edu/files/jenniferlerner/files/2000_the_psychology_of_the_unthinkable.pdf?m=145089665)"
- "[Bayesian](https://arbital.com/p/bayes_rule_guide/)"
- "[prior probability](https://arbital.com/p/prior_probability/)"
- "[universal priors](https://arbital.com/p/universal_prior/)"
- "[mutually exclusive](https://arbital.com/p/exclusive_exhaustive/)"
- "[exhaustive](https://arbital.com/p/exclusive_exhaustive/)"
- "[conditional probability](https://arbital.com/p/conditional_probability/)"
- "[Abraham Wald's complete class theorem](https://projecteuclid.org/download/pdf_1/euclid.aoms/1177730345)"
- "[one set of axioms](https://en.wikipedia.org/wiki/Von_Neumann%E2%80%93Morgenstern_utility_theorem#The_axioms)"
- "[Cox's Theorem](https://en.wikipedia.org/wiki/Cox's_theorem)"
- "[Consequentialist cognition](https://arbital.com/p/consequentialist/)"
- "[the orthogonality of agents' utility functions and capabilities](https://arbital.com/p/1y)"
- "[epistemic and instrumental efficiency](https://arbital.com/p/10g)"
- "[instrumental strategies sufficiently capable agents tend to converge on](https://arbital.com/p/instrumental_convergence/)"
- "[properties of sufficiently advanced agents](https://arbital.com/p/advanced_agent/)"
- "[The controversial counterfactual at the heart of the expected utility formula](https://intelligence.org/2018/10/31/embedded-decisions/)"
- "[tiny bit less](https://arbital.com/p/cromwells_rule/)"
- "[update](https://arbital.com/p/bayes_update/)"