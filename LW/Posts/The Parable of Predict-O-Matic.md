---
_id: SwcyMEgLyd4C3Dern
title: The Parable of Predict-O-Matic
author: null
url: null
slug: the-parable-of-predict-o-matic
type: post
tags:
  - LessWrong
  - Concept
  - Post
  - AI
  - Myopia
  - Oracle_AI
  - Parables_& Fables
  - Self_Fulfilling/Refuting Prophecies
  - Parables_&_Fables
  - Self_Fulfilling/Refuting_Prophecies
href: >-
  https://www.lesswrong.com/posts/SwcyMEgLyd4C3Dern/the-parable-of-predict-o-matic
sequence: Failure
chapter: null
synchedAt: '2022-09-01T09:09:22.322Z'
status: todo
collection: Best of LessWrong
book: The Engines of Cognition
---

# The Parable of Predict-O-Matic


# Related

- [[AI]]
- [[Myopia]]
- [[Oracle AI]]
- [[Parables & Fables]]
- [[Self Fulfilling/Refuting Prophecies]]
- "[previous post](https://www.lesswrong.com/posts/4hdHto3uHejhY2F3Q/partial-agency)"
- "[select the prediction which results in the best overall future](https://www.lesswrong.com/posts/KbCHcb8yyjAMFAAPJ/when-wishful-thinking-works)"
- "[decision market](https://www.semanticscholar.org/paper/Eliciting-information-for-decision-making-from-and-Oesterheld-Conitzer/066ffe868d88ff1ad526cc0cad5296c3ffc290eb)"
- "[Partial Agency](https://www.lesswrong.com/posts/4hdHto3uHejhY2F3Q/partial-agency)"
- "[Towards a Mechanistic Understanding of Corrigibility](https://www.lesswrong.com/posts/BKM8uQS6QdJPZLqCr/towards-a-mechanistic-understanding-of-corrigibility)"
- "[Risks from Learned Optimization](https://www.alignmentforum.org/s/r9tYkB2a8Fp4DN8yB)"
- "[When Wishful Thinking Works](https://www.lesswrong.com/posts/KbCHcb8yyjAMFAAPJ/when-wishful-thinking-works)"
- "[Futarchy Fix](https://www.lesswrong.com/posts/5bd75cc58225bf0670375432/futarchy-fix)"
- "[Bayesian Probability is for Things that are Space-Like Separated From You](https://www.lesswrong.com/posts/FvcyMMaJKhYibtFDD/bayesian-probability-is-for-things-that-are-space-like)"
- "[Self-Supervised Learning and Manipulative Predictions](https://www.lesswrong.com/posts/L3Ryxszc3X2J7WRwt/self-supervised-learning-and-manipulative-predictions)"
- "[Predictors as Agents](https://www.lesswrong.com/posts/G2EupNcdtigdyNhL2/predictors-as-agents)"
- "[Is it Possible to Build a Safe Oracle AI?](https://www.lesswrong.com/posts/SFtJq2vwTXQNATEZe/is-it-possible-to-build-a-safe-oracle-ai)"
- "[Tools versus Agents](https://www.lesswrong.com/posts/nAwTGhgrdxE85Bjmg/tools-versus-agents)"
- "[A Taxonomy of Oracle AIs](https://www.lesswrong.com/posts/XddMs9kSGtm6L8522/a-taxonomy-of-oracle-ais)"
- "[Yet another Safe Oracle AI Proposal](https://www.lesswrong.com/posts/NwNru5H4TuiS65xqz/yet-another-safe-oracle-ai-proposal)"
- "[Why Safe Oracle AI is Easier Than Safe General AI, in a Nutshell](https://www.lesswrong.com/posts/7nLMhdhXMKBLWiynJ/why-safe-oracle-ai-is-easier-than-safe-general-ai-in-a)"
- "[Let's Talk About "Convergent Rationality"](https://www.lesswrong.com/posts/pLZ3bdeng4u5W8Yft/let-s-talk-about-convergent-rationality-1)"
- "[Counterfactual Oracles = online supervised learning with random selection of training episodes](https://www.lesswrong.com/posts/yAiqLmLFxvyANSfs2/counterfactual-oracles-online-supervised-learning-with)"