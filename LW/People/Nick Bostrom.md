---
_id: 5f5c37ee1b5cdee568cfb1c7
title: Nick Bostrom
href: https://www.lesswrong.com/tag/nick-bostrom
slug: nick-bostrom
type: tag
tags:
  - LessWrong
  - Concept
  - Tag
synchedAt: '2022-09-01T09:42:16.205Z'
status: todo
---

# Nick Bostrom

**Nick Bostrom** is a philosopher at the University of Oxford, director of the [[Future of Humanity Institute (FHI)|Future of Humanity Institute]] (FHI), the main academic institution on that field. As a director he coordinates and conducts researches on crucial points to the progress and future of humanity. Among those crucial points are: [[Artificial General Intelligence]] (AGI), [[EA/Topics/Existential risk|Existential risk]], [[Nootropics & Other Cognitive Enhancement|Biological Cognitive Enhancement]] and [[Whole Brain Emulation|Whole brain emulation]]. He has personally raised more than 13 million dollars on research grants, awards and donations.

He also founded the first transhumanistic association, World Transhumanism Association (now [Humanity+](http://http://humanityplus.org/)), in 1998. Bostrom made several major contributions in relevant fields to transhumanism. His more than 200 published papers have been translated to more than 20 languages. They spread throughout topics such as:

- [[EA/Topics/Existential risk|Existential risk]] – hazards with potential to destroy the entire human race, a concept he was the first to [define](http://www.nickbostrom.com/existential/risks.pdf), give attention to its [large ethical relevance](http://www.existential-risk.org/concept.pdf) and untangle its [particular difficulties](http://www.nickbostrom.com/papers/anthropicshadow.pdf).
- [[Nootropics & Other Cognitive Enhancement|Biological Cognitive Enhancement]] – developing and [heuristic](http://www.nickbostrom.com/evolution.pdf) about how to safely technologically enhance human condition.
- [[Infinities In Ethics|Infinities in ethics]] \- how to act in a universe where any finite action doesn’t add up good to a infinite world.
- [Anthropic principle](http://wiki.lesswrong.com/wiki/Observation_selection_effect) – a better and sound formalization of the anthropic principle, where one must think as a random member of its own reference class.

Bostrom has a BA in Philosophy, Mathematics, Mathematical Logic and in Artificial Intelligence; MA in Philosophy and in Physics; MSc in Computational Neuroscience and PhD in Philosophy. [One of his theses in philosophy](http://www.anthropic-principle.com/book/anthropicbias.pdf) entered the Routledge Hall of Fame, and made a formalization of the anthropic principle, giving birth to the Strong self-sampling assumption (SSSA): "Each observer-moment should reason as if it were randomly selected from the class of all observer-moments in its reference class". With this formalization many paradoxes emerging from intuitive versions of the anthropic principle were avoided.

Later, the kind of reasoning developed in his thesis lead to many other insights, such as the [[Simulation Argument]], demonstrating that there is a considerable chance that we are living inside a computer simulation.

## Blog Posts

- [The Anthropic Trilemma](http://lesswrong.com/lw/19d/the_anthropic_trilemma/)
- [Transcription and Summary of Nick Bostrom's Q&A](http://lesswrong.com/lw/8h1/transcription_and_summary_of_nick_bostroms_qa/)

## External Links

- [Nick Bostrom's Home Page](http://www.nickbostrom.com/)
- [Future of Humanity Institute's Home Page](http://www.fhi.ox.ac.uk/)
- [Nick Bostrom's CV](http://www.nickbostrom.com/cv.pdf)
- [Nick Bostrom's site on the Anthropic Principle](http://http://www.anthropic-principle.com/)
- [Paper on Infinites Ethics](http://www.nickbostrom.com/ethics/infinite.pdf)


%%

% START
Basic (and reversed card)
What is **Nick Bostrom**?
Back: {TODO}
Tags: LessWrong
END

%%
	
