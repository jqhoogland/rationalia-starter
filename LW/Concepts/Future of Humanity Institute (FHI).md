---
_id: K6oowPZC6kds6LDTg
title: Future of Humanity Institute (FHI)
href: https://www.lesswrong.com/tag/future-of-humanity-institute-fhi
slug: future-of-humanity-institute-fhi
type: tag
tags:
  - LessWrong
  - Concept
  - Tag
synchedAt: '2022-09-01T09:42:42.813Z'
status: todo
---

# Future of Humanity Institute (FHI)

The **Future of Humanity Institute** is part of the Faculty of Philosophy and the Oxford Martin School at the University of Oxford. Founded in 2005, its director is [[Nick Bostrom]]. The mission of FHI is described on their website:

FHI puts together a wide range of researches, prominent on their original fields, which decided to focus on global questions about the progress and future of humanity, e.g.:

- [[Nick Bostrom]] : Director, philosopher, has more than 200 publications on subjects such as: [[Artificial General Intelligence]] (AGI) Risks, [[Existential Risk|Existential risk]], [[Nootropics & Other Cognitive Enhancement|Biological Cognitive Enhancement]] and [[Whole Brain Emulation|Whole brain emulation]]
- [Anders Sandberg](http://en.wikipedia.org/wiki/Anders_Sandberg): Research Fellow, computational neuroscientist, researches human enhancement and ethics of new technologies
- [Robin Hanson](http://en.wikipedia.org/wiki/Robin_Hanson): Research Associate, economist, interested in prediction market given the future of technology and many other questions involving [bayesianism](http://wiki.lesswrong.com/wiki/Bayesian), [cognitive biases](http://wiki.lesswrong.com/wiki/Bias), technology, policies and the [Fermi Paradox](http://en.wikipedia.org/wiki/Fermi_paradox).
- [Toby Ord](http://en.wikipedia.org/wiki/Toby_Ord): Research Associate, philosopher, researches decision making and theoretical and pratical ethics. Founder of [Giving What We Can](http://www.givingwhatwecan.org/), an international society dedicated to the elimination of poverty;
- [Milan Cirkovic](http://mcirkovic.aob.rs/): Research Associate, astrophysicist, interested in the anthropic principle and the [Fermi Paradox Fermi Paradox](http://en.wikipedia.org/wiki/Fermi_paradox).

The FHI is an affiliate to LessWrong and [Overcoming Bias](http://www.overcomingbias.com/). Their past activities include holding a conference in 2008 titled [Global Catastrophic Risks Conference](http://www.global-catastrophic-risks.com/aboutconf.html) and publishing a book, also titled [Global Catastrophic Risks](http://www.global-catastrophic-risks.com/book.html).

## See Also

- [[Nick Bostrom]] (`= [[Nick Bostrom]].status`)
- [[Existential Risk|Existential risk]] (`= [[Existential Risk|Existential risk]].status`)
- [[Machine Intelligence Research Institute (MIRI)|Machine Intelligence Research Institute]] (`= [[Machine Intelligence Research Institute (MIRI)|Machine Intelligence Research Institute]].status`)

## External Links

- [FHI website](http://www.fhi.ox.ac.uk/)


%%

% START
Basic (and reversed card)
What is **Future of Humanity Institute (FHI)**?
Back: {TODO}
Tags: LessWrong
END

%%
	
