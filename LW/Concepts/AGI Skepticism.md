---
_id: 5f5c37ee1b5cdee568cfb28d
title: AGI Skepticism
href: https://lesswrong.com/tag/agi-skepticism
slug: agi-skepticism
type: tag
tags:
  - LessWrong
  - Concept
  - Tag
synchedAt: '2022-08-29T11:09:12.923Z'
---
# AGI Skepticism

**AGI skepticism** involves objections to the possibility of [[Artificial General Intelligence]] being developed in the near future. Skeptics include [various technology and science luminaries](http://spectrum.ieee.org/computing/hardware/tech-luminaries-address-singularity) such as Douglas Hofstadter, Gordon Bell, Steven Pinker, and Gordon Moore:

> "It might happen someday, but I think life and intelligence are far more complex than the current singularitarians seem to believe, so I doubt it will happen in the next couple of centuries." -- Douglas Hofstadter

A typical argument is that we currently only have narrow AI, and that there is no sign of progress towards general intelligence. Some critics even argue that predictions of near-term AGI [belong to the realm of religion](http://kryten.mm.rpi.edu/SB_AB_PB_sing_fideism_022412.pdf), not science or engineering.

Some skeptics also say that discussion about AGI risk is a dangerous waste of time that diverts attention from more important issues. [Daniel Dennett](http://ingentaconnect.com/content/imp/jcs/2012/00000019/F0020001/art00005) considers AGI risk an "imprudent pastime" because it distracts our attention from more immediate threats, and the philosopher Alfred Nordmann holds the view that ethical concern is a scarce resource, not to be wasted on unlikely future scenarios ([1](http://commonsenseatheism.com/wp-content/uploads/2011/02/nordmann-if-and-then-a-critique-of-speculative-nanoethics.pdf), [2](http://spectrum.ieee.org/robotics/robotics-software/singular-simplicity)).

There are also skeptics who think that the prospect of near-term AGI seems remote, but don't dismiss the issue entirely. An [AAAI presidential panel on long-term AI futures](http://www.aaai.org/Organization/Panel/panel-note.pdf) concluded that

> There was overall skepticism about the prospect of an intelligence explosion as well as of a “coming singularity,” and also about the large-scale loss of control of intelligent systems. Nevertheless, there was a shared sense that additional research would be valuable on methods for understanding and verifying the range of behaviors of complex computational systems to minimize unexpected outcomes. Some panelists recommended that more research needs to be done to better define “intelligence explosion,” and also to better formulate different classes of such accelerating intelligences. Technical work would likely lead to enhanced understanding of the likelihood of such phenomena, and the nature, risks, and overall outcomes associated with different conceived variants.

## External Links

- [A history of the AI winter](http://en.wikipedia.org/wiki/AI_winter) from Wikipedia

## See Also

- [[Artificial General Intelligence]]
- [[Technological Forecasting|Technological forecasting]]
- [[Unfriendly Artificial Intelligence]]
- [[Friendly Artificial Intelligence]]
- [[Economic Consequences of AGI|Economic Consequences of AI]]