---
tags: ['LessWrong', 'Portal', 'Category']
href: https://www.lesswrong.com/tag/world-optimization
---

# World optimization


---

### Moral Theory
- [[Altruism]]
- [[Consequentialism]]
- [[Deontology]]
- [[Ethics & Morality]]
- [[Metaethics]]
- [[1 Projects/Learning/Rationalism/Concepts/Moral Uncertainty]]
- [[Trolley Problem]]


### Causes / Interventions
- [[Aging]]
- [[Animal Welfare]]
- [[Climate Change]]
- [[1 Projects/Learning/Rationalism/Concepts/Existential Risk]]
- [[Futurism]]
- [[Intellectual Progress]]
- [[Mind Uploading]]
- [[Life Extension]]
- [[S-risks]]
- [[Transhumanism]]
- [[Voting Theory]]


### Working with Humans
- [[Coalitional Instincts]]
- [[Common Knowledge]]
- [[Coordination & Cooperation]]
- [[Game Theory]]
- [[Group Rationality]]
- [[Institution Design]]
- [[Moloch]]
- [[Organizational Design and Culture]]
- [[Signaling]]
- [[Simulacrum Levels]]
- [[Social Status]]


### Applied Topics
- [[Acausal Trade]]
- [[Blackmail]]
- [[Censorship]]
- [[Chesterton's Fence]]
- [[Death]]
- [[Deception]]
- [[Honesty]]
- [[Hypocrisy]]
- [[Information Hazards]]
- [[Meta-Honesty]]
- [[Pascal's Mugging]]
- [[Privacy]]
- [[War]]


### Value & Virtue
- [[Ambition]]
- [[Art]]
- [[Aesthetics]]
- [[Complexity of Value]]
- [[Courage]]
- [[Fun Theory]]
- [[Principles]]
- [[Suffering]]
- [[Superstimuli]]
- [[Wireheading]]


### Meta
- [[80,000 Hours]]
- [[Cause Prioritization]]
- [[Center for Long-term Risk]]
- [[Effective Altruism]]
- [[GiveWell]]
- [[Heroic Responsibility]]


