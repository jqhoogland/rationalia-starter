---
_id: qNF7Ti87CLfHhbttj
title: Treacherous Turn
href: https://lesswrong.com/tag/treacherous-turn
slug: treacherous-turn
type: tag
tags:
  - LessWrong
  - Concept
  - Tag
synchedAt: '2022-08-29T10:47:20.954Z'
status: todo
---

# Treacherous Turn

A **Treacherous Turn** is a hypothetical event where an advanced [AI](ai) system which has been pretending to be aligned due to its relative weakness turns on humanity once it achieves sufficient power that it can pursue its true objective without risk.
