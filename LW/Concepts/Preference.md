---
_id: 5f5c37ee1b5cdee568cfb1c5
title: Preference
href: https://www.lesswrong.com/tag/preference
slug: preference
type: tag
tags:
  - LessWrong
  - Concept
  - Tag
synchedAt: '2022-09-01T09:42:28.058Z'
status: todo
---

# Preference

**Preference** is usually conceptualized as a set of attitudes or evaluations made by an agent towards a specific object, and it has been proposed that AI has a robust set of methods to deal with them. These can be divided in several steps:

1. **Preferences acquisition**: Extraction of preferences from a user, through an interactive learning system, e.g. a question-answer process.
2. **Preferences modeling**: After extraction, the goal is to create a mathematical model expressing the preferences, taking into account its properties (for instance, if the preferences are transitive between pairs of choices).
3. **Preferences representation**: With a robust model of preferences, it becomes necessary to develop a symbolic system to represent them - a preference representation language.
4. **Preferences reasoning**: Finally, having represented a user’s or agent’s preferences, it is possible to mine the data looking for new insights and knowledge. This could be used, for instance, to aggregate users based on preferences or as biases in decision processes and game theory scenarios.

This sequential chain of thought can be particularly useful when dealing with [[Coherent Extrapolated Volition]], as a way of systematically exploring agent’s goals and motivations.

## Further Reading & References

- [Would Your Real Preferences Please Stand Up?](http://lesswrong.com/lw/15c/would_your_real_preferences_please_stand_up) by [Yvain](https://wiki.lesswrong.com/wiki/Yvain)
- [Notion of Preference in Ambient Control](http://lesswrong.com/lw/2tq/notion_of_preference_in_ambient_control/) by [Vladimir Nesov](https://wiki.lesswrong.com/wiki/Vladimir_Nesov)
- [To What Degree Do We Have Goals?](http://lesswrong.com/lw/6oo/to_what_degree_do_we_have_goals/) by Yvain
- [A brief tutorial on preferences in AI](http://lesswrong.com/lw/a73/a_brief_tutorial_on_preferences_in_ai/) by Luke Muehlhauser

## See Also

- [[Complexity of Value|Complexity of value]] (`= [[Complexity of Value|Complexity of value]].status`)
- [[Utility Functions|Utility function]] (`= [[Utility Functions|Utility function]].status`)
- [[Decision Theory|Decision theory]] (`= [[Decision Theory|Decision theory]].status`)
- [[Optimization|Optimization process]] (`= [[Optimization|Optimization process]].status`)
- [[Akrasia]] (`= [[Akrasia]].status`)
- [[Corrupted Hardware|Corrupted hardware]] (`= [[Corrupted Hardware|Corrupted hardware]].status`)


%%

% START
Basic (and reversed card)
What is **Preference**?
Back: {TODO}
Tags: LessWrong
END

%%
	
