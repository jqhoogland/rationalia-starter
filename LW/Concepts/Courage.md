---
title: Courage
href: https://lesswrong.com/tags/courage
type: tag
tags:
  - LessWrong
  - Concept
  - Tag
---

**Courage** is important to being rational. You will not be very rational if you are too scared to act differently to the people around you, or too scared to even think about very big ideas-- these are the two main threads touched on in this tag.

_Related Tags: [[Fallacies|Fallacies]], [Groupthink](https://www.lesswrong.com/tag/groupthink?showPostCount=true&useTagName=true), [Heroic Responsibility](https://www.lesswrong.com/tag/heroic-responsibility?showPostCount=true&useTagName=true), [Heuristics and Biases](https://www.lesswrong.com/tag/heuristics-and-biases?showPostCount=true&useTagName=true), [Motivated Reasoning](https://www.lesswrong.com/tag/motivated-reasoning?showPostCount=true&useTagName=true), [Rationalisation](https://www.lesswrong.com/tag/rationalization?showPostCount=true&useTagName=true), [Self-Deception](https://www.lesswrong.com/tag/self-deception?showPostCount=true&useTagName=true)_

More thorough explanations of the importance of courage can be found [here](https://www.lesswrong.com/posts/WHK94zXkQm7qm7wXk/asch-s-conformity-experiment) and [here](https://www.lesswrong.com/posts/ovvwAhKKoNbfcMz8K/on-expressing-your-concerns). Suggestions for how to improve or become more courageous in this sense can be found [here](https://www.lesswrong.com/posts/3XgYbghWruBMrPTAL/leave-a-line-of-retreat) and [[You Can Face Reality|here]].

  

If a fire alarm goes off, but everybody around you is sat still as though they can't hear it, what do you do? Well, apparently, [nothing](https://www.lesswrong.com/posts/BEtzRE2M5m9YEAQpX/there-s-no-fire-alarm-for-artificial-general-intelligence) (for 90% of people). Even when your options are 'be a little embarrassed' or 'maybe burn to death', people still struggle to have the courage to stand up and act how they know makes sense. Cultivating the ability to know when you're right, regardless of how other people are acting, may be an important step for you becoming more rational.

Similarly, it's important to rationalists to [take ideas seriously,](https://www.lesswrong.com/s/wnQWakxdRodnKm5kH) because otherwise you can't make any progress to figuring out if they're right or wrong. Many of the really important-seeming ideas (like [AI risk](https://www.lesswrong.com/tag/ai-risk?showPostCount=true&useTagName=true), other [existential risk](https://www.lesswrong.com/tag/existential-risk?showPostCount=true&useTagName=true), and even what would happen if AI went 'right') are _scary_. Even just visualising their consequences if they _were_ true can be scary-- just like theists who insist that, [without god, there would be no morality](https://www.lesswrong.com/posts/3XgYbghWruBMrPTAL/leave-a-line-of-retreat) (despite the notable absence of atheist baby-murderers). However, these ideas may also be the most important to think about before they happen _specifically because they are so scary._ You can't dodge a knife if you're pretending it doesn't exist.