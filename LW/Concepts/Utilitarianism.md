---
_id: Zs4nYLkNr7Rbo4mAP
title: Utilitarianism
href: https://lesswrong.com/tag/utilitarianism
type: tag
tags:
  - LessWrong
  - Concept
  - Tag
synchedAt: '2022-08-29T10:48:12.065Z'
---
# Utilitarianism

**Utilitarianism** is a moral [[Philosophy|philosophy]] that says that what matters is the sum of everyone's welfare, or the "greatest good for the greatest number".

Not to be confused with maximization of [utility](https://www.lessestwrong.com/tag/utility-functions), or [expected utility](https://www.lessestwrong.com/tag/expected-utility). If you're a utilitarian, you don't just sum over [possible worlds](https://www.lessestwrong.com/tag/possible-world); you sum over *people*.

Utilitarianism comes in different variants. For example, unlike standard [total utilitarianism](https://en.wikipedia.org/wiki/Total_utilitarianism), [average utilitarianism](https://en.wikipedia.org/wiki/Average_utilitarianism) values the *average* utility among a group's members. [Negative utilitarianism](https://en.wikipedia.org/wiki/utilitarianism#Negative_utilitarianism) seeks only to minimize suffering, and is often discussed for its extreme implications.

**Related Pages:** [[Negative Utilitarianism]], [[Consequentialism]], [[Ethics & Morality]], [[Fun Theory]], [[Complexity of Value]]