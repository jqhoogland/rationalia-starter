---
title: Deconfusion
href: https://lesswrong.com/tag/deconfusion
type: tag
tags:
  - LessWrong
  - Concept
  - Tag
---

Narrowly, **deconfusion** is a specific branch of AI alignment research, discussed in [MIRI's 2018 research update](https://intelligence.org/2018/11/22/2018-update-our-new-research-directions/). More broadly, the term applies to any domain. Quoting from the research update:

> By deconfusion, I mean something like “making it so that you can think about a given topic without continuously accidentally spouting nonsense.”