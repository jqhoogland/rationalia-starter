---
_id: 5f5c37ee1b5cdee568cfb1cd
title: Really Powerful Optimization Process
href: https://lesswrong.com/tag/really-powerful-optimization-process
slug: really-powerful-optimization-process
type: tag
tags:
  - LessWrong
  - Concept
  - Tag
synchedAt: '2022-08-29T11:07:15.539Z'
status: todo
---

# Really Powerful Optimization Process

The term [[Artificial General Intelligence|artificial intelligence]] can have [[Anthropomorphism|anthropomorphic]] connotations. In some contexts, it might be useful to speak of a **really powerful optimization process** rather than a *superintelligence*. An AI that was nonanthropomorphic and nonsentient could theoretically still be a very powerful device that could drastically affect the future in precise ways.

## Blog Posts

- [Dreams of Friendliness](http://lesswrong.com/lw/tj/dreams_of_friendliness/)
- [Aiming at the Target](http://lesswrong.com/lw/v9/aiming_at_the_target/)
- [Efficient Cross-Domain Optimization](http://lesswrong.com/lw/vb/efficient_crossdomain_optimization/)
- [Nonsentient Optimizers](http://lesswrong.com/lw/x5/nonsentient_optimizers/)
- [The Design Space of Minds-in-General](http://lesswrong.com/lw/rm/the_design_space_of_mindsingeneral/)

## External Links

- [Creature or Technology](http://www.acceleratingfuture.com/steven/?p=227) by [[Steven Kaas]]
- [The Stamp Collecting Device](http://intelligence.org/blog/2007/06/11/the-stamp-collecting-device/) by Nick Hay

## See Also

- [[Optimization|Optimization process]], [[Configuration Space|configuration space]]
- [[Artificial General Intelligence|Artificial general intelligence]], [[Singleton|singleton]]
- [[Friendly Artificial Intelligence]]
- [[Anthropomorphism]], [[Alien Values|alien values]]
- [[Evolution As Alien God|Evolution as alien god]]
- [[Complexity of Value|Complexity of value]]
