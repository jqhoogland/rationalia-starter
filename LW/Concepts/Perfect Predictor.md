---
_id: SgpwPSrHRbeRSxKus
title: Perfect Predictor
href: https://www.lesswrong.com/tag/perfect-predictor
slug: perfect-predictor
type: tag
tags:
  - LessWrong
  - Concept
  - Tag
synchedAt: '2022-09-01T09:42:30.659Z'
status: todo
---

# Perfect Predictor

A **perfect predictor** is an agent which can predict the behaviour of an agent or the outcome of an event with perfect accuracy. It is often given the name [[Omega]], but Omega sometimes refers to an almost perfect predictor.

## Possibility and Relevance:

Perfect predictors are generally understood to be impossible due to the [Uncertainty Principle](https://www.wikiwand.com/en/Uncertainty_principle) or just from our general experience that perfect observation or accuracy aren't a feature of our universe. Some people claim this makes them irrelevant for real decision theory problems. See the page on [[Hypotheticals|hypotheticals]] for further discussion on whether or not this is valid. Some [people](https://www.lesswrong.com/posts/AKkFh3zKGzcYBiPo7/counterfactuals-for-perfect-predictors?commentId=zZDWxYmbd6m6nDpHf) have objected on the basis of [[Free Will|free will]].

Some people have [attempted](https://www.lesswrong.com/posts/de3xjFaACCAk6imzv/towards-a-new-decision-theory) to make these problems more realistic and concrete by reframing it in terms of computational agents with access to other agents source code or the program representing the environment. This won't be perfect in the sense that there's nothing stopping a machine error or a hacker messing ruining the prediction, but it is close enough that it can be approximately to perfect predictors.

## Inconsistent Counterfactuals:

One challenge with perfect predictors is that it might be unclear what Omega is predicting, particularly in situations that are only [[Conditional Consistency|conditionally consistent]]. Take for example [[Parfit's Hitchhiker]]. In this problem, you are trapped dying in a desert and a passing driver will only pick you up if you promise to pay them $100 once you are in town. If the driver is a perfect predictor, then someone who always defects will never end up in town, so it is unclear what exactly they are predicting, since the situation is contradictory and the [Principle of Explosion](https://en.wikipedia.org/wiki/Principle_of_explosion) means that you can prove anything.

[Counterfactuals for Perfect Predictors](https://www.lesswrong.com/posts/AKkFh3zKGzcYBiPo7/counterfactuals-for-perfect-predictors) suggests that even if we can't predict what an agent would do in an inconsistent or [[Conditional Consistency|conditionally consistent]] situation, we can predict how it would respond if given input representing an inconsistent situation (we can represent this response as an output). This aligns with [[Updateless Decision Theory]] which isn't subject to this issue as it uses input-output maps.


%%

% START
Basic (and reversed card)
What is **Perfect Predictor**?
Back: {TODO}
Tags: LessWrong
END
<!--ID: 1663156984503-->


%%
	
