---
_id: DdgSyQoZXjj3KnF4N
title: Tribalism
href: https://lesswrong.com/tag/tribalism
slug: tribalism
type: tag
tags:
  - LessWrong
  - Concept
  - Tag
synchedAt: '2022-08-29T11:03:19.811Z'
status: todo
---

# Tribalism

**Tribalism** or **Coalitional Instincts** is closely connected to the concept of in/out-groups. Coalitional instincts drive humans to act in ways which cause them join, support, defend, and maintain their membership in various coalitions that are defined by sharing a common identity. An illustrative example can be found in [[A Fable of Science and Politics]].

See also: [[Blues & Greens (metaphor)|Blues and Greens]], [[Groupthink]], [[Motivated Reasoning]], [[Social & Cultural Dynamics|Social and Cultural Dynamics]], [[Social Reality]].

> The primary function that drove the evolution of coalitions is the amplification of the power of its members in conflicts with non-members. This function explains a number of otherwise puzzling phenomena. For example, ancestrally, if you had no coalition you were nakedly at the mercy of everyone else, so the instinct to belong to a coalition has urgency, preexisting and superseding any policy-driven basis for membership. This is why group beliefs are free to be so weird. \[…\]

> … to earn membership in a group you must send signals that clearly indicate that you differentially support it, compared to rival groups. Hence, optimal weighting of beliefs and communications in the individual mind will make it feel good to think and express content conforming to and flattering to one’s group’s shared beliefs and to attack and misrepresent rival groups. The more biased away from neutral truth, the better the communication functions to affirm coalitional identity, generating polarization in excess of actual policy disagreements. Communications of practical and functional truths are generally useless as differential signals, because any honest person might say them regardless of coalitional loyalty. In contrast, unusual, exaggerated beliefs \[…\] are unlikely to be said except as expressive of identity, because there is no external reality to motivate nonmembers to speak absurdities.

> \-\- John Tooby, "[Coalitional Instincts](https://www.edge.org/conversation/john_tooby-coalitional-instincts)"

> Humans interact in dense social networks, and this poses a problem for bystanders when conflicts arise: which side, if any, to support. Choosing sides is a difficult strategic problem because the outcome of a conflict critically depends on which side other bystanders support. One strategy is siding with the higher status disputant, which can allow bystanders to coordinate with one another to take the same side, reducing fighting costs. However, this strategy carries the cost of empowering high-status individuals to exploit others. A second possible strategy is choosing sides based on preexisting relationships. This strategy balances power but carries another cost: Bystanders choose different sides, and this discoordination causes escalated conflicts and high fighting costs. We propose that moral cognition is designed to manage both of these problems by implementing a dynamic coordination strategy in which bystanders coordinate side-taking based on a public signal derived from disputants’ actions rather than their identities. By focusing on disputants’ actions, bystanders can dynamically change which individuals they support across different disputes, simultaneously solving the problems of coordination and exploitation.

> \-\- Peter DeScioli & Robert Kurzban, " [A Solution to the Mysteries of Morality](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.840.3768&rep=rep1&type=pdf)"
