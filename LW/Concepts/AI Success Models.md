---
title: AI Success Models
href: https://lesswrong.com/tags/ai-success-models
type: tag
tags:
  - LessWrong
  - Concept
  - Tag
---

**AI Success Models** are proposed paths to an existential win via aligned AI. They are (so far) high level overviews and won't contain all the details, but present at least a sketch of what a full solution might look like. They can be contrasted with [[Threat Models|threat models]], which are stories about how AI might lead to major problems.