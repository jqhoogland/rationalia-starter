---
_id: rWzGNdjuep56W5u2d
title: Inside, Outside View
href: https://lesswrong.com/tag/inside-outside-view
slug: inside-outside-view
type: tag
tags:
  - LessWrong
  - Concept
  - Tag
synchedAt: '2022-08-29T11:02:43.866Z'
aliases:
  - Inside View
  - Outside View
status: todo
---

# Inside, Outside View

An **Inside View** on a topic involves making predictions based on your understanding of the details of the process. An **Outside View** involves ignoring these details and using an estimate based on a class of roughly similar previous cases (alternatively, this is called [reference class forecasting](http://en.wikipedia.org/wiki/Reference_class_forecasting)), though it has been [pointed out](https://www.lesswrong.com/posts/BcYfsi7vmhDvzQGiF/taboo-outside-view) that the possible meaning has expanded beyond that.

For example, someone working on a project may estimate that they can reasonably get 20% of it done per day, so they will get it done in five days (inside view). Or they might consider that all of their previous projects were completed just before the deadline, so since the deadline for this project is in 30 days, that's when it will get done (outside view).

The terms were originally developed by Daniel Kahneman and Amos Tversky. An early use is in [Timid Choices and Bold Forecasts: A Cognitive Perspective on Risk Taking (Kahneman & Lovallo, 1993)](http://doi.org/10.1287/mnsc.39.1.17) and the terms were popularised in *Thinking, Fast and Slow* (Kahneman, 2011; [relevant excerpt](https://www.mckinsey.com/business-functions/strategy-and-corporate-finance/our-insights/daniel-kahneman-beware-the-inside-view)). The planning example is discussed in [The Planning Fallacy](https://www.lesswrong.com/posts/CPm5LTwHrvBJCa9h5/planning-fallacy). 

## Examples of Outside View

**1.** From [Beware the Inside View](https://www.overcomingbias.com/2007/07/beware-the-insi.html), by Robin Hanson:

> I did 1500 piece jigsaw puzzle of fireworks, my first jigsaw in at least ten years.  Several times I had the strong impression that I had carefully eliminated every possible place a piece could go, or every possible piece that could go in a place.  I was very tempted to conclude that many pieces were missing, or that the box had extra pieces from another puzzle.  This wasn’t impossible – the puzzle was an open box a relative had done before.  And the alternative seemed humiliating. 

> But I allowed a very different part of my mind, using different considerations, to overrule this judgment; so many extra or missing pieces seemed unlikely.  And in the end there was only one missing and no extra pieces.  I recall a similar experience when I was learning to program. I would carefully check my program and find no errors, and then when my program wouldn’t run I was tempted to suspect compiler or hardware errors.  Of course the problem was almost always my fault.   

**2.** Japanese students expected to finish their essays an average of 10 days before deadline. The average completion time was actually 1 day before deadline. When asked when they'd completed similar, previous tasks, the average reply was 1 day before deadline\[1\].

**3.** Students instructed to visualize how, where, and when they would perform their Christmas shopping, expected to finish shopping more than a week before Christmas. A control group asked when they expected their Christmas shopping to be finished, expected it to be done 4 days before Christmas. Both groups finished 3 days before Christmas\[2\].

## Problems with the Outside View

It is controversial how far the lesson of these experiments can be extended. Robin Hanson argues that this implies that, in futurism, forecasts should be made by trying to find a reference class of similar cases, rather than by trying to visualize outcomes. Eliezer Yudkowsky responds that this leads to "reference class tennis" wherein people feel that the same event 'obviously' belongs to two different reference classes, and that the above experiments were performed in cases where the new example was highly similar to past examples. I.e., this year's Christmas shopping optimism and last year's Christmas shopping optimism are much more similar to one another, than the invention of the Internet is to the invention of agriculture. If someone else then feels that the invention of the Internet is more like the category 'recent communications innovations' and should be forecast by reference to television instead of agriculture, both sides pleading the outside view has no resolution except "I'm taking my reference class and going home!"

More possible limitations and problems with using the outside view are discussed in [The Outside View's Domain](https://www.lesswrong.com/posts/pqoxE3AGMbse68dvb/the-outside-view-s-domain) and ["Outside View" as Conversation-Halter](https://www.lesswrong.com/posts/FsfnDfADftGDYeG4c/outside-view-as-conversation-halter). [Model Combination and Adjustment](https://www.lesswrong.com/posts/iyRpsScBa6y4rduEt/model-combination-and-adjustment) discusses the implications of there usually existing multiple *different* outside views. [Taboo "Outside View"](https://www.lesswrong.com/posts/BcYfsi7vmhDvzQGiF/taboo-outside-view) argues that the meaning of "Outside View" have expanded too much, and that it should be [[Rationalist Taboo|tabooed]] and replaced with more precise terminology. An alternative to "Inside, Outside View" has been proposed in [Gears Level & Policy Level](https://www.lesswrong.com/s/uLEjM2ij5y3CXXW6c/p/vKbAWFZRDBhyD6K6A).

## External Posts

- [Beware the Inside View](http://www.overcomingbias.com/2007/07/beware-the-insi.html) by [Robin Hanson](https://lessestwrong.com/tag/robin-hanson)

## See Also

- [Planning fallacy](https://lessestwrong.com/tag/planning-fallacy)
- [[Modest Epistemology]]
- [Near, Far Thinking](https://lessestwrong.com/tag/near-far-thinking)
- [Connotation](https://lessestwrong.com/tag/connotation), [Absurdity heuristic](https://lessestwrong.com/tag/absurdity-heuristic)
- [Arguing by analogy](https://lessestwrong.com/tag/arguing-by-analogy)
- [Intelligence explosion](https://lessestwrong.com/tag/intelligence-explosion), [The Hanson-Yudkowsky AI-Foom Debate](https://lessestwrong.com/tag/the-hanson-yudkowsky-ai-foom-debate)

\[1\] Buehler, R., Griffin, D., & Ross, M. 2002. Inside the planning fallacy: The causes and consequences of optimistic time predictions. Heuristics and biases: The psychology of intuitive judgment, 250-270. Cambridge, UK: Cambridge University Press.

\[2\] Buehler, R., Griffin, D. and Ross, M. 1995. It's about time: Optimistic predictions in work and love. European Review of Social Psychology, Volume 6, eds. W. Stroebe and M. Hewstone. Chichester: John Wiley & Sons.
