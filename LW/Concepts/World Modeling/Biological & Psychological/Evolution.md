---
_id: nZCb9BSnmXZXSNA2u
title: Evolution
href: https://www.lesswrong.com/tag/evolution
slug: evolution
type: tag
tags:
  - LessWrong
  - Concept
  - Tag
synchedAt: '2022-09-01T09:42:48.085Z'
status: todo
---

# Evolution

**Evolution** is "*change in the heritable characteristics of biological populations over successive generations*" ([Wikipedia](https://en.wikipedia.org/wiki/Evolution)). For posts about machine learning look [[Machine Learning  (ML)|here]].

*Related:* [[Biology]], [[LW/Concepts/Evolutionary Psychology]],

The sequence, [The Simple Math of Evolution](https://www.lesswrong.com/s/MH2b8NfWv22dBtrs8) provides a good introduction to LessWrong thinking about evolution.

Why be interested in evolution?
===============================

Firstly, evolution is a useful case study of humans' ability (or inability) to model the real world. This is because it has a single clear criterion ("relative reproductive fitness") which is selected (optimized) for:

> *"If we can't see clearly the result of a single monotone optimization criterion—if we can't even train ourselves to hear a single pure note—then how will we listen to an orchestra? How will we see that "Always be selfish" or "Always obey the government" are poor guiding principles for human beings to adopt—if we think that even optimizing genes for inclusive fitness will yield organisms which sacrifice reproductive opportunities in the name of social resource conservation?*

> *To train ourselves to see clearly, we need simple practice cases" --* Eliezer Yudkowsky*,* [*Fake Optimisation Criteria*](https://www.lesswrong.com/s/MH2b8NfWv22dBtrs8/p/i6fKszWY6gLZSX2Ey)

Secondly, much of rationality necessarily revolves around the human brain ([[Transhumanism|for]] [now](https://www.lesswrong.com/tag/mind-uploading?showPostCount=false&useTagName=false)). An understanding of how it came into being can be very helpful both for understanding 'bugs' in the system (like superstimuli), and for explaining [[Complexity of Value]], among others.

> *A candy bar is a superstimulus: it contains more concentrated sugar, salt, and fat than anything that exists in the ancestral environment.   A candy bar matches taste buds that evolved in a hunter-gatherer environment, but it matches those taste buds much more strongly than anything that actually existed in the hunter-gatherer environment.  The signal that once reliably correlated to healthy food has been hijacked, blotted out with a point in tastespace that wasn't in the training dataset - an impossibly distant outlier on the old ancestral graphs. *
> *\-\-* Eliezer Yudkowsky, [Superstimuli and the Collapse of Western Civilisation](https://www.lesswrong.com/s/MH2b8NfWv22dBtrs8/p/Jq73GozjsuhdwMLEG)

## See Also

- [Evolution as alien god](https://lessestwrong.com/tag/evolution-as-alien-god)
- [Slowness of evolution](https://lessestwrong.com/tag/slowness-of-evolution)
- [Stupidity of evolution](https://lessestwrong.com/tag/stupidity-of-evolution)
- [Evolutionary psychology](https://lessestwrong.com/tag/evolutionary-psychology)

## External Links

- [Richard Dawkins - The Selfish Gene](http://dl.dropbox.com/u/33627365/Scholarship/Selfish%20Gene%20-%20Dawkins.pdf) (PDF)

## Summaries of Sequence's Posts on Evolution

*The following are summaries of posts concerning evolution in the Eliezer's sequences:*

- [An Alien God](https://lessestwrong.com/lw/kr/an_alien_god/) \- Evolution is awesomely powerful, unbelievably stupid, incredibly slow, monomaniacally singleminded, irrevocably splintered in focus, blindly shortsighted, and itself a completely accidental process. If evolution were a god, it would not be Jehovah, but H. P. Lovecraft's Azathoth, the blind idiot God burbling chaotically at the center of everything.
- [The Wonder of Evolution](https://lessestwrong.com/lw/ks/the_wonder_of_evolution/) \- The wonder of the first replicator was not how amazingly well it replicated, but that a first replicator could arise, at all, by pure accident, in the primordial seas of Earth. That first replicator would undoubtedly be devoured in an instant by a sophisticated modern bacterium. Likewise, the wonder of evolution itself is not how *well* it works, but that a *brainless, accidentally occurring* [optimization process](https://lessestwrong.com/tag/optimization) can work *at all*. If you praise evolution for being such a wonderfully intelligent Creator, you're entirely missing the wonderful thing about it.
- [Evolutions Are Stupid (But Work Anyway)](https://lessestwrong.com/lw/kt/evolutions_are_stupid_but_work_anyway/) \- Modern evolutionary theory gives us a definite picture of evolution's capabilities. If you praise evolution one millimeter higher than this, you are not scoring points against creationists, you are just being factually inaccurate. In particular we can calculate the probability and time for advantageous genes to rise to fixation. For example, a mutation conferring a 3% advantage would have only a 6% probability of surviving, and if it did so, would take 875 generations to rise to fixation in a population of 500,000 (on average).
- [Speed limit and complexity bound for evolution](https://lessestwrong.com/tag/speed-limit-and-complexity-bound-for-evolution) \- It is widely understood that there is a limit on how fast evolution can accumulate information in a gene pool, and an upper bound on how much genetic information can be sustained against the degenerative pressure of copying errors. (But Yudkowsky's attempt to calculate an actual bound failed mathematically, so see the referenced summary of the discussion instead of the original blog post.)
- [Adaptation-Executers, not Fitness-Maximizers](https://lessestwrong.com/lw/l0/adaptationexecuters_not_fitnessmaximizers/) \- A central principle of evolutionary biology in general, and [evolutionary psychology](https://lessestwrong.com/tag/evolutionary-psychology) in particular. If we regarded human taste buds as trying to *maximize fitness*, we might expect that, say, humans fed a diet too high in calories and too low in micronutrients, would begin to find lettuce delicious, and cheeseburgers distasteful. But it is better to regard taste buds as an *executing adaptation* \- they are adapted to an ancestral environment in which calories, not micronutrients, were the limiting factor.
- [No Evolutions for Corporations or Nanodevices](https://lessestwrong.com/lw/l6/no_evolutions_for_corporations_or_nanodevices/) \- Price's Equation describes quantitatively how the change in a average trait, in each generation, is equal to the covariance between that trait and fitness. Such covariance requires substantial variation in traits, substantial variation in fitness, and substantial correlation between the two - and then, to get large *cumulative* selection pressures, the correlation must have persisted over *many* generations with *high-fidelity* inheritance, continuing sources of new variation, and frequent birth of a significant fraction of the population. People think of "evolution" as something that automatically gets invoked where "reproduction" exists, but these other conditions may not be fulfilled - which is why corporations haven't evolved, and nanodevices probably won't.
- [Evolving to Extinction](https://lessestwrong.com/lw/l5/evolving_to_extinction/) \- Contrary to a naive view that evolution works for the good of a species, evolution says that genes which outreproduce their alternative alleles increase in frequency within a gene pool. It is entirely possible for genes which "harm" the species to outcompete their alternatives in this way - indeed, it is entirely possible for a species to *evolve to extinction*.
- [The Tragedy of Group Selectionism](https://lessestwrong.com/lw/kw/the_tragedy_of_group_selectionism/) \- Describes a key case where some pre-1960s evolutionary biologists went wrong by [anthropomorphizing](https://wiki.lesswrong.com/wiki/anthropomorphizing) evolution - in particular, Wynne-Edwards, Allee, and Brereton among others believed that predators would voluntarily restrain their breeding to avoid overpopulating their habitat. Since evolution does not usually do this sort of thing, their rationale was [group selection](https://lessestwrong.com/tag/group-selection) \- populations that did this would survive better. But group selection is extremely difficult to make work mathematically, and an experiment under sufficiently extreme conditions to permit group selection, had rather different results.
- [Fake Optimization Criteria](https://lessestwrong.com/lw/kz/fake_optimization_criteria/) \- Why study evolution? For one thing - it lets us see an alien [optimization process](https://lessestwrong.com/tag/optimization) up close - lets us see the *real* consequence of optimizing *strictly* for an alien optimization criterion like inclusive genetic fitness. Humans, who try to persuade other humans to do things their way, think that this policy criterion ought to require predators to [restrain their breeding](https://lessestwrong.com/tag/group-selection) to live in harmony with prey; the true result is something that humans find less aesthetic.
- [Beware of Stephen J. Gould](https://lessestwrong.com/lw/kv/beware_of_stephen_j_gould/) \- A lot of people have gotten their grasp of evolutionary theory from Stephen J. Gould, a man who committed the moral equivalent of fraud in a way that is difficult to explain. At any rate, he severely misrepresented what evolutionary biologists believe, in the course of pretending to attack certain beliefs. One needs to clear from memory, as much as possible, not just everything that Gould positively stated but everything he seemed to imply the mainstream theory believed.
- [Conjuring An Evolution To Serve You](https://lessestwrong.com/lw/l8/conjuring_an_evolution_to_serve_you/) \- If you take the hens who lay the most eggs in each generation, and breed from them, you should get hens who lay more and more eggs. Sounds logical, right? But this selection may actually favor the most *dominant* hen, that pecked its way to the top of the pecking order at the expense of other hens. Such breeding programs produce hens that must be housed in individual cages, or they will peck each other to death. Jeff Skilling of Enron fancied himself an evolution-conjurer - summoning *the awesome power of evolution* to work for him - and so, every year, every Enron employee's performance would be evaluated, and the bottom 10% would get fired, and the top performers would get huge raises and bonuses.


%%

% START
Basic (and reversed card)
What is **Evolution**?
Back: {TODO}
Tags: LessWrong
END
<!--ID: 1663156958352-->


%%
	
