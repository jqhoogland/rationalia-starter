---
tags: ['LessWrong', 'Concept']
href: https://www.lesswrong.com/tag/aixi
---

# AIXI
AIXI is a mathematical formalism for a hypothetical [(super)intelligence](https://www.lesswrong.com/tag/superintelligence), developed by Marcus Hutter (2005, 2007). AIXI is not computable, and so does not serve as a design for a real-world AI, but is considered a valuable theoretical illustration with both positive and negative aspects (things AIXI would be able to do and things it arguably couldn't do).

*See also: *[[Solomonoff Induction|Solomonoff induction]],[[Decision Theory|Decision theory]], [AI](https://www.lesswrong.com/ai)

The AIXI formalism says roughly to consider all possible computable models of the environment, Bayes-update them on past experiences, and use the resulting updated predictions to model the expected sensory reward of all possible strategies. This is an application of [Solomonoff Induction](https://www.lesswrong.com/tag/solomonoff-induction?useTagName=true)....[(Read More)]()

