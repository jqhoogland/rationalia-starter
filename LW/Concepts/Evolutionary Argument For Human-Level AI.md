---
_id: 5f5c37ee1b5cdee568cfb2cf
title: Evolutionary Argument For Human-Level AI
href: https://lesswrong.com/tag/evolutionary-argument-for-human-level-ai
type: tag
tags:
  - LessWrong
  - Concept
  - Tag
synchedAt: '2022-08-29T11:09:40.616Z'
---
# Evolutionary Argument For Human-Level AI

An **Evolutionary argument for human-level** [**AI**](https://wiki.lesswrong.com/wiki/AGI) is an argument that uses the fact that [[Evolution|evolution]] produced human level intelligence to argue for the feasibility of human-level [AI](https://wiki.lesswrong.com/wiki/AGI)[^1^](#fn1). Evolution is an extremely slow, random and erratic process, sometimes compared to a drunkard’s walk [^2^](#fn2) or a "fickle, and tightly shackled tinkerer"[^3^](#fn3). It has, however, produced human intelligence in this manner, so intelligent humans with a plan should produce it much faster. Bostrom and Shulman[^4^](#fn4) formalize the many steps of the argument for non-hard human level AI as follows: "

*   1’. Evolution produced human intelligence.
*   2’. If evolution produced human intelligence, then it is “non-hard” for evolutionary processes to produce human intelligence.
*   3’. If it is “non-hard” for evolutionary processes to produce human evolution, then it is not extremely difficult for engineers to produce human-level machine intelligence.
*   4’. If it is not extremely difficult for engineers to produce human-level machine intelligence, it will probably be done before too long.

\_\_\_\_\_\_\_\_\_

*   5’. Engineers will (before long) produce human-level machine intelligence."

There are variations of this argument, some argue for the easily feasibility of human level AI through the use of [[Evolutionary Algorithm|evolutionary algorithms]]. These arguments use estimates on the total amount of computational power needed to simulate the entire evolution of human level intelligence and argue such level of computational power is well within range. Bostrom and Shulman[^5^](#fn5) argue that, in fact, it would take more than a century of Moore’s Law progress in order to match the entire evolution of intelligence computational powers. They also make a careful analysis of Evolutionary argument for human-level AI considering [[Observation Selection Effect|observational selection effects]].

## References

1.  CHALMERS, David. (2010) "The Singularity: A Philosophical Analysis, Journal of Consciousness Studies", 17 (9-10), pp. 7-65.[↩](#fnref1)
2.  MLODINOW, Leonard. (2008) "The Drunkard's walk : how randomness rules our lives." New York: Pantheon Books.[↩](#fnref2)
3.  POWELL, Russell & BUCHANAN, Allen. (2011) "Breaking Evolution's Chains: The Promise of Enhancement by Design" In: SAVULESCU, J. e MEULEN, Rudd ter (orgs.) "Enhancing Human Capacities". Wiley-Blackwell.[↩](#fnref3)
4.  BOSTROM, Nick & SHULMAN, Carl. (2012) "How Hard is Artificial Intelligence? Evolutionary Arguments and Selection Effects" Forthcoming in the Journal of Consciousness Studies. Available at: [http://www.nickbostrom.com/aievolution.pdf](http://www.nickbostrom.com/aievolution.pdf)[↩](#fnref4)