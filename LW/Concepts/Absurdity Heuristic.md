---
_id: 5f5c37ee1b5cdee568cfb19d
title: Absurdity Heuristic
href: https://lesswrong.com/tag/absurdity-heuristic
slug: absurdity-heuristic
type: tag
tags:
  - LessWrong
  - Concept
  - Tag
synchedAt: '2022-08-29T10:47:54.429Z'
---
# Absurdity Heuristic

The **absurdity heuristic** classifies highly untypical situations as "absurd", or [[Antiprediction|impossible]]. While normally very useful as a form of [[Epistemic Hygiene|epistemic hygiene]], allowing us to detect nonsense, it suffers from the same problems as the [[Representativeness Heuristic|representativeness heuristic]].

There are a number of situations in which the absurdity heuristic is wrong. A deep theory has to [[Shut Up and Multiply|override the intuitive expectation]]. Where you don't expect intuition to construct an [[Technical Explanation|adequate model]] of reality, classifying an idea as impossible may be [[Overconfidence|overconfident]]. [The future is usually "absurd"](http://lesswrong.com/lw/j1/stranger_than_history/), although sometimes it's possible to [[Exploratory Engineering|rigorously infer low bounds on capabilities of the future]], proving possible what is intuitively absurd.

## See also

- [[Representativeness Heuristic|Representativeness heuristic]]
- [[Shut Up and Multiply|Shut up and multiply]]
- [[Antiprediction]]
- [[Epistemic Hygiene|Epistemic hygiene]]
- [[Exploratory Engineering|Exploratory engineering]]
- [[Illusion of Transparency|Illusion of transparency]]
- [[Status Quo Bias|Status quo bias]], [[Reversal Test|Reversal test]]

## External References

- [Arbitrary Silliness](http://www.overcomingbias.com/2008/04/arbitrary-silli.html) by [[Robin Hanson]]