---
_id: bbdbpGWWPMfKBzk7z
title: Gradient Hacking
href: https://www.lesswrong.com/tag/gradient-hacking
slug: gradient-hacking
type: tag
tags:
  - LessWrong
  - Concept
  - Tag
synchedAt: '2022-09-01T09:42:42.041Z'
status: todo
---

# Gradient Hacking

%%

My intuition is that gradient hacking is unlikely. That it requires global knowledge of the loss landscape, which is unlikely to be accessible to the embedded model. (Cf. we can't simulate a universe in our universe with more computational resources than our universe). Unfortunately, this also makes it less likely that we can understand the loss landscape. 

My main crux is probably the path-dependence of training.]]

%%