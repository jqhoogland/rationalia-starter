---
_id: 5f5c37ee1b5cdee568cfb2b0
title: Technological Forecasting
href: https://lesswrong.com/tag/technological-forecasting
type: tag
tags:
  - LessWrong
  - Concept
  - Tag
synchedAt: '2022-08-29T10:47:38.576Z'
---
# Technological Forecasting

**Technological forecasting** means making predictions about future technological advances.

One approach is extrapolating from past data. [Moore's Law](http://en.wikipedia.org/wiki/Moore's_law), which says that the number of transistors on an integrated circuit doubles every two years, is the classic example. Bela Nagy's [performance curve database](http://pcdb.santafe.edu/), perhaps the most systematic attempt at such extrapolation, [has found](http://tuvalu.santafe.edu/~bn/workingpapers/NagyFarmerTrancikBui.pdf) similar trends in many technologies. [Ray Kurzweil](http://www.kurzweilai.net/the-law-of-accelerating-returns) is a well-known advocate of exponential technological growth models. On the other hand, an exponential curve is [indistinguishable](http://commonsenseatheism.com/wp-content/uploads/2012/01/Modis-The-singularity-myth.pdf) from the early stages of a logistic curve that eventually approaches a ceiling.

Another approach is [expert elicitation](http://teaching.p-design.ch/forecasting07/texts/RoweWright2001_Delphi_Technique.pdf), such as in the [survey taken at the Global Catastrophic Risk Conference](http://www.philosophy.ox.ac.uk/__data/assets/pdf_file/0020/3854/global-catastrophic-risks-report.pdf), and [a survey of artificial general intelligence researchers](http://sethbaum.com/ac/2011_AI-Experts.html) on AGI timelines.

One could create probabilistic models more complicated than a simple trend extrapolation. Anders Sandberg has done calculations on timelines for [[Whole Brain Emulation|whole brain emulation]], based on an analysis of [prerequisite technologies](http://www.fhi.ox.ac.uk/__data/assets/pdf_file/0019/3853/brain-emulation-roadmap-report.pdf). [The Uncertain Future](http://www.theuncertainfuture.com) is a web application (developed by the [[Machine Intelligence Research Institute (MIRI)|Machine Intelligence Research Institute]] and currently in beta) that works with probability distributions provided by the user to calculate the probability of a disruption to "business as usual", which could come in the form of either a global disaster or the invention of [[Artificial General Intelligence|artificial general intelligence]].

An important danger in predicting the future is that one might tell complex stories with many details, any of which could fail and invalidate the prediction. Models like that used in The Uncertain Future attempt to avoid this problem by considering outcomes that could come about in multiple ways, and assigning some probability to many different scenarios.

## Blog posts

- [Long-term technological forecasting](http://lesswrong.com/lw/9ao/longterm_technological_forecasting/)

## External links

- [Changing the frame of AI futurism: From storytelling to heavy-tailed, high-dimensional probability distributions](http://intelligence.org/files/ChangingTheFrame.html) (a conference paper explaining the reasoning behind the Uncertain Future app)

## See also

- [Acceleration thesis](https://wiki.lesswrong.com/wiki/Acceleration_thesis)
- [[Good-Story Bias|Good-story bias]]
- [[Economic Consequences of AGI|Economic consequences of AI and whole brain emulation]]