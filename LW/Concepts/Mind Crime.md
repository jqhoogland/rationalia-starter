---
_id: mxSBcaTrakvCkgLzL
title: Mind Crime
href: https://www.lesswrong.com/tag/mind-crime
slug: mind-crime
type: tag
tags:
  - LessWrong
  - Concept
  - Tag
synchedAt: '2022-09-01T09:42:35.370Z'
status: todo
---

# Mind Crime

**Mind Crime** occurs when a computational process which has moral value is mistreated. For example, an advanced AI trying to predict human behavior might create simulations of humans so detailed as to be conscious observers, which would then suffer through whatever hypothetical scenarios the AI wanted to test and then be discarded.

Mind crime on a large scale constitutes a [[Risks of Astronomical Suffering (S-risks)|risk of astronomical suffering]].

Mind crime is different from other AI risks in that the AI need not even affect anything outside its box for the catastrophe to occur.

The term was coined by Nick Bostrom in *Superintelligence: Paths, Dangers, Strategies.*

Not the same as [thoughtcrime](https://en.wikipedia.org/wiki/Thoughtcrime), a term for having beliefs considered unacceptable by society.


%%

% START
Basic (and reversed card)
What is **Mind Crime**?
Back: {TODO}
Tags: LessWrong
END
<!--ID: 1663156989909-->


%%
	
