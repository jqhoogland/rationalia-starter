---
_id: 6zBEfFYJxhSEcchbR
title: AI Alignment Fieldbuilding
href: https://www.lesswrong.com/tag/ai-alignment-fieldbuilding
slug: ai-alignment-fieldbuilding
type: tag
tags:
  - LessWrong
  - Concept
  - Tag
synchedAt: '2022-09-01T09:42:59.263Z'
status: todo
---

# AI Alignment Fieldbuilding

**AI Alignment Fieldbuilding** is the effort to improve the alignment ecosystem. Some priorities include introducing new people to the importance of AI risk, on-boarding them by connecting them with key resources and ideas, educating them on existing literature and methods for generating new and valuable research, supporting people who are contributing, and maintaining and improving the funding systems.

There is an invite-only Slack for people working on the alignment ecosystem. If you'd like to join message [plex](https://www.lesswrong.com/users/ete) with an overview of your involvement.


%%

% START
Basic (and reversed card)
What is **AI Alignment Fieldbuilding**?
Back: {TODO}
Tags: LessWrong
END

%%
	
