---
_id: YSSNFEnW6ugFhEE6m
title: Adversarial Examples
href: https://www.lesswrong.com/tag/adversarial-examples
slug: adversarial-examples
type: tag
tags:
  - LessWrong
  - Concept
  - Tag
synchedAt: '2022-09-01T09:42:58.168Z'
status: todo
---

# Adversarial Examples

**Adversarial examples** are situations that have unusual features that will cause an [[AI]] to make choices that seem obviously wrong to a human. For example, an image of a panda can be subtly manipulated so that an image classifier classifies it as a gibbon.

%%

% START

Basic (and reversed card)

What are **Adversarial Examples**?

Back: Situations with unusual features that cause an AI to make choices that seem obviously wrong to a human. (E.g., adding the right "noise" to an image classifier can make it identify the wrong class.)

Tags: LessWrong

END

%%
