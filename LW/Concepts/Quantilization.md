---
title: Quantilization
href: https://lesswrong.com/tag/quantilization
type: tag
tags:
  - LessWrong
  - Concept
  - Tag
---

A **Quantilizer** is a proposed AI design which aims to reduce the harms from [[Goodhart's Law|Goodhart's law]] and specification gaming by selecting reasonably effective actions from a distribution of human-like actions, rather than maximizing over actions. It it more of a theoretical tool for exploring ways around these problems than a practical buildable design.

### See also

*   [**Rob Miles's Quantilizers: AI That Doesn't Try Too Hard**](https://www.youtube.com/watch?v=gdKMG6kTl6Y)
*   [**Arbital page on Quantilizers**](https://arbital.com/p/soft_optimizer?l=2r8#Quantilizing)