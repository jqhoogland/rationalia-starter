---
_id: MP8NqPNATMqPrij4n
title: Embedded Agency
href: https://lesswrong.com/tag/embedded-agency
slug: embedded-agency
type: tag
tags:
  - LessWrong
  - Concept
  - Tag
synchedAt: '2022-08-29T11:03:15.119Z'
---
# Embedded Agency

**Embedded Agency** is the problem that an understanding of the theory of rational agents must account for the fact that the agents we create (and we ourselves) are inside the world or universe we are trying to affect, and not separated from it. This is in contrast with much current basic theory of AI or Rationality (such as Solomonoff induction or Bayesianism) which implicitly supposes a separation between the agent and the-things-the-agent-has-beliefs about. In other words, agents in this universe do not have Cartesian or dualistic boundaries like much of philosophy thinks, and are instead reductionist, that is agents are made up of non-agent parts like bits and atoms.

Embedded Agency is not a fully formalised research agenda, but Scott Garrabrant and Abram Demski have written the canonical explanation of the idea in their sequence [*Embedded Agency*](https://www.lesswrong.com/s/Rm6oQRJJmhGCcLvxh). This points to many of the core confusions we have about rational agency and attempts to tie them into a single picture.