---
title: Center on Long-Term Risk (CLR)
href: https://lesswrong.com/tags/center-on-long-term-risk-clr
type: tag
tags:
  - LessWrong
  - Concept
  - Tag
---

The **Center on Long-Term Risk**, formerly _Foundational Research Institute,_ is an [[Effective Altruism|effective altruist]] is a research group affiliated with the Swiss/German [Effective Altruism Foundation](https://ea-foundation.org/). It investigates cooperative strategies to reduce [[Risks of Astronomical Suffering (S-risks)|risks of astronomical suffering]] in humanity's future (s-risks). This includes not only (post-)human suffering, but also the suffering of non-human animals and potential digital sentience. Their research is interdisciplinary, drawing on insights from [artificial intelligence](https://www.lesswrong.com/tag/artificial-general-intelligence), [anthropic reasoning](https://wiki.lesswrong.com/wiki/anthropic_reasoning), international relations, sociology, philosophy, and other fields.

**See also**
------------

*   [Suffering risk](https://www.lesswrong.com/tag/risks-of-astronomical-suffering-s-risks)
*   [[Abolitionism|Abolitionism]]

**External links**
------------------

*   [CLR website](https://longtermrisk.org/)
*   [Effective Altruism Wiki article on FRI](http://archive.is/aZjiv)