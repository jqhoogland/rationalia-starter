---
_id: 5f5c37ee1b5cdee568cfb1f8
title: Sequences
href: https://lesswrong.com/tag/sequences
type: tag
tags:
  - LessWrong
  - Concept
  - Tag
synchedAt: '2022-08-29T11:09:10.180Z'
---
# Sequences

A **sequence** is a series of multiple posts on Less Wrong on the same topic, to coherently and fully explore a particular thesis. See the [Library page](/library) for a list of LessWrong sequences in their modern form.

The [original sequences](/tag/original-sequences) were written by [[Eliezer Yudkowsky]] with the goal of creating a book on rationality. [MIRI](https://wiki.lesswrong.com/wiki/MIRI) has since collated and edited the sequences into [[Rationality: From AI To Zombies|Rationality: From AI to Zombies]]. If you are new to Less Wrong, this book is the best place to start.

## Rationality: From AI to Zombies

![](https://wiki.lesswrong.com/images/2/23/Rationality-Angled-Cover-Web.jpg)

[*Rationality: From AI to Zombies*](https://wiki.lesswrong.com/wiki/Rationality:_From_AI_to_Zombies) cover image.

*[[Rationality: From AI To Zombies|Rationality: From AI to Zombies]]* is an ebook collecting six books worth of essays on the science and philosophy of human rationality. It's one of the best places to start for people who want to better understand topics that crop up on *Less Wrong*, such as cognitive bias, the map-territory distinction, meta-ethics, and existential risk.

The ebook can be downloaded on a "pay-what-you-want" basis from [intelligence.org](https://intelligence.org/rationality-ai-zombies). Its six books in turn break down into twenty-six sections:

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

*   Book I: ***[[Map and Territory|Map and Territory]]***. An introduction to the Bayesian concept of rational belief.
    *   A. Predictably Wrong
    *   B. Fake Beliefs
    *   C. Noticing Confusion
    *   D. Mysterious Answers

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

*   Book II: ***[[How To Actually Change Your Mind|How to Actually Change Your Mind]]***. A guide to noticing motivated reasoning and overcoming confirmation bias.
    *   E. Overly Convenient Excuses
    *   F. Politics and Rationality
    *   G. Against Rationalization
    *   H. Against Doublethink
    *   I. Seeing with Fresh Eyes
    *   J. Death Spirals
    *   K. Letting Go

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

*   Book III: ***[[The Machine In The Ghost|The Machine in the Ghost]]***. Essays on the general topic of minds, goals, and concepts.
    *   L. The Simple Math of Evolution
    *   M. Fragile Purposes
    *   N. A Human's Guide to Words

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

*   Book IV: ***[[Mere Reality|Mere Reality]]***. Essays on science and the physical world.
    *   O. Lawful Truth
    *   P. Reductionism 101
    *   Q. Joy in the Merely Real
    *   R. Physicalism 201
    *   S. Quantum Physics and Many Worlds
    *   T. Science and Rationality

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

*   Book V: ***[[Mere Goodness|Mere Goodness]]***. A discussion of ethics, and of things people value in general.
    *   U. Fake Preferences
    *   V. Value Theory
    *   W. Quantified Humanism

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

*   Book VI: ***[[Becoming Stronger|Becoming Stronger]]***. Essays on self-improvement, group rationality, and rationality groups.
    *   X. Yudkowsky's Coming of Age
    *   Y. Challenging the Difficult
    *   Z. The Craft and the Community

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

## Other sequences by Eliezer Yudkowsky

The following collections of essays come from the **[[Original Sequences|original sequences]]**, an earlier version of much of the material from *Rationality: From AI to Zombies*:

*   [Ethical Injunctions](https://wiki.lesswrong.com/wiki/Ethical_Injunctions): A discussion of prohibitions you may want to follow even when you've thought of a clever reason to think they don't apply.
*   [[Metaethics Sequence|The Metaethics Sequence]]: A longer version of "Value Theory", discussing the apparent "arbitrariness" of human morality.
*   [[The Fun Theory Sequence]]: A discussion of the complexity of human value, and what the universe might look like if everything were much, much better. Fun theory is the optimistic, far-future-oriented part of value theory, asking: How much fun is there in the universe; will we ever run out of fun; are we having fun yet; could we be having more fun?
*   [[The Quantum Physics Sequence]]: A much longer version of the "Quantum Physics and Many Worlds", delving more into the implications of physics for our concepts of personal identity and time.

Other collections from the same time period (2006-2009) include:

*   **[[The Hanson-Yudkowsky AI-Foom Debate|The Hanson-Yudkowsky AI-Foom Debate]]**: A blog conversation between Eliezer Yudkowsky and Robin Hanson on the topic of [[Intelligence Explosion|intelligence explosion]] and how concerned we should be about superintelligent AI.
*   **[[Free Will (Solution)|Free Will]]**: Yudkowsky's answer to a challenge he raises in *Rationality: From AI to Zombies* to come up with an explanation for the human *feeling* that we have free will.

Yudkowsky has also written a more recent sequence:

*   **[[Highly Advanced Epistemology 101 For Beginners|Highly Advanced Epistemology 101 for Beginners]]**. These essays include a discussion of truth, formal logic, causality, and metaethics, and are a good way for more ambitious readers to quickly get up to speed.

## Sequences by others

Sequences of essays by [**Scott Alexander**](https://wiki.lesswrong.com/wiki/Yvain) include:

*   [[Positivism, Self Deception, and Neuroscience (Sequence)|Positivism, Self Deception, and Neuroscience]]
*   [Priming and Implicit Association](https://wiki.lesswrong.com/wiki/Priming_and_Implicit_Association_(sequence)). Priming may be described as the capability of any random stimulus to commandeer your thinking and judgement for the next several minutes. Scared? Don't be. There exist ways to defend yourself against these kinds of intrusions, and there are even methods to harness them into useful testing mechanisms.
*   [The Blue-Minimizing Robot](https://wiki.lesswrong.com/wiki/The_Blue-Minimizing_Robot_(sequence))
*   [Introduction to Game Theory](http://lesswrong.com/lw/dbe/introduction_to_game_theory_sequence_guide)

Sequences by [**Luke Muehlhauser**](https://wiki.lesswrong.com/wiki/Lukeprog):

*   [The Science of Winning at Life](https://www.lesswrong.com/tag/the-science-of-winning-at-life). This sequence summarizes scientifically-backed advice for "winning" at everyday life: in one's productivity, in one's relationships, in one's emotions, etc. Each post concludes with footnotes and a long list of references from the academic literature.
*   [[Rationality and Philosophy]]. This sequence explains how intuitions are used in mainstream philosophy and what the science of intuitions suggests about how intuitions *should* be used in philosophy.
*   [[No-Nonsense Metaethics]]. This sequence explains and defends a naturalistic approach to metaethics.

By [**Anna Salamon**](https://wiki.lesswrong.com/wiki/AnnaSalamon):

*   [Decision Theory of Newcomblike Problems](https://wiki.lesswrong.com/wiki/Decision_Theory_of_Newcomblike_Problems_(sequence)). Decisions need to be modeled with some structure in order to be scrutinized and systematically improved; simply "intuiting" the answers to decision problems by ad-hoc methods is not conducive to thorough analysis. For this, we formulate decision theories. This sequence, themed with an analysis of Newcomb's problem, is a consolidated summary and context for the many decision theory discussions found on LessWrong at the time of writing.

By [**Alicorn**](https://wiki.lesswrong.com/wiki/Alicorn):

*   [Living Luminously](http://lesswrong.com/lw/1xh/living_luminously/). [[Luminosity]], as used here, is self-awareness. A luminous mental state is one that you have and know that you have. It could be an [[Emotions|emotion]], a [[Belief|belief]] or [[Alief|alief]], a disposition, a [[Qualia|quale]], a memory - anything that might happen or be stored in your brain. What's going on in your head?

And by [**Kaj Sotala**](https://wiki.lesswrong.com/wiki/Kaj_Sotala):

*   [What Intelligence Tests Miss](http://lesswrong.com/tag/whatintelligencetestsmiss). A sequence summarizing the content of Keith Stanovich's book *What Intelligence Tests Miss*.
*   [Why Everyone (Else) Is a Hypocrite](http://lesswrong.com/tag/whyeveryonehypocrite) by [Kaj_Sotala](https://wiki.lesswrong.com/wiki/Kaj_Sotala). An unfinished sequence summarizing the content of Robert Kurzban's book *Why Everyone (Else) is a Hypocrite: Evolution and the Modular Mind*.

## Other resources

[Benito's Guide](http://lesswrong.com/user/Benito/) aims to systematically fill the reader in on the most important ideas discussed on LessWrong (not just in the sequences). It also begins with a series of videos, which are a friendly introduction, and useful if you enjoy talks and interviews.

*Thinking and Deciding* by Jonathan Baron and *Good and Real* by Gary Drescher have been mentioned as books that overlap significantly with the sequences. [More about how the sequences fit in with work done by others](http://lesswrong.com/r/all/lw/eik/eliezers_sequences_and_mainstream_academia/).

## Translations

*   [French](http://rationalite.wordpress.com)
*   [Italian](http://xrazionalita.wordpress.com)
*   [Spanish](http://xracionalidad.wordpress.com)
*   [Russian](http://lesswrong.ru)
*   [Bahasa Indonesia](https://sites.google.com/site/makananuntukpikiran/sequences)
*   [Slovak](http://bur.sk/sk/lesswrong)