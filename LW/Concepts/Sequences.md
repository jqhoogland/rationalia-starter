---
tags: ['LessWrong', 'Portal', 'Concept']
href: https://www.lesswrong.com/tag/sequences
---

A sequence is a series of multiple posts on Less Wrong on the same topic, to coherently and fully explore a particular thesis. See the [Library page](/library) for a list of LessWrong sequences in their modern form.

The [[Original Sequences|original sequences]] were written by [[Eliezer Yudkowsky]] with the goal of creating a book on rationality. [MIRI](https://wiki.lesswrong.com/wiki/MIRI) has since collated and edited the sequences into [[Rationality: From AI To Zombies|Rationality: From AI to Zombies]]. If you are new to Less Wrong, this book is the best place to start.

## Rationality: From AI to Zombies
[*Rationality: From AI to Zombies*](https://www.lesswrong.com/tag/rationality:-from-ai-to-zombies) is an ebook collecting six books worth of essays on the science and philosophy of human rationality. It's one of the best places to start for people who want to better understand topics that crop up on *Less Wrong*, such as cognitive bias, the map-territory distinction, meta-ethics, and existential risk.

The ebook can be downloaded on a "pay-what-you-want" basis from [intelligence.org](https://intelligence.org/rationality-ai-zombies). Its six books in turn break down into twenty-six sections:

__________________________________________________________________

- Book I: 
- [*Map and Territory*](https://www.lesswrong.com/tag/map-and-territory)
- . An introduction to the Bayesian concept
-  of 
- rational belief.
- A. Predictably Wrong
- B. Fake Beliefs
- C. Noticing Confusion
- D. 
- Mysterious Answers

__________________________________________________________________

- Book II: 
- [*How to Actually Change Your Mind*](https://www.lesswrong.com/tag/how-to-actually-change-your-mind)
- .
-  A guide to noticing motivated reasoning
-  and 
- overcoming confirmation bias.
- E. Overly Convenient Excuses
- F. Politics and Rationality
- G. Against Rationalization
- H. Against Doublethink
- I. Seeing with Fresh Eyes
- J. Death Spirals
- K. Letting Go

__________________________________________________________________

- Book III: 
- [*The Machine in the Ghost*](https://www.lesswrong.com/tag/the-machine-in-the-ghost)
- . Essays on the general topic
-  of 
- minds, goals, and concepts.
- L. The Simple Math of Evolution
- M. Fragile Purposes
- N. 
- A Human's Guide to Words

__________________________________________________________________

- Book IV: 
- [*Mere Reality*](https://www.lesswrong.com/tag/mere-reality)
- . Essays
-  on 
- science
-  and the 
- physical world.
- O. Lawful Truth
- P. Reductionism 101
- Q. Joy in the Merely Real
- R. Physicalism 201
- S. Quantum Physics and Many Worlds
- T. Science and Rationality

__________________________________________________________________

- Book V: 
- [*Mere Goodness*](https://www.lesswrong.com/tag/mere-goodness)
- . A discussion
-  of 
- ethics, and of things people value in general.
- U. Fake Preferences
- V. Value Theory
- W. Quantified Humanism

__________________________________________________________________

- Book VI: 
- [*Becoming Stronger*](https://www.lesswrong.com/tag/becoming-stronger)
- . Essays on self-improvement, group rationality, and rationality groups.
- X. Yudkowsky's Coming of Age
- Y. Challenging the Difficult
- Z. The Craft and the Community

__________________________________________________________________

 

## Other sequences by Eliezer Yudkowsky
The following collections of essays come from the [[Original Sequences|original sequences]], an earlier version of much of the material from *Rationality: From AI to Zombies*:

- [Ethical Injunctions](https://wiki.lesswrong.com/wiki/Ethical_Injunctions)
- : 
- A 
- discussion
-  of 
- prohibitions you may want to follow even when you've thought
-  of 
- a clever reason
-  to 
- think they don't apply.
-[[Metaethics Sequence|The Metaethics Sequence]]
- : A longer version of "Value Theory", discussing
-  the 
- apparent "arbitrariness"
-  of 
- human morality.
- [[The Fun Theory Sequence]]
- : 
- A 
- discussion of the complexity of human value, and what the universe might look like if everything were much, much better. Fun
-  theory 
- is the optimistic, far-future-oriented part 
- of 
- value theory, asking:
-  How much fun is there in the universe; will we ever run out of fun; are we having fun yet; could we be having more 
- fun?
- [[The Quantum Physics Sequence]]
- : A much longer version
-  of the 
- "Quantum Physics and Many Worlds", delving more into the implications
-  of 
- physics for our concepts of personal identity and time.

Other collections from the same time period (2006-2009) include:

- [[The Hanson-Yudkowsky AI-Foom Debate]]
- : A blog conversation between Eliezer Yudkowsky and Robin Hanson on the topic of 
-[[Intelligence Explosion|intelligence explosion]]
-  
- and how concerned we should be about superintelligent AI.
-[[Free Will (Solution)|Free Will]]
- : Yudkowsky's
-  answer to 
- a challenge he raises in 
- *Rationality: From AI to Zombies*
-  to come up with an explanation for
-  the 
- human 
- *feeling*
-  that we have free will.

Yudkowsky has also written a more recent sequence:

-[[Highly Advanced Epistemology 101 For Beginners|Highly Advanced Epistemology 101 for Beginners]]
- . These essays include
-  a discussion of truth, formal logic, causality, and 
- metaethics, and are a good way for more ambitious readers to quickly get up to speed.

 

## 
Sequences of essays by [Scott Alexander](https://wiki.lesswrong.com/wiki/Yvain) include:

- [Positivism, Self Deception, and Neuroscience](https://www.lesswrong.com/tag/positivism-self-deception-and-neuroscience-sequence)
- [Priming and Implicit Association](https://wiki.lesswrong.com/wiki/Priming_and_Implicit_Association_(sequence))
- . 
- Priming may be described as the capability of any random stimulus to commandeer your thinking and judgement for the next several minutes. Scared? Don't be. There exist ways to defend yourself against these kinds of intrusions, and there are even methods to harness them into useful testing mechanisms.
- [The Blue-Minimizing Robot](https://wiki.lesswrong.com/wiki/The_Blue-Minimizing_Robot_(sequence))
- [Introduction to Game Theory](http://lesswrong.com/lw/dbe/introduction_to_game_theory_sequence_guide)

 

Sequences by [Luke Muehlhauser](https://wiki.lesswrong.com/wiki/Lukeprog):

-[[The Science of Winning At Life (Sequence)|The Science of Winning at Life]]
- . This sequence summarizes scientifically-backed advice for "winning" at everyday life: in one's productivity, in one's relationships, in one's emotions, etc. Each post concludes with footnotes and a long list of references from the academic literature.
- [[Rationality and Philosophy]]
- . This sequence explains how intuitions are used in mainstream philosophy and what the science of intuitions suggests about how intuitions 
- *should*
-  be used in philosophy.
- [[No-Nonsense Metaethics]]
- . This sequence explains and defends a naturalistic approach to metaethics.

 

By [Anna Salamon](https://wiki.lesswrong.com/wiki/AnnaSalamon):

- [Decision Theory of Newcomblike Problems](https://wiki.lesswrong.com/wiki/Decision_Theory_of_Newcomblike_Problems_(sequence))
- . 
- Decisions need to be modeled with some structure in order to be scrutinized and systematically improved; simply "intuiting" the answers to decision problems by ad-hoc methods is not conducive to thorough analysis. For this, we formulate decision theories. This sequence, themed with an analysis of Newcomb's problem, is a consolidated summary and context for the many decision theory discussions found on LessWrong at the time of writing.

 

By [Alicorn](https://wiki.lesswrong.com/wiki/Alicorn):

- [Living Luminously](http://lesswrong.com/lw/1xh/living_luminously/)
- . 
- [[Luminosity]]
- ,
-  as used here, is self-awareness. A luminous mental state is one that you have and know that you have. It could be an 
-[[Emotions|emotion]]
- ,
-  a 
-[[Belief|belief]]
-  or 
-[[Alief|alief]]
- ,
-  a disposition, a 
-[[Qualia|quale]]
- ,
-  a memory - anything that might happen or be stored in your brain. What's going on in your head?

 

And by [Kaj Sotala](https://wiki.lesswrong.com/wiki/Kaj_Sotala):

-[[None|What Intelligence Tests Miss]]
- . 
- A sequence summarizing the content of Keith Stanovich's book 
- *What Intelligence Tests Miss*
- .
- [Why Everyone (Else) Is a Hypocrite](http://lesswrong.com/tag/whyeveryonehypocrite)
-  by 
- [Kaj_Sotala](https://wiki.lesswrong.com/wiki/Kaj_Sotala)
- . An unfinished
-  sequence summarizing the content of Robert Kurzban's book 
- *Why Everyone (Else) is a Hypocrite: Evolution and the Modular Mind*
- .

 

## Other resources
[Benito's Guide](http://lesswrong.com/user/Benito/) aims to systematically fill the reader in on the most important ideas discussed on LessWrong (not just in the sequences). It also begins with a series of videos, which are a friendly introduction, and useful if you enjoy talks and interviews.

*Thinking and Deciding* by Jonathan Baron and *Good and Real* by Gary Drescher have been mentioned as books that overlap significantly with the sequences. [More about how the sequences fit in with work done by others](http://lesswrong.com/r/all/lw/eik/eliezers_sequences_and_mainstream_academia/).

## Translations
- [French](http://rationalite.wordpress.com)
- [Italian](http://xrazionalita.wordpress.com)
- [Spanish](http://xracionalidad.wordpress.com)
- [Russian](http://lesswrong.ru)
- [Bahasa Indonesia](https://sites.google.com/site/makananuntukpikiran/sequences)
- [Slovak](http://bur.sk/sk/lesswrong)



---

