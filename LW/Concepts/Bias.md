---
_id: 5f5c37ee1b5cdee568cfb0d5
title: Bias
href: https://lesswrong.com/tag/bias
slug: bias
type: tag
tags:
  - LessWrong
  - Concept
  - Tag
synchedAt: '2022-08-29T11:06:03.926Z'
---

# Bias

**Bias** or Cognitive Bias is a systematic deviation from [[Rationality|rationality]] committed by our cognition. They are specific, predictable error patterns in the human mind [^1^](#fn1). The [[Heuristics & Biases|heuristics and biases]] program in cognitive psychology has documented hundreds of reproducible errors - often big errors. This continues to be a highly active area of investigation in cognitive psychology.

In our evolutionary past, in order that a cognitive algorithm turned out into a satisfactory solution to a given problem, it wasn't enough to solve it properly. It was necessary that the solution accounted for a large number of restrictions, such as time and energetic costs. This algorithm didn't need to be perfect, only good enough to guarantee the survival and reproduction of the individual: “What selective pressures impact on decision mechanisms? Foremost is selection for making an appropriate decision in the given domain. This domain-specific pressure does not imply the need to make the best possible decision, but rather one that is good enough (a satisficing choice, as Herbert Simon, 1955, put it) and, on average, better than those of an individual’s competitors, given the costs and benefits involved.” [^2^](#fn2)

Therefore, the human brain make operations which solve cognitive tasks through ‘shortcuts’, that work well on some cases but fail in others. Since the cognitive modules that make those tasks are universals in the human species, how and where those shortcuts lead to mistakes are also regular. The study of why, how and where such errors arise is the field of cognitive bias. Understanding cognitive biases and trying to defend against their effects has been a basic theme of [Less Wrong](https://www.lesswrong.com/about) since the days it was part of [[Overcoming Bias]].

## Starting Points

- Daniel Kahneman's [Nobel prize acceptance speech](http://nobelprize.org/nobel_prizes/economics/laureates/2002/kahneman-lecture.html), where he summarizes the work for which he won the prize;
- [Wikipedia:List of cognitive biases](https://en.wikipedia.org/wiki/List_of_cognitive_biases);
- Kahneman et al's [three](http://www.amazon.com/Judgment-under-Uncertainty-Heuristics-Biases/dp/0521284147) [edited](http://www.amazon.com/Choices-Values-Frames-Daniel-Kahneman/dp/0521627494/ref=pd_bxgy_b_text_b) [volumes](http://www.amazon.com/Heuristics-Biases-Psychology-Intuitive-Judgment/dp/0521796792/ref=pd_bxgy_b_img_c) of research on heuristics and biases (this is the best solid source, but requires obtaining hard-copy books, and is slower reading);
- Eliezer's introductory book chapter [Cognitive biases affecting judgment of existential risks](http://intelligence.org/files/CognitiveBiases.pdf) (available online).
- Cialdini's book [Influence: Science and Practice](http://www.amazon.com/Influence-Practice-Robert-B-Cialdini/dp/0205609996/ref=sr_1_3?ie=UTF8&s=books&qid=1239074671&sr=1-3) (at once contentful and full of engaging anecdotes and cartoons, but, again, requires actually obtaining a book);
- [Psychology Wiki's list of Cognitive Biases](http://psychology.wikia.com/wiki/Category:Cognitive_biases)

## Blog Posts on the Concept of "bias"

- [What exactly is bias?](http://www.overcomingbias.com/2006/11/what_exactly_is.html) by [[Nick Bostrom]]
- [To the barricades! Against ... what exactly?](http://www.overcomingbias.com/2006/11/to_the_barricad.html) by [[Robin Hanson]]
- [...What's a bias, again?](http://lesswrong.com/lw/gp/whats_a_bias_again/) by [[Eliezer Yudkowsky]]
- [Are The Big Four Econ Errors Biases?](http://www.overcomingbias.com/2006/11/the_big_four_ec.html) by [[Robin Hanson]]
- [In cautious defense of bias](http://www.overcomingbias.com/2006/11/incautious_defe.html) by [Paul Gowder](https://wiki.lesswrong.com/wiki/Paul_Gowder)
- [Seen vs. Unseen Biases](http://www.overcomingbias.com/2006/12/seen_vs_unseen_.html) by [[Robin Hanson]]
- [Knowing About Biases Can Hurt People](http://lesswrong.com/lw/he/knowing_about_biases_can_hurt_people/) by [[Eliezer Yudkowsky]] \- Knowing about common biases doesn't help you obtain truth if you only use this knowledge to attack beliefs you don't like.

## Blog Posts About Known Cognitive Biases

- [Scope Insensitivity](http://lesswrong.com/lw/hw/scope_insensitivity/) \- The human brain can't represent large quantities: an environmental measure that will save 200,000 birds doesn't conjure anywhere near a hundred times the emotional impact and willingness-to-pay of a measure that would save 2,000 birds.
- [Correspondence Bias](http://lesswrong.com/lw/hz/correspondence_bias/), also known as the fundamental attribution error, refers to the tendency to attribute the behavior of others to intrinsic dispositions, while excusing one's own behavior as the result of circumstance.
- Confirmation bias, or [Positive Bias](http://lesswrong.com/lw/iw/positive_bias_look_into_the_dark/) is the tendency to look for evidence that confirms a hypothesis, rather than disconfirming evidence.
- [Hindsight Bias](http://lesswrong.com/lw/il/hindsight_bias/) describes the tendency to seem much more likely in hindsight than could have been predicted beforehand.
- [Planning Fallacy](http://lesswrong.com/lw/jg/planning_fallacy/) \- We tend to plan envisioning that everything will go as expected. Even assuming that such an estimate is accurate conditional on everything going as expected, things will *not* go as expected. As a result, we routinely see outcomes worse than the *ex ante* worst case scenario.
- [Conjunction Fallacy](http://lesswrong.com/lw/ji/conjunction_fallacy/) \- Elementary probability theory tells us that the probability of one thing (we write P(A)) is necessarily greater than or equal to the *conjunction* of that thing *and* another thing (write P(A&B)). However, in the psychology lab, subjects' judgments do not conform to this rule. This is [not an isolated artifact](http://lesswrong.com/lw/jj/conjunction_controversy_or_how_they_nail_it_down/) of a particular study design. Debiasing [won't be as simple](http://lesswrong.com/lw/jk/burdensome_details/) as practicing specific questions, it requires certain general habits of thought.
- [We Change Our Minds Less Often Than We Think](http://lesswrong.com/lw/jx/we_change_our_minds_less_often_than_we_think/) \- we all change our minds occasionally, but we don't constantly, honestly reevaluate every decision and course of action. Once you think you believe something, the chances are good that you already do, for better or worse.
- [Priming and Contamination](http://lesswrong.com/lw/k3/priming_and_contamination/) \- Even slight exposure to a stimulus is enough to change the outcome of a decision or estimate. See also [Never Leave Your Room](http://lesswrong.com/lw/3b/never_leave_your_room/) by Yvain, and [Cached Selves](http://lesswrong.com/lw/4e/cached_selves/) by Salamon and Rayhawk.
- [Do We Believe *Everything* We're Told?](http://lesswrong.com/lw/k4/do_we_believe_everything_were_told/) \- Some experiments on priming suggest that mere exposure to a view is enough to get one to passively accept it, at least until it is specifically rejected.
- [Illusion of Transparency](http://lesswrong.com/lw/ke/illusion_of_transparency_why_no_one_understands/) \- Everyone knows what their own words mean, but experiments have confirmed that we systematically overestimate how much sense we are making to others.
- [Self-Anchoring](http://lesswrong.com/lw/kf/selfanchoring/) \- Related to contamination and the illusion of transparancy, we "anchor" on our own experience and underadjust when trying to understand others.
- [Affect Heuristic](http://lesswrong.com/lw/lg/the_affect_heuristic/) \- Positive and negative emotional impressions exert a greater effect on many decisions than does rational analysis.
- [Evaluability](http://lesswrong.com/lw/lh/evaluability_and_cheap_holiday_shopping/) \- It's difficult for humans to evaluate an option except in comparison to other options. Poor decisions result when a poor category for comparison is used. Includes an application for cheap gift-shopping.
- [Unbounded Scales, Huge Jury Awards, and Futurism](http://lesswrong.com/lw/li/unbounded_scales_huge_jury_awards_futurism/) \- Without a metric for comparison, estimates of, e.g., what sorts of punative damages should be awarded, or when some future advance will happen, vary widely simply due to the lack of a scale.
- [The Halo Effect](http://lesswrong.com/lw/lj/the_halo_effect/) \- Positive qualities *seem* to correlate with each other, whether or not they *actually* do.
- [Asch's Conformity Experiment](http://lesswrong.com/lw/m9/aschs_conformity_experiment/) \- The unanimous agreement of surrounding others can make subjects disbelieve (or at least, fail to report) what's right before their eyes. The addition of just one dissenter is enough to dramatically reduce the rates of improper conformity.
- [The Allais Paradox](http://lesswrong.com/lw/my/the_allais_paradox/) (and [subsequent](http://lesswrong.com/lw/mz/zut_allais/) [followups](http://lesswrong.com/lw/n1/allais_malaise/)) \- Offered choices between gambles, people make decision-theoretically inconsistent decisions.

## References

## See Also

- [[Heuristics & Biases|Heuristics and biases]], [[Heuristic]]
- [[Debiasing]], [[Dangerous Knowledge|Dangerous knowledge]]
- [[No Safe Defense|No safe defense]]

## Not to Be Confused with

- [Statistical bias](https://www.lesswrong.com/tag/statistical-bias)
- [[Inductive Bias|Inductive bias]]

* * *

1. POHL, Rüdiger (orgs.). (2005) "Cognitive Illusions: A Handbook on Fallacies and Biases in Thinking, Judgement and Memory". Psychology Press. p. 2[↩](#fnref1)
2. BUSS, David(orgs.). (2005) "The Handbook of Evolutionary Psychology". Wiley, New Jersey. p. 778.[↩](#fnref2)
