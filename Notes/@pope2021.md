---
title: Text Counterfactuals via Latent Optimization and Shapley-Guided Search
href: https://arxiv.org/pdf/2110.11589.pdf
---

**Problem**: How to adversarially perturb LLMs' inputs? This is significantly harder to do than for vision models where the input is continuous â€” text is discrete.

How to generate a **counterfactual** of some input $X$?
- I.e.: A set of tokens which differs in no more than $C_\max$ \% of locations, yet produces a different classification (while remaining grammatically correct)?

**Method**
1. Generate set of candidate substitutions (by optimizing the latent space embedding)
2. Evaluate substitutions' ability to change the classification (via [[Shapley values]])
3. Construct the final counterfactual by beam search.