---
title: Transformers are Sample Efficient World Models
href: https://arxiv.org/pdf/2209.00588.pdf
aliases: 
  - IRIS
  - Imagination with auto-Regression over an Inner Speech
---

> Our approach casts dynamics learning as a sequence modeling problem, where an autoencoder builds a language of image tokens and a Transformer composes that language over time.

