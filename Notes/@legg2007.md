---
title: Universal intelligence\: A definition of machine intelligence
authors: Shane Legg, Marcus Hutter
year: 2007
href: https://arxiv.org/abs/0712.3329
---

==How to develop a definition (& measure) of general intelligence tests that extend to non-humans (both animals & machines)?==

**Outline**

- [[#Natural Intelligence]]
- [[#A Definition of Machine Intelligence]]
- [[#Definitions and Tests of Machine Intelligence]]

**See also**: [[AIXI]]

# Natural Intelligence

See also: Sternberg's Handbook of Intelligence

## Human Intelligence Test

> Contrary to popular public opinion, most psychologists believe that the usual tests of intelligence, such as IQ tests, reliably measure something important in humans [NBB+95, Got97b]. In fact, These are among the most statistically stable & reliable of psychological tests.

Remaining contention:

- Whether tests measure a particular (narrow) type of intelligence
- Whether tests are biased towards particular groups / skillsets

Alfred Binet developed the first "modern style intelligence test" in 1905.

- Focused on complex mental tasks rather than, e.g., the reaction times, auditory discrimination ability, physical coordination that [[Francis Galton]] had focused on.
- 30 short tasks related to everyday problems.
- Scores were normalized against peers of the same age.

**Stanford-Binet test**

- This was adapted by Lewis Terman into the English-language **Stanford-Binet test**, the basis for many later variants.
- 5 areas: Fluid resaoning, knowledge, quantitative reasoning, visual-spatial processing, working memory

**Wechsler Adult Intelligence Scale** (WAIS-III) (and variants)

- David Wechsler criticized the focus on verbal skills, and his tests became the standard in the 1960s and '70s.
- Verbal areas: Knowledge, basic arithmetic, comprehension, vocabulary, short-term memory
- Non-verbal areas: picture completion, spatial completion, problem-solving, symbol search, object assembly

**Raven' progressive matrices**

- An attempt to make the tests less cultural

**[[IQ and g-factor|IQ]]**

- Introduced by Stern
- Originally computed by dividing age estimated by performance on test by biological age and multiplying by 100.
- Now computed by normalizing scores to a Gaussian distribution with a mean of 100 and standard deviation of 15 or 25. ==Who thought this was a good idea?==

For the sake of machines, we need an *absolute measure.*

## Animal Intelligence Tests

A challenge is that we cannot directly explain the goals of our tests (which is also at play in machines). Instead, we use some sort of reward signal. This poses a problem as it confounds task-learning task-completing ability.

## Desirable Properties of an Intelligence Test

- Repeatable, consistent results (trade-off with the length & cost of the test)
- Tester bias — the bias introduced by the test-giver.
- Cultural bias — ==how to weight performance in different areas?==
- Cost-effective
- Predictive power (e.g., academic performance)

## Static Vs. Dynamic Tests

- Most intelligence tests are "static" — they measure ability to solve problems, not ability to learn to solve problems.
- "Dynamic tests" are more difficult because they are costlier and have greater risk of tester bias.

## Theories of Human Intelligence

==Is it one ability or many?==

**Polyintelligentism** %% My jargon %%

- (Probably outdated) Thurstone's multiple factors proposes 7 "primary mental abilities": verbal comprehension, word fluency, number facility, spatial visualization, associative memory, perceptual speed, reasoning
- (Outdated) Sternberg's "Triarchic mind": analytical intelligence, creative intelligence, practical intelligence
- Guilford's "Structure of Intellect":
	- 3 dimensions: Contents, operations, and products
	- 120-150 categories
- Gardner's "Multiple intelligences": linguistic, musical, logical-mathematical, spatial, bodily kinaesthetic, intra-personal, inter-personal

**Monointelligentism**

- Spearman & others: intelligence is a general mental ability that contributes to all others
- Evidence: positive correlation — [[IQ and g-factor|g-factor]]
- Catell:
	- **Fluid intelligence**: ability to acquire knowledge & abilities
	- **Crystallized intelligence**: acquired knowledge & abilities

**Hierarchical view**

- g-factor at apex, and increasing levels of specialization on the way down

## Ten Definitions of Human Intelligence

Commonalities:

- Agent that is interacting with an external environment
- Related to ability to "succeed" (implies the existence of a goal)

Proposed unification:

> Intelligence measures an **agent**’s ability to achieve **goals** in a wide range of **environments**.

==What, then, is the ability to choose goals? Wisdom? A bacterium may be great at accomplishing its narrow goals, but it doesn't have a wide range to choose from. Or is this contained in the "wide range of environments"==

### More Definitions of Human Intelligence

> “Intelligence is what is measured by intelligence tests.” E. Boring [Bor23]

# A Definition of Machine Intelligence

## Basic Agent-environment Framework

See:

- [[Reinforcement Learning]]
- [Controller-plant framework]

**Definitions**

- **Perceptions**: the signals received by the agent from the environment.
- **Actions**: the signals sent by the agent to the environment.
- **Reward**: the signal that indicates how good the agent's current situation is.

![[Screen Shot 2022-09-04 at 2.06.26 PM.png|400]]

## Formal Agent-environment Framework

**Definitions**

- **Symbols**: the elements of some finite set which comprise the signals sent between agent & environment
- **Action space** ($\mathcal A$): The set of action symbols
- **Reward space** ($\mathcal R \subset [0, 1] \cap \mathbb Q$ ): A subset of the rational unit interval
- **Perception space** ($\mathcal P := \mathcal A \times\mathcal R$): The set of perception signals
- **History** ($\mathcal H_n = o_1\ r_1\ a_1\ o_2\ r_2\ a_2\ \dots\ o_n\ r_n a_n$)
- **Agent** ($\pi(a_n|\mathcal H_{n-1}\ o_n\ r_n)$): a function (probability measure to make it easy on us) that chooses the next action. For the sake of formalism, this doesn't even have to be a computable function.
- **Environment** ($\mu(o_n\ r_n| \mathcal H_{n-1}\ a_{n-1})$): a function that gives the next observation and reward.
- Space of computable reward summable environmental measures ($E$), defined wrt a reference machine $\mathcal U$

**Measure of success**

==How to weigh current vs. future reward? So as to not overly punish early exploration?==

Why discount?

- To normalize the reward so its sum is finite.
- To encode [[Temporal preference]].

**[[Geometric Discounting]]**

- Expected value $V_\mu^\pi(\gamma) := \frac{1}{\Gamma} \mathbb E\left(\sum_{i=1}^\infty \gamma^i r_i\right).$, where $\gamma$ is the discount rate, and $\Gamma$ is a normalization factor $\Gamma = \sum_{i=1}^\infty \gamma^i$.
- **Effective horizon** ($\frac{1}{1-\gamma}$) -> Not good.

**[[Quadratic discounting]]** (aka near-harmonic)

- $\gamma^i \to 1/i^2$
- Agent looks forward into future in way that is proportional to current age.
- Avoids effective horizon and free parameter

Or, just require a finite sum of rewards:

$$V_\mu^\pi := \mathbb E\left(\sum_{i=1}^\infty r_i\right) \leq 1.$$

That is, directly encode temporal preference into the rewards.

**The space of environments**

For tractability, we limit to computable environments.

## A Formal Definition of Machine Intelligence

[[Occam's Razor]] is baked into our assumptions of what intelligence is. We expect our ideal agent to go with the simplest hypothesis of its environment.

We formalize "complexity of the environment" with (prefix-free) [[Kolmogorov Complexity]] & [[Solomonoff Induction]].

**Universal intelligence**

$$\Upsilon(\pi) := \sum_{\mu\in E} 2^{-K(\mu)}V_{\mu}^\pi$$

## Universal Intelligence of Various Agents

- **A random agent** ($\pi^{\text{rand}}$) — the agent with the lowest intelligence
- **A very specialized agent** ("narrow intelligence") — is one which can excel in narrow environments but still receive a low universal intelligence (because $2^{-K(\mu^\text{domain})}$ is low)
- …
- **A theoretical optimal agent** ([[AIXI]], "superintelligence") - one which maximizes expected future reward. It's not computable because $K$ is not computable, but interesting as the theoretically perfect agent.

## Properties of Universal Intelligence

- **Valid** — it matches our informal intuitions
- **Meaningful** — independent of whether it is considered to be a measure of intelligence
- **Informative** — independent of other agents
- **Wide range** — it sets a logical order where we can come up with toy models
- **General** — more general would break the [[Church-Turing thesis]]
- **Unbiased** — universal Turing computation as basis (rather than any particular culture). It does depend on the reference machine $U$
- **Fundamental** — based on computation, information, & complexity
- **Formal** — expressed as mathematical equation
- **Objective**
- **Universal** — non-anthropocentric
- **Practical** — pure form is not computable, but you can sample it by randomly generating programs that describe environmental probability measures

# Definitions and Tests of Machine Intelligence

## Informal Definition of Machine Intelligence

Differences

- Legg and Hutter don't care about imposing resource limitations. Universal intelligence does however measure how quickly agents can learn from past data, in which sense it is "data efficient"

## Formal Definitions and Tests of Machine Intelligence

- **[[Turing test]] and derivatives.**
	- Criticism: neither necessary nor sufficient.
- **Compression tests** & "cloze/fill-in-the-missing-word tests"
- **Linguistic complexity**: adapt tools from study of linguistic ability of children
- **Multiple cognitive abilities**
- **Competitive games**
- **Collection of psychometric tests**

==It is sobering to see that now, 15 years later, computers have us beat on pretty much all of these tests==

- **C-test**: common view of "intelligence" as "ability to deal with complexity" among psychologists. Similar to definition here. Uses Levin's computable $Kt$ complexity (requires assumption that UTMs can simulate each other in linear time). Test include sequence prediction tests
	- Criticism: static test in passive environments

| | Universal agent | Universal test |
| --- | --- | --- |
| Passive environment |  Solomonoff induction | C-Test |
| Active environment |  AIXI | Universal intelligence |

**Smith's Test**

- Criticism: restricts to problems in $P$, static measurement & passive environments, not fully specified definition

![[Screen Shot 2022-09-04 at 3.23.16 PM.png]]

# Discussion & Conclusions

==How to turn this into a workable test?==

Common critique

- Insubstantial %% my wordchoice %% hand-waving about it being "obviously not-correct"
- "It's obviously correct & … everybody already knows this stuff".
- A computable environment is too strong an assumption.
	- Counter: until now, all physical evidence suggests computable processes.
- Bounded-sum rewards is unrealistic.
- What about "Blockhead" or Searle's "[[Chinese room]]"? Etc.
	- Efficiency does not matter. Consciousness does not matter.
- Universal intelligence is impossible due to the [[No-Free-Lunch Theorem]]
	- Doesn't apply because we didn't take a uniform distribution over the space of environments.
	- There might exist a more general version that limits the maximum intelligence. %% so come on with the proofs! %%
