---
_id: 5pdNux8dFm2uBDpHE
title: Flourishing futures
href: https://forum.effectivealtruism.org/tag/flourishing-futures
type: tag
tags:
  - LessWrong
  - Topic
  - Tag
synchedAt: '2022-09-11T14:34:24.797Z'
---
# Flourishing futures

**Flourishing futures**, **utopias**, **ideal futures**, or simply **(highly) positive futures** are expressions used to describe the extremely good forms that the [[Long-term future|long-term future]] could assume.

It could be important to consider what types of flourishing future are possible, how good each would be, how likely each is, and what would make these futures more or less likely. Reasons why this might be important include the following:

*   A better understanding of how positive the future might be or is likely to be is relevant to the question of how much to prioritise reducing [[EA/Topics/Existential risk|existential risks]].
*   A better understanding of how good and likely various flourishing futures are, and what would make them more or less likely, could aid in generating, prioritising among, and implementing [[EA/Topics/Longtermism|longtermist]] interventions.
*   Having clearer pictures of how the future might go extremely well could aid in building support for work to reduce existential risks.
*   A better understanding of what futures should be steered towards might aid in working out which scenarios might constitute unrecoverable [[Dystopia|dystopias]] or unrecoverable [[Civilizational collapse|collapses]] (i.e., existential catastrophes other than extinction).

Further reading
---------------

Bostrom, Nick (2008) [Letter from utopia](http://doi.org/10.2202/1941-6008.1025), *Studies in Ethics, Law, and Technology*, vol. 2.

Cotton-Barratt, Owen & Toby Ord (2015) [Existential risk and existential hope: Definitions](https://www.fhi.ox.ac.uk/xrisk-xhope-dfns/), Technical Report #2015-1, Future of Humanity Institute, University of Oxford.

LessWrong (2009) [Fun theory](https://www.lesswrong.com/tag/fun-theory), *LessWrong Wiki*, June 25.

Ord, Toby (2020) [*The Precipice: Existential Risk and the Future of Humanity*](https://en.wikipedia.org/wiki/Special:BookSources/1526600218), chapter 8, London: Bloomsbury Publishing.

Pearce, David (1995) [*The Hedonistic Imperative*](https://www.hedweb.com/hedab.htm), BLTC Research (updated 2007).

Sandberg, Anders (2020) [Post scarcity civilizations & cognitive enhancement](https://www.youtube.com/watch?v=DZfh3JRlc44), *Foresight Institute*, September 4.

Wiblin, Robert & Keiran Harris (2018) [The world’s most intellectual foundation is hiring. Holden Karnofsky, founder of GiveWell, on how philanthropy can have maximum impact by taking big risks](https://80000hours.org/podcast/episodes/holden-karnofsky-open-philanthropy/), *80,000 Hours*, February 27.

Related entries
---------------

[[Dystopia|dystopia]] | [[Existential security|existential security]] | [[Future of Humanity Institute]] | [[Future of Life Institute]] | [[Hedonium|hedonium]] | [[Hellish existential catastrophe|hellish existential catastrophe]] | [[Invincible Wellbeing]] | [[Long reflection|long reflection]] | [[Long-term future|long-term future]] | [[EA/Topics/Longtermism|longtermism]] | [[Motivational|motivational]] | [[Transhumanism|transhumanism]] | [[Welfare biology|welfare biology]]