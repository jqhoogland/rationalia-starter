---
_id: 69w9jjBQ7QMG8vRA4
title: Cause X
href: https://forum.effectivealtruism.org/tag/cause-x
type: tag
tags:
  - LessWrong
  - Topic
  - Tag
synchedAt: '2022-09-11T14:35:17.473Z'
---
# Cause X

**Cause X** is a cause area currently neglected by the effective altruism community, typically due to some form of moral blindness or fundamental oversight, yet more important than all the causes currently prioritized by it.

The idea was introduced by [[William MacAskill]],^[\[1\]](#fneytiqj2b18a)^ possibly by analogy with [[Derek Parfit]]'s "Theory X", a currently unknown hypothetical theory which would solve a number of important open problems in [[Population ethics|population ethics]].^[\[2\]](#fnsjhush0l07r)^ ("Cause X" is also sometimes used loosely to refer to any promising and neglected cause,^[\[3\]](#fnyfk965xsx6p)^^[\[4\]](#fn41pf6gr37so)^ but this is not how the expression is generally understood.)^[\[5\]](#fnrjm7iwwz74)^

Does Cause X exist?
-------------------

The existence of Cause X should not be taken for granted; whether there is a Cause X is an open question. In contrast to Parfit's Theory X, however, there are no impossibility theorems that could disprove the existence of Cause X.^[\[6\]](#fnzxgrnseokn)^ Furthermore, if there is a Cause X, there is no determinate way of ascertaining that it has been found; this is another disanalogy with Theory X, whose conditions are defined with sufficient precision that it is possible to establish when a theory satisfies them.

There are, however, good reasons for expecting Cause X to exist. All previous generations overlooked highly important causes—usually by neglecting large groups of morally relevant beings, such as women, racial minorities, and nonhuman animals—,^[\[7\]](#fno7e899lj9t9)^ so it would be a remarkable coincidence if our generation was the first to avoid this moral shortcoming.^[\[1\]](#fneytiqj2b18a)^^[\[8\]](#fniob062ibn8n)^^[\[9\]](#fn80hvcbjhjnb)^ In addition, the appearance that the present generation is different may itself be [[Debunking argument|debunked]] as a manifestation of the "end of history illusion",^[\[10\]](#fn8vhob9tf085)^ "new era thinking",^[\[11\]](#fnip5d6b32kb)^ and related [[Cognitive bias|cognitive biases]]. Furthermore, the space of possible cause areas is vast, and humans have only recently begun to explore it systematically, so it seems antecedently very likely that a cause more important than the current top causes remains to be found.^[\[8\]](#fniob062ibn8n)^ Yet another argument for the existence of Cause X is that the effective altruism community has, to a certain extent, changed its views about which causes are most important over the years. An induction from this history suggests further changes in what causes the community will consider most impactful.

Heuristics for finding Cause X
------------------------------

A number of heuristics for finding Cause X have been proposed.^[\[3\]](#fnyfk965xsx6p)^^[\[12\]](#fn6it36fyk5gb)^ Kerry Vaughan suggests three such heuristics:

Heuristic 1: *Moral circle expansion*. One apparently robust historical trend since at least the last few centuries is the gradual [[Moral circle expansion|expansion of the circle of moral concern]].^[\[13\]](#fn3x5cflvt4pw)^^[\[14\]](#fnrd98jg0yf3)^^[\[15\]](#fn505osw5siy6)^ Furthermore, this expansion appears to account for much of the moral progress that occurred during this period. Thus, a plausible heuristic is to push this expansion even further. This heuristic suggests [[Wild animal welfare|wild animal welfare]], [[Invertebrate welfare|invertebrate welfare]], [[Artificial sentience|artificial sentience]], as well as research on [[Moral patienthood|moral patienthood]], as Cause X candidates.

Heuristic 2: *Transformative technology*. Technological progress has the potential to radically transform the world in moral relevant respects. This assessment is plausible both on the basis of historical analysis—many of the most significant changes have occurred due to some form of human innovation—and upon consideration of various anticipated technologies not yet developed, such as [[Whole brain emulation|whole brain emulation]],  [artificial general intelligence](https://forum.effectivealtruism.org/tag/human-level-artificial-intelligence), and [[Atomically precise manufacturing|atomically precise manufacturing]]. The heuristic suggests work on making these technologies safer, such as [[AI safety]], as well as [[Differential progress|differential technological development]], as Cause X candidates.

Heuristic 3: *Crucial considerations*. A [[Crucial consideration|crucial consideration]] is one that warrants a major reassessment of a cause's impact. Actively looking for such considerations is thus of clear relevance for finding Cause X. Here the heuristic would favor making lists of crucial considerations, as well as the search for additional "[deliberation ladders](https://forum.effectivealtruism.org/tag/crucial-consideration#Related_concepts)" in existing arguments for specific causes.

The meta-heuristic of holding events where attempts are made to find potential Cause X candidates has also been suggested as an effective discovery method.^[\[16\]](#fnryao7u9mo9)^ Such events could take the form of informal meetups, conference workshops, or academic conferences.

Further reading
---------------

MacAskill, William (2016) [Moral progress and Cause X](https://www.effectivealtruism.org/articles/moral-progress-and-cause-x/) , *Effective Altruism*, October 7.

Related entries
---------------

[[Cause candidates|cause candidates]] | [[Cause prioritization|cause prioritization]] | [[Global priorities research|global priorities research]] | [[Less-discussed causes|less-discussed causes]]

1.  ^**[^](#fnrefeytiqj2b18a)**^
    
    MacAskill, William (2016) [Moral progress and Cause X](https://www.effectivealtruism.org/articles/moral-progress-and-cause-x/) , *Effective Altruism*, October 7.
    
2.  ^**[^](#fnrefsjhush0l07r)**^
    
    Parfit, Derek (1984) [*Reasons and Persons*](https://en.wikipedia.org/wiki/Special:BookSources/019824908X), Oxford: Clarendon Press.
    
3.  ^**[^](#fnrefyfk965xsx6p)**^
    
    Savoie, Joey (2019) [Cause X guide](https://forum.effectivealtruism.org/posts/kFmFLcdSFKo2GFJkc/cause-x-guide), *Effective Altruism Forum*, September 1.
    
4.  ^**[^](#fnref41pf6gr37so)**^
    
    Gómez Emilsson, Andrés (2019) [Cause X – what will the new shiny effective altruist cause be?](https://qualiacomputing.com/2019/02/07/cause-x-what-will-the-new-shiny-effective-altruist-cause-be/), *Qualia Computing*, February 7.
    
5.  ^**[^](#fnrefrjm7iwwz74)**^
    
    Rice, Issa (2019) [Comment on “Cause X guide”](https://forum.effectivealtruism.org/posts/kFmFLcdSFKo2GFJkc/cause-x-guide#dqCy9FEuLDP25hw9a), *Effective Altruism Forum*, September 1.
    
6.  ^**[^](#fnrefzxgrnseokn)**^
    
    Ng, Yew-Kwang (1989) [What should we do about future generations? Impossibility of Parfit’s Theory X](https://doi.org/10.1017/S0266267100002406), *Economics and Philosophy*, vol. 5, pp. 235–253.
    
7.  ^**[^](#fnrefo7e899lj9t9)**^
    
    Karnofsky, Holden (2017) [Radical empathy](https://www.openphilanthropy.org/blog/radical-empathy), *Open Philanthropy*, February 16.
    
8.  ^**[^](#fnrefiob062ibn8n)**^
    
    Williams, Evan G. (2015) [The possibility of an ongoing moral catastrophe](https://doi.org/10.1007/s10677-015-9567-7), *Ethical Theory and Moral Practice*, vol. 18, pp. 971–982.
    
9.  ^**[^](#fnref80hvcbjhjnb)**^
    
    Cf. Lewis, Gregory (2016) [Beware surprising and suspicious convergence](https://forum.effectivealtruism.org/posts/omoZDu8ScNbot6kXS/beware-surprising-and-suspicious-convergence), *Effective Altruism Forum*, January 24.
    
10.  ^**[^](#fnref8vhob9tf085)**^
    
    Quoidbach, Jordi, Daniel T. Gilbert & Timothy D. Wilson (2013) [The end of history illusion](https://doi.org/10.1126/science.1229294), *Science*, vol. 339, pp. 96–98.
    
11.  ^**[^](#fnrefip5d6b32kb)**^
    
    Schiller, Robert J. (2015) [*Irrational Exuberance*](https://en.wikipedia.org/wiki/Special:BookSources/978-0-691-16626-1), 3rd ed., Princeton, New Jersey: Princeton University Press.
    
12.  ^**[^](#fnref6it36fyk5gb)**^
    
    Vaughan, Kerry (2016) [Three heuristics for finding cause X](https://www.effectivealtruism.org/articles/three-heuristics-for-finding-cause-x/), *Effective Altruism*, November 4.
    
13.  ^**[^](#fnref3x5cflvt4pw)**^
    
    Singer, Peter (1981) [*The Expanding Circle: Ethics and Sociobiology*](https://en.wikipedia.org/wiki/Special:BookSources/9780198246466), Oxford: Clarendon Press.
    
14.  ^**[^](#fnrefrd98jg0yf3)**^
    
    Pinker, Steven (2011) [*The Better Angels of Our Nature: Why Violence Has Declined*](https://en.wikipedia.org/wiki/Special:BookSources/9780670022953), New York: Viking.
    
15.  ^**[^](#fnref505osw5siy6)**^
    
    But cf. Branwen, Gwern (2019) [The narrowing circle](https://www.gwern.net/The-Narrowing-Circle), *Gwern Branwen's Website*, April 27.
    
16.  ^**[^](#fnrefryao7u9mo9)**^
    
    Gómez Emilsson, Andrés (2020) [Improve your indoor air quality by 99% by optimizing the use of HEPA filters](https://qualiacomputing.com/2020/09/16/improve-your-indoor-air-quality-by-99-by-optimizing-the-use-of-hepa-filters/), *Qualia Computing*, September 16.