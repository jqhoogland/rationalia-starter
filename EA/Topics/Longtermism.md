---
_id: t2L2RziMDLEuHBWNF
title: Longtermism
href: https://forum.effectivealtruism.org/tag/longtermism
type: tag
tags:
  - LessWrong
  - Topic
  - Tag
synchedAt: '2022-09-11T14:35:44.700Z'
---
# Longtermism

**Longtermism** is the view that positively influencing the [[Long-term future|long-term future]] is a key moral priority of our time.^[\[1\]](#fn2iwddw4crwt)^^[\[2\]](#fnz6yx5b2rpim)^

Longtermism may be seen as following from the conjunction of three key claims.^[\[3\]](#fn6frik8lwexe)^ First, future people matter morally. Second, the vast majority of people that will ever exist, if Earth-originating intelligence is not prematurely extinguished, exist in the future. Third, people alive today can predictably influence whether these people exist, and how well their lives go.

Types of longtermism
--------------------

### Strong vs. weak longtermism

Strong longtermism holds that positively influencing the long-term future is the key moral priority of our time. This form of longtermism was introduced by [[Hilary Greaves]] and [[William MacAskill|Will MacAskill]],^[\[4\]](#fn4lqrm1tu6v4)^ and has precedents in the work of [[Nick Bostrom]],^[\[5\]](#fnijdcuqtcsja)^^[\[6\]](#fnrxubxlbto4l)^ [[Nick Beckstead]],^[\[7\]](#fnohggtozamwg)^^[\[8\]](#fn1j6xqn8ih7f)^ and others. Note that the authors do not define or discuss "weak" longtermism; the contrast is rather with longtermism as such, which as noted above holds that positively influencing the long-term future is a key priority, but not necessarily the top priority. 

### Patient vs. urgent longtermism

This distinction can be explained in reference to the [[Hinge of history|hinge of history hypothesis]], i.e. the hypothesis that we are currently living at a time where humanity has unusually high influence over the long-term future. Urgent longtermists find the hypothesis plausible and, accordingly, hold that it makes sense to spend our altruistic resources relatively quickly. (Altruistic resources include not just financial assets, but other resources that can accumulate and be spent deliberately in the pursuit of altruistic goals, such as credibility, career capital and coordination ability.) By contrast, patient longtermists hold that the opportunities for influence are not concentrated in the near term and, in line with this, they favour investing these resources so that they can be deployed at some point in the future, when the moments of significant influence arrive.

### Broad vs. targeted longtermism

This distinction was originally introduced by Nick Beckstead in his doctoral dissertation, *On the Overwhelming Importance of Shaping the Far Future*.^[\[9\]](#fn73581e7p8q)^ Targeted (or narrow) longtermism attempts to positively influence the long-term future by focusing on specific, identifiable scenarios, such as the risks of [[AI risk|misaligned AI]] or an [[Biosecurity|engineered pandemic]]. By contrast, broad longtermism tries to have a long-term influence by pursuing general approaches with the potential to be useful in a broader range of contexts, such as [[Building effective altruism|building effective altruism]] or [[Moral cooperation|promoting global cooperation]].

Both patient and urgent longtermism, and broad and targeted longtermism, are positions that exist on a continuum. The terms "urgent"/"patient" and "broad"/"targeted" divide these continua into two discrete regions, similarly to how the terms "tall" and "short" divide the height continuum. These distinctions may thus be seen as uncovering an underlying dimension along which longtermism can vary. Accordingly, the more relevant questions are "How patient/urgent should longtermism be?" or "How broad/targeted should longtermist interventions be?", rather than "Should longtermism be patient or urgent?" or "Should longtermism be targeted or narrow?"

### Other distinctions

One additional distinction sometimes made—which also originates in Greaves and MacAskill—is between *axiological* and *deontic* longtermism. ("Axiological" and "deontic" are technical terms borrowed from [[Moral philosophy|moral philosophy]]: "axiological" means "related to what is good or valuable" and "deontic" means "related to what we ought to do or have reason to do".) Axiological longtermism holds that positively influencing the long-term future is among the most valuable things we can do, whereas deontic longtermism holds that positively influencing the long-term future is among the things we have most reason to do. Sometimes these views are combined with strong longtermism, so axiological strong longtermism becomes the view that influencing the long-term future is the most valuable thing to do and deontic strong longtermism becomes the view that influencing the long-term future is the thing we have most reason to do.

Another relevant distinction, introduced by the philosophers Johan Gustafsson and Petra Kosonen, is between *normative* and *prudential* longtermism.^[\[10\]](#fn9uksbqguhw)^ Normative longtermism is longtermism as it is normally understood, i.e. as a view about what is valuable, or we have reason to do, from an impersonal or moral perspective. However, one can also consider a form of longtermism focused on what is in a person's self-interest. If humans could live for thousands or millions of years, it could be argued that, even from a self-interested perspective, each person should focus primarily on the long-term effects of their actions, because a person's lifetime wellbeing will be largely determined by those effects.

Further reading
---------------

Balfour, Dylan (2021) [Longtermism: how much should we care about the far future?](https://1000wordphilosophy.com/2021/09/17/longtermism/), *1000-Word Philosophy: An Introductory Anthology*, September 17.

Beckstead, Nick (2019) [A brief argument for the overwhelming importance of shaping the far future](https://doi.org/10.1093/oso/9780198841364.003.0006), in Hilary Greaves & Theron Pummer (eds.) *Effective Altruism: Philosophical Issues*, Oxford: Oxford University Press, pp. 80–98.

MacAskill, William (2022) [What is longtermism and why does it matter?](https://www.bbc.com/future/article/20220805-what-is-longtermism-and-why-does-it-matter), *BBC News*, August 8.

MacAskill, William, Hilary Greaves & Elliott Thornley (2021) [The moral case for long-term thinking](https://en.wikipedia.org/wiki/Special:BookSources/978-0-9957281-8-9), in Natalie Cargill & Tyler John (eds.) *The Long View: Essays on Policy, Philanthropy, and the Long-Term Future*, London: First, pp. 19–28.

Moorhouse, Fin (2021) [Introduction to longtermism](https://www.effectivealtruism.org/articles/longtermism/), *Effective Altruism*, January 27.

Roser, Max (2022) [The future is vast: longtermism’s perspective on humanity’s past, present, and future](https://ourworldindata.org/longtermism), *Our World in Data*, March 15.

Todd, Benjamin (2017) [Longtermism: the moral significance of future generations](https://80000hours.org/articles/future-generations/), *80,000 Hours*, October.

Wikipedia (2021) [Longtermism](https://en.wikipedia.org/w/index.php?title=Longtermism&oldid=1090541975), *Wikipedia*, October 28 (updated 30 May 2022‎).

External links
--------------

[Longtermism](https://longtermism.com/). Online introduction to longtermism.

Related entries
---------------

[[Criticism of longtermism and existential risk studies|criticism of longtermism and existential risk studies]] **|** [ethics of existential risk](/tag/ethics-of-existential-risk) | [[EA/Topics/Existential risk|existential risk]] | [existential security](/tag/existential-security) | [[Global health and wellbeing|global health and wellbeing]] | [[Longtermist institutional reform|institutions for future generations]] | [[Long-range forecasting|long-range forecasting]] | [[Macrostrategy|macrostrategy]] | [non-humans and the long-term future](/tag/non-humans-and-the-long-term-future) | [[Patient altruism|patient altruism]] | [[Trajectory change|trajectory change]]

1.  ^**[^](#fnref2iwddw4crwt)**^
    
    Ord, Toby (2020) [*The Precipice: Existential Risk and the Future of Humanity*](https://en.wikipedia.org/wiki/Special:BookSources/1526600218), London: Bloomsbury Publishing, p. 46.
    
2.  ^**[^](#fnrefz6yx5b2rpim)**^
    
    MacAskill, William (2022) [*What We Owe the Future*](https://en.wikipedia.org/wiki/Special:BookSources/978-1-5416-1862-6), New York: Basic Books.
    
3.  ^**[^](#fnref6frik8lwexe)**^
    
    Moorhouse, Fin (2021) [Introduction to longtermism](https://www.effectivealtruism.org/articles/longtermism/), *Effective Altruism*, January 27. 
    
4.  ^**[^](#fnref4lqrm1tu6v4)**^
    
    Greaves, Hilary & William Macaskill (2021) [The case for strong longtermism](https://globalprioritiesinstitute.org/hilary-greaves-william-macaskill-the-case-for-strong-longtermism-2/), Global Priorities Institute, University of Oxford.
    
5.  ^**[^](#fnrefijdcuqtcsja)**^
    
    Bostrom, Nick (2003) [Astronomical waste: The opportunity cost of delayed technological development](https://doi.org/10.1017/S0953820800004076), *Utilitas*, vol. 15, pp. 308–314.
    
6.  ^**[^](#fnrefrxubxlbto4l)**^
    
    Bostrom, Nick (2013) [Existential risk prevention as global priority](https://doi.org/10.1111/1758-5899.12002), *Global Policy*, vol. 4, pp. 15–31.
    
7.  ^**[^](#fnrefohggtozamwg)**^
    
    Beckstead, Nick (2013) [*On the Overwhelming Importance of Shaping the Far Future*](http://doi.org/10.7282/T35M649T), doctoral thesis, Rutgers University.
    
8.  ^**[^](#fnref1j6xqn8ih7f)**^
    
    Beckstead, Nick (2019) [A brief argument for the overwhelming importance of shaping the far future](https://doi.org/10.1093/oso/9780198841364.003.0006), in Hilary Greaves & Theron Pummer (eds.) *Effective Altruism: Philosophical Issues*, Oxford: Oxford University Press, pp. 80–98.
    
9.  ^**[^](#fnref73581e7p8q)**^
    
    Beckstead, Nick (2013) [*On the Overwhelming Importance of Shaping the Far Future*](https://doi.org/10.7282/T35M649T), PhD thesis, Rutgers University.
    
10.  ^**[^](#fnref9uksbqguhw)**^
    
    Gustafsson, Johan & Petra Kosonen (2022) 'Prudential longtermism', unpublished.
    
11.  ^**[^](#fnrefihuafonhwkm)**^
    
    MacAskill, William (2019) [“Longtermism”](https://forum.effectivealtruism.org/posts/qZyshHCNkjs3TvSem/longtermism), *Effective Altruism Forum*, July 25.
    
12.  ^**[^](#fnref92v82tny4ss)**^
    
    Greaves, Hilary & William MacAskill (2021) [The case for strong longtermism](https://globalprioritiesinstitute.org/hilary-greaves-william-macaskill-the-case-for-strong-longtermism/), working paper.