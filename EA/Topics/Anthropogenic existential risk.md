---
_id: uEnvZnLG7Cbd8jeco
title: Anthropogenic existential risk
href: https://forum.effectivealtruism.org/tag/anthropogenic-existential-risk
type: tag
tags:
  - LessWrong
  - Topic
  - Tag
synchedAt: '2022-09-11T14:35:22.472Z'
---
# Anthropogenic existential risk

An **anthropogenic existential risk** is an [[EA/Topics/Existential risk|existential risk]] arising from intentional or accidental human activity rather than underlying [[Natural existential risk|natural processes]].

New technologies have played a huge part in the massive growth in human flourishing over the past centuries. However, they also pose some serious risks. [[Nuclear warfare|Nuclear weapons]], for example, may have created the potential for wars that result in human extinction. Other technologies may pose similar risks in the future, such as synthetic biology (see [[Global catastrophic biological risk|global catastrophic biological risk]]) and [[AI risk|artificial intelligence]], as well as risks from [[Existential risks from fundamental physics research|fundamental physics research]] and [[Unknown existential risk|unknown risks]].

That our species has so far survived both natural and anthropogenic risks puts an upper bound on how high these risks can be. But humanity has been exposed to natural risks throughout the entirety of its history, whereas anthropogenic risks have emerged only in the last century. This difference between these two types of risks implies that their respective upper bounds are also very different. Specifically, this consideration is generally believed to warrant the conclusion that anthropogenic risks are significantly higher than natural risks.^[\[1\]](#fnn6e74do5ms)^^[\[2\]](#fnyqbq9ej5ebr)^^[\[3\]](#fnl2jqcz9r8e)^ According to [[Toby Ord]], "we face about a thousand times more anthropogenic risk over the next century than natural risk."^[\[4\]](#fnqokji1pqjxb)^ 

Further reading
---------------

Beckstead, Nick *et al.* (2014) [Unprecedented technological risks](http://globalprioritiesproject.org/wp-content/uploads/2015/04/Unprecedented-Technological-Risks.pdf), Global Priorities Project.

Ord, Toby (2020) [*The Precipice: Existential Risk and the Future of Humanity*](https://en.wikipedia.org/wiki/Special:BookSources/1526600218), London: Bloomsbury Publishing.

Related entries
---------------

[[Differential progress|differential progress]] | [[Natural existential risk|natural existential risk]] | [vulnerable world hypothesis](/tag/vulnerable-world-hypothesis) | [[Weapons of mass destruction|weapons of mass destruction]]

1.  ^**[^](#fnrefn6e74do5ms)**^
    
    Bostrom, Nick (2004) [The future of human evolution](https://en.wikipedia.org/wiki/Special:BookSources/9780974347226), in Charles Tandy (ed.) *Death and Anti-Death: Two Hundred Years after Kant, Fifty Years after Turing*, vol. 2, Palo Alto, California: Ria University Press, pp. 339–371.
    
2.  ^**[^](#fnrefyqbq9ej5ebr)**^
    
    Snyder-Beattie, Andrew, Toby Ord & Michael B. Bonsall (2019) [An upper bound for the background rate of human extinction](http://doi.org/10.1038/s41598-019-47540-7), *Scientific Reports*, vol. 9, pp. 1–9.
    
3.  ^**[^](#fnrefl2jqcz9r8e)**^
    
    Aschenbrenner, Leopold (2020) [Securing posterity](https://worksinprogress.co/issue/securing-posterity/), *Works in Progress*, October 19.
    
4.  ^**[^](#fnrefqokji1pqjxb)**^
    
    Ord, Toby (2020) [*The Precipice: Existential Risk and the Future of Humanity*](https://en.wikipedia.org/wiki/Special:BookSources/1526600218), London: Bloomsbury Publishing, p. 87.