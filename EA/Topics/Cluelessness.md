---
_id: Direa63BcP6pjAcFh
title: Cluelessness
href: https://forum.effectivealtruism.org/tag/cluelessness
type: tag
tags:
  - LessWrong
  - Topic
  - Tag
synchedAt: '2022-09-11T14:35:15.125Z'
---
# Cluelessness

**Cluelessness** is radical uncertainty about the long-term effects of our actions.

Simple versus complex cluelessness
----------------------------------

All actions we take have huge effects on the future. One way of seeing this is by considering identity-altering actions. Imagine that Amy passes her friend on the street and they stop to chat. Amy and her friend will now be on a different trajectory than they would have been otherwise. They will interact with different people, at a different time, in a different place, or in a different way than if they hadn’t paused. This will eventually change the circumstances of a conception event such that a different person will now be born because they paused to speak on the street. Now, when the person who is conceived takes actions, Amy will be causally responsible for those actions and their effects. She is also causally responsible for all the effects flowing from those effects.

This is an example of ***simple*** **cluelessness**, which isn't generally considered problematic. In the above example, Amy has no reason to believe that the many consequences that would follow from pausing would be better than the many consequences that follow from not pausing. Amy has *evidential symmetry* between the two following claims:

*   Pausing to chat would have catastrophic effects for humanity
*   Not pausing to chat would have catastrophic effects for humanity

And similarly, Amy has evidential symmetry between the two following claims:

*   Pausing to chat would have miraculous effects for humanity
*   Not pausing to chat would have miraculous effects for humanity

(The example assumes that there is nothing particularly special about this chat — eg. Amy and her friend are not chatting about starting a nuclear war or influencing AI policy.)

By *evidential symmetry* between two actions it is meant that, though massive value or disvalue could come from a given action, these effects could equally easily, and in precisely analogous ways, result from the relevant alternative actions. In the previous scenario, it was assumed that each of the possible people that will be born are as likely as each other to be the next Norman Borlaug. And each of the possible people are as likely as each other to be the next Joseph Stalin.

So this situation is not problematic; the possible effects, though they are huge, cancel out precisely in an expected value estimate.

Cluelessness is problematic, however, in situations where there is no evidential symmetry. For a pair of actions (act one and act two), **complex cluelessness** obtains when:

*   There are reasons to think that the effects of act one would systematically ^[\[1\]](#fn6yb492fcwj8)^ tend to be substantially better than those of act two;
*   There are reasons to think that the effects of act two would systematically tend to be substantially better than those of act one;
*   It is unclear how to weigh up these reasons against one another.

For example, there are some reasons to think that the long-term effects of a marginally higher economic growth rate would be good—for example, via driving more patient and pro-social attitudes. This would mean that taking action to increase economic growth could have much better effects than not taking the action. We have some reasons to think that the long-term effects of a marginally higher economic growth rate would be bad —for example, via increased carbon emissions leading to climate change. This would mean that not taking the action that increases economic growth could be a much better idea. It is not immediately obvious that one of these is better than the other, but we also cannot say they have equal expected value. That would need either evidential symmetry, or a very detailed expected value estimate.

Some authors claim that complex cluelessness implies that we should be very skeptical of interventions whose claim to cost-effectiveness is through their direct, proximate effects. As Benjamin Todd and others have argued, the long-term effects of these actions probably dominate.^[\[2\]](#fn8j6rdm3ki7)^ But we do not know what the long-term effects of many interventions are or just how good or bad they will be.

Actions we take today have indirect long-term effects, and they seem to dominate over the direct near-term effects. In the absence of evidential symmetry, these long-term effects cannot be ignored. So it seems that those concerned about future generations have to justify interventions via their long-term effects, rather than their proximate ones.

Further reading
---------------

Greaves, Hilary (2020) [Evidence, cluelessness, and the long term](https://forum.effectivealtruism.org/posts/LdZcit8zX89rofZf3/evidence-cluelessness-and-the-long-term-hilary-greaves), *Effective Altruism Forum*, November 1.

Mogensen, Andreas (2020) [Maximal cluelessness](https://doi.org/10.1093/pq/pqaa021), *The Philosophical Quarterly*, vol. 71, pp. 141–162.

Schubert, Stefan (2022) [Against cluelessness: pockets of predictability](https://stefanfschubert.com/blog/2022/5/18/against-cluelessness-pockets-of-predictability), *Stefan Schubert’s Blog*, May 18.

Tarsney, Christian (2022) [The epistemic challenge to longtermism](https://globalprioritiesinstitute.org/wp-content/uploads/Tarsney-Epistemic-Challenge-to-Longtermism.pdf), GPI Working Paper No. 3-2022, Global Priorities Institute.

Related entries
---------------

[[Accidental harm|accidental harm]] | [[Alternatives to expected value theory |alternatives to expected value theory]] | [[Crucial consideration|crucial consideration]] | [](https://forum.effectivealtruism.org/topics/crucial-consideration) [[Expected value|expected value]] | [[Forecasting|forecasting]] | [[Indirect long-term effects|indirect long-term effects]] | [[Long-range forecasting|long-range forecasting]] | [[Model uncertainty|model uncertainty]] | [[Value of information|value of information]]

1.  ^**[^](#fnref6yb492fcwj8)**^
    
    An explanation of what is meant by ‘systematically’ can be found in section 5 of Greaves, Hilary (2016) [Cluelessness](http://doi.org/10.1093/arisoc/aow018), *Proceedings of the Aristotelian Society*, vol. 116, pp. 311–339.
    
2.  ^**[^](#fnref8j6rdm3ki7)**^
    
    Todd, Benjamin (2017) [Longtermism: the moral significance of future generations](https://80000hours.org/articles/future-generations/), *80,000 Hours*, October.