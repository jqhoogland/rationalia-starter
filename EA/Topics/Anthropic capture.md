---
_id: dNNa2uqMHNNn7tN56
title: Anthropic capture
href: https://forum.effectivealtruism.org/tag/anthropic-capture
type: tag
tags:
  - LessWrong
  - Topic
  - Tag
synchedAt: '2022-09-11T14:35:23.887Z'
---
# Anthropic capture

**Anthropic capture** is a [[Capability control method|capability control method]] in which an advanced [[Artificial intelligence|artificial intelligence]] thinks it might be in a simulation and as such attempts to behave in ways that will be rewarded by its simulators.

Further reading
---------------

Bostrom, Nick (2014) [*Superintelligence: paths, dangers, strategies*](https://en.wikipedia.org/wiki/Special:BookSources/9780199678112), Oxford: Oxford University Press, pp. 134â€“135.