---
_id: oNiQsBHA3i837sySD
title: AI safety
href: https://forum.effectivealtruism.org/tag/ai-safety
type: tag
tags:
  - LessWrong
  - Topic
  - Tag
synchedAt: '2022-09-11T14:35:16.071Z'
---
# AI safety

**AI safety** is the study of ways to reduce risks posed by [[Artificial intelligence|artificial intelligence]].

AI safety as a career
---------------------

[[80,000 Hours]]' medium-depth investigation rates technical AI safety research a "priority path"—among the most promising career opportunities the organization has identified so far.^[\[1\]](#fnoy0q6nfb1j)^^[\[2\]](#fnle8osyeymtm)^

Further reading
---------------

Gates, Vael (2022) [Resources I send to AI researchers about AI safety](https://forum.effectivealtruism.org/posts/8sAzgNcssH3mdb8ya/resources-i-send-to-ai-researchers-about-ai-safety), *Effective Altruism Forum*, June 13.

Krakovna, Victoria (2017) [Introductory resources on AI safety research](https://vkrakovna.wordpress.com/2016/02/28/introductory-resources-on-ai-safety-research/), *Victoria Krakovna's Blog*, October 19.  
*A list of readings on AI safety.*

Ngo, Richard (2019) [Disentangling arguments for the importance of AI safety](https://forum.effectivealtruism.org/posts/LprnaEj3uhkmYtmat/disentangling-arguments-for-the-importance-of-ai-safety), *Effective Altruism Forum*, January 21.

Related entries
---------------

[[AI alignment]] | [[AI interpretability]] | [[AI risk]] | [[Cooperative AI|cooperative AI]] 

1.  ^**[^](#fnrefoy0q6nfb1j)**^
    
    Todd, Benjamin (2018) [The highest impact career paths our research has identified so far](https://80000hours.org/articles/high-impact-careers/), *80,000 Hours*, August 12.
    
2.  ^**[^](#fnrefle8osyeymtm)**^
    
    Todd, Benjamin (2021) [AI safety technical research](https://80000hours.org/career-reviews/ai-safety-researcher/), *80,000 Hours*, October.