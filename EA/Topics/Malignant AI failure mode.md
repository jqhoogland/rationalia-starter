---
_id: JEHutiZopomHSkaSC
title: Malignant AI failure mode
href: https://forum.effectivealtruism.org/tag/malignant-ai-failure-mode
type: tag
tags:
  - LessWrong
  - Topic
  - Tag
synchedAt: '2022-09-11T14:35:02.736Z'
---
# Malignant AI failure mode

An **AI failure mode** is a way in which a project to develop machine [[Superintelligence|superintelligence]] may fail. ***Malignant*** **AI failure modes** are AI failure modes that result in an [[Existential catastrophe|existential catastrophe]].

[[Nick Bostrom]] categorizes malignant AI failure modes into three basic types: [[Perverse instantiation|perverse instantiation]], which involves the satisfaction of an AI's goals in ways contrary to the intentions of those who programmed it; [[Infrastructure profusion|infrastructure profusion]], which involves the transformation of large parts of the accessible universe into infrastructure in the service of some goal that impedes the realization of humanity's long-term potential; and [[Mind crime|mind crime]], which involves the mistreatment of [[Moral patienthood|morally relevant]] computational processes.

Further reading
---------------

Bostrom, Nick (2014) [*Superintelligence: Paths, Dangers, Strategies*](https://en.wikipedia.org/wiki/Special:BookSources/9780199678112), Oxford: Oxford University Press, pp. 119-126.

Related entries
---------------

[[EA/Topics/Existential risk|existential risk]] | [[Infrastructure profusion|infrastructure profusion]] | [[Mind crime|mind crime]] | [[Perverse instantiation|perverse instantiation]] | [[Superintelligence|superintelligence]]