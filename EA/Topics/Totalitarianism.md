---
_id: 4JAa3nwAmjEoe8Rgx
title: Totalitarianism
href: https://forum.effectivealtruism.org/tag/totalitarianism
type: tag
tags:
  - LessWrong
  - Topic
  - Tag
synchedAt: '2022-09-11T14:35:09.805Z'
---
# Totalitarianism

**Totalitarianism** is an all-embracing system of government that exercises virtually complete control over every aspect of individual life. ***Robust*** **totalitarianism** may be defined as a type of totalitarianism particularly effective at enforcing its ideological vision and preventing internal and external threats to its authority.

Characteristics
---------------

Benito Mussolini famously characterized totalitarianism as "all within the state, nothing outside the state, none against the state."^[\[1\]](#fnk8ygoel1d6q)^ Contemporary scholars have listed several distinctive features of totalitarian regimes. These features include a radical official ideology, usually exclusionary and future-oriented; a single party, typically led by one man; a monopoly of the means of both persuasion and coercion; a centrally planned economy, in which most professional activities are part of the state; and extreme [[Political polarization|polarization]] and widespread use of [[Terrorism|terror]] in all spheres of life.^[\[2\]](#fn3v923odr1t5)^^[\[3\]](#fna5qji60xdhw)^^[\[4\]](#fnoemid6eomnp)^ Totalitarian regimes are estimated to have been responsible for the deaths of over 125 million people in the 20th century, mostly in the Soviet Union, Nazi Germany, and communist China.^[\[5\]](#fnwq5yh8r3h3g)^ To this tragic loss of life needs to be added the major loss of [[Wellbeing|quality of life]] experienced by those living under such regimes.

Robust totalitarianism as a catastrophic and existential risk
-------------------------------------------------------------

Because of its scale, the threat of robust totalitarianism constitutes a [[Global catastrophic risk|global catastrophic risk]]. If the totalitarian regime has the potential to be both global and stable, it could also constitute an [[EA/Topics/Existential risk|existential risk]]—specifically a risk of an unrecoverable [[Dystopia|dystopia]].

Advances in [[Artificial intelligence|artificial intelligence]] in areas such as lie detection, social persuasion and deception, autonomous weapons, and ubiquitous surveillance could entrench existing totalitarian regimes. These developments may also [[Safeguarding liberal democracy|cause democracies to slide into totalitarianism]].^[\[6\]](#fnhwktxygoxx5)^ On the other hand, AI could conceivably destabilize totalitarian systems or protect against their emergence.^[\[7\]](#fnwnabi8fm50q)^ To this date, no detailed analysis exists of the potential impact of artificial intelligence on the risk of robust totalitarianism. The literature on robust totalitarianism in general is itself very small.^[\[8\]](#fnkf66sg490ji)^

Evaluation
----------

[[80,000 Hours]] rates risks of robust totalitarianism a "potential highest priority area": an issue that, if more thoroughly examined, could rank as a top global challenge.^[\[10\]](#fnfjgm1g1sz5a)^

Further reading
---------------

Aird, Michael (2020) [Collection of sources related to dystopias and "robust totalitarianism"](https://forum.effectivealtruism.org/posts/EMKf4Gyee7BsY2RP8/michaela-s-shortform?commentId=8GJtZ6DrEn5MDf6dZ), *Effective Altruism Forum*, March 30.  
*Many additional resources on this topic.*

Caplan, Bryan (2008) [The totalitarian threat](https://en.wikipedia.org/wiki/Special:BookSources/9780199606504), in Nick Bostrom & Milan M. Ćirković (eds.) *Global Catastrophic Risks*, Oxford: Oxford University Press, pp. 504–519.

Related entries
---------------

[[Dystopia|dystopia]] | [[Global governance|global governance]]

1.  ^**[^](#fnrefk8ygoel1d6q)**^
    
    Mussolini, Benito (1932) 'La dottrina del fascismo', in *Enciclopedia italiana di scienze, lettere ed arti*, Roma: Istituto della Enciclopedia Italiana.
    
2.  ^**[^](#fnref3v923odr1t5)**^
    
    Friedrich, Carl J. & Zbigniew K. Brzezinski (1965) *Totalitarian Dictatorship and Autocracy*, 2nd ed., Cambridge: Harvard University Press, p. 22.
    
3.  ^**[^](#fnrefa5qji60xdhw)**^
    
    Aron, Raymond (1965) *Démocratie et totalitarisme*, Paris: Gallimard, ch. 15.
    
4.  ^**[^](#fnrefoemid6eomnp)**^
    
    Holmes, Leslie (2001) [Totalitarianism](http://doi.org/10.1016/B0-08-043076-7/01240-7), in Neil J. Smelser & Paul B. Baltes (eds.) *International Encyclopedia of the Social & Behavioral Sciences*, Amsterdam: Elsevier, pp. 15788–15791.
    
5.  ^**[^](#fnrefwq5yh8r3h3g)**^
    
    Bernholz, Peter (2000) [Totalitarianism](http://doi.org/10.1007/978-0-306-47828-4_201), in Charles K. Rowley & Friedrich Schneider (eds.) *The Encyclopedia of Public Choice*, Boston: Springer, pp. 565–569, p. 568.
    
6.  ^**[^](#fnrefhwktxygoxx5)**^
    
    Dafoe, Allan (2018) [AI governance: A research agenda](https://www.fhi.ox.ac.uk/wp-content/uploads/GovAI-Agenda.pdf), Future of Humanity Institute, University of Oxford, section 4.1.
    
7.  ^**[^](#fnrefwnabi8fm50q)**^
    
    Adamczewski, Tom (2019) [A shift in arguments for AI risk](https://fragile-credences.github.io/prioritising-ai/), *Fragile Credences*, May 25, section 'Robust totalitarianism'.
    
8.  ^**[^](#fnrefkf66sg490ji)**^
    
    Caplan, Bryan (2008) [The totalitarian threat](https://en.wikipedia.org/wiki/Special:BookSources/9780199606504), in Nick Bostrom & Milan M. Ćirković (eds.) *Global Catastrophic Risks*, Oxford: Oxford University Press, pp. 504–519.
    
9.  ^**[^](#fnref1s2cbixdbiz)**^
    
    Koehler, Arden (2020) [Problem areas beyond 80,000 Hours’ current priorities](https://forum.effectivealtruism.org/posts/xoxbDsKGvHpkGfw9R/problem-areas-beyond-80-000-hours-current-priorities), *Effective Altruism Forum*, June 22, section 'Risks of stable totalitarianism'.
    
10.  ^**[^](#fnreffjgm1g1sz5a)**^
    
    80,000 Hours (2022) [Our current list of pressing world problems](https://80000hours.org/problem-profiles/), *80,000 Hours*.