---
_id: MsZJrnxnoG7QRnhYe
title: Orthogonality thesis
href: https://forum.effectivealtruism.org/tag/orthogonality-thesis
type: tag
tags:
  - LessWrong
  - Topic
  - Tag
synchedAt: '2022-09-11T14:34:51.898Z'
---
# Orthogonality thesis

From [[Superintelligence (book)]]
> Intelligence and final goals are orthogonal: more or less any level of intelligence
could in principle be combined with more or less any final goal.

How might we go about predicting motivations?
- **Through design**
- **Through inheritance**: for em-like AGIs
- **Through [[instrumental convergence thesis|convergent instrumental reasons]]**

# Further reading

Bostrom, Nick (2012) [The superintelligent will: motivation and instrumental rationality in advanced artificial agents](http://doi.org/10.1007/s11023-012-9281-3), *Minds and Machines*, vol. 22, pp. 71â€“85.

Yudkowsky, Eliezer (2013) [Five theses, two lemmas, and a couple of strategic implications](https://intelligence.org/2013/05/05/five-theses-two-lemmas-and-a-couple-of-strategic-implications/), *Machine Intelligence Research Institute's Blog*, May 5.

# Related entries
- [[Instrumental convergence thesis|instrumental convergence thesis]]



