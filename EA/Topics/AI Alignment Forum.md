---
_id: Q9CvvDgHQ3hs4TtKm
title: AI Alignment Forum
href: https://forum.effectivealtruism.org/tag/ai-alignment-forum
type: tag
tags:
  - LessWrong
  - Topic
  - Tag
synchedAt: '2022-09-11T14:35:26.496Z'
---
# AI Alignment Forum

The **AI Alignment Forum** is a forum for discussing technical research on [[AI alignment]] that superseded the **Agent Foundations Forum**, established around 2015.^[\[1\]](#fnbap097k8ubj)^

A beta version of the site, at the time named the **Alignment Forum**, was announced on 10 July 2018.^[\[2\]](#fnn6mx1am65ug)^ The site under its current name was officially launched on 29 October 2018.^[\[3\]](#fn8bdrwpqllap)^ The authors describe its purpose as follows:

> Our first priority is obviously to avert catastrophic outcomes from unaligned Artificial Intelligence. We think the best way to achieve this at the margin is to build an online-hub for AI Alignment research, which both allows the existing top researchers in the field to talk about cutting-edge ideas and approaches, as well as the onboarding of new researchers and contributors.
> 
> We think that to solve the AI Alignment problem, the field of AI Alignment research needs to be able to effectively coordinate a large number of researchers from a large number of organisations, with significantly different approaches. Two decades ago we might have invested heavily in the development of a conference or a journal, but with the onset of the internet, an online forum with its ability to do much faster and more comprehensive forms of peer-review seemed to us like a more promising way to help the field form a good set of standards and methodologies.

The AI Alignment Forum is built by [[Lightcone Infrastructure]].

Further reading
---------------

Habryka, Oliver *et al.* (2018) [Introducing the AI Alignment Forum (FAQ)](https://www.alignmentforum.org/posts/FoiiRDC3EhjHx7ayY/introducing-the-ai-alignment-forum-faq), *AI Alignment Forum*, October 29.

External links
--------------

[AI Alignment Forum](https://www.alignmentforum.org/). Official website.

Related entries
---------------

[[Alignment Newsletter]] | [[LessWrong]] | [[Lightcone Infrastructure]]

1.  ^**[^](#fnrefbap097k8ubj)**^
    
    LaVictoire, Patrick (2015) [Welcome, new contributors](https://www.alignmentforum.org/posts/5bd75cc58225bf0670374efa/welcome-new-contributors), *Agent Foundations Forum*, March 23.
    
2.  ^**[^](#fnrefn6mx1am65ug)**^
    
    Arnold, Raymond (2018) [Announcing AlignmentForum.org beta](https://www.alignmentforum.org/posts/JiMAMNAb55Qq24nES/announcing-alignmentforum-org-beta), *AI Alignment Forum*, July 10.
    
3.  ^**[^](#fnref8bdrwpqllap)**^
    
    Habryka, Oliver *et al.* (2018) [Introducing the AI Alignment Forum (FAQ)](https://www.alignmentforum.org/posts/FoiiRDC3EhjHx7ayY/introducing-the-ai-alignment-forum-faq), *AI Alignment Forum*, October 29.