---
_id: ee66CtAMYurQreWBH
title: Existential risk
href: https://forum.effectivealtruism.org/tag/existential-risk
type: tag
tags:
  - LessWrong
  - Topic
  - Tag
core: true
synchedAt: '2022-09-11T14:35:38.832Z'
---
# Existential risk

An **existential risk** is the risk of an [[Existential catastrophe|existential catastrophe]], i.e. one that threatens the destruction of humanity’s longterm potential.^[\[1\]](#fn0f5x8s34vee)^^[\[2\]](#fns39fj4bj7yr)^ Existential risks include [[Natural existential risk|natural risks]] such as those posed by [[Asteroids|asteroids]] or [[Supervolcano|supervolcanoes]] as well as [[Anthropogenic existential risk|anthropogenic risks]] like mishaps resulting from [[Global catastrophic biological risk|synthetic biology]] or [[AI risk|artificial intelligence]].

A number of authors have argued that existential risks are especially important because the [[EA/Topics/Longtermism|long-run future of humanity]] matters a great deal.^[\[1\]](#fn0f5x8s34vee)^^[\[3\]](#fnehnudz7v1f)^^[\[4\]](#fnx1zw0p7aful)^^[\[5\]](#fnxep7ip80wm)^ Many believe that there is [[Temporal discounting|no intrinsic moral difference]] between the importance of a life today and one in a hundred years. However, there may be many more people in the future than there are now. They argue, therefore, that it is overwhelmingly important to preserve that potential, even if the risks to humanity are small.

One objection to this argument is that people have a special responsibility to other people currently alive that they do not have to people who have not yet been born.^[\[6\]](#fnql2k3envp7)^ Another objection is that, although it would in principle be important to manage, the risks are currently so unlikely and poorly understood that existential risk reduction is less cost-effective than work on other promising areas.

Recommendations
---------------

In [[The Precipice|*The Precipice: Existential Risk and the Future of Humanity*]], [[Toby Ord]] offers several [[Policy|policy]] and [[Research|research]] recommendations for handling existential risks:^[\[7\]](#fn52gvr4dqg9p)^

*   Explore options for new [[Global governance|international institutions]] aimed at reducing existential risk, both incremental and revolutionary.
*   Investigate possibilities for making the deliberate or reckless imposition of [[Human extinction|human extinction]] risk an international crime.
*   Investigate possibilities for bringing the [[Longtermist institutional reform|representation of future generations]] into national and international democratic institutions.
*   Each major world power should have an appointed senior government position responsible for registering and responding to existential risks that can be realistically foreseen in the next 20 years.
*   Find the major [[Existential risk factor|existential risk factors]] and security factors—both in terms of absolute size and in the cost-effectiveness of marginal changes.
*   Target efforts at reducing the likelihood of military conflicts between the US, [[Russia]] and [[China]].
*   Improve horizon-scanning for unforeseen and emerging risks.
*   Investigate [[Resilient food|food substitutes]] in case of extreme and lasting reduction in the world’s ability to supply food.
*   Develop better theoretical and practical tools for assessing risks with extremely high stakes that are either [[Unprecedented risks|unprecedented]] or thought to have extremely low probability.
*   Improve our understanding of the chance civilization will recover after a [[Civilizational collapse|global collapse]], what might prevent this, and how to improve the odds.
*   Develop our thinking about [[Existential security|grand strategy]] for humanity.
*   Develop our understanding of the [[Ethics of existential risk|ethics of existential risk]] and valuing the [[Long-term future|longterm future]].

Further reading
---------------

Bostrom, Nick (2002) [Existential risks: analyzing human extinction scenarios and related hazards](https://www.jetpress.org/volume9/risks.html), *Journal of Evolution and Technology*, vol. 9.  
*A paper surveying a wide range of non-extinction existential risks.*

Bostrom, Nick (2013) [Existential risk prevention as global priority](http://doi.org/10.1111/1758-5899.12002), *Global Policy*, vol. 4, pp. 15–31.

Matheny, Jason Gaverick (2007) [Reducing the risk of human extinction](http://doi.org/10.1111/j.1539-6924.2007.00960.x), *Risk Analysis*, vol. 27, pp. 1335–1344.  
*A paper exploring the cost-effectiveness of extinction risk reduction.*

Ord, Toby (2020) [*The Precipice: Existential Risk and the Future of Humanity*](https://en.wikipedia.org/wiki/Special:BookSources/1526600218), London: Bloomsbury Publishing.

Ord, Toby (2020) [Existential risks to humanity](https://en.wikipedia.org/wiki/Special:BookSources/9789211264425) in Pedro Conceição (ed.) *The 2020 Human Development Report: The Next Frontier: Human Development and the Anthropocene*, New York: United Nations Development Programme, pp. 106–111.

Related entries
---------------

[[Civilizational collapse|civilizational collapse]] | [[Criticism of longtermism and existential risk studies|criticism of longtermism and existential risk studies]] **|** [[Dystopia|dystopia]] | [[Estimation of existential risk|estimation of existential risks]] | [[Ethics of existential risk|ethics of existential risk]] | [[Existential catastrophe|existential catastrophe]] | [[Existential risk factor|existential risk factor]] | [[Existential security|existential security]] | [[Global catastrophic risk|global catastrophic risk]] | [[Hinge of history|hinge of history]] | [[EA/Topics/Longtermism|longtermism]] | [[Toby Ord]] | [[Rationality community|rationality community]] | [[Russell–Einstein Manifesto]] | [s-risk](/tag/s-risk)

1.  ^**[^](#fnref0f5x8s34vee)**^
    
    Bostrom, Nick (2012) [Frequently asked questions](https://www.existential-risk.org/faq.html), *Existential Risk: Threats to Humanity’s Future* (updated 2013).
    
2.  ^**[^](#fnrefs39fj4bj7yr)**^
    
    Ord, Toby (2020) [*The Precipice: Existential Risk and the Future of Humanity*](https://en.wikipedia.org/wiki/Special:BookSources/1526600218), London: Bloomsbury Publishing.
    
3.  ^**[^](#fnrefehnudz7v1f)**^
    
    Beckstead, Nick (2013) [*On the Overwhelming Importance of Shaping the Far Future*](http://doi.org/10.7282/T35M649T), PhD thesis, Rutgers University.
    
4.  ^**[^](#fnrefx1zw0p7aful)**^
    
    Bostrom, Nick (2013) [Existential risk prevention as global priority](http://doi.org/10.1111/1758-5899.12002), *Global Policy*, vol. 4, pp. 15–31.
    
5.  ^**[^](#fnrefxep7ip80wm)**^
    
    Greaves, Hilary & William Macaskill (2019) [The case for strong longtermism](https://globalprioritiesinstitute.org/hilary-greaves-william-macaskill-the-case-for-strong-longtermism/), GPI working paper No. 7-2019, Working paper Global Priorities Institute, Oxford University.
    
6.  ^**[^](#fnrefql2k3envp7)**^
    
    Roberts, M. A. (2009) [The nonidentity problem](https://plato.stanford.edu/entries/nonidentity-problem/), *Stanford Encyclopedia of Philosophy*, July 21 (updated 1 December 2020).
    
7.  ^**[^](#fnref52gvr4dqg9p)**^
    
    Ord, Toby (2020) [*The Precipice: Existential Risk and the Future of Humanity*](https://en.wikipedia.org/wiki/Special:BookSources/1-5266-0021-8), London: Bloomsbury Publishing, pp. 280–281.