---
_id: gn5XrdqN4bwix9CT8
title: Astronomical waste
href: https://forum.effectivealtruism.org/tag/astronomical-waste
type: tag
tags:
  - LessWrong
  - Topic
  - Tag
synchedAt: '2022-09-11T14:35:21.297Z'
---
# Astronomical waste

**Astronomical waste** is the loss of potential value resulting from delaying the efficient exploitation of the [[Universe's resources|universe's resources]]. The term and the concept expressed by it were introduced by [[Nick Bostrom]] in a seminal paper.^[\[1\]](#fn50capbten0t)^

The accessible universe is vast, and virtually all of it remains unexploited. The Virgo Supercluster contains \\(10^{13}\\) stars, and the energy of each star could power \\(10^{42}\\) computations per second. The human brain can perform about \\(10^{17}\\) computations per second. Assuming that the morally relevant properties of the brain—such as phenomenal consciousness—supervene on its functional organization, it follows that the universe could support, every second, an amount of value equivalent to that realized in \\(10^{13} \\times 10^{42} \\div 10^{17} = 10^{28}\\) human lives. The moral costs of failing to actualize this potential thus appear to be enormous.

In relative terms, however, the costs may be quite modest. The cosmos has existed for about 10 billion years, so one should not antecedently expect cosmological processes to cause value to decay by more than 1 part in 10 billion or so per year. And the observational evidence appears to be consistent with this prior assessment. The finitude, expansion, and burndown of the universe seem all to be occurring at a slow enough rate as to be in line with the estimate based on the duration of the universe so far.^[\[2\]](#fn38v46w5bueu)^

If the opportunity costs of delaying the exploitation of the universe's resources are so low in relative terms, however large they may be in absolute terms, it follows that such costs are unimportant relative to the costs arising from exposure to [[EA/Topics/Existential risk|existential risk]], which are much higher in comparison. Over the next decade, maybe a billionth of total attainable value will be lost as a result of failing to arrange the universe optimally. Over that same decade, perhaps a thousandth of this value will be lost in expectation from exposure to a 0.1 percent risk of an existential catastrophe. The costs from existential risk exposure thus appear to exceed the opportunity costs from delayed expansion by several orders of magnitude.

Thus, although upon first noticing the astronomical costs of delayed technological development an altruist may be tempted to conclude that such development should be hastened, that conclusion does not survive careful reflection. Because the bulk of existential risk is posed by [[Anthropogenic existential risk|anthropogenic existential risks]] from new technologies, accelerating the development of new technology will itself have major effects on existential risk. Such effects will dwarf any gains from reduction of astronomical waste, and should therefore be the primary consideration for decision making.

A note about terminology
------------------------

Astronomical waste is often cited as a consideration in favor of [[EA/Topics/Longtermism|longtermism]]. When authors talk about "astronomical waste" in these contexts, however, what they typically mean by that phrase are not the costs of delayed expansion, but the costs of failed (or flawed) expansion. Thus, [[Carl Shulman]] mentions "the expected Astronomical Waste if humanity were rendered extinct by a sudden asteroid impact."^[\[3\]](#fn8cmzntaw7z9)^ Similarly, linking to Bostrom's paper, Gwern Branwen writes that "human extinction represents the loss of literally astronomical amounts of utility."^[\[4\]](#fnnwz5spo9tj)^ And Siebe Rozendal writes that "Extinction would be an ‘astronomical waste’."^[\[5\]](#fnvn45cr797ss)^^[\[6\]](#fntew3mbba4k)^ The expression *astronomical stakes*^[\[7\]](#fnd9jw30oybef)^^[\[8\]](#fnlb2an4aje6m)^ may be used to express this idea, while reserving *astronomical waste* to refer to the  opportunity costs of delayed technological development.

Further reading
---------------

Bostrom, Nick (2003) [Astronomical waste: the opportunity cost of delayed technological development](https://doi.org/10.1017/S0953820800004076), *Utilitas*, vol. 15, pp. 308–314.

Christiano, Paul (2013) [Astronomical waste](https://rationalaltruist.com/2013/04/30/astronomical-waste/), *Rational Altruist*, April 30.

Related entries
---------------

[[Differential progress|differential progress]] | [[Ethics of existential risk|ethics of existential risk]] | [[Space colonization|space colonization]] | [[Speeding up development|speeding up development]]

1.  ^**[^](#fnref50capbten0t)**^
    
    Bostrom, Nick (2003) [Astronomical waste: the opportunity cost of delayed technological development](https://doi.org/10.1017/S0953820800004076), *Utilitas*, vol. 15, pp. 308–314.
    
2.  ^**[^](#fnref38v46w5bueu)**^
    
    Christiano, Paul (2013) [Astronomical waste](https://rationalaltruist.com/2013/04/30/astronomical-waste/), *Rational Altruist*, April 30.
    
3.  ^**[^](#fnref8cmzntaw7z9)**^
    
    Shulman, Carl (2012) [Are pain and pleasure equally energy-efficient?](http://reflectivedisequilibrium.blogspot.com/2012/03/are-pain-and-pleasure-equally-energy.html), *Reflective Disequilibrium*, March 24.
    
4.  ^**[^](#fnrefnwz5spo9tj)**^
    
    Branwen, Gwern (2020) [Optimal existential risk reduction investment](https://www.gwern.net/Statistical-notes#optimal-existential-risk-reduction-investment), *Gwern.net*, May 28.
    
5.  ^**[^](#fnrefvn45cr797ss)**^
    
    Rozendal, Siebe (2019) [Eight high-level uncertainties about global catastrophic and existential risk](https://forum.effectivealtruism.org/posts/QjKRBcobCzeeerMbP/eight-high-level-uncertainties-about-global-catastrophic-and), *Effective Altruism Forum*, November 28.
    
6.  ^**[^](#fnreftew3mbba4k)**^
    
    See also Wei Dai (2014) [Is the potential astronomical waste in our universe too small to care about?](https://www.lesswrong.com/posts/BNbxueXEcm6dCkDuk/is-the-potential-astronomical-waste-in-our-universe-too), *LessWrong*, October 21, Gregory Lewis (2018) [The person-affecting value of existential risk reduction](https://forum.effectivealtruism.org/posts/dfiKak8ZPa46N7Np6/the-person-affecting-value-of-existential-risk-reduction), *Effective Altruism Forum*, April 13, and David Kristoffersson (2020) [The ‘far future’ is not just the far future](https://forum.effectivealtruism.org/posts/X5aJKx3f6z5sX2Ji4/the-far-future-is-not-just-the-far-futu), *Effective Altruism Forum*, January 16.
    
7.  ^**[^](#fnrefd9jw30oybef)**^
    
    Bostrom, Nick (2015) [Astronomical stakes](https://www.youtube.com/watch?v=fmQkLKLmfQU), *Effective Altruism Global*, November 25.
    
8.  ^**[^](#fnreflb2an4aje6m)**^
    
    Wiblin, Robert (2016) [Making sense of long-term indirect effects](https://www.effectivealtruism.org/articles/making-sense-of-long-term-indirect-effects-rob-wiblin/), *Effective Altruism*, August 7.