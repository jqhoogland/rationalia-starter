---
_id: hhFr2bWLftFhMQHu9
title: Superintelligence
href: https://forum.effectivealtruism.org/tag/superintelligence
type: tag
tags:
  - LessWrong
  - Topic
  - Tag
synchedAt: '2022-09-11T14:35:14.276Z'
---
# Superintelligence

A **superintelligence** is a cognitive system whose intellectual performance across all relevant domains vastly exceeds that of any human. Forms of superintelligence include [[Quality superintelligence|quality superintelligence]], [[Speed superintelligence|speed superintelligence]] and [[Collective superintelligence|collective superintelligence]].

If a superintelligence comes to exist, it could conceivably be either a machine (created through substantial progress in [[Artificial intelligence|artificial intelligence]]) or a biological entity (created through genetic engineering or other human modification).

Since intelligence is the distinctive trait that has enabled humans to develop a civilization and become the dominant species on Earth, the development of much smarter agents than us would arguably be the most significant event in human history.

While it is difficult to predict, or even to conceive, what a future in which such agents exist would look like, several philosophers and computer scientists have recently argued that the arrival of superintelligence, particularly machine superintelligence, could pose an [[AI risk|existential risk]]. On the other hand, if these risks are avoided, a superintelligence could be greatly beneficial, and might enable many of the world’s problems to be solved.

Further reading
---------------

Bostrom, Nick (2014) [*Superintelligence: Paths, Dangers, Strategies*](https://en.wikipedia.org/wiki/Special:BookSources/9780199678112), Oxford: Oxford University Press.

Related entries
---------------

[[Artificial intelligence|artificial intelligence]] | [[Collective superintelligence|collective superintelligence]] | [[Quality superintelligence|quality superintelligence]] | [[Speed superintelligence|speed superintelligence]]