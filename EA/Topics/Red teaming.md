---
_id: tRqH8tbgwDNpcMyGP
title: Red teaming
href: https://forum.effectivealtruism.org/tag/red-teaming
type: tag
tags:
  - LessWrong
  - Topic
  - Tag
synchedAt: '2022-09-11T14:33:46.148Z'
---
# Red teaming

A **red team** is an independent group that challenges an organization or movement in order to improve it. **Red teaming** is the practice of using red teams.

History of the term
-------------------

The term "red teaming" appears to originate in the United States military. A common exercise was to pitch an offensive "red team", representing the enemy, against a defensive "blue team", representing the U.S. The purpose of the exercise was to identify vulnerabilities and develop effective countermeasures.^[\[1\]](#fn1bt59b23sc2)^ The term was later extended to cover related practices in other fields, including [[Information security|information security]] and intelligence analysis.

Red teaming in effective altruism
---------------------------------

Within [[Effective altruism|effective altruism]], "red teaming" refers to attempts to identify problems or errors in popular or prestigious views held by members of this community, such as views about the value of different causes or organizations.^[\[2\]](#fn6q3xj5z40b7)^

Related concepts include *minimal-trust investigations*,^[\[3\]](#fnv6hony7jd28)^ *epistemic spot-checks*,^[\[4\]](#fnx9lppxl4apk)^ and *hypothetical apostasy*.^[\[5\]](#fn1odprbpu5jp)^

Further reading
---------------

Räuker, Max *et al.* (2022) [Idea: Red-teaming fellowships](https://forum.effectivealtruism.org/posts/obHA95otPtDNSD6MD/idea-red-teaming-fellowships), *Effective Altruism Forum*, February 2.

Vaintrob, Lizka & Fin Moorhouse (2022) [Resource for criticisms and red teaming](https://forum.effectivealtruism.org/posts/uuQDgiJJaswEyyzan/resource-for-criticisms-and-red-teaming), *Effective Altruism Forum*, June 1.

Zhang, Linchuan (2021) [Red teaming papers as an EA training exercise?](https://forum.effectivealtruism.org/posts/myp9Y9qJnpEEWhJF9/linch-s-shortform), *Effective Altruism Forum*, June 22.

Related entries
---------------

[[Criticism of effective altruism|criticism of effective altruism]] | [[Epistemology|epistemology]] | [[Epistemic deference|epistemic deference]] | [[Tabletop exercises|tabletop exercises]]

1.  ^**[^](#fnref1bt59b23sc2)**^
    
    Johnson, Rowland (2015) [How your red team penetration testers can help improve your blue team](https://web.archive.org/web/20160530230034/http://www.scmagazineuk.com/how-your-red-team-penetration-testers-can-help-improve-your-blue-team/article/431023/), *SC Magazine*, August 18.
    
2.  ^**[^](#fnref6q3xj5z40b7)**^
    
    Räuker, Max *et al.* (2022) [Idea: Red-teaming fellowships](https://forum.effectivealtruism.org/posts/obHA95otPtDNSD6MD/idea-red-teaming-fellowships), *Effective Altruism Forum*, February 2.
    
3.  ^**[^](#fnrefv6hony7jd28)**^
    
    Karnofsky, Holden (2021) [Minimal-trust investigations](https://forum.effectivealtruism.org/posts/8RcFQPiza2rvicNqw/minimal-trust-investigations), *Effective Altruism Forum*, November 23.
    
4.  ^**[^](#fnrefx9lppxl4apk)**^
    
    Ravid, Yoav (2020) [Epistemic spot check](https://www.lesswrong.com/tag/epistemic-spot-check), *LessWrong Wiki*, August 7.
    
5.  ^**[^](#fnref1odprbpu5jp)**^
    
    Bostrom, Nick (2009) [Write your hypothetical apostasy](https://www.overcomingbias.com/2009/02/write-your-hypothetical-apostasy.html), *Overcoming Bias*, February 21.