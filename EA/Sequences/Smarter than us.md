---
_id: tEdmXiQSkFW8Yz5Gf
type: sequence
tags:
  - EA
  - Sequence
title: Smarter than us
curatedOrder: null
href: https://forum.effectivealtruism.org/s/tEdmXiQSkFW8Yz5Gf
synchedAt: '2022-09-11T19:52:52.754Z'
status: todo
---

# Smarter Than Us

Transformative artificial intelligence may well be developed this century. If it is, it may begin to make many significant decisions for us, and rapidly accelerate changes like economic growth. Are we set up to deal with this new technology safely?

As we try to think about these and other difficult questions, how should we update our views? Bayes' rule is a theory designed just for this: it can help us to think more clearly about how to think clearly.

# Smarter Than Us

# Introduction

- [[Smarter than us]]

# The Case for Focusing on AI Risk

- [[The case for taking AI seriously as a threat to humanity]]
- [[Why AI alignment could be hard with modern deep learning]]
- [[AI Timelines— Where the Arguments, and the "Experts," Stand]]

# Strategies for Reducing AI Risk

- [[The longtermist AI governance landscape— a basic overview]]
- [[AI Safety researcher career review]]
- [[Long-term AI policy strategy research and implementation]]

# Bayes' Rule and Evidence

- [[Bayes' rule— Guide]]
- [[Making beliefs pay rent]]
- [[What is evidence? ]]

# Suffering Risks

- [[Why s-risks are the worst existential risks, and how to prevent them]]

# More to Explore

- [[More to explore on 'Risks from Artificial Intelligence']]
