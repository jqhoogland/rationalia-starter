---
href: https://rohinshah.com/faq-career-advice-for-ai-alignment-researchers/
---

# Resources

(Alphabetically ordered)

[80,000 Hours Podcast with Daniel Ziegler and Catherine Olsson](https://80000hours.org/podcast/episodes/olsson-and-ziegler-ml-engineering-and-safety/) (and [companion piece](https://80000hours.org/articles/ml-engineering-career-transition-guide/)). Lays out a path by which one can quickly gain the relevant skills and be hired as a research engineer at an industry lab.

[A Survival Guide to a PhD](http://karpathy.github.io/2016/09/07/phd/), Andrej Karpathy. Excellent advice on everything PhD-related. Especially recommended because I expect my readers will not have heard this sort of advice before.

[AI safety starter pack](https://forum.effectivealtruism.org/posts/pbiGHk6AjRxdBPoD8/ai-safety-starter-pack), Marius Hobbhahn. Advice on how to start learning about AI safety, if you’ve already decided that you want to learn.

[Beneficial AI Research Career Advice](https://docs.google.com/document/d/1RFo7_9JVmt0z8RPwUjB-mUMgCMoUQmsaj2CM5aHvxCw/edit#), Adam Gleave. Advice on the stages from “Huh, I hear this AI safety thing is important, I wonder if I should work in it” to getting a job or a PhD in AI safety.

[Concrete Advice for Forming Inside Views on AI Safety](https://www.alignmentforum.org/posts/LbSWMfbAHQnFpApQ7/concrete-advice-for-forming-inside-views-on-ai-safety), Neel Nanda. Besides the concrete advice, there’s also some discussion of why you should care about forming inside views. I disagree with some parts of the post; if you want my take, it’s currently the top comment on the post ([direct link](https://www.alignmentforum.org/posts/LbSWMfbAHQnFpApQ7/concrete-advice-for-forming-inside-views-on-ai-safety?commentId=HfR6cKxskabxmHMCa)).

[Deliberate Grad School](https://acritch.com/deliberate-grad-school/), Andrew Critch. Advice about what to do once you’re in a PhD. It is also somewhat relevant to choosing which university to do a PhD at.

[Film Study for Research](https://jsteinhardt.stat.berkeley.edu/blog/film-study), Jacob Steinhardt. Techniques for building research ability beyond “try it” and “work with a mentor”.

[How to become an AI safety researcher](https://forum.effectivealtruism.org/posts/PH2pqsqgXQkfCdmkv/how-to-become-an-ai-safety-researcher), Peter Barnett. A collection of advice, based on interviews with eleven AI safety researchers. Most of the advice is in a category where I expect it will be useful to some people but not others, so I’d recommend treating it more as a set of plausible ideas to consider implementing rather than advice you should definitely follow.

[How to PhD](https://forum.effectivealtruism.org/posts/B7AQF7HNiLRbKMKJt/how-to-phd), eca. An analysis of the various benefits you can get out of a PhD, and some advice on how to figure out which ones you care about and how to optimize for those benefits in particular.

[How to pursue a career in technical AI alignment](https://forum.effectivealtruism.org/posts/7WXPkpqKGKewAymJf/how-to-pursue-a-career-in-technical-ai-alignment), Charlie Rogers-Smith. Similar to this post, except more detailed and with more advice.

[How to succeed as an early-stage researcher: the “lean startup” approach](https://forum.effectivealtruism.org/posts/jfHPBbYFzCrbdEXXd/how-to-succeed-as-an-early-stage-researcher-the-lean-startup), Toby Shevlane. Argues that you should be lean and nimble when early in your research career, being willing to pivot to a new direction based on feedback from more senior people.

[Leveraging academia](http://acritch.com/leveraging-academia/), Andrew Critch. The core piece of advice here is to learn generic research skills from other areas of academia (which are not as mentorship-bottlenecked), since those form ~90% of the important skills for you to develop. I strongly agree with this piece of advice; I personally learned most of my research skills from three years of a PhD in programming languages. I got very little mentorship from anyone working on existential risk. Related: [this post](https://www.lesswrong.com/posts/7uJnA3XDpTgemRH2c/critch-on-career-advice-for-junior-ai-x-risk-concerned) (meant more for people giving advice).

[Reflections on a PhD](https://vaelsblog.wordpress.com/2021/03/17/reflections-on-a-phd/), Vael Gates. Long (~15K words) reflections on the 5 years of the author’s PhD, focusing on all aspects of their life (not just academia / career). This is not at all optimized for career advice, but I think it’s good for getting the gestalt of what a PhD is like. The PhD parts of their story are somewhat atypical, but not that much — maybe 80th percentile.

[Research as a Stochastic Decision Process](https://docs.google.com/document/d/1KCSXYmInnBrOnFw5y3kQdNluLTYKt-jF1psyviNAeag/edit#), Jacob Steinhardt. Advice on how to prioritize amongst different subtasks when executing on an uncertain project; core idea is to aim to fail fast.

[Research Taste Exercises](http://colah.github.io/notes/taste/), Chris Olah. Ideas on how to build research taste.

[The 5 Year Update on Skipping Grad School (and Whether I’d Recommend It)](https://www.alexirpan.com/2021/04/07/grad-school-5years.html), Alex Irpan. Evaluation of the author’s choice to go to an industry research lab instead of grad school. The industry lab comes out slightly ahead, though I suspect it is quite hard to get the sort of industry job he got.

[The PhD Grind](https://pdf4pro.com/view/the-ph-d-grind-philip-guo-1a9c08.html), Philip Guo. ~100 pages about the author’s PhD experience. The early years sounded to me like one of the worse experiences of a PhD; probably 80% of PhD students have better experiences? Also note that the author worked in a field with different expectations for papers than in AI / ML; in particular most papers in his field are significantly more work than a typical ML paper. Still, the general patterns all rang true to me.

[Want To Be An Expert? Build Deep Models](https://forum.effectivealtruism.org/posts/ckj6Moau9qpYArHWc/want-to-be-an-expert-build-deep-models), Lynette Bye. Argues that in order to have an extraordinary impact, you should spend a significant fraction of your time building a “deep model” of your field. I strongly endorse it (I helped in the creation of this post, and it quotes me in some places).
