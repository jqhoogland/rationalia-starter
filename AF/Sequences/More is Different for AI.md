---
href: https://bounded-regret.ghost.io/more-is-different-for-ai/
---

Two approaches to AI Safety:
1. **Engineering Approach**: empirical, focused on existing issues, bottom-up, anchored to current systems ^9c4149
2. **Philosophical Approach**: thinks about the limits of very advanced systems.

Some agreement: e.g., misaligned objectives are dangerous, out-of-distribution robustness is important

Disagreement elsewhere:
> -   Engineering tends to focus on tasks where current ML systems don't work well, weighted by their impact and representativeness. Philosophy focuses on tasks that have a certain abstract property that seems important, such as [imitative deception](https://arxiv.org/abs/2109.07958).

Jacob's takeaways:
 - **Philosophy is significantly underrated by most ML researchers**.
 - Philosophy continues to significantly underrate the value of empirical data.

# Posts
- [[Future ML Systems will be qualitatively different]]
- [[Thought Experiments Provide a Third Anchor]]
- [[ML Systems Will Have Weird Failure Modes]]
- [[Empirical Findings Generalize Surprisingly Far]]
- [[Appendix— More is Different in Other Domainsi]]