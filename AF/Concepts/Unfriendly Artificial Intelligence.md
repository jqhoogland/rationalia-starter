---
_id: 5f5c37ee1b5cdee568cfb119
title: Unfriendly Artificial Intelligence
href: https://www.lesswrong.com/tag/unfriendly-artificial-intelligence
slug: unfriendly-artificial-intelligence
type: tag
tags:
  - LessWrong
  - Concept
  - Tag
synchedAt: '2022-09-01T09:42:19.667Z'
aliases:
  - Unfriendly AI
  - UFAI
status: todo
---

# Unfriendly Artificial Intelligence

An **Unfriendly artificial intelligence** (or **UFAI**) is an [[Artificial General Intelligence|artificial general intelligence]] capable of causing [[EA/Topics/Existential risk|great harm]] to humanity, and having goals that [make it useful](https://wiki.lesswrong.com/wiki/Instrumental_values) for the AI to do so. The AI's goals don't need to be antagonistic to humanity's goals for it to be Unfriendly; there are [[Instrumental Convergence|strong reasons]] to expect that almost any powerful AGI not explicitly programmed to be benevolent to humans is lethal. A [[Paperclip Maximizer|paperclip maximizer]] is often imagined as an illustrative example of an unFriendly AI indifferent to humanity. An AGI specifically designed to have a positive effect on humanity is called a [Friendly AI](https://wiki.lesswrong.com/wiki/Friendly_AI).

## See Also

- [[Mind Design Space|Mind design space]], [[LW/Concepts/Magical Categories|magical categories]]
- [[Really Powerful Optimization Process|Really powerful optimization process]] (`= [[Really Powerful Optimization Process|Really powerful optimization process]].status`)
- [[Instrumental Convergence|Basic AI drives]] (`= [[Instrumental Convergence|Basic AI drives]].status`)
- [[Paperclip Maximizer|Paperclip maximizer]] (`= [[Paperclip Maximizer|Paperclip maximizer]].status`)
- [[EA/Topics/Existential risk|Existential risk]] (`= [[Existential Risk|Existential risk]].status`)
- [Friendly AI](https://wiki.lesswrong.com/wiki/Friendly_AI)

## References

- Eliezer S. Yudkowsky (2008). "[Artificial Intelligence as a Positive and Negative Factor in Global Risk](https://yudkowsky.net/singularity/ai-risk/)". Global Catastrophic Risks. Oxford University Press. ([PDF](http://intelligence.org/files/AIPosNegFactor.pdf))
- Stephen M. Omohundro (2008). "[The Basic AI Drives](https://selfawaresystems.com/2007/11/30/paper-on-the-basic-ai-drives/)". Frontiers in Artificial Intelligence and Applications (IOS Press). ([PDF](http://selfawaresystems.files.wordpress.com/2008/01/ai_drives_final.pdf))


%%

% START
Basic (and reversed card)
What is **Unfriendly Artificial Intelligence**?
Back: {TODO}
Tags: LessWrong
END

%%
	
