---
_id: 5f5c37ee1b5cdee568cfb297
title: Superintelligence
href: https://www.lesswrong.com/tag/superintelligence
slug: superintelligence
type: tag
tags:
  - LessWrong
  - Concept
  - Tag
synchedAt: '2022-09-01T09:42:21.948Z'
status: todo
---

# Superintelligence

A **Superintelligence** is a being with superhuman intelligence, and a focus of the [[Machine Intelligence Research Institute (MIRI)|Machine Intelligence Research Institute]]'s research. Specifically, Nick Bostrom (1997) defined it as

> "An intellect that is much smarter than the best human brains in practically every field, including scientific creativity, general wisdom and social skills."

^6cd1f4

The [[Machine Intelligence Research Institute (MIRI)|Machine Intelligence Research Institute]] is dedicated to ensuring humanity's safety and prosperity by preparing for the development of an [[Artificial General Intelligence]] with superintelligence. Given its intelligence, it is likely to be [[AI Boxing (Containment)|incapable of being controlled]] by humanity. It is important to prepare early for the development of [[Friendly Artificial Intelligence|friendly artificial intelligence]], as there may be an [[AI Arms Race|AI arms race]]. A strong superintelligence is a term describing a superintelligence which is not designed with the same architecture as the human brain.

An [[Artificial General Intelligence]] will have a number of advantages aiding it in becoming a superintelligence. It can improve the hardware it runs on and obtain better hardware. It will be capable of directly editing its own code. Depending on how easy its code is to modify, it might carry out software improvements that [[Recursive Self-Improvement|spark further improvements]]. Where a task can be accomplished in a repetitive way, a module preforming the task far more efficiently might be developed. Its motivations and preferences can be edited to be more consistent with each other. It will have an indefinite life span, be capable of reproducing, and transfer knowledge, skills, and code among its copies as well as cooperating and communicating with them better than humans do with each other.

The development of superintelligence from humans is another possibility, sometimes termed a weak superintelligence. It may come in the form of [[Whole Brain Emulation|whole brain emulation]], where a human brain is scanned and simulated on a computer. Many of the advantages a AGI has in developing superintelligence apply here as well. The development of [[1 Projects/Rationalia/EA/Topics/Brain-computer interfaces|Brain-computer interfaces]] may also lead to the creation of superintelligence. Biological enhancements such as genetic engineering and the use of nootropics could lead to superintelligence as well.

## Blog Posts

- [Superintelligence](http://www.acceleratingfuture.com/articles/superintelligencehowsoon.htm) by Michael Anissimov

## External Links

- [How long before Superintelligence?](http://www.nickbostrom.com/superintelligence.html) by Nick Bostrom
- [A discussion between Hugo de Garis and Ben Goertzel on superintelligence](http://profhugodegaris.files.wordpress.com/2011/04/nocyborgsbghugo.pdf)
- [Advantages of Artificial Intelligences, Uploads, And Digital Minds](http://www.xuenay.net/Papers/DigitalAdvantages.pdf) by Kaj Sotala

## See Also

- [[1 Projects/Rationalia/EA/Topics/Brain-computer interfaces|Brain-computer interfaces]]
- [[Singularity]]
- [Hard takeoff](https://wiki.lesswrong.com/wiki/Hard_takeoff)


%%

% START
Basic (and reversed card)
What is **Superintelligence**?
Back: {TODO}
Tags: LessWrong
END
<!--ID: 1663157028005-->


%%
	
