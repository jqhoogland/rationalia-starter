---
type: post
href: https://bounded-regret.ghost.io/ml-systems-will-have-weird-failure-modes-2/
---

Example: [[Deceptive Alignment]]

Jacob describes how his initial intuitions about ML being bad at long-term planning & high-level self-awareness primed him against this possibility.

> With AI, we currently lack both Fermi's conceptual understanding of the underlying risk factors and his ability to continuously measure them. We have neither a cadmium rod nor a measure of reaction criticality.