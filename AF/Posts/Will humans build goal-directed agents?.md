---
type: post
_id: 9zpT9dikrrebdq3Jf
title: Will humans build goal-directed agents?
slug: will-humans-build-goal-directed-agents
href: >-
  https://www.lesswrong.com/posts/9zpT9dikrrebdq3Jf/will-humans-build-goal-directed-agents
synchedAt: '2022-09-25T13:46:58.642Z'
tags:
  - Post
  - AI
  - Goal-Directedness
sequence: Value Learning
author: rohinmshah
status: todo
---


### ==Why might we expect goal-directed behavior?==
- Goals allow agents to outperform humans in ways we don't yet know how to. 
- RL is based on goal-directedness.
- Our reference class (humans, animals) are considerably goal-directed (though evolution may be pretty different from SGD).
- Goal-directedness might make interpretability easier (it requires much less information to specify the system's long-term behavior). Shah isn't a fan of this as a reason to build goal-directed agents.

# Related

- [[AI]]
- [[Goal-Directedness]]
- [[Coherence arguments do not entail goal-directed behavior]]
- "[Tool AI vs. Agent AI](http://www.gwern.net/Tool-AI)"
- "[this comment thread](https://www.alignmentforum.org/posts/9zpT9dikrrebdq3Jf/will-humans-build-goal-directed-agents#mjYjBiq4mQosy6Wwt)"
- "[corrigible](https://www.alignmentforum.org/posts/fkLYhTQteAu5SinAc/corrigibility)"
- "[I canâ€™t predict how he will play, but I can predict that he will win](https://www.lesswrong.com/posts/rEDpaTTEzhPLz4fHh/expected-creative-surprises)"