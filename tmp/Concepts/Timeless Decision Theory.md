---
tags: ['LessWrong', 'Portal', 'Concept']
href: https://www.lesswrong.com/tag/timeless-decision-theory
---

Timeless decision theory (TDT) is a [decision theory](https://www.lesswrong.com/tag/decision-theory), [developed by Eliezer Yudkowsky](http://intelligence.org/files/TDT.pdf) which, in slogan form, says that agents should decide as if they are determining the output of the abstract computation that they implement. This theory was developed in response to the view that rationality should be about winning (that is, about agents achieving their desired ends) rather than about behaving in a manner that we would intuitively label as rational. Prominent existing decision theories (including [causal decision theory](https://www.lesswrong.com/tag/causal-decision-theory), or CDT) fail to choose the winning decision in some scenarios and so there is a need to develop a more successful theory.

## 
<more needed>

## TDT and Newcomb's problem
A better sense of the motivations behind, and form of, TDT can be gained by considering a particular decision scenario: [Newcomb's problem](http://lesswrong.com/lw/nc/newcombs_problem_and_regret_of_rationality/). In Newcomb's problem, a superintelligent artificial intelligence, Omega, presents you with a transparent box and an opaque box. The transparent box contains $1000 while the opaque box contains either $1,000,000 or nothing. You are given the choice to either take both boxes (called two-boxing) or just the opaque box (one-boxing). However, things are complicated by the fact that Omega is an almost perfect predictor of human behavior and has filled the opaque box as follows: if Omega predicted that you would one-box, it filled the box with $1,000,000 whereas if Omega predicted that you would two-box it filled it with nothing....[(Read More)]()



---

