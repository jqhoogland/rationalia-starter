---
tags: ['LessWrong', 'Concept']
href: https://www.lesswrong.com/tag/goodhart-s-law
---

# Goodhart’s Law
Goodhart's Law states that when a proxy for some value becomes the target of optimization pressure, the proxy will cease to be a good proxy. One form of Goodhart is demonstrated by the Soviet story of a factory graded on how many shoes they produced (a good proxy for productivity) – they soon began producing a higher number of tiny shoes. Useless, but the numbers look good.

Goodhart's Law is of particular relevance to [[AI|AI Alignment]]. Suppose you have something which is generally a good proxy for "the stuff that humans care about", it would be dangerous to have a powerful AI optimize for the proxy, in accordance with Goodhart's law, the proxy will breakdown.  

## Goodhart Taxonomy
In [Goodhart Taxonomy](https://www.lessestwrong.com/posts/EbFABnst8LsidYs5Y/goodhart-taxonomy), Scott Garrabrant identifies four kinds of Goodharting:...[(Read More)]()

