---
tags: ['LessWrong', 'Portal', 'Concept']
href: https://www.lesswrong.com/tag/really-powerful-optimization-process
---

The term [[1 Projects/Learning/Rationalism/Concepts/Artificial General Intelligence|artificial intelligence]] can have [[Anthropomorphism|anthropomorphic]] connotations. In some contexts, it might be useful to speak of a really powerful optimization process rather than a *superintelligence*. An AI that was nonanthropomorphic and nonsentient could theoretically still be a very powerful device that could drastically affect the future in precise ways.

## Blog posts
- [Dreams of Friendliness](http://lesswrong.com/lw/tj/dreams_of_friendliness/)
- [Aiming at the Target](http://lesswrong.com/lw/v9/aiming_at_the_target/)
- [Efficient Cross-Domain Optimization](http://lesswrong.com/lw/vb/efficient_crossdomain_optimization/)
- [Nonsentient Optimizers](http://lesswrong.com/lw/x5/nonsentient_optimizers/)
- [The Design Space of Minds-in-General](http://lesswrong.com/lw/rm/the_design_space_of_mindsingeneral/)

## 
- [Creature or Technology](http://www.acceleratingfuture.com/steven/?p=227)
-  by 
- [[Steven Kaas]]
- [The Stamp Collecting Device](http://intelligence.org/blog/2007/06/11/the-stamp-collecting-device/)
-  by Nick Hay

## See also
-[[Optimization|Optimization process]]
- , 
-[[Configuration Space|configuration space]]
-[[1 Projects/Learning/Rationalism/Concepts/Artificial General Intelligence|Artificial general intelligence]]
- , 
-[[Singleton|singleton]]
- [[Friendly Artificial Intelligence]]
- [[Anthropomorphism]]
- , 
-[[Alien Values|alien values]]
-[[Evolution As Alien God|Evolution as alien god]]
-[[Complexity of Value|Complexity of value]]



---

